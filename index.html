<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"real-zhangzhe.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Zhangzhe&#39;s Blog">
<meta property="og:url" content="https://real-zhangzhe.github.io/index.html">
<meta property="og:site_name" content="Zhangzhe&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhangzhe">
<meta property="article:tag" content="No mistakes in the tango, not like life.">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://real-zhangzhe.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Zhangzhe's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhangzhe's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">The projection of my life.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/archives/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/12/06/MammothModa2-A-Unified-AR-Diffusion-Framework-for-Multimodal-Understanding-and-Generation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/12/06/MammothModa2-A-Unified-AR-Diffusion-Framework-for-Multimodal-Understanding-and-Generation/" class="post-title-link" itemprop="url">MammothModa2: A Unified AR-Diffusion Framework for Multimodal Understanding and Generation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-12-06 18:25:24" itemprop="dateCreated datePublished" datetime="2025-12-06T18:25:24+08:00">2025-12-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:54:59" itemprop="dateModified" datetime="2025-12-11T13:54:59+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Diffusion/" itemprop="url" rel="index"><span itemprop="name">Diffusion</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/12/06/MammothModa2-A-Unified-AR-Diffusion-Framework-for-Multimodal-Understanding-and-Generation/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/12/06/MammothModa2-A-Unified-AR-Diffusion-Framework-for-Multimodal-Understanding-and-Generation/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2511.18262">https://arxiv.org/pdf/2511.18262</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/bytedance/mammothmoda">https://github.com/bytedance/mammothmoda</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一种多模态理解和生成统一的架构，在 <code>Qwen3-VL-8B</code> 的基础上加入了 <code>generation experts（3B）</code> 和 <code>DiT（2B）</code>，在不牺牲任何多模态理解能力的情况下，实现了生成和理解的统一。</li>
<li>可以解决图文输入图文输出的多模态任务，比如：
<ol>
<li>文生图</li>
<li>图像编辑</li>
<li>多模态理解等</li>
</ol>
</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="1-硬路由混合专家hard-routing-mixture-of-experts"><a class="markdownIt-Anchor" href="#1-硬路由混合专家hard-routing-mixture-of-experts"></a> 1. 硬路由混合专家（Hard-Routing Mixture-of-Experts）</h3>
<ul>
<li>为了增加图像生成能力，<code>Mammothmoda2</code> 在 <code>Qwen3-VL-8B</code> 的内部加入了随即初始化的 <code>generation experts</code></li>
<li>为了不牺牲 <code>pretrain</code> 多模态理解的能力，<code>pretrain</code> 模型的参数和 <code>generation experts</code> 的参数是通过 <strong>硬路由混合专家</strong> 的方式选择 <code>token</code> 的，具体来说就是：<strong>多模态理解的 <code>token</code> 激活原 <code>pretrain</code> 模型的参数（也被叫做 <code>understanding experts</code>），图像生成的 <code>token</code> 激活新增的随机初始化的 <code>generation experts</code></strong></li>
<li>这样做的好处是啥？</li>
</ul>
<p><img src="https://s2.loli.net/2025/12/06/M3icFrKVbC8Skzp.png" alt="mammothmoda.png" /></p>
<ul>
<li>从上图可以看出在 <code>pre-stage 1 / 2</code> 阶段，模型的 <code>backbone</code> 参数是冻结的，也就是说在第三列的 <code>SFT</code> 阶段之前，<code>qwen3-vl-8b</code> 的多模态理解能力是不会受到任何影响的</li>
<li>硬路由混合专家的具体实现方式：
<ol>
<li>每层 <code>transformer</code> 初始化一个新的 <code>ffn</code> 层，被称为 <code>generation experts</code>；原始的 <code>ffn</code> 层叫做 <code>understanding experts</code></li>
<li>为 <code>generation</code> 任务扩展词表和扩展 <code>vocab embedding</code> 参数随机初始化</li>
<li>根据每一个 <code>token</code> 是否属于 <code>generation token</code> 得到一个 <code>gen token mask</code></li>
<li>每一层根据 <code>gen token mask</code> 来为每一个 <code>token</code> 选择是激活哪个 <code>ffn</code></li>
</ol>
</li>
<li>作者通过消融实验对比了 <code>ffn moe</code> / <code>attention moe</code> / <code>ffn-attention moe</code> 以及全层使用和仅深层使用，最终发现 <code>14</code> 层之后用 <code>ffn moe</code> 效果很好</li>
</ul>
<h3 id="2-扩散生成器diffusion-generator"><a class="markdownIt-Anchor" href="#2-扩散生成器diffusion-generator"></a> 2. 扩散生成器（Diffusion Generator）</h3>
<ul>
<li><code>qwen3-vl-8b</code> 作为大脑，<code>DiT</code> 就是画图的手</li>
<li>本文使用了一种单流扩散架构 <code>DiT</code>，将处理后的条件信号和噪声潜变量（由 <code>VAE</code> 编码）作为统一输入（而不是两个输入），通过全序列自注意力机制进行生成</li>
</ul>
<h3 id="3-ar-diffusion-特征对齐模块"><a class="markdownIt-Anchor" href="#3-ar-diffusion-特征对齐模块"></a> 3. AR-Diffusion 特征对齐模块</h3>
<ul>
<li>如果说 <code>Qwen3-VL</code> 是大脑，<code>DiT</code> 是手，那么 <code>AR-Diffusion</code> 特征对齐模块 就是神经系统</li>
<li>总体来说，特征对齐分为三个步骤：
<ol>
<li><strong>多层级特征融合</strong>：不仅仅用 <code>qwen3-vl-8b</code> 的最后一层输出，而是使用了模型深层的多层特征</li>
<li><strong>统一条件编码</strong>：将 <code>backbone</code> 输出的特征重新按照模态拆分，并分别压缩，再用双向 <code>transformer</code> 融合，作为 <code>condition encoding</code></li>
<li><strong>上下文条件注入</strong>：将原图通过 <code>vae</code> 编码为 <code>noise</code>，和 <code>condition encoding</code> 合并作为单流 <code>DiT</code> 的输入</li>
</ol>
</li>
<li>用一个例子说明：图像编辑任务，图像是一只猫，shape = (256, 256, 3)，文本是：“给这只猫戴个红色的帽子”
<ol>
<li>假设图像经过 <code>vit</code> 压缩之后的 <code>token</code> 长度 <code>L_v = 224</code>，文本 <code>token</code> 长度 <code>L_t = 32</code>，总长度 <code>L_seq = 256</code></li>
<li>取 <code>qwen3-vl-8b</code> 后 <code>6</code> 层的特征，每层 <code>shape = (256, 4096)</code>，<code>4096</code> 是 <code>qwen3-vl-8b</code> 的 <code>hidden size</code></li>
<li>对 <code>6</code> 层特征作平均池化 <code>(6, 256, 4096) -&gt; (256, 4096)</code></li>
<li>分离图文特征：<code>(256, 4096) -&gt; (32, 4096) + (224, 4096)</code></li>
<li>文本特征压缩：<code>(32, 4096) -&gt; mlp -&gt; (32, 1024)</code>，<code>1024</code> 是 <code>DiT</code> 的 <code>hidden size</code></li>
<li>图像特征压缩：<code>(224, 4096) -&gt; QFormer -&gt; (64, 4096)</code>，<code>QFormer</code> 可以将任意长度的视觉特征编码成固定长度（<code>64</code>）的特征，做法是用 <code>64</code> 个 <code>query</code> 去 <code>cross attention</code></li>
<li>图文特征重新融合得到 <strong>条件特征</strong> ：文本 <code>(32, 1024)</code> + 视觉 <code>(64, 1024)</code> -&gt; 拼接为 <code>(96, 1024)</code> -&gt; 双向 <code>Transformer</code> 编码  -&gt; 输出 <strong>条件特征</strong> <code>(96, 1024)</code></li>
<li>原图用 <code>vae</code> 压缩为 <strong>噪声潜变量</strong>：<code>(256, 256, 3) -&gt; vae -&gt; (32, 32, 4) -&gt; flatten -&gt; (1024, 4) -&gt; mlp -&gt; (1024, 1024)</code></li>
<li>噪声潜变量和条件特征合并作为单流 <code>DiT</code> 输入：<code>(96, 1024) + (1024, 1024) -&gt; (1120, 1024) -&gt; DiT -&gt; Target Image</code></li>
</ol>
</li>
</ul>
<h3 id="4-训练策略"><a class="markdownIt-Anchor" href="#4-训练策略"></a> 4. 训练策略</h3>
<h4 id="41-预训练"><a class="markdownIt-Anchor" href="#41-预训练"></a> 4.1 预训练</h4>
<p>预训练过程冻结 <code>backbone</code></p>
<ul>
<li>第一阶段：生成基础（<code>Pre-Stage 1</code>）
<ul>
<li>目标：建立文本到图像（<code>T2I</code>）的基础映射关系。</li>
<li>数据：仅使用 <code>T2I</code> 数据，分辨率限制在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>512</mn><mo>×</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">512 \times 512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span></span></span></span>。</li>
<li>策略：<code>DiT</code> <strong>仅接收来自 <code>AR</code> 骨干网的文本特征</strong> 作为条件。此时，生成专家（<code>Generation Experts</code>）和 <code>DiT</code> 参数从零开始训练，而理解参数被冻结。</li>
<li>逻辑：在低分辨率和单一模态条件下，模型更容易收敛，学会基本的物体形状和构图。</li>
</ul>
</li>
<li>第二阶段：复杂指令与编辑（<code>Pre-Stage 2</code>）
<ul>
<li>目标：引入图像编辑能力和高分辨率生成。</li>
<li>数据：引入图像编辑（<code>Image Editing</code>）数据，分辨率提升至 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1024</mn><mo>×</mo><mn>1024</mn></mrow><annotation encoding="application/x-tex">1024 \times 1024</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span></span></span></span>。</li>
<li>策略：<strong><code>DiT</code> 开始接收文本+视觉的双重特征</strong>。此时，模型开始学习如何理解输入图像（例如“把图中的猫变成狗”），并保留原图的背景结构。</li>
<li>关键点：这一阶段是 <code>Mammoth2</code> 区别于普通 <code>T2I</code> 模型的关键，它开始具备“看图改图”的能力。</li>
</ul>
</li>
</ul>
<h4 id="42-sft"><a class="markdownIt-Anchor" href="#42-sft"></a> 4.2 SFT</h4>
<ul>
<li>所有参数都解冻，全部参与更新，通过联合优化，<code>AR</code> 部分学会了生成更适合 <code>DiT</code> 解码的语义规划，而 <code>DiT</code> 也学会了更好地适应 <code>AR</code> 的意图</li>
</ul>
<h4 id="43-rl"><a class="markdownIt-Anchor" href="#43-rl"></a> 4.3 RL</h4>
<ul>
<li><code>Mammoth2</code> 引入了 <code>DiffusionNFT (Negative-aware Fine-Tuning)</code>，这是一种针对流匹配模型的开创性 <code>RL</code> 算法 。</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>为了保留 <code>vlm</code> 模型的能力作了很大的创新，理论上作生成任务的潜力很大</li>
<li>理解和生成统一架构可能是未来发展方向</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/10/26/Structured-3D-Latents-for-Scalable-and-Versatile-3D-Generation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/26/Structured-3D-Latents-for-Scalable-and-Versatile-3D-Generation/" class="post-title-link" itemprop="url">Structured 3D Latents for Scalable and Versatile 3D Generation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-10-26 15:40:10" itemprop="dateCreated datePublished" datetime="2025-10-26T15:40:10+08:00">2025-10-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/3D/" itemprop="url" rel="index"><span itemprop="name">3D</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/10/26/Structured-3D-Latents-for-Scalable-and-Versatile-3D-Generation/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/10/26/Structured-3D-Latents-for-Scalable-and-Versatile-3D-Generation/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.01506">https://arxiv.org/pdf/2412.01506</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/Microsoft/TRELLIS">https://github.com/Microsoft/TRELLIS</a></li>
<li>model: <a target="_blank" rel="noopener" href="https://huggingface.co/microsoft/TRELLIS-text-xlarge">https://huggingface.co/microsoft/TRELLIS-text-xlarge</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一个图/文生 <code>3D</code> 的模型 <code>TRELLIS</code> 和一种 <code>3D</code> 表征方式 <code>SLAT (Structured LATent)</code>，具体来说 <code>SLAT</code> 表征包含两个部分：
<ul>
<li><code>coords</code>: 整数坐标 (N, 4) int32 - [batch, x, y, z]，用于描述 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>6</mn><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">16^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">6</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> <code>voxel</code> 空间下的物体 <strong>表面</strong> 占据的体素坐标</li>
<li><code>feats</code>: 浮点特征 (N, 8) float32 - 8通道特征向量，用于描述每一个激活体素坐标上的特征编码，编码长度为 <code>8</code></li>
</ul>
</li>
<li>关键就是两个 <code>DiT</code> 模型，两个模型的输出结果合并就是 <code>SLAT</code> 表征，两个 <code>DiT</code> 都是使用流匹配范式训练的
<ul>
<li>第一个 <code>DiT</code> 模型从图像/文本特征中得到 <code>3D</code> 物体的表明占据体素坐标，这个模型被称为 <code>SparseStructureFlowModel</code></li>
<li>第二个 <code>DiT</code> 模型从图像/文本特征以及体素占据坐标得到每个激活体素的特征向量，这个模型被称为 <code>ElasticSLatFlowModel</code></li>
</ul>
</li>
<li>模型在 <code>3D</code> 数据集上通过自监督方式训练得到，可从图片或文本得到不同的 <code>3D</code> 输出格式（<code>3D Gaussian、Radiance Field、mesh</code> 等）</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2025/10/22/2CIpe3jnG7q1yVb.png" alt="2025-10-22_12-32.png" /></p>
<h3 id="1-推理过程"><a class="markdownIt-Anchor" href="#1-推理过程"></a> 1. 推理过程</h3>
<ul>
<li>以图片 -&gt; 3D 为例：</li>
</ul>
<pre class="mermaid">flowchart TD
    A[输入图片] --> B[预处理 518x518]
    B --> C[DINOv2编码 Bx1369x1024]
    C --> D[Stage 1: Sparse Structure Flow]
    D --> E[噪声 Bx8x16x16x16]
    E --> F[DiT Transformer 24层]
    C --> F
    F --> G[Sparse Structure Latent Bx8x16x16x16]
    G --> H[Decoder]
    H --> I[稀疏坐标 Nx4]
    I --> J[Stage 2: SLAT Flow]
    J --> K[稀疏噪声 SparseTensor Nx8]
    K --> L[稀疏DiT Transformer 24层]
    C --> L
    L --> M[SLAT表征 SparseTensor Nx8 分辨率64^3]
    M --> N[Gaussian解码器]
    M --> O[Radiance Field解码器]
    M --> P[Mesh解码器]
    N --> Q[3D Gaussians]
    O --> S[Strivect辐射场]
    P --> T[三角网格]</pre>
<h4 id="0-图像预处理"><a class="markdownIt-Anchor" href="#0-图像预处理"></a> 0: 图像预处理</h4>
<ul>
<li>功能：去除背景、裁剪、归一化</li>
<li>输入：原始PIL图像（任意尺寸）</li>
<li>输出：<strong>518×518 RGB图像，带alpha通道</strong></li>
<li>处理步骤：
<ul>
<li>使用 rembg (U2-Net) 去除背景</li>
<li>根据前景内容裁剪并居中</li>
<li>调整大小到 518×518</li>
</ul>
</li>
</ul>
<h4 id="1-图像条件编码"><a class="markdownIt-Anchor" href="#1-图像条件编码"></a> 1: 图像条件编码</h4>
<ul>
<li>模型：DINOv2 ViT-L/14-reg</li>
<li>输入：(B, 3, 518, 518) - 预处理后的图像</li>
<li>输出：<strong>(B, N, 1024)</strong> - 图像特征tokens，其中 N = (518/14)² = 1369（37 x 37）</li>
<li>处理：通过 DINOv2 提取 patch tokens</li>
</ul>
<h4 id="2-稀疏结构生成-stage-1"><a class="markdownIt-Anchor" href="#2-稀疏结构生成-stage-1"></a> 2: 稀疏结构生成 (Stage 1)</h4>
<ul>
<li>模型：SparseStructureFlowModel（DiT）</li>
<li>输入：
<ul>
<li>Noise: (B, 8, 16, 16, 16) - 3D噪声张量</li>
<li>Image condition: (B, 1369, 1024) - DINOv2特征</li>
<li>Timestep: (B,) - Flow matching时间步</li>
</ul>
</li>
<li>处理流程：
<ul>
<li>将3D噪声 patchify（如果patch_size&gt;1）</li>
<li>添加3D位置编码</li>
<li>通过24层 DiT transformer blocks，进行图像条件的交叉注意力</li>
<li>Unpatchify 回3D体积</li>
</ul>
</li>
<li>输出：(B, 8, 16, 16, 16) - 稀疏结构latent</li>
<li>解码到坐标：
<ul>
<li>通过 SparseStructureDecoder 解码为occupancy grid</li>
<li>Resolution: 16³</li>
<li>提取 occupancy &gt; 0 的体素坐标</li>
</ul>
</li>
<li>解码器输出：(B, 1, 16, 16, 16) - occupancy概率</li>
<li>提取坐标：<strong>(N_occupied, 4)</strong> - [batch_idx, x, y, z]，其中 N_occupied 是非空体素数量</li>
</ul>
<h4 id="3-slat-生成-stage-2-核心表征"><a class="markdownIt-Anchor" href="#3-slat-生成-stage-2-核心表征"></a> 3: SLAT 生成 (Stage 2) - 核心表征</h4>
<ul>
<li>模型：ElasticSLatFlowModel</li>
<li>输入：
<ul>
<li>Sparse noise: SparseTensor
<ul>
<li>coords: (N_voxels, 4) - 从Stage 1得到的坐标</li>
<li>feats: (N_voxels, 8) - 随机噪声特征</li>
</ul>
</li>
<li>Image condition: (B, 1369, 1024) - DINOv2特征</li>
<li>Timestep: (B,) - Flow matching时间步</li>
</ul>
</li>
<li>处理流程：
<ul>
<li>通过sparse linear层和下采样ResBlocks处理输入 (2倍下采样)</li>
<li>添加稀疏3D位置编码</li>
<li>通过24层稀疏DiT transformer blocks，带图像交叉注意力</li>
<li>通过上采样ResBlocks和skip connections恢复分辨率</li>
<li>输出层产生8通道特征</li>
</ul>
</li>
<li>输出 - SLAT表征：<strong>SparseTensor</strong>
<ul>
<li>coords: (N_voxels, 4) - [batch_idx, x, y, z]，坐标在64³空间</li>
<li>feats: (N_voxels, 8) - 8通道特征，应用归一化</li>
</ul>
</li>
</ul>
<h4 id="4-slat-解码到多种3d表征"><a class="markdownIt-Anchor" href="#4-slat-解码到多种3d表征"></a> 4: SLAT 解码到多种3D表征</h4>
<ul>
<li>SLAT (Structured Latent) 是TRELLIS的统一3D表征，以稀疏张量格式存储，可以解码为三种不同的3D资产格式：
<ul>
<li>Gaussian Splatting 解码</li>
<li>Radiance Field 解码</li>
<li>Mesh 解码</li>
</ul>
</li>
</ul>
<h3 id="2-训练过程"><a class="markdownIt-Anchor" href="#2-训练过程"></a> 2. 训练过程</h3>
<h4 id="0-数据准备与多视角特征提取"><a class="markdownIt-Anchor" href="#0-数据准备与多视角特征提取"></a> 0. 数据准备与多视角特征提取</h4>
<ul>
<li>输入：
<ul>
<li>3D 资产模型（mesh 或 point cloud）</li>
<li>渲染器生成的多视角 RGB 图像（约 150 views）</li>
<li>每张图的相机姿态（R, t, intrinsics）</li>
</ul>
</li>
<li>过程：
<ul>
<li>使用预训练视觉模型 DINOv2 提取每张图的 patch-level 特征（每张图被切成 37x37 个 patch，每个 patch 提取成 1024 长度的特征向量）；</li>
<li>将 3D 资产 voxel 化（64 x 64 x 64 分辨率）</li>
<li>体素稀疏化，只保留表面区域激活体素，平均每个样本保留 20k 左右的体素；</li>
<li>通过已知相机位姿把这些特征反投影到 3D voxel grid；</li>
<li>在每个 voxel 聚合多视角特征（平均 / max pooling）→ 得到 voxel feature grid f(x, y, z)；</li>
</ul>
</li>
<li>输出：
<ul>
<li>稀疏 3D 特征 (pi, fi) 组成的序列（active voxels），pi 表示体素 i 的位置坐标，fi 表示体素 i 的特征向量</li>
</ul>
</li>
</ul>
<h4 id="1-训练稀疏结构生成模型-sparsestructureflowmodel"><a class="markdownIt-Anchor" href="#1-训练稀疏结构生成模型-sparsestructureflowmodel"></a> 1. 训练稀疏结构生成模型 SparseStructureFlowModel</h4>
<ul>
<li>输入：
<table>
<thead>
<tr>
<th>名称</th>
<th>Shape</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>noise</td>
<td>(B, 8, 16, 16, 16)</td>
<td>初始高斯噪声</td>
</tr>
<tr>
<td>image_feats</td>
<td>(B, 1369, 1024)</td>
<td>DINOv2 提取的图像特征</td>
</tr>
<tr>
<td>t</td>
<td>(B,)</td>
<td>flow matching 时间步</td>
</tr>
</tbody>
</table>
</li>
<li>输出：
<table>
<thead>
<tr>
<th>名称</th>
<th>Shape</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>latent</td>
<td>(B, 8, 16, 16, 16)</td>
<td>生成的体素 latent</td>
</tr>
<tr>
<td>occupancy</td>
<td>(B, 1, 16, 16, 16)</td>
<td>occupancy 概率 (经解码器预测)</td>
</tr>
</tbody>
</table>
</li>
<li>监督信号：监督目标来自 ground-truth occupancy grids（稀疏体素结构），根据 3d 资产可以得到（64 下采样到 16）</li>
</ul>
<h4 id="2-训练-slat-核心生成-elasticslatflowmodel"><a class="markdownIt-Anchor" href="#2-训练-slat-核心生成-elasticslatflowmodel"></a> 2. 训练 SLAT 核心生成 (ElasticSLatFlowModel)</h4>
<ul>
<li>输入：
<table>
<thead>
<tr>
<th>输入</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sparse coords</td>
<td>Stage 1 输出的非空体素坐标</td>
</tr>
<tr>
<td>Sparse feats</td>
<td>随机噪声特征 (8维)</td>
</tr>
<tr>
<td>Image feats</td>
<td>DINOv2 图像特征</td>
</tr>
<tr>
<td>t</td>
<td>时间步，用于 flow matching</td>
</tr>
</tbody>
</table>
</li>
<li>输出：
<table>
<thead>
<tr>
<th>输出</th>
<th>Shape</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>SLAT coords</td>
<td>(N_voxels, 4)</td>
<td>稀疏坐标 (batch,x,y,z)</td>
</tr>
<tr>
<td>SLAT feats</td>
<td>(N_voxels, 8)</td>
<td>稀疏latent特征</td>
</tr>
</tbody>
</table>
</li>
<li>监督信号（SLAT 表征无法直接监督，需要 decode 为 3D 才可以）：
<ul>
<li>多视图渲染监督
<ul>
<li>对每个 3D 资产有多视角图像</li>
<li>SLAT → 解码为 NeRF / Gaussian → 渲染成图像</li>
<li>与真实视图计算重建损失</li>
</ul>
</li>
<li>几何一致性监督：SLAT → 解码为 mesh / occupancy → 与真实 mesh 计算 Chamfer 距离</li>
<li>稀疏特征正则化：约束 latent 特征的分布，促进稀疏性和稳定性</li>
</ul>
</li>
</ul>
<h4 id="3-训练多格式解码器"><a class="markdownIt-Anchor" href="#3-训练多格式解码器"></a> 3. 训练多格式解码器</h4>
<ul>
<li>SLAT 是统一稀疏latent论文中提到它可被解码为三种不同的 3D 资产类型：Gaussian / Radiance Field / Mesh</li>
<li>这三个解码器各自独立训练，共享同一 SLAT latent 空间</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li><code>3D</code> 生成基本都几何结构 + 纹理信息分开训练，都是用 <code>Diffusion</code> 模型在隐空间做，图像 / 文本作为 <code>Diffusion</code> 的 <code>condition</code></li>
<li>生成的 <code>3D</code> 模型 -&gt; 渲染得到某个视角的 <code>2D</code> 图片，和原始 <code>3D</code> 模型对应视角渲染图片做 <code>pixel-level</code> 的损失，是自监督 <code>3D</code> 生成模型绕不开的</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/10/23/EMMA-End-to-End-Multimodal-Model-for-Autonomous-Driving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/23/EMMA-End-to-End-Multimodal-Model-for-Autonomous-Driving/" class="post-title-link" itemprop="url">EMMA: End-to-End Multimodal Model for Autonomous Driving</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-10-23 23:03:44" itemprop="dateCreated datePublished" datetime="2025-10-23T23:03:44+08:00">2025-10-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/VLA/" itemprop="url" rel="index"><span itemprop="name">VLA</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/10/23/EMMA-End-to-End-Multimodal-Model-for-Autonomous-Driving/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/10/23/EMMA-End-to-End-Multimodal-Model-for-Autonomous-Driving/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2410.23262">https://arxiv.org/pdf/2410.23262</a></li>
<li>code（民间实现）:<a target="_blank" rel="noopener" href="https://github.com/taco-group/OpenEMMA/blob/main/README_zh-CN.md">https://github.com/taco-group/OpenEMMA/blob/main/README_zh-CN.md</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>EMMA</code> 是 <code>Waymo</code> 提出的端到端自动驾驶 <code>VLA</code> 模型，不像 <code>RT-1</code> 和 <code>RT-2</code> 模型输出离散化的动作 <code>token</code>，<code>EMMA</code> 的输出是纯文本。</li>
<li>模型架构特别简单，就是一个标准的 <code>VLM（&#123;image, text&#125; -&gt; &#123;text&#125;）</code>，在预训练基础上进行自动驾驶数据和通用多模态数据共训练得到。</li>
<li>纯 <code>VLA</code> 架构，没有除图和文之外的其他任何模态（例如激光雷达、毫米波雷达、高精度地图定位等）。</li>
</ul>
<h2 id="algorithms"><a class="markdownIt-Anchor" href="#algorithms"></a> Algorithms</h2>
<h3 id="核心思想"><a class="markdownIt-Anchor" href="#核心思想"></a> 核心思想</h3>
<ul>
<li>核心思想：<strong>将自动驾驶任务转化为语言建模问题</strong></li>
<li>将所有文本类数据都统一到纯自然语言空间，不做任何的编码，这样所有任务都能在一个“语言空间”中统一表示与训练，利用预训练权重中的语言知识和推理能力。</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>表示方式</th>
</tr>
</thead>
<tbody>
<tr>
<td>视觉输入 (V)</td>
<td>多摄像头拼接图像或视频帧</td>
</tr>
<tr>
<td>非视觉输入 (T)</td>
<td>文本（包括导航意图、历史状态等）</td>
</tr>
<tr>
<td>输出 (O)</td>
<td>文本（轨迹点、3D框、车道线等）</td>
</tr>
</tbody>
</table>
<h3 id="模型架构"><a class="markdownIt-Anchor" href="#模型架构"></a> 模型架构</h3>
<p><img src="https://s2.loli.net/2025/10/23/MRnNyYQIlB4fxgu.png" alt="2025-10-23_21-04.png" /></p>
<h3 id="模型能力"><a class="markdownIt-Anchor" href="#模型能力"></a> 模型能力</h3>
<ul>
<li><code>EMMA</code> 有三大能力：
<ul>
<li>端到端运动规划（E2E Planning）</li>
<li>推理增强 (Chain-of-Thought)</li>
<li>通用多任务（Generalist EMMA）</li>
</ul>
</li>
<li>这三种能力均来自于同一个模型的同一组参数，区别只是 <code>prompt</code> 中描述的任务内容不同。</li>
</ul>
<h4 id="1-端到端运动规划能力"><a class="markdownIt-Anchor" href="#1-端到端运动规划能力"></a> 1. 端到端运动规划能力</h4>
<ul>
<li>输入：
<ul>
<li>视频图像 V（多相机）</li>
<li>高层导航意图 T<sub>intent</sub>（如 “turn left”）</li>
<li>历史自车轨迹 T<sub>ego</sub>（BEV坐标文本序列）</li>
</ul>
</li>
<li>输出：
<ul>
<li>未来轨迹 O<sub>trajectory</sub>：未来 T<sub>f</sub> 个时刻的坐标 {(x<sub>t</sub>, y<sub>t</sub>)}，纯文本形式输出</li>
</ul>
</li>
<li>监督：
<ul>
<li>自监督，仅需未来轨迹真实值（无需人工标注）</li>
<li>无需 HD 地图，无需 LiDAR</li>
</ul>
</li>
</ul>
<h4 id="2-思维链推理增强能力"><a class="markdownIt-Anchor" href="#2-思维链推理增强能力"></a> 2. 思维链推理增强能力</h4>
<ul>
<li>在输出轨迹前，模型生成 4 层“推理文本”，如下</li>
</ul>
<table>
<thead>
<tr>
<th>层级</th>
<th>含义</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>R1</td>
<td>场景描述（天气、路况等）</td>
<td>“It’s sunny and the road is four-lane…”</td>
</tr>
<tr>
<td>R2</td>
<td>关键物体及其坐标</td>
<td>“Pedestrian at [9.01, 3.22], vehicle at [11.58, 0.35]”</td>
</tr>
<tr>
<td>R3</td>
<td>关键物体行为</td>
<td>“The pedestrian looks toward the road and may cross.”</td>
</tr>
<tr>
<td>R4</td>
<td>元驾驶决策</td>
<td>“I should keep my current low speed.”</td>
</tr>
</tbody>
</table>
<ul>
<li>训练标签自动生成：
<ul>
<li>由专家感知模型+启发式算法+Gemini生成描述 → 无需人工标注</li>
</ul>
</li>
<li>效果：
<ul>
<li>CoT 提升规划质量约 6.7%</li>
<li>关键贡献来自 meta-decision (+3.0%) 与关键对象识别 (+1.5%)</li>
</ul>
</li>
</ul>
<h4 id="3-通用多任务"><a class="markdownIt-Anchor" href="#3-通用多任务"></a> 3. 通用多任务</h4>
<p><img src="https://s2.loli.net/2025/10/23/l6CvMDwVFIHrRQZ.png" alt="2025-10-23_22-59.png" /></p>
<h3 id="模型表现"><a class="markdownIt-Anchor" href="#模型表现"></a> 模型表现</h3>
<ul>
<li>一句话概括：在所有任务上，超越所有 SOTA</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>和某车企复杂晦涩的 <code>VLA</code> 框架相比，<code>EMMA</code> 简直太优雅了，没有复杂的设计，统一框架上解决所有自动驾驶问题</li>
<li>如果只做端到端，甚至不需要数据标注，只需要把驾驶数据的数量和质量堆上去就行</li>
<li>可以只输出感知结果，也可以端到端，甚至 <code>CoT</code> 还可以做到白盒端到端，太雅了…</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/10/23/RT-2-Vision-Language-Action-Models-Transfer-Web-Knowledge-to-Robotic-Control/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/23/RT-2-Vision-Language-Action-Models-Transfer-Web-Knowledge-to-Robotic-Control/" class="post-title-link" itemprop="url">RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-10-23 13:35:09" itemprop="dateCreated datePublished" datetime="2025-10-23T13:35:09+08:00">2025-10-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/VLA/" itemprop="url" rel="index"><span itemprop="name">VLA</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/10/23/RT-2-Vision-Language-Action-Models-Transfer-Web-Knowledge-to-Robotic-Control/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/10/23/RT-2-Vision-Language-Action-Models-Transfer-Web-Knowledge-to-Robotic-Control/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2307.15818">https://arxiv.org/pdf/2307.15818</a></li>
<li>homepage: <a target="_blank" rel="noopener" href="https://robotics-transformer2.github.io/">https://robotics-transformer2.github.io/</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文算是第一个真正意义上的 <code>VLA</code> 模型，和 <code>RT-1</code> 相比，有两个显著特征：
<ul>
<li>使用了大量互联网的 <code>VL</code> 数据和 <code>Robotic</code> 数据混合训练做 <code>co-fine-tuning</code></li>
<li>模型更大了，<code>5 - 55B</code> 规模参数量，且 <code>co-fine-tuning</code> 的起点模型就是在互联网数据上训练收敛的模型</li>
</ul>
</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="rt-1-的意义是什么"><a class="markdownIt-Anchor" href="#rt-1-的意义是什么"></a> RT-1 的意义是什么？</h3>
<ul>
<li><code>RT-1</code> 最主要的意义是证明了：<strong>将机器人控制信号离散化为动作 token，用 transformer 架构直接预测是可行的</strong></li>
<li>既然架构是可行的，那就顺其自然做 <code>scaling</code>（放大数据量和参数量）</li>
</ul>
<h3 id="rt-2-做了什么"><a class="markdownIt-Anchor" href="#rt-2-做了什么"></a> RT-2 做了什么？</h3>
<h4 id="1-起点是个-vlm"><a class="markdownIt-Anchor" href="#1-起点是个-vlm"></a> 1. 起点是个 <code>VLM</code></h4>
<ul>
<li><code>RT-2</code> 分别用了谷歌自家的 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.03378"><code>PaLM-E</code></a> 和 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.18565"><code>PaLI-X</code></a> 两个多模态模型做为起点模型，两个模型都是单独使用的</li>
<li>二者都是 <code>ViT</code> + <code>LLM</code> 架构，且都是 <code>&#123;image, text&#125; -&gt; &#123;text&#125;</code> 范式</li>
</ul>
<h4 id="2-统一-vl-和-robotic-数据格式"><a class="markdownIt-Anchor" href="#2-统一-vl-和-robotic-数据格式"></a> 2. 统一 <code>VL</code> 和 <code>Robotic</code> 数据格式</h4>
<p><img src="https://s2.loli.net/2025/10/23/ECQhyBfqJHmnMpu.png" alt="2025-10-23_13-47.png" /></p>
<ul>
<li>方法和 <code>RT-1</code> 一样，将机器人动作信号离散化，并编码成动作 <code>token</code></li>
<li>具体来说：
<ul>
<li>8-DoF 动作空间：6 个自由度（位置 + 旋转）+ 手爪开合 + “终止”标志</li>
<li>每个连续维度被离散化为 256 个 bin</li>
<li>每个 bin 对应一个 token</li>
</ul>
</li>
<li>将 VLM 已有的 tokens 与这 256 个离散量联系起来，才能实现 VLM 到 VLA 的转换</li>
<li>PaLI-X 和 PaLM-E 使用不同的 tokenization 方法，action tokens 需要与分别与其保持一致：
<ul>
<li>PaLI-X：1000 以内的每个数字都有一个相应的token，因此只需将 256 个离散量等于 256 个整数即可</li>
<li>PaLM-E：将最少出现的 256 个 tokens 覆盖掉，分别对应 256 个离散量</li>
</ul>
</li>
</ul>
<h4 id="3-混合数据集"><a class="markdownIt-Anchor" href="#3-混合数据集"></a> 3. 混合数据集</h4>
<ul>
<li>vision-language datasets：来源于 PaLI-x 和 Palm-e 所使用的数据集，数据包括：
<ul>
<li>VQA: visual question answering</li>
<li>Captioning</li>
<li>unstructured interwoven image and text examples</li>
<li>PaLI数据集（WebLI）大小：10B images and covering over 109 anguages</li>
<li>Palm-e 使用多个数据集联合训练，其中 WebLI 占比52.4%</li>
</ul>
</li>
<li>robotics dataset：RT1 dataset（13个机器人，17个月收集得到的数据）</li>
<li>混合方式：co-fine-tuning 过程中，对数据做加权
<ul>
<li>RT-2-PaLI-X 中 robotics 数据占 50%</li>
<li>RT-2-PaLM-E 中 robotics 数据占 66%</li>
</ul>
</li>
</ul>
<h3 id="泛化能力如何"><a class="markdownIt-Anchor" href="#泛化能力如何"></a> 泛化能力如何？</h3>
<h4 id="1-在没见过的物体-背景-环境下的泛化能力"><a class="markdownIt-Anchor" href="#1-在没见过的物体-背景-环境下的泛化能力"></a> 1. 在没见过的物体、背景、环境下的泛化能力</h4>
<p><img src="https://s2.loli.net/2025/10/23/TPYNc6nqD7myfRa.png" alt="2025-10-23_14-08.png" /></p>
<p><img src="https://s2.loli.net/2025/10/23/DaA2fvdMVH8Rnt9.png" alt="2025-10-23_14-09.png" /></p>
<blockquote>
<p>在同场景下，<code>RT-2</code> 和 <code>RT-1</code> 差别很小，在没见过的物体、背景、环境下，<code>RT-2</code> 遥遥领先</p>
</blockquote>
<h4 id="2-涌现能力"><a class="markdownIt-Anchor" href="#2-涌现能力"></a> 2. 涌现能力</h4>
<p><img src="https://s2.loli.net/2025/10/23/DF2E7lbqNSteBMk.png" alt="2025-10-23_14-19.png" /></p>
<h4 id="3-cot-能力"><a class="markdownIt-Anchor" href="#3-cot-能力"></a> 3. CoT 能力</h4>
<ul>
<li>在 <code>robotic</code> 数据的动作 <code>token</code> 之前，加入 <code>resoning token</code>，会提高模型解决问题的能力</li>
</ul>
<p><img src="https://s2.loli.net/2025/10/23/DijR85NzHchZFQO.png" alt="2025-10-23_14-20.png" /></p>
<blockquote>
<p><code>resoning</code> 即图中的 <code>plan</code> 部分</p>
</blockquote>
<h3 id="局限性和展望"><a class="markdownIt-Anchor" href="#局限性和展望"></a> 局限性和展望</h3>
<ul>
<li>局限：
<ul>
<li>物理技能仍局限于机器人数据分布（无法生成全新动作）。</li>
<li>推理频率低，云端计算成本高。</li>
</ul>
</li>
<li>未来方向：
<ul>
<li>结合人类视频学习新技能；</li>
<li>模型量化与蒸馏以提升实时性；</li>
<li>更多开源 VLM 融合（如 LLaVA、InternVL 等）。</li>
</ul>
</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>很有趣的工作，ppl 非常简单，引领了之后 <code>VLA</code> 的发展</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/10/08/Unsupervised-Domain-Adaptation-by-Backpropagation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/08/Unsupervised-Domain-Adaptation-by-Backpropagation/" class="post-title-link" itemprop="url">Unsupervised Domain Adaptation by Backpropagation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-10-08 17:08:05" itemprop="dateCreated datePublished" datetime="2025-10-08T17:08:05+08:00">2025-10-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Adversarial-learning/" itemprop="url" rel="index"><span itemprop="name">Adversarial learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/10/08/Unsupervised-Domain-Adaptation-by-Backpropagation/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/10/08/Unsupervised-Domain-Adaptation-by-Backpropagation/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.7495">https://arxiv.org/pdf/1409.7495</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/tadeephuy/GradientReversal">https://github.com/tadeephuy/GradientReversal</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文的标题很直白《通过反向传播进行无监督领域自适应》，目标是实现无监督领域自适应。</li>
<li>提出了梯度反转层 (<code>Gradient Reversal Layer, GRL</code>)，用于无监督领域自适应任务中，通过在特征提取器和领域分类器之间插入 <code>GRL</code>，实现特征提取器在训练过程中 <strong>最大化</strong> 领域分类器的损失，从而通过对抗学习到领域不变的特征表示。</li>
<li>和 <code>GAN</code> 的思想有些类似，不过 <code>GAN</code> 的目标是生成，<code>GRL</code> 的目标是表征。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="什么是无监督领域自适应"><a class="markdownIt-Anchor" href="#什么是无监督领域自适应"></a> 什么是无监督领域自适应</h3>
<ul>
<li>领域自适应 (<code>Domain Adaptation</code>) 是迁移学习 (<code>Transfer Learning</code>) 的核心问题之一，旨在将从源领域 (<code>Source Domain</code>) 学习到的知识迁移到目标领域 (<code>Target Domain</code>)。<br />
<img src="https://s2.loli.net/2025/10/08/Talm9JFgyIc3UAr.png" alt="GRL_1.png" /></li>
<li>比如上图所示，有一批 <code>MNIST</code> 黑底白字的手写数字识别数据集，包含图像和标签，作为源领域；还有一批背景和字体颜色都随机的 <code>MNIST-M</code> 手写数字识别数据集，只有图像没有标签，作为目标领域。</li>
<li><strong>目标是利用源领域的有标签数据训练一个分类器，并使其在目标领域上也能有较好的性能。</strong></li>
</ul>
<h3 id="如何实现无监督领域自适应"><a class="markdownIt-Anchor" href="#如何实现无监督领域自适应"></a> 如何实现无监督领域自适应</h3>
<ul>
<li>最直接的方法：在源领域数据上训练，直接迁移到目标领域。但效果显然会很差，因为两个领域的数据分布差异较大。</li>
<li>本文提出的方法：通过对抗训练学习领域不变的特征表示。<br />
<img src="https://s2.loli.net/2025/10/08/zKhN4j2TOunU9Vd.png" alt="GRL_2.png" /></li>
<li>模型分成三个部分：
<ul>
<li>特征提取器 (<code>Feature Extractor, G_f</code>): 提取输入数据的特征表示，上图绿色部分。</li>
<li>标签分类器 (<code>Label Classifier, G_y</code>): 根据特征表示预测标签，上图蓝色部分。</li>
<li>领域分类器 (<code>Domain Classifier, G_d</code>): 根据特征表示预测数据来自哪个领域（源领域或目标领域），上图红色部分。</li>
</ul>
</li>
<li>训练目标：
<ul>
<li>最小化标签分类器的损失，使其在源领域数据上表现良好。</li>
<li><strong>最大化</strong>（注意这里是最大化，不是最小化）领域分类器的损失，使特征提取器学习到领域不变的特征表示。</li>
</ul>
</li>
<li>损失函数：
<ul>
<li>标签分类器只对源领域数据计算交叉熵损失 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">L_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li>领域分类器对源领域和目标领域数据都计算交叉熵损失 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">L_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li>两个损失直接求和就是总损失 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>L</mi><mi>y</mi></msub><mo>+</mo><msub><mi>L</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">L=L_y + L_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（一定要注意这里没有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>λ</mi></mrow><annotation encoding="application/x-tex">-\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord mathnormal">λ</span></span></span></span>，别被论文带沟里去）。</li>
</ul>
</li>
<li>梯度反转层 (<code>Gradient Reversal Layer, GRL</code>) 如何起作用：
<ul>
<li>位置：插入在特征提取器和领域分类器之间。</li>
<li>前向传播：<code>GRL</code> 不改变输入，直接将特征传递给领域分类器。</li>
<li>反向传播：<code>GRL</code> 将从领域分类器传回的梯度乘以一个负的常数 <code>-λ</code>，使得特征提取器在更新时朝着最大化领域分类器损失的方向调整参数。</li>
</ul>
</li>
<li>梯度反转层的数学表达（设输入特征为 <code>x</code>，<code>GRL</code> 的输出为 <code>y</code>）：
<ul>
<li>前向传播：<code>y = x</code></li>
<li>反向传播：<code>dL/dx = -λ * dL/dy</code></li>
</ul>
</li>
<li>梯度反转层的 <code>PyTorch</code> 实现：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Function</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GradientReversal</span>(<span class="params">Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">ctx, x, alpha</span>):</span></span><br><span class="line">        ctx.save_for_backward(x, alpha)</span><br><span class="line">        <span class="comment"># 啥都不做，透传</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span></span><br><span class="line">        grad_input = <span class="literal">None</span></span><br><span class="line">        _, alpha = ctx.saved_tensors</span><br><span class="line">        <span class="keyword">if</span> ctx.needs_input_grad[<span class="number">0</span>]:</span><br><span class="line">            <span class="comment"># 梯度乘以 -alpha 实现反转</span></span><br><span class="line">            grad_input = -alpha * grad_output</span><br><span class="line">        <span class="keyword">return</span> grad_input, <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span></span></span></span> 的调节：从 <code>0</code> 逐渐增加到 <code>1</code>，意义：
<ul>
<li>训练初期，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>，模型主要关注源领域的标签分类任务，确保分类器能学到有用的特征。</li>
<li>随着训练进行，逐渐增加 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span></span></span></span>，模型开始更多地关注领域分类器的对抗任务，促使特征提取器学习到领域不变的特征表示。</li>
</ul>
</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>很有趣的对抗学习设计，很简单但很有效。</li>
<li>本质就是让领域分类器掌握的领域分类知识泄露给特征提取器，从而让特征提取器不断调整自己提取的特征，使得领域分类器无法区分源领域和目标领域的数据。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/09/24/IndexTTS2-A-Breakthrough-in-Emotionally-Expressive-and-Duration-Controlled-Auto-Regressive-Zero-Shot-Text-to-Speech/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/24/IndexTTS2-A-Breakthrough-in-Emotionally-Expressive-and-Duration-Controlled-Auto-Regressive-Zero-Shot-Text-to-Speech/" class="post-title-link" itemprop="url">IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-24 22:46:52" itemprop="dateCreated datePublished" datetime="2025-09-24T22:46:52+08:00">2025-09-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TTS/" itemprop="url" rel="index"><span itemprop="name">TTS</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/09/24/IndexTTS2-A-Breakthrough-in-Emotionally-Expressive-and-Duration-Controlled-Auto-Regressive-Zero-Shot-Text-to-Speech/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/09/24/IndexTTS2-A-Breakthrough-in-Emotionally-Expressive-and-Duration-Controlled-Auto-Regressive-Zero-Shot-Text-to-Speech/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.21619">https://arxiv.org/pdf/2506.21619</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/index-tts/index-tts">https://github.com/index-tts/index-tts</a></li>
<li>demo: <a target="_blank" rel="noopener" href="https://index-tts.github.io/index-tts2.github.io">https://index-tts.github.io/index-tts2.github.io</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>IndexTTS2</code> 是 <code>BiliBili</code> 提出的一种 <code>TTS</code> 模型，有如下几个特点：
<ul>
<li><strong>情感表达</strong>：能够生成具有特定情感的语音，如快乐、悲伤、愤怒等。</li>
<li><strong>时长控制</strong>：可以通过输入一个数字来精确控制生成语音的时长。</li>
<li><strong>零样本学习</strong>：无需针对特定说话人进行训练，能够适应新的说话人（常见的 <code>TTS</code> 只提供少量的说话人音色供选择，<code>IndexTTS2</code> 可以适配任何给定样本的音色）。</li>
<li><strong>自回归生成</strong>：通过逐步生成语音帧，提升了语音的自然度和连贯性。</li>
</ul>
</li>
<li><code>IndexTTS2</code> 的输入：
<ul>
<li>源文本 (<code>Source Text</code>)：需要转换为语音的文字。</li>
<li>音色提示 (<code>Timbre Prompt</code>)：一小段目标说话人的音频，用于提取“音色”特征，决定了合成语音“像谁”。</li>
<li>风格提示 (<code>Style Prompt</code>)：一小段带有特定情感的音频，用于提取“情感”特征，决定了合成语音的“情绪”。</li>
<li>语音 Token 数量 (<code>Speech Token Num</code>)（可选）：一个数字，用于精确控制生成语音的时长。</li>
</ul>
</li>
<li><code>IndexTTS2</code> 的输出：目标语音 (<code>Target Speech</code>)：最终合成的音频波形文件。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="0-基础知识"><a class="markdownIt-Anchor" href="#0-基础知识"></a> 0. 基础知识</h3>
<h4 id="01-语音的表示方法"><a class="markdownIt-Anchor" href="#01-语音的表示方法"></a> 0.1 语音的表示方法</h4>
<ul>
<li><strong>连续表示：声音的物理基础</strong>
<ul>
<li><strong>数字波形</strong>：数字波形（<code>Digital Waveform</code>）是语音最直接、最基础的表示形式。它是通过对连续的模拟声波进行“采样”（<code>Sampling</code>）得到的。采样过程以固定的时间间隔（由采样率决定，如 <code>16000 Hz</code> 或 <code>24000 Hz</code>）测量声波的振幅，从而将连续的信号转换为一个离散的数值序列。这个序列在时间维度上描绘了声音振幅的变化，因此也被称为声音的时域（<code>time domain</code>）表示。</li>
<li><strong>梅尔频谱图</strong>：为了解决波形表示的难题，研究者们借鉴了人类听觉系统的特性，提出了一种更高效、更符合感知的表示方法——梅尔频谱图（<code>Mel-Spectrogram</code>）。它是一种时频（<code>time-frequency</code>）表示，描绘了语音信号的能量如何随时间和频率变化。其生成过程大致如下：
<ul>
<li><strong>分帧与加窗</strong>：将长段的音频波形切分成许多短暂的、有重叠的“帧”（<code>frame</code>），并对每一帧应用一个窗函数。</li>
<li><strong>傅里叶变换</strong>：对每一帧进行短时傅里叶变换（<code>STFT</code>），得到其频谱，即能量在不同频率上的分布。</li>
<li><strong>梅尔尺度映射</strong>：将频谱的频率轴从线性的赫兹（<code>Hz</code>）尺度，映射到梅尔（<code>Mel</code>）尺度。梅尔尺度是一种非线性尺度，它模拟了人耳对频率的感知特性——人耳对低频声音的变化比对高频声音的变化更敏感。</li>
<li><strong>能量取对数</strong>：最后，通常会对能量值取对数，使其更符合人类对音量大小的感知。</li>
</ul>
</li>
</ul>
</li>
<li><strong>离散表示：现代语音模型的通用语言</strong>
<ul>
<li>随着自监督学习（<code>Self-Supervised Learning, SSL</code>）的兴起，语音表示领域迎来了第二次、也是更深刻的一次抽象革命：将连续的语音特征离散化为一系列符号，即“语音令牌”（<code>Speech Tokens</code>）。</li>
<li>离散化，或称之为令牌化（<code>Tokenization</code>），是指将连续的高维语音特征向量，映射到一个有限的、离散的符号集合（称为“码本”或“<code>codebook</code>”）中的过程。这个过程通常通过矢量量化（<code>Vector Quantization, VQ</code>）技术实现，例如使用 <code>k-means</code> 聚类算法，将海量语音特征向量聚类成有限个簇，每个簇的中心点就成为了码本中的一个符号（或称为令牌）。</li>
<li>语义令牌（<code>Semantic Tokens</code>）：这类令牌旨在捕捉语音的语言学内容，即“说了什么”。它们通常是从大规模自监督学习模型（如<code>HuBERT, WavLM</code>）的中间层特征中提取并聚类得到的。这些 <code>SSL</code> 模型在训练时被要求完成与语音内容相关的任务（如掩码预测），因此其学到的特征富含语义信息，并且在很大程度上与说话人的音色、韵律、口音等无关。</li>
<li>声学令牌（<code>Acoustic Tokens</code>）：这类令牌旨在捕捉语音的声学属性，即“听起来怎么样”，包括音色、韵律、音高等信息。它们通常由神经音频编解码器（<code>Neural Audio Codec</code>，如 <code>EnCodec</code>）学习得到。这类模型的训练目标是能够从令牌中高质量地重建原始音频波形，因此令牌必须编码足够丰富的声学细节。</li>
</ul>
</li>
</ul>
<h4 id="02-现代-tts-模型的架构"><a class="markdownIt-Anchor" href="#02-现代-tts-模型的架构"></a> 0.2 现代 TTS 模型的架构</h4>
<ul>
<li><strong>端到端流派</strong>：输入为文本，输出为波形，中间不做监督。
<ul>
<li>代表模型为 <code>Char2Wav</code></li>
<li>缺点：因为原始音频波形的时间分辨率极高（例如，每秒 <code>24000</code> 个采样点），直接建模非常困难。因此难度高、效果差。</li>
</ul>
</li>
<li><strong>两阶段流派</strong>：
<ul>
<li>将模型拆分成两个阶段：
<ul>
<li>一个声学模型（如 <code>Tacotron 2</code>），负责将文本转换为梅尔频谱图这种低维度的声学表示。</li>
<li>一个神经声码器（如 <code>WaveNet, WaveGlow</code>），负责将梅尔频谱图高质量地转换为最终的音频波形。</li>
</ul>
</li>
<li>缺点：如果想在声学模型中加入更多的控制条件（如情感、时长等），会使得声学模型的输入变得非常复杂，难以训练。</li>
</ul>
</li>
<li><strong>三阶段流派</strong>：
<ul>
<li>在二阶段的基础上，将声学模型继续拆分成两个子模块：
<ul>
<li>如文本到语义（<code>Text-to-Semantic, T2S</code>）</li>
<li>语义表示到声学表示（如语义令牌到梅尔频谱图，<code>Semantic-to-Mel, S2M</code>）</li>
</ul>
</li>
<li>这种三阶段的设计，方便在语义之外加入更多的控制条件（如音色、情感、时长等），并且每个子模块的任务相对单一，易于训练。</li>
</ul>
</li>
</ul>
<h3 id="1-indextts2-的架构"><a class="markdownIt-Anchor" href="#1-indextts2-的架构"></a> 1. IndexTTS2 的架构</h3>
<p><img src="https://s2.loli.net/2025/10/08/IOEtzhljA3BkP4q.png" alt="indextts2_1.png" /></p>
<ul>
<li>主要由三部分组成：
<ul>
<li><code>Text-to-Semantic</code> (<code>T2S</code>)：
<ul>
<li>输入：
<ul>
<li>文本（待合成的文字）</li>
<li><code>Timbre Prompt</code>（说话人参考音频）</li>
<li><code>Style Prompt</code>（情感参考音频）</li>
<li>可选的 <code>Duration</code> 控制（语义 <code>token</code> 序列长度）</li>
</ul>
</li>
<li>输出
<ul>
<li>语义 <code>token</code>（<code>semantic tokens</code>）</li>
</ul>
</li>
</ul>
</li>
<li><code>Semantic-to-Mel</code> (<code>S2M</code>)：一个基于 <code>flow-matching</code> 的非自回归模型
<ul>
<li>输入：
<ul>
<li>语义 <code>token</code>（<code>semantic tokens</code>）</li>
<li>说话人提示 (音色，<code>timbre prompt</code>)</li>
</ul>
</li>
<li>输出：<code>Mel</code> 频谱图</li>
</ul>
</li>
<li><code>Vocoder</code> (<code>BigVGANv2</code>)：把 <code>Mel</code> 频谱解码成最终的音频波形</li>
</ul>
</li>
</ul>
<h3 id="2-text-to-semantic-详解"><a class="markdownIt-Anchor" href="#2-text-to-semantic-详解"></a> 2. <code>Text-to-Semantic</code> 详解</h3>
<p><img src="https://s2.loli.net/2025/10/08/An4bjB7RWSVxrmw.png" alt="indextts2_2.png" /></p>
<ul>
<li>这个模块是模型的核心，采用自回归的 <code>Transformer</code> 架构，负责将文本和其他条件信息转换为中间的语义表征（<code>Semantic Tokens</code>）。</li>
<li>输入:
<ul>
<li>文本序列 (<code>Text</code>): 经过分词器处理后的文本嵌入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">E_{text}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li>说话人音色提示 (<code>Timbre Prompt</code>): 一段音频，通过预训练的 Speaker Perceiver Conditioner 提取为说话人特征向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span>。</li>
<li>情感风格提示 (<code>Style Prompt</code>): 一段音频，通过 <code>Emotion Perceiver Conditioner</code> 提取为情感嵌入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">e</span></span></span></span>。</li>
<li>时长控制信号 (<code>Speech Token Num</code>): 一个可选的数字，指定希望生成的语义令牌数量，被转换为时长嵌入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>。如果不指定，则用于自由生成。</li>
</ul>
</li>
<li>输出：
<ul>
<li>语义令牌序列 (<code>Semantic Tokens</code>): 模型预测出的语义令牌序列。</li>
<li><code>GPT</code> 隐层状态 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mrow><mi>G</mi><mi>P</mi><mi>T</mi></mrow></msub></mrow><annotation encoding="application/x-tex">H_{GPT}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>): <code>T2S</code> 模块最后一个 <code>Transformer</code> 层的输出，包含了丰富的文本和上下文信息，会作为增强特征送入后续的 <code>S2M</code> 模块。</li>
</ul>
</li>
<li>监督信号：基准语音 (<code>Ground-Truth Speech</code>)。将基准语音通过语义编码器 (<code>Semantic Codec</code>) 转换成真实的语义令牌序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><mi>s</mi><mi>e</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">E_{sem}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li>损失函数：交叉熵损失</li>
<li>技巧：使用 <code>GRL + speaker classifier</code>，对抗训练，避免 <code>style</code> 携带 <code>timbre</code> 信息</li>
</ul>
<h3 id="3-semantic-to-mel-详解"><a class="markdownIt-Anchor" href="#3-semantic-to-mel-详解"></a> 3. <code>Semantic-to-Mel</code> 详解</h3>
<p><img src="https://s2.loli.net/2025/10/08/BVyDCqNMn8p6odG.png" alt="indextts2_3.png" /></p>
<ul>
<li>该模块基于流匹配 (<code>Flow Matching</code>) 的非自回归框架，负责将 <code>T2S</code> 生成的语义令牌序列合成为梅尔频谱图。</li>
<li>输入:
<ul>
<li>语义令牌 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>s</mi><mi>e</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{sem}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>): 来自 <code>T2S</code> 模块的输出。</li>
<li><code>GPT</code> 隐层状态 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mrow><mi>G</mi><mi>P</mi><mi>T</mi></mrow></msub></mrow><annotation encoding="application/x-tex">H_{GPT}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>): 来自 <code>T2S</code> 模块的输出，用于增强语义信息。这两者会通过一个 <code>MLP</code> 以 <code>50%</code> 的概率进行随机融合，形成最终的语义表征 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>f</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{fin}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li>说话人嵌入 (<code>Speaker Embedding</code>): 从音色提示音频中提取的说话人特征，以保证音色的一致性。</li>
<li>提示梅尔频谱 (<code>Prompt Mel-spectrograms</code>): 训练时，输入音频会被随机切分为提示段和目标段，提示段的梅尔频谱作为参考。</li>
</ul>
</li>
<li>输出：目标梅尔频谱图 (<code>Target Mel Spectrogram</code>)</li>
<li>训练方式：模型学习一个常微分方程 (<code>ODE</code>)，将高斯噪声映射到目标梅尔频谱。训练时，目标段的真实梅尔频谱被完全加噪，模型需要学习去噪并重建它。</li>
<li>监督信号：目标段的真实梅尔频谱图 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>t</mi><mi>a</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">y_{tar}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)</li>
<li>损失函数：<code>L1 loss</code></li>
</ul>
<h3 id="4-vocoder-详解"><a class="markdownIt-Anchor" href="#4-vocoder-详解"></a> 4. <code>Vocoder</code> 详解</h3>
<ul>
<li>输入：
<ul>
<li>由 <code>S2M</code> 模块生成的梅尔频谱图 (<code>Mel Spectrogram</code>)。</li>
</ul>
</li>
<li>输出:
<ul>
<li>最终的音频波形 (<code>Audio Waveform</code>)。</li>
</ul>
</li>
<li>直接使用了训练好的 <code>BigVGANv2</code> 模型</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li><code>TTS</code> 是个很有趣的领域，直觉上看流媒体平台上有大量的语音数据，应该很容易训练一个 <code>TTS</code> 模型，但实际上似乎并不是很容易。</li>
<li>用 <code>GRL</code> 来去除 <code>style</code> 中的 <code>timbre</code> 信息是个不错的想法。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/09/19/Qwen3-Next%EF%BC%9A%E8%BF%88%E5%90%91%E6%9B%B4%E6%9E%81%E8%87%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%80%A7%E4%BB%B7%E6%AF%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/19/Qwen3-Next%EF%BC%9A%E8%BF%88%E5%90%91%E6%9B%B4%E6%9E%81%E8%87%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%80%A7%E4%BB%B7%E6%AF%94/" class="post-title-link" itemprop="url">Qwen3-Next：迈向更极致的训练推理性价比</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-19 15:12:15" itemprop="dateCreated datePublished" datetime="2025-09-19T15:12:15+08:00">2025-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/09/19/Qwen3-Next%EF%BC%9A%E8%BF%88%E5%90%91%E6%9B%B4%E6%9E%81%E8%87%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%80%A7%E4%BB%B7%E6%AF%94/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/09/19/Qwen3-Next%EF%BC%9A%E8%BF%88%E5%90%91%E6%9B%B4%E6%9E%81%E8%87%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E6%80%A7%E4%BB%B7%E6%AF%94/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>blog: <a target="_blank" rel="noopener" href="https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd&amp;from=research.latest-advancements-list">https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd&amp;from=research.latest-advancements-list</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文主要介绍 <code>Qwen3-Next</code> 架构，由于还没有发正式论文，所以主要参考官方博客和 <code>transformers</code> 实现代码</li>
</ul>
<h2 id="架构优化"><a class="markdownIt-Anchor" href="#架构优化"></a> 架构优化</h2>
<h3 id="混合架构"><a class="markdownIt-Anchor" href="#混合架构"></a> 混合架构</h3>
<p><img src="https://s2.loli.net/2025/09/19/5GUHjSBzEnYAQae.png" alt="qwen3-next.png" /></p>
<ul>
<li>与之前使用标准 <code>Scaled Dot-Product Attention(SDPA)</code> 层不同，本次 <code>Qwen3-Next</code> 采用 <code>GatedDeltaNet</code> + <code>GatedAttention</code> 混合的方式构建模型</li>
<li><code>GatedDeltaNet</code> 是一种线性复杂度的注意力机制，在 <code>Mamba2</code> 上改进得到的，详细参考：<a target="_blank" rel="noopener" href="https://zhangzhe.space/2025/09/15/Gated-Delta-Networks-Improving-Mamba2-with-Delta-Rule/">Gated Delta Networks: Improving Mamba2 with Delta Rule</a></li>
<li><code>GatedAttention</code> 出自 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.06708">https://arxiv.org/pdf/2505.06708</a> ，本质就是在标准 <code>SDPA</code> 之后加入了 <code>Gate</code> 操作：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Output</mtext><mo>=</mo><mtext>SDPA</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>⊙</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mi>W</mi><mi>θ</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Output}=\text{SDPA}(Q,K,V) \odot \sigma(XW_\theta)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">SDPA</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li>二者层数占比：
<ul>
<li><code>GatedDeltaNet</code> 占比 <code>75%</code></li>
<li><code>GatedAttention</code> 占比 <code>25%</code></li>
</ul>
</li>
</ul>
<h3 id="极致稀疏-moe"><a class="markdownIt-Anchor" href="#极致稀疏-moe"></a> 极致稀疏 MoE</h3>
<ul>
<li>共有 <code>512</code> 个专家，每次只激活 <code>10</code> 个路由专家 + <code>1</code> 个共享专家</li>
<li>激活参数只占原参数的 <code>3.7%</code>，因此采用 <code>80B-A3</code> 这种又大又快的模型</li>
</ul>
<h3 id="训练稳定性友好设计"><a class="markdownIt-Anchor" href="#训练稳定性友好设计"></a> 训练稳定性友好设计</h3>
<h4 id="zero-centered-rmsnorm"><a class="markdownIt-Anchor" href="#zero-centered-rmsnorm"></a> Zero-Centered RMSNorm</h4>
<ul>
<li>在 <code>GatedAttention</code> 的 <code>QK Norm</code> （上图中 <code>QK</code> 做 <code>Attention</code> 之前的）用 <code>Zero-Centered RMSNorm</code></li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>LayerNorm</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><msqrt><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mn>1</mn><mi>N</mi></munderover><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mo>⋅</mo><mi>γ</mi><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">\text{LayerNorm}(x) = \frac{x-\mu}{\sqrt{\frac{1}{N}\sum_1^N(x_i-\mu)^2+\epsilon}} \cdot \gamma+\beta
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">LayerNorm</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.99033em;vertical-align:-1.7300000000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603300000000002em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.3031155em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3031155em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-3.2631154999999996em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5368845em;"><span></span></span></span></span></span></span></span><span style="top:-3.5331155em;"><span class="pstrut" style="height:3.3031155em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.9801155em;"><span class="pstrut" style="height:3.3031155em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>RMSNorm</mtext><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mi>x</mi><msqrt><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mn>1</mn><mi>N</mi></munderover><msubsup><mi>x</mi><mi>i</mi><mn>2</mn></msubsup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mo>⋅</mo><mi>γ</mi></mrow><annotation encoding="application/x-tex">\text{RMSNorm}(x_i) = \frac{x}{\sqrt{\frac{1}{N}\sum_1^Nx_i^2+\epsilon}} \cdot \gamma
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">RMSNorm</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.8375600000000003em;vertical-align:-1.7300000000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.10756em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.3031155em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3031155em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959080000000001em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.27686399999999994em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-3.2631154999999996em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5368845em;"><span></span></span></span></span></span></span></span><span style="top:-3.5331155em;"><span class="pstrut" style="height:3.3031155em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.9801155em;"><span class="pstrut" style="height:3.3031155em;"></span><span class="mord"><span class="mord mathnormal">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Zero-Centered RMSNorm</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><msqrt><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mn>1</mn><mi>N</mi></munderover><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mo>⋅</mo><mi>γ</mi></mrow><annotation encoding="application/x-tex">\text{Zero-Centered RMSNorm}(x) = \frac{x-\mu}{\sqrt{\frac{1}{N}\sum_1^N(x_i-\mu)^2+\epsilon}} \cdot \gamma
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Zero-Centered RMSNorm</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.99033em;vertical-align:-1.7300000000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603300000000002em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.3031155em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3031155em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-3.2631154999999996em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5368845em;"><span></span></span></span></span></span></span></span><span style="top:-3.5331155em;"><span class="pstrut" style="height:3.3031155em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.9801155em;"><span class="pstrut" style="height:3.3031155em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span></span></p>
<ul>
<li>从公式上看 <code>Zero-Centered RMSNorm</code> 本质就是不带 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 的 <code>LayerNorm</code></li>
</ul>
<h4 id="moe-router-权重初始化"><a class="markdownIt-Anchor" href="#moe-router-权重初始化"></a> MoE router 权重初始化</h4>
<ul>
<li>初始化时归一化了 <code>MoE router</code> 的参数，确保每个 <code>expert</code> 在训练早期都能被无偏地选中，减小初始化对实验结果的扰动</li>
</ul>
<h3 id="multi-token-prediction"><a class="markdownIt-Anchor" href="#multi-token-prediction"></a> Multi-Token Prediction</h3>
<ul>
<li>和 <code>DeepSeek-V3</code> 的 <code>MTP</code> 的区别是：本 <code>MTP</code> 不仅在训练时候预测多个，推理的时候也预测多个，非常方便 <code>Speculative Decoding</code></li>
</ul>
<h2 id="预训练"><a class="markdownIt-Anchor" href="#预训练"></a> 预训练</h2>
<ul>
<li><code>Qwen3-Next</code> 采用的是 <code>Qwen3 36T</code> 预训练语料的一个均匀采样子集，仅包含 <code>15T tokens</code></li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li><code>Qwen3-Next-80B-A3B</code> 比 <code>Qwen3-32B</code> 效果更好，速度更快，这主要归功于超稀疏 <code>MoE</code> 带来的计算量显著下降，以及 <code>GatedDeltaNet</code> 带来的平方复杂度到线性复杂度的下降</li>
<li>预训练竟然会对数据做采样使用，这个有点反直觉，后续会关注论文中有没有详细解释</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/09/15/Gated-Delta-Networks-Improving-Mamba2-with-Delta-Rule/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/15/Gated-Delta-Networks-Improving-Mamba2-with-Delta-Rule/" class="post-title-link" itemprop="url">Gated Delta Networks: Improving Mamba2 with Delta Rule</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-15 22:46:31" itemprop="dateCreated datePublished" datetime="2025-09-15T22:46:31+08:00">2025-09-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linear-transformer/" itemprop="url" rel="index"><span itemprop="name">linear-transformer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/09/15/Gated-Delta-Networks-Improving-Mamba2-with-Delta-Rule/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/09/15/Gated-Delta-Networks-Improving-Mamba2-with-Delta-Rule/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.06464">https://arxiv.org/pdf/2412.06464</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/NVlabs/GatedDeltaNet">https://github.com/NVlabs/GatedDeltaNet</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一种名为 <code>GatedDeltaNet</code> 的神经网络架构，其类型属于状态空间模型 <code>SSM</code>，属于 <code>Mamba2</code> 的改进版本</li>
</ul>
<h2 id="algorithms"><a class="markdownIt-Anchor" href="#algorithms"></a> Algorithms</h2>
<h3 id="核心公式"><a class="markdownIt-Anchor" href="#核心公式"></a> 核心公式</h3>
<ul>
<li>状态更新公式</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><msub><mi>α</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>I</mi><mo>−</mo><msub><mi>β</mi><mi>t</mi></msub><msub><mi>k</mi><mi>t</mi></msub><msubsup><mi>k</mi><mi>t</mi><mi>T</mi></msubsup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><msub><mi>β</mi><mi>t</mi></msub><msub><mi>v</mi><mi>t</mi></msub><msubsup><mi>k</mi><mi>t</mi><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">S_t=S_{t-1}(\alpha_t(I-\beta_tk_tk_t^T)) + \beta_tv_tk_t^T
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.138331em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>输出公式</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>o</mi><mi>t</mi></msub><mo>=</mo><msubsup><mi>q</mi><mi>t</mi><mi>T</mi></msubsup><msub><mi>S</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">o_t = q_t^T S_t
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.138331em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>其中：
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>：序列位置，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><mi>t</mi><mo>&lt;</mo><mi>L</mi></mrow><annotation encoding="application/x-tex">0 \leq t &lt; L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.78041em;vertical-align:-0.13597em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.65418em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span></span></span></span> 为序列长度，之后统称为时间步</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>t</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">q_t\in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span>：时间步 <code>t</code> 的查询向量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>t</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">k_t\in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span>：时间步 <code>t</code> 的键向量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">v_t\in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span>：时间步 <code>t</code> 的值向量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">S_t\in \mathbb{R}^{d \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>：时间步 <code>t</code> 的状态矩阵，存储的是历史键值相关性矩阵</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>t</mi></msub><mo>∈</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\alpha_t\in \mathbb{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbb">R</span></span></span></span></span>：时间步 <code>t</code> 的遗忘因子，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><msub><mi>α</mi><mi>t</mi></msub><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 &lt; \alpha_t \leq 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68354em;vertical-align:-0.0391em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7859700000000001em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>，控制历史信息的遗忘程度</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>t</mi></msub><mo>∈</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\beta_t\in \mathbb{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbb">R</span></span></span></span></span>：时间步 <code>t</code> 的更新因子，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><msub><mi>β</mi><mi>t</mi></msub><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \leq \beta_t &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.78041em;vertical-align:-0.13597em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>，控制当前信息的更新程度</li>
</ul>
</li>
<li>对比 <code>Mamba2</code> 的状态更新公式</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><msub><mi>α</mi><mi>t</mi></msub><msub><mi>S</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>v</mi><mi>t</mi></msub><msubsup><mi>k</mi><mi>t</mi><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">S_t = \alpha_t S_{t-1}+  v_t k_t^T
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.138331em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<h3 id="ssm-结构的优势"><a class="markdownIt-Anchor" href="#ssm-结构的优势"></a> SSM 结构的优势</h3>
<ul>
<li><code>transformer</code> 的自注意力矩阵是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>L</mi><mo>×</mo><mi>L</mi></mrow></msup></mrow><annotation encoding="application/x-tex">S \in \mathbb{R}^{L \times L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">L</span></span></span></span></span></span></span></span></span></span></span></span>，计算和存储成本为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>L</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(L^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span></span></span></span> 是序列长度</li>
<li><code>SSM</code> 的状态矩阵是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>L</mi><mo>×</mo><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">S \in \mathbb{R}^{L\times d \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>，由于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>≪</mo><mi>L</mi></mrow><annotation encoding="application/x-tex">d \ll L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≪</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span></span></span></span>，计算和存储成本为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(L)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mclose">)</span></span></span></span>，大大降低了计算复杂度</li>
</ul>
<h3 id="分块加速"><a class="markdownIt-Anchor" href="#分块加速"></a> 分块加速</h3>
<ul>
<li>作者对 <code>GatedDeltaNet</code> 的实现做了数学等价的分块加速，<code>repo</code> 名就是 <code>flash-linear-attention</code></li>
<li>类似 <code>attention</code> 和 <code>flash-attention</code> 的关系</li>
</ul>
<h2 id="关于-gateddeltanet-和-rwkv-7-两位作者互撕的一些看法"><a class="markdownIt-Anchor" href="#关于-gateddeltanet-和-rwkv-7-两位作者互撕的一些看法"></a> 关于 <code>GatedDeltaNet</code> 和 <code>RWKV-7</code> 两位作者互撕的一些看法</h2>
<ul>
<li>背景：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1915054612559426430">https://zhuanlan.zhihu.com/p/1915054612559426430</a></li>
<li>省流版本：
<ul>
<li><code>GatedDeltaNet</code> 的作者 <code>Songlin Yang</code> 在自己的论文中，把 <code>RWKV-7</code> 的表现压的很低，比原论文低很多，然后 <code>RWKV-7</code> 原作者 <code>Peng Bo</code> 质疑 <code>GatedDeltaNet</code> 对比实验中对 <code>RWKV-7</code> 的实现有问题</li>
<li><code>GatedDeltaNet</code> 作者 <code>Songlin Yang</code> 在微信群怒喷 <code>RWKV-7</code> 作者 <code>Peng Bo</code>，让其要么给自己的 <code>fla Repo</code> 提 <code>PR</code> 修复实现，要么闭嘴，随后还将其踢出微信群</li>
</ul>
</li>
<li>个人看法：
<ul>
<li>对于论文中引用别人论文做 <code>baseline</code> 常出现的无意的有意压低表现的情况，算是行业通病了，但被指出来立正挨打就完了，作者竟然还怒喷对方，要求其帮自己修复实现，合着你发论文，<code>bug</code> 我帮你修？实验我帮你做？这是什么逻辑</li>
<li>虽然 <code>fla</code> 在社区有一些影响力，也有 <code>3.3k</code> 的 <code>star</code>，但其显然还不是唯一主流的实现库（像 <code>Pytorch</code>、<code>Transformers</code> 这种级别），写论文必须用 <code>fla</code> 显然不是行业共识，不能要求原作者必须用 <code>fla</code> 去实现自己的算法（<code>who think you are</code>），竟然还要求要么给 <code>PR</code>，要么就把把自己 <code>fla</code> 中 <code>RWKV-7</code> 相关实现全删了。原作者也开源了自己的实现库，这个库可以完全复现论文结果，这一点想必 <code>GatedDeltaNet</code> 作者也清楚</li>
<li>虽然 <code>GatedDeltaNet</code> 能被 <code>Qwen3-Next</code> 这种大模型用上，说明含金量还是有的，但作者的这种行为，实在让人不齿，世界就是一个大的回旋镖，不能等回旋镖打到自己身上才喊疼</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/09/09/The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/09/The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey/" class="post-title-link" itemprop="url">The Landscape of Agentic Reinforcement Learning for LLMs: A Survey</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-09 10:06:26" itemprop="dateCreated datePublished" datetime="2025-09-09T10:06:26+08:00">2025-09-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reinforcement-Learning/" itemprop="url" rel="index"><span itemprop="name">Reinforcement Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/09/09/The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/09/09/The-Landscape-of-Agentic-Reinforcement-Learning-for-LLMs-A-Survey/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2509.02547">https://arxiv.org/pdf/2509.02547</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers">https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>Agentic Reinforcement Learning (Agentic RL)</code> 是指将大型语言模型（<code>LLM</code>）视作嵌入在交互式决策环境中的可学习策略，而非仅仅作为静态文本生成器来优化单步输出</li>
<li>与常规的基于偏好的序列微调（<code>PBRFT</code>，如 <code>RLHF</code>）只做单回合优化不同，<code>Agentic RL</code> 考虑多回合的状态演化和长期奖励，从单步马尔科夫决策过程（<code>MDP</code>）变成了部分可观测马尔可夫决策过程 (<code>POMDP</code>)</li>
</ul>
<h2 id="algorithms"><a class="markdownIt-Anchor" href="#algorithms"></a> Algorithms</h2>
<h3 id="agentic-rl-的定义"><a class="markdownIt-Anchor" href="#agentic-rl-的定义"></a> Agentic RL 的定义</h3>
<ul>
<li><code>Agentic Reinforcement Learning (Agentic RL)</code> 是指将大型语言模型（<code>LLM</code>）视作嵌入在交互式决策环境中的可学习策略，而非仅仅作为静态文本生成器来优化单步输出</li>
<li>通过强化学习，<code>Agentic RL</code> 赋予 <code>LLM</code> 规划、推理、工具调用、记忆管理和自我反思等能力，使其在部分可观测、动态环境中产生长期、多步的智能行为</li>
</ul>
<h3 id="mdp-vs-pomdp"><a class="markdownIt-Anchor" href="#mdp-vs-pomdp"></a> MDP vs POMDP</h3>
<table>
<thead>
<tr>
<th style="text-align:center">特性</th>
<th style="text-align:left">MDP (马尔可夫决策过程)</th>
<th style="text-align:left">POMDP (部分可观察马尔可夫决策过程)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">可观察性</td>
<td style="text-align:left">完全可观察：智能体总是知道它所在的物理状态</td>
<td style="text-align:left">部分可观察：智能体无法直接知道物理状态，只能通过观察来推断</td>
</tr>
<tr>
<td style="text-align:center">决策依据</td>
<td style="text-align:left">基于当前物理状态做出决策</td>
<td style="text-align:left">基于信念状态（对所有可能物理状态的概率分布）做出决策</td>
</tr>
<tr>
<td style="text-align:center">状态空间</td>
<td style="text-align:left">状态空间由物理状态组成</td>
<td style="text-align:left">决策空间在信念空间中，这是一个连续的、更高维度的空间，因此求解起来通常更复杂</td>
</tr>
<tr>
<td style="text-align:center">计算复杂度</td>
<td style="text-align:left">相对较低，有成熟的动态规划算法（如价值迭代、策略迭代）</td>
<td style="text-align:left">求解难度更大，通常是 PSPACE-完全问题，因为需要在连续的信念空间中进行规划</td>
</tr>
<tr>
<td style="text-align:center">适用场景</td>
<td style="text-align:left">机器人能用传感器完美定位、国际象棋、简单的棋盘游戏</td>
<td style="text-align:left">自动驾驶（传感器有误差）、医疗诊断（医生无法 100% 确定病因）</td>
</tr>
</tbody>
</table>
<h3 id="agentic-rl-和-rlhf-的区别"><a class="markdownIt-Anchor" href="#agentic-rl-和-rlhf-的区别"></a> Agentic RL 和 RLHF 的区别</h3>
<ul>
<li><code>Agentic RL</code>
<ul>
<li><strong>核心思想</strong>：将 LLM 转变为拥有连续交互能力的智能体，而不仅是一次性生成答案的模型</li>
<li><code>Agentic RL</code> 中，智能体在一个 <code>POMDP</code> 中跨越多个时间步进行交互：每次基于当前观测（可能只部分反映真实世界状态）选择行动，环境状态随机转换，并在整个过程中累积稀疏或稠密奖励</li>
</ul>
</li>
<li>传统 <code>RLHF</code> 训练中，一个 <code>Prompt</code> 对应一次输出，训练过程可以形式化为退化的单步 <code>MDP</code>：状态空间仅为给定提示，动作是生成一段文本，动作结束后立即结束回合，奖励依据生成内容质量一次性给出</li>
<li>传统 <code>RLHF</code> 只能优化单句输出的对齐度，而 <code>Agentic RL</code> 则同时涉及多轮规划、动态工具调用、带状态记忆和长程回报的学习，使 <code>LLM</code> 真正成为自主决策的代理人</li>
</ul>
<h3 id="agentic-rl-的关键组成部分"><a class="markdownIt-Anchor" href="#agentic-rl-的关键组成部分"></a> Agentic RL 的关键组成部分</h3>
<p><code>Agentic RL</code> 智能体通常包括多个相互协作的核心模块，这些模块由 <code>RL</code> 统一优化：</p>
<ul>
<li><strong>规划 (Planning)</strong>：规划是在多个步骤上推演行动序列以达成目标。通常情况下是将 <code>LLM</code> 本身视为策略网络，<code>RL</code> 通过与环境的反复试错直接微调其长程规划和执行协调能力</li>
<li><strong>工具使用 (Tool Use)</strong>：<code>LLM</code> 智能体可以调用外部工具（例如搜索引擎、计算器、代码执行环境等）来扩展能力。传统的 <code>ReAct</code> 风格方法或人工构造的示例往往只能让模型模仿固定的工具调用模式，而 <code>Agentic RL</code> 则通过结果驱动优化，使智能体自主学习何时、如何调用工具</li>
<li><strong>记忆 (Memory)</strong>：在 <code>Agentic RL</code> 中，记忆不再是被动的内容检索，而是智能体可控制的动态子系统，<code>RL</code> 学习使智能体决定何时存储、检索或删除记忆</li>
<li><strong>推理 (Reasoning)</strong>：<code>LLM</code> 智能体需要在解决复杂问题时进行多步逻辑推理。通常将推理分为“快推理”（快速、启发式）和“慢推理”（逐步演绎式）</li>
<li><strong>自我改进 (Self-Improvement/Reflection)</strong>：<code>Agentic RL</code> 强调智能体持续学习和反思自身。智能体能够在执行任务后“自我批评”并改进，具体来说，研究者使用 <code>RLHF</code> 或 <code>DPO</code> 等算法来奖励生成正确/优质轨迹，相当于让模型学会识别和改正错误，从而提高未来推理的可靠性；甚至有尝试让智能体自行生成问题并解答（类似 <code>AlphaZero</code> 的自我博弈），实现无人监督的终身学习循环</li>
<li><strong>感知 (Perception)</strong>：在多模态环境中，智能体需要感知视觉、听觉等信息并综合语言推理。大型视觉-语言模型（<code>LVLM</code>）通过在视觉输入上附加推理模块，被动感知转向主动视觉认知。<code>Agentic RL</code> 将强化学习应用于视觉-语言任务，使模型在视图下生成多步推理策略</li>
</ul>
<h3 id="agentic-rl-的奖励设计"><a class="markdownIt-Anchor" href="#agentic-rl-的奖励设计"></a> Agentic RL 的奖励设计</h3>
<ul>
<li>和 <code>RLHF</code> 这种稀疏奖励不同，<code>Agentic RL</code> 需要设计更复杂的奖励结构来引导长期行为</li>
<li>如果只在最终任务成功时给予奖励，会出现信用分配问题 (<code>credit assignment</code>)，智能体可能难以学习到有效的中间步骤</li>
<li>因此 <code>Agentic RL</code> 更倾向于引入中间奖励 (<code>dense or shaped rewards</code>)，往往是基于规则或启发式的，比如：
<ul>
<li>规划：计划是否合理拆解任务。</li>
<li>记忆：写入/检索是否对最终解答有帮助。</li>
<li>工具使用：API 调用是否成功、是否缩短了解题时间。</li>
<li>推理：中间推理步骤是否能被验证（例如算式对/错）。</li>
</ul>
</li>
<li>这些中间奖励可以是：
<ul>
<li>显式规则（比如 “子问题答案正确 → +1”）。</li>
<li>自动判别器（比如 单元测试、符号验证器）。</li>
<li>学习的奖励模型（训练一个模型来评估中间步骤质量）。</li>
</ul>
</li>
</ul>
<h3 id="强化学习算法"><a class="markdownIt-Anchor" href="#强化学习算法"></a> 强化学习算法</h3>
<ul>
<li>还是 <code>PPO</code>、<code>GRPO</code>、<code>DPO</code> 这些常见算法</li>
</ul>
<h3 id="应用场景与系统实例"><a class="markdownIt-Anchor" href="#应用场景与系统实例"></a> 应用场景与系统实例</h3>
<ul>
<li><strong>搜索与研究助手</strong>：智能体利用 <code>RL</code> 优化查询生成和多步检索策略，完成复杂的研究任务</li>
<li><strong>代码生成与软件工程</strong>：在编程任务中，执行反馈（如编译成功与否、单元测试结果等）作为奖励信号可直接指导模型优化</li>
<li><strong>视觉与多模态任务</strong>：如自动视觉问答、图像编辑与导航等任务，可将视图信息作为环境观测，引入工具（比如画图 <code>API</code>）作为动作</li>
<li><strong>多智能体系统</strong>：在需要多个协同或对抗智能体的场景（如游戏博弈、协作代理）中，<code>Agentic RL</code> 将整个系统建模为去中心化 <code>POMDP (Dec-POMDP)</code>，并训练每个 <code>LLM</code> 代理的策略</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>单回合优化 -&gt; 多回合协同优化，听上去很 <code>makes sense</code>，毕竟超集总是更好？</li>
<li>把 <code>Agent</code> 的难点转移到奖励设计上了，每个细粒度的奖励设计和不同奖励的平衡看上去挺难的</li>
<li>如果做成纯稀疏奖励（只在最终结果上打分），那么由于搜索空间太大，训练会非常困难，除非堆海量数据和算力</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/08/14/RT-1-Robotics-Transformer-for-Real-World-Control-at-Scale/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/14/RT-1-Robotics-Transformer-for-Real-World-Control-at-Scale/" class="post-title-link" itemprop="url">RT-1: Robotics Transformer for Real-World Control at Scale</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-14 22:02:28" itemprop="dateCreated datePublished" datetime="2025-08-14T22:02:28+08:00">2025-08-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/VLA/" itemprop="url" rel="index"><span itemprop="name">VLA</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/08/14/RT-1-Robotics-Transformer-for-Real-World-Control-at-Scale/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/08/14/RT-1-Robotics-Transformer-for-Real-World-Control-at-Scale/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2212.06817">https://arxiv.org/pdf/2212.06817</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/google-research/robotics_transformer">https://github.com/google-research/robotics_transformer</a></li>
<li>homepage: <a target="_blank" rel="noopener" href="https://robotics-transformer1.github.io">https://robotics-transformer1.github.io</a></li>
<li>dataset: <a target="_blank" rel="noopener" href="https://console.cloud.google.com/storage/browser/gresearch/rt-1-data-release">https://console.cloud.google.com/storage/browser/gresearch/rt-1-data-release</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出了 <code>RT-1</code> 模型，本质是一个输入连续 <code>6</code> 帧图像 + 一句语言指令，输出是 <code>11</code> 维动作空间的 <code>VLA</code> 模型，控制一个有可移动底座和一个手臂的机器人，也就是说，<code>RT-1</code> 实际上是一个 <strong>小脑模型</strong>（执行控制模型，输入是相对简单的指令，输出是精细动作控制信号）</li>
<li><code>RT-1</code> 首次证明大规模 <code>Transformer</code> 模型在机器人控制的可行性：通过​​任务无关训练​​、​​高效架构设计​​及​​异构数据融合​​，实现 <code>700+</code>任务的 <code>97%</code> 成功率及显著零样本泛化能力</li>
<li>整个模型非常轻量，只有 <code>35M</code> 的参数</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="网络结构"><a class="markdownIt-Anchor" href="#网络结构"></a> 网络结构</h3>
<p><img src="https://s2.loli.net/2025/08/14/lR4XZs97P8FCLwN.png" alt="rt1_2.png" /></p>
<ul>
<li>模型大概由四部分组成：</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">​​模块​​</th>
<th style="text-align:center">​​输入形状​​</th>
<th style="text-align:center">​​输出形状​​</th>
<th style="text-align:center">​​关键说明​​</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Universal Sentence Encoder</td>
<td style="text-align:center">文本字符串</td>
<td style="text-align:center">512维向量</td>
<td style="text-align:center">语言语义编码</td>
</tr>
<tr>
<td style="text-align:center">FiLM EfficientNet-B3</td>
<td style="text-align:center">6×300×300×3(图像) + 512</td>
<td style="text-align:center">486×512</td>
<td style="text-align:center">每帧生成81个视觉Token</td>
</tr>
<tr>
<td style="text-align:center">TokenLearner</td>
<td style="text-align:center">486×512</td>
<td style="text-align:center">48×512</td>
<td style="text-align:center">压缩至8 Token/帧</td>
</tr>
<tr>
<td style="text-align:center">Transformer</td>
<td style="text-align:center">48×512(+位置编码)</td>
<td style="text-align:center">11×256</td>
<td style="text-align:center">输出离散化动作分布</td>
</tr>
</tbody>
</table>
<h3 id="模型输出"><a class="markdownIt-Anchor" href="#模型输出"></a> 模型输出</h3>
<ul>
<li>输出 <code>11</code> 维动作空间，每个动作空间都是离散的 <code>256</code> 个值</li>
<li><code>11</code> 个动作空间分别表示：
<ul>
<li><code>1</code> 个离散维度用于控制模式切换：
<ul>
<li>控制底座</li>
<li>控制手臂</li>
<li>终止</li>
</ul>
</li>
<li><code>7</code> 个维度控制机械臂：
<ul>
<li>末端位置：<code>x, y, z</code></li>
<li>末端姿态：<code>roll, pitch, yaw</code></li>
<li>抓夹：开合度</li>
</ul>
</li>
<li><code>3</code> 个维度控制底座：
<ul>
<li>位置：<code>x, y</code></li>
<li>旋转角度：<code>yaw</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="数据集"><a class="markdownIt-Anchor" href="#数据集"></a> 数据集</h3>
<ul>
<li>可参考 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/650714103">https://zhuanlan.zhihu.com/p/650714103</a></li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>模型很简单，数据很简单，训练范式也很简单，但泛化能力很强</li>
<li><code>RT-1</code> 数据开源，推动具身智能社区发展</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhangzhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">173</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">104</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhangzhe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js', () => {
    // 初始化 Mermaid 配置
    mermaid.initialize({
      theme    : 'dark',  // 设置主题
      logLevel : 3,  // 设置日志等级
      flowchart: { curve: 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 },
      themeVariables: {
        'fontFamily': 'Microsoft YaHei, Arial, sans-serif',  // 设置中文字体
      }
    });

    // 初始化 Mermaid 图表
    mermaid.init(undefined, document.querySelectorAll('pre.mermaid'));
  }, window.mermaid);
}
</script>


  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'eK3W25jybCO5jVUrYBBpAPqM-gzGzoHsz',
      appKey     : 'F4KVyUj9wHI5c80Bhz7O2uhq',
      placeholder: "说点什么再走吧...",
      avatar     : 'hide',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
