<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"real-zhangzhe.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Zhangzhe&#39;s Blog">
<meta property="og:url" content="https://real-zhangzhe.github.io/page/11/index.html">
<meta property="og:site_name" content="Zhangzhe&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhangzhe">
<meta property="article:tag" content="No mistakes in the tango, not like life.">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://real-zhangzhe.github.io/page/11/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Zhangzhe's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhangzhe's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">The projection of my life.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/archives/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/05/16/GPT2-Language-Models-are-Unsupervised-Multitask-Learners/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/05/16/GPT2-Language-Models-are-Unsupervised-Multitask-Learners/" class="post-title-link" itemprop="url">GPT2: Language Models are Unsupervised Multitask Learners</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-05-16 11:43:57" itemprop="dateCreated datePublished" datetime="2023-05-16T11:43:57+08:00">2023-05-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Self-Supervised-Learning/" itemprop="url" rel="index"><span itemprop="name">Self-Supervised Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/05/16/GPT2-Language-Models-are-Unsupervised-Multitask-Learners/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/05/16/GPT2-Language-Models-are-Unsupervised-Multitask-Learners/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/openai/gpt-2">https://github.com/openai/gpt-2</a></li>
<li>demo code: <a target="_blank" rel="noopener" href="https://github.com/karpathy/minGPT">https://github.com/karpathy/minGPT</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>继 <code>Bert</code> 全方位打败 <code>GPT</code> 之后，<code>OpenAI</code> 推出了参数量更大的 <code>GPT2</code></li>
<li>但 <code>GPT2</code> 与之前所有的 <code>NLP</code> 预训练模型使用的 <em>自监督预训练 + 任务相关 fine-tuning</em> 范式不同，<code>GPT2</code> 不再需要任何数据相关 <code>fine-tuning</code>，而是使用 <strong><code>prompt</code>（提示词）</strong></li>
<li><strong><code>prompt</code>（提示词）</strong> 是一段在模型推理阶段用于描述任务的文本，通常加在问题之前，起到提示模型的作用</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><code>GPT2</code> 很大程度上只是 <code>GPT</code> 的放大版，所引入的创新并不多</p>
<ul>
<li>使用了 <code>Byte Pair Encoding（BPE）</code> 分词算法，本质是一种贪心算法</li>
<li>由于自回归（<code>auto-regression</code>）模型推理容易出现死循环，所以本文提出一种 <code>top-k</code> 输出按 <code>softmax</code> 概率采样的 <code>trick</code>，增加模型的随机性</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li><code>GPT2</code> 最重要的作用是提出了使用 <code>Prompt</code> 替代 <code>fine-tuning</code> 的范式，为之后的 <code>AIGC</code> 大面积推广扫平了障碍</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/04/19/FCOS3D-Fully-Convolutional-One-Stage-Monocular-3D-Object-Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/19/FCOS3D-Fully-Convolutional-One-Stage-Monocular-3D-Object-Detection/" class="post-title-link" itemprop="url">FCOS3D: Fully Convolutional One-Stage Monocular 3D Object Detection</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-19 10:00:53" itemprop="dateCreated datePublished" datetime="2023-04-19T10:00:53+08:00">2023-04-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Monocular-3D-Object-Detection/" itemprop="url" rel="index"><span itemprop="name">Monocular 3D Object Detection</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/04/19/FCOS3D-Fully-Convolutional-One-Stage-Monocular-3D-Object-Detection/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/04/19/FCOS3D-Fully-Convolutional-One-Stage-Monocular-3D-Object-Detection/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.10956.pdf">https://arxiv.org/pdf/2104.10956.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmdetection3d/blob/main/mmdet3d/models/dense_heads/fcos_mono3d_head.py">https://github.com/open-mmlab/mmdetection3d/blob/main/mmdet3d/models/dense_heads/fcos_mono3d_head.py</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文基于 <code>FCOS</code> 论文提出一种架构简单的 <code>Anchor Free</code> 的单目 <code>3D</code> 检测算法 <code>FCOS3D</code>，在 <code>NeurIPS 2020</code> 的 <code>nuScenes 3D</code> 检测比赛纯视觉赛道上取得了第一名。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="问题定义"><a class="markdownIt-Anchor" href="#问题定义"></a> 问题定义</h3>
<ul>
<li>
<p>本文提出的 <code>FCOS3D</code> 要解决的核心问题是一个 <strong>图片到 7-DoF 属性（x, y, z, w, l, h, yaw+dir）的预测</strong>。</p>
<ul>
<li><code>DoF</code> 是指 <code>degree of freedom</code>（自由度）。</li>
<li><code>(x, y, z, w, l, h, yaw+dir)</code> 分别表示物体在相机坐标系下的 3 维坐标和长宽高（单位都是米），和偏航角（俯视图角度，单位是弧度）和方向 2 分类共同构成朝向。</li>
</ul>
</li>
<li>
<p>对于 <code>nuScenes 3D</code> 检测比赛，还需要解决的非核心问题包括：</p>
<ul>
<li>预测出的 <code>3D</code> 框物体的类别（10类物体）</li>
<li>预测出的 <code>3D</code> 框物体的属性（9种属性）</li>
<li>预测出的 <code>3D</code> 框物体的 <code>x, y</code> 轴速度（不是 “病态” 问题了，已经属于癌症问题了…）</li>
</ul>
</li>
</ul>
<h3 id="网络结构"><a class="markdownIt-Anchor" href="#网络结构"></a> 网络结构</h3>
<p><img src="https://s2.loli.net/2023/04/19/oysj5k6Z3IKvNnr.png" alt="fcos3d.png" /></p>
<ul>
<li>
<p><code>backbone</code> 和 <code>FPN</code> 比较常规</p>
</li>
<li>
<p><code>decode head</code> 和 <code>FCOS</code> 一样，使用了不同 <code>level feature</code> 的参数共享（反正是全卷积，不存在 shape 问题）</p>
</li>
<li>
<p><code>decode head</code> 中包括：</p>
<ul>
<li>
<p>分类分支：</p>
<ul>
<li>class: <code>output_shape = (N, 10, H, W)</code>，使用 <code>FocalLoss</code></li>
<li>attribute: <code>output_shape = (N, 9, H, W)</code>，使用 <code>CrossEntropyLoss</code></li>
</ul>
</li>
<li>
<p>回归分支：</p>
<ul>
<li>box:  <code>output_shape = (N, 9, H, W)</code>， <code>(dx, dy, log(z), log(w), log(l), log(h), yaw, vx, vy)</code>，使用 <code>SmoothL1Loss</code></li>
<li>centerness: <code>output_shape = (N, 1, H, W)</code>，使用 <code>BCEWithLogitsLoss</code></li>
<li>direction: <code>output_shape = (N, 2, H, W)</code>，使用 <code>CrossEntropyLoss</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="target-设置"><a class="markdownIt-Anchor" href="#target-设置"></a> target 设置</h3>
<ul>
<li>target 设置中使用了很多 <strong>2D 引导 3D</strong> 的思想。</li>
</ul>
<h4 id="x-y-z-target-设置"><a class="markdownIt-Anchor" href="#x-y-z-target-设置"></a> <code>(x, y, z)</code> target 设置</h4>
<ul>
<li>由于是 3D 检测，所以 GT 的 3D 框坐标（x, y, z, w, l, h）单位都是米，这对神经网络是不友好的（因为神经网络看到的是像素，预测以像素为单位更容易）。</li>
<li>因此，<strong>本文实际是一个 <code>2.5D</code> 的预测<code>（xy 2D, z 3D）</code>，实际预测的 <code>x, y</code> 是像素坐标系下相对于 feature map 每一个点的偏移量（由相机坐标系和相机内参可计算得到像素坐标系），<code>z, w, l, h</code> 的预测是相机坐标系下的米为单位的真值取 <code>log</code>。</strong></li>
</ul>
<h4 id="centerness-target-设置"><a class="markdownIt-Anchor" href="#centerness-target-设置"></a> centerness target 设置</h4>
<ul>
<li>与 <code>FCOS</code> 不同，<code>FCOS3D centerness</code>: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>=</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>α</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi mathvariant="normal">Δ</mi><mi>x</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mi mathvariant="normal">Δ</mi><mi>y</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c = e^{-\alpha((\Delta x)^2+(\Delta y)^2)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9869199999999998em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9869199999999998em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span><span class="mopen mtight">(</span><span class="mopen mtight">(</span><span class="mord mtight">Δ</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mopen mtight">(</span><span class="mord mtight">Δ</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> ，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>2.5</mn></mrow><annotation encoding="application/x-tex">\alpha=2.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">.</span><span class="mord">5</span></span></span></span></li>
</ul>
<h4 id="yaw-target-设置"><a class="markdownIt-Anchor" href="#yaw-target-设置"></a> yaw target 设置</h4>
<ul>
<li>本文将 yaw （0 ~ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>π</mi></mrow><annotation encoding="application/x-tex">2\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span>）编码成 yaw （0 ~ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span>）和方向</li>
</ul>
<h3 id="正样本选择"><a class="markdownIt-Anchor" href="#正样本选择"></a> 正样本选择</h3>
<ul>
<li><code>FCOS</code> 是将 <code>feature map</code> 上的每个位置到 GT 中心点的距离小于 <code>1.5 * stride</code> 的点作为正样本。</li>
<li>但 <code>FCOS3D</code> 是 <code>3D</code> 检测，没办法直接使用 <code>FCOS</code> 提出的方法；解决方法和 <code>x, y</code> 坐标回归方法类似，如果 <code>2.5D</code> 坐标下的 <code>x, y</code> 和 <code>feature map</code> 位置距离小于 <code>1.5 * stride</code>，则算作正例。</li>
</ul>
<h3 id="gt-尺度分配"><a class="markdownIt-Anchor" href="#gt-尺度分配"></a> GT 尺度分配</h3>
<ul>
<li>和 <code>FCOS</code> 思想一样</li>
</ul>
<h3 id="不同尺度-feature-map-缩放"><a class="markdownIt-Anchor" href="#不同尺度-feature-map-缩放"></a> 不同尺度 feature map 缩放</h3>
<ul>
<li>和 <code>FCOS</code> 思想一样，只是更丰富 <strong><code>scale.shape == (num_of_level, 3)，分别表示 scale_offset(for xy) / scale_depth(for z) / scale_size(for wlh)</code></strong></li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>本文极大程度的借鉴了 <code>FCOS</code>，相当于 <code>FCOS</code> 的 <code>2.5D</code> 版</li>
<li>加入了很多 <code>trick</code>: log(z), centerness target 定义，encode yaw 等，很 work</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/04/17/FCOS-A-Simple-and-Strong-Anchor-free-Object-Detector/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/17/FCOS-A-Simple-and-Strong-Anchor-free-Object-Detector/" class="post-title-link" itemprop="url">FCOS: A Simple and Strong Anchor-free Object Detector</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-17 10:29:57" itemprop="dateCreated datePublished" datetime="2023-04-17T10:29:57+08:00">2023-04-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Object-Detection/" itemprop="url" rel="index"><span itemprop="name">Object Detection</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/04/17/FCOS-A-Simple-and-Strong-Anchor-free-Object-Detector/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/04/17/FCOS-A-Simple-and-Strong-Anchor-free-Object-Detector/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.09214.pdf">https://arxiv.org/pdf/2006.09214.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/dense_heads/fcos_head.py">https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/dense_heads/fcos_head.py</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>Faster RCNN</code> 系列、<code>SSD</code>、<code>YOLOv2~v5</code>（注意 <code>YOLOv1</code> 不包括在内）都是基于 <code>Anchor</code> 进行预测的。</li>
<li>本文提出一种 Anchor Free 的 one stage 目标检测方法，整个模型结构非常轻量，效果强大。</li>
<li>由于没有了 anchor，所以 fcos 可方便拓展到其他任务。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="网络结构"><a class="markdownIt-Anchor" href="#网络结构"></a> 网络结构</h3>
<p><img src="https://s2.loli.net/2023/04/17/PqfYI2Ka5zEULT1.png" alt="fcos.png" /></p>
<ul>
<li><code>backbone + FPN</code> 输出了 5 种尺度的 <code>feature map</code> 用于预测，由于是全卷积网络，所以 <strong>5 个输出头共享一份参数</strong>，<strong>对于每个尺度的 <code>feature map</code> 上的每一个位置</strong> 预测包括类别（N，Cls，H，W）、框的位置（N，4，H，W）和一个中心置信度（N，1，H，W）。</li>
<li>由于共享输出头，所以本文作者 <strong>为每个输出头增加了不共享的 scale 参数，scale.shape == (num_of_level, 1)</strong><br />
<img src="https://s2.loli.net/2023/04/17/zuh6ilv4jT1xOyp.png" alt="fcos_2.png" /></li>
<li>其中位置参数模型预测的是如上图所示的（l，t，b，r），即相对于 feature map 上的点到 GT 的上下左右偏移量。</li>
</ul>
<h3 id="centerness"><a class="markdownIt-Anchor" href="#centerness"></a> centerness</h3>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>s</mi><mi>s</mi><mo>=</mo><msqrt><mrow><mfrac><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><msup><mi>l</mi><mo>⋆</mo></msup><mo separator="true">,</mo><msup><mi>r</mi><mo>⋆</mo></msup><mo stretchy="false">)</mo></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msup><mi>l</mi><mo>⋆</mo></msup><mo separator="true">,</mo><msup><mi>r</mi><mo>⋆</mo></msup><mo stretchy="false">)</mo></mrow></mfrac><mo>×</mo><mfrac><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><msup><mi>t</mi><mo>⋆</mo></msup><mo separator="true">,</mo><msup><mi>b</mi><mo>⋆</mo></msup><mo stretchy="false">)</mo></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msup><mi>t</mi><mo>⋆</mo></msup><mo separator="true">,</mo><msup><mi>b</mi><mo>⋆</mo></msup><mo stretchy="false">)</mo></mrow></mfrac></mrow></msqrt></mrow><annotation encoding="application/x-tex">centerness=\sqrt{\frac{min(l^\star,r^\star)}{max(l^\star,r^\star)}\times \frac{min(t^\star,b^\star)}{max(t^\star,b^\star)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.6100000000000001em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.23em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">x</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.1899999999999995em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6100000000000001em;"><span></span></span></span></span></span></span></span></span> ，即 <code>GT bbox</code> 内的点越靠近中心越大，越远离中心越小，取值范围 <code>[0, 1]</code>，可视化 <code>centerness</code> 热力图如上图所示。</li>
<li>最终预测时，score 阈值过滤的是 <code>centerness * score</code>。</li>
</ul>
<h3 id="损失函数"><a class="markdownIt-Anchor" href="#损失函数"></a> 损失函数</h3>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mo stretchy="false">{</mo><msub><mi>p</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><mo stretchy="false">}</mo><mo separator="true">,</mo><mo stretchy="false">{</mo><msub><mi>t</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><mo stretchy="false">}</mo><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><msub><mi>N</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mfrac><msub><mo>∑</mo><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><msub><mi>L</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>p</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><mo separator="true">,</mo><msubsup><mi>c</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mo>⋆</mo></msubsup><mo stretchy="false">)</mo><mo>+</mo><mfrac><mi>λ</mi><msub><mi>N</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mfrac><msub><mo>∑</mo><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><msub><mi mathvariant="double-struck">I</mi><mrow><msubsup><mi>c</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mo>⋆</mo></msubsup><mo>&gt;</mo><mn>0</mn></mrow></msub><msub><mi>L</mi><mrow><mi>r</mi><mi>e</mi><mi>g</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>t</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><mo separator="true">,</mo><msubsup><mi>t</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mo>⋆</mo></msubsup><mo stretchy="false">)</mo><mo>+</mo><mfrac><mi>γ</mi><msub><mi>N</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mfrac><msub><mo>∑</mo><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><msub><mi mathvariant="double-struck">I</mi><mrow><msubsup><mi>c</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mo>⋆</mo></msubsup><mo>&gt;</mo><mn>0</mn></mrow></msub><msub><mi>L</mi><mrow><mi>c</mi><mi>t</mi><mi>r</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub><mo separator="true">,</mo><msubsup><mi>s</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mo>⋆</mo></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(\{p_{x,y}\},\{t_{x,y}\})=\frac{1}{N_{pos}}\sum_{x,y}L_{cls}(p_{x,y},c^\star_{x,y})+\frac{\lambda}{N_{pos}}\sum_{x,y}\mathbb{I}_{c_{x,y}^\star&gt;0}L_{reg}(t_{x,y},t^\star_{x,y})+\frac{\gamma}{N_{pos}}\sum_{x,y}\mathbb{I}_{c_{x,y}^\star&gt;0}L_{ctr}(s_{x,y},s^\star_{x,y})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.3874279999999999em;vertical-align:-0.5423199999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285716em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423199999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0016819999999999613em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.4224279999999998em;vertical-align:-0.5423199999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285716em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">λ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423199999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0016819999999999613em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">I</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.214em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.42488571428571426em;"><span></span></span></span></span></span></span><span class="mrel mtight">&gt;</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44741999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.29232em;vertical-align:-0.5423199999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285716em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05556em;">γ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423199999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0016819999999999613em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">I</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.214em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">⋆</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.42488571428571426em;"><span></span></span></span></span></span></span><span class="mrel mtight">&gt;</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44741999999999993em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<ul>
<li>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_{x,y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示在特征图点（x,y）处预测的每个类别的 score</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>c</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mo>⋆</mo></msubsup></mrow><annotation encoding="application/x-tex">c^\star_{x,y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.071804em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span> 表示在特征图点（x,y）处的真实类别（<strong>负样本类别为 0</strong>）</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{x,y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示在特征图点（x,y）处预测的目标边界信息</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{x,y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示在特征图点处预测的centerness</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{cls}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 使用 <code>focal loss</code> 以平衡正负样本</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>r</mi><mi>e</mi><mi>g</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{reg}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 使用 <code>GIOU loss</code>，<strong>且只对正样本计算</strong></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>c</mi><mi>t</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{ctr}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 使用 <code>focal loss</code>，<strong>且只对正样本计算</strong></li>
</ul>
<h3 id="正样本选择策略"><a class="markdownIt-Anchor" href="#正样本选择策略"></a> 正样本选择策略</h3>
<ul>
<li>与 <code>anchor base</code> 方法不同，<code>fcos</code> 对正样本的选择较为苛刻，<strong>仅当 feature map 上的某个点落入 gt bbox 中心区域（sub-box）时才被当做正样本</strong> 。</li>
<li><code>sub-box</code> 的定义： <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>c</mi><mi>x</mi></msub><mo>−</mo><mi>r</mi><mi>s</mi><mo separator="true">,</mo><msub><mi>c</mi><mi>y</mi></msub><mo>−</mo><mi>r</mi><mi>s</mi><mo separator="true">,</mo><msub><mi>c</mi><mi>x</mi></msub><mo>+</mo><mi>r</mi><mi>s</mi><mo separator="true">,</mo><msub><mi>c</mi><mi>y</mi></msub><mo>+</mo><mi>r</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(c_x-rs,c_y-rs,c_x+rs,c_y+rs)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span> ，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>c</mi><mi>x</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>y</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(c_x,c_y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 表示 <code>gt bbox</code> 中心点在原始图上的坐标；<code>s</code> 表示 <code>stride</code> 即当前 <code>feature map</code> 相较于原图下采样倍数；<code>r</code> 表示 <code>radius</code> 半径超参数，在 <code>coco</code> 数据集上取 <code>1.5</code>。</li>
<li>除了正样本之外，其他样本的 <code>cls</code> 类别都被置为 <code>0（background）</code>，负样本只计算 <code>cls loss</code>，不计算 <code>reg loss</code> 和 <code>centerness loss</code>（也没法计算，有框才能计算）。</li>
</ul>
<h3 id="ambiguous-sample"><a class="markdownIt-Anchor" href="#ambiguous-sample"></a> Ambiguous sample</h3>
<ul>
<li><code>anchor free</code> 的检测方法绕不开一个天然的问题：如果一个 <code>feature map</code> 的特征点（x,y）同时是两个 <code>GT bbox</code> 的正例，应该如何预测，毕竟 <code>fcos</code> 每个特征点只预测一个框。</li>
<li>本文缓解该问题的方法是：<strong>使用 FPN box 尺度分配 + center sampling</strong>。
<ul>
<li><code>FPN bbox</code> 尺度分配是一个常用的解决 <code>Ambiguity</code> 问题的方法，越大的 <code>feature map</code> 负责检测越小的框。（将 <code>Ambiguity</code> 出现的概率从 <code>23.16%</code> 降低到 <code>7.24%</code>）</li>
<li><code>center sampling</code>：即上面提到的 sub-box 采样方法，<strong>radius = 1.5</strong>。（将 <code>Ambiguity</code> 出现的概率从 <code>7.24%</code> 降低到 <code>2.66%</code>）</li>
</ul>
</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li><code>FCOS</code> 是一种很简单高效的 <code>2D anchor free</code> 物体检测算法，迁移性强，启发了后面的 <code>FCOS3D</code> 单目 <code>3D</code> 检测。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/04/15/Ultra-Fast-Structure-aware-Deep-Lane-Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/15/Ultra-Fast-Structure-aware-Deep-Lane-Detection/" class="post-title-link" itemprop="url">Ultra Fast Structure-aware Deep Lane Detection</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-15 11:10:31" itemprop="dateCreated datePublished" datetime="2023-04-15T11:10:31+08:00">2023-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Autopilot/" itemprop="url" rel="index"><span itemprop="name">Autopilot</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/04/15/Ultra-Fast-Structure-aware-Deep-Lane-Detection/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/04/15/Ultra-Fast-Structure-aware-Deep-Lane-Detection/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2004.11757.pdf">https://arxiv.org/pdf/2004.11757.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/cfzd/Ultra-Fast-Lane-Detection">https://github.com/cfzd/Ultra-Fast-Lane-Detection</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一种新的车道线检测范式，可以在极低的计算复杂度下精准预测车道线位置。</li>
<li>与常见的使用语义分割算法实现车道线检测的范式不同，本文提出的车道线检测范式是将图片 ROI 区域分割成若干像素块，使用分类的方法判断像素块是否包含车道线。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="算法思想"><a class="markdownIt-Anchor" href="#算法思想"></a> 算法思想</h3>
<p><img src="https://s2.loli.net/2023/04/15/DZCGcId3mWU7hYH.png" alt="ufld.png" /></p>
<ul>
<li>将 ROI 区域（通常是一张图片的下半部分，上半部分是天空不包含车道线）分成若干 <strong>稀疏的行和稠密的列</strong>，论文给出的行数是 <code>18 行 200 列</code>。</li>
<li>模型预测每个小格子是否包含车道线，以及包含的车道线属于哪一个车道线实例（主流 benchmark 要求模型预测相邻的 4 条车道线：| |车| |）。</li>
<li>对于 <code>CULane</code> 数据集，模型输出 <strong>shape == (N, 4, 18, 201)</strong>，分别表示 18 行 200 列每个格子是否包含车道线（所以是 201 分类），以及包含的车道线的实例编号。</li>
<li>加入了一个普通分割辅助任务头加速训练，推理时丢弃，不影响速度。</li>
<li>另外除了分类交叉熵损失函数之外，本文加入了两个车道线相关的先验损失函数：
<ul>
<li>
<p>基于车道线连续属性：每条车道线的第 i 行和第 i + 1 行应该具有相近的位置。</p>
</li>
<li>
<p>基于车道线相对笔直属性：每条车道线点第 i 行和第 i + 1 行的连线应该和第 i + 1 行与第 i + 2 行的连线共线。</p>
</li>
</ul>
</li>
</ul>
<h3 id="部署优化"><a class="markdownIt-Anchor" href="#部署优化"></a> 部署优化</h3>
<ul>
<li>网络末尾使用的高维 FC 层对部署模型加速不利，使用 conv + pixelshuffle（depth to space） 可有效解决。</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>辅助训练输出头是分割任务的标配</li>
<li>结构先验损失函数貌似是个故事，作者开源代码中这两个 loss 的权重都是 0</li>
<li>范式很好，可经过部署优化后上车</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/04/09/tetris/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/09/tetris/" class="post-title-link" itemprop="url">tetris</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-09 20:05:13" itemprop="dateCreated datePublished" datetime="2023-04-09T20:05:13+08:00">2023-04-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/shell-game/" itemprop="url" rel="index"><span itemprop="name">shell game</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/04/09/tetris/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/04/09/tetris/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>《俄罗斯方块》这部电影里游戏作者用命令行玩俄罗斯方块原型机太酷了，所以决定自己实现一把<br />
<img src="https://s2.loli.net/2023/04/09/EtSlrozCOQxYcL8.png" alt="tetris.png" /></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> func_timeout <span class="keyword">import</span> FunctionTimedOut, func_set_timeout</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"><span class="keyword">import</span> keyboard</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> choice</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_choice_block</span>():</span></span><br><span class="line">    blocks = [</span><br><span class="line">        (</span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x][x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x][x] .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">        ),</span><br><span class="line">        (</span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x][x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  .  . [x][x] .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">2</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">            ),</span><br><span class="line">        ),</span><br><span class="line">        (</span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x][x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x] .  .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">        ),</span><br><span class="line">        (</span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x][x][x][x] .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">2</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">3</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">        ),</span><br><span class="line">        (</span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x][x] .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x][x] .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x][x] .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x] .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  . [x] .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">        ),</span><br><span class="line">        (</span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x][x] .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x] .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x][x] .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  .  .  . [x] .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  . [x][x] .  .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">        ),</span><br><span class="line">        (</span><br><span class="line">            <span class="comment"># .  .  .  .  .  .  . [x] .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x][x] .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x] .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  .  . [x][x][x] .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> + <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># .  .  .  . [x][x] .  .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            <span class="comment"># .  .  .  .  . [x] .  .  .  .  .  .  .</span></span><br><span class="line">            (</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span> - <span class="number">1</span>],</span><br><span class="line">                [<span class="number">0</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">1</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">                [<span class="number">2</span>, space.shape[<span class="number">1</span>] // <span class="number">2</span>],</span><br><span class="line">            ),</span><br><span class="line">        ),</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> choice(blocks)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">can_transform</span>():</span></span><br><span class="line">    <span class="keyword">global</span> block_idx, position</span><br><span class="line">    block = block_list[block_idx]</span><br><span class="line">    next_block = block_list[(block_idx + <span class="number">1</span>) % <span class="built_in">len</span>(block_list)]</span><br><span class="line">    shift = (position[<span class="number">1</span>][<span class="number">0</span>] - block[<span class="number">1</span>][<span class="number">0</span>], position[<span class="number">1</span>][<span class="number">1</span>] - block[<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">    next_position = np.zeros_like(position, dtype=np.int64)</span><br><span class="line">    <span class="keyword">for</span> i, p <span class="keyword">in</span> <span class="built_in">enumerate</span>(next_block):</span><br><span class="line">        next_position[i][<span class="number">0</span>] = p[<span class="number">0</span>] + shift[<span class="number">0</span>]</span><br><span class="line">        next_position[i][<span class="number">1</span>] = p[<span class="number">1</span>] + shift[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> next_position[:, <span class="number">0</span>].<span class="built_in">min</span>() &lt; <span class="number">0</span>:</span><br><span class="line">        next_position[:, <span class="number">0</span>] -= next_position[:, <span class="number">0</span>].<span class="built_in">min</span>()</span><br><span class="line">    <span class="keyword">if</span> next_position[:, <span class="number">0</span>].<span class="built_in">max</span>() &gt;= space.shape[<span class="number">0</span>]:</span><br><span class="line">        next_position[:, <span class="number">0</span>] -= next_position[:, <span class="number">0</span>].<span class="built_in">max</span>() - space.shape[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> next_position[:, <span class="number">1</span>].<span class="built_in">min</span>() &lt; <span class="number">0</span>:</span><br><span class="line">        next_position[:, <span class="number">1</span>] -= next_position[:, <span class="number">1</span>].<span class="built_in">min</span>()</span><br><span class="line">    <span class="keyword">if</span> next_position[:, <span class="number">1</span>].<span class="built_in">max</span>() &gt;= space.shape[<span class="number">1</span>]:</span><br><span class="line">        next_position[:, <span class="number">1</span>] -= next_position[:, <span class="number">1</span>].<span class="built_in">max</span>() - space.shape[<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> next_position:</span><br><span class="line">        <span class="keyword">if</span> space[p[<span class="number">0</span>], p[<span class="number">1</span>]] <span class="keyword">and</span> <span class="built_in">list</span>(p) <span class="keyword">not</span> <span class="keyword">in</span> position.tolist():</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> position:</span><br><span class="line">        space[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">False</span></span><br><span class="line">    position = next_position</span><br><span class="line">    block_idx = (block_idx + <span class="number">1</span>) % <span class="built_in">len</span>(block_list)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform</span>():</span></span><br><span class="line">    <span class="keyword">if</span> can_transform():</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> position:</span><br><span class="line">            space[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">True</span></span><br><span class="line">    show_space()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_block</span>():</span></span><br><span class="line">    <span class="keyword">global</span> position</span><br><span class="line">    <span class="keyword">global</span> block_list</span><br><span class="line">    <span class="keyword">global</span> block_idx</span><br><span class="line">    <span class="keyword">global</span> next_block_list</span><br><span class="line">    <span class="keyword">global</span> next_block_idx</span><br><span class="line">    <span class="keyword">if</span> position <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        block_list = next_block_list</span><br><span class="line">        block_idx = next_block_idx</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        block_list = random_choice_block()</span><br><span class="line">        block_idx = choice([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(block_list))])</span><br><span class="line">    block = block_list[block_idx]</span><br><span class="line">    next_block_list = random_choice_block()</span><br><span class="line">    next_block_idx = choice([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(next_block_list))])</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> block:</span><br><span class="line">        <span class="keyword">if</span> space[p[<span class="number">0</span>], p[<span class="number">1</span>]]:</span><br><span class="line">            show_space()</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> block:</span><br><span class="line">        position = np.array(</span><br><span class="line">            block,</span><br><span class="line">            dtype=np.int64,</span><br><span class="line">        )</span><br><span class="line">        space[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">True</span></span><br><span class="line">    show_space()</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">can_down</span>():</span></span><br><span class="line">    down_position = deepcopy(position)</span><br><span class="line">    down_position[:, <span class="number">0</span>] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> down_position[:, <span class="number">0</span>].<span class="built_in">max</span>() &gt;= space.shape[<span class="number">0</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> dp <span class="keyword">in</span> down_position:</span><br><span class="line">        <span class="keyword">if</span> dp.tolist() <span class="keyword">not</span> <span class="keyword">in</span> position.tolist() <span class="keyword">and</span> space[dp[<span class="number">0</span>], dp[<span class="number">1</span>]]:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">can_cancel_layer</span>():</span></span><br><span class="line">    <span class="keyword">for</span> i, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">reversed</span>(space)):</span><br><span class="line">        <span class="keyword">if</span> line.<span class="built_in">sum</span>() == <span class="built_in">len</span>(line):</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(space) - i - <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cancel_layer</span>(<span class="params">layer_label</span>):</span></span><br><span class="line">    <span class="keyword">global</span> score</span><br><span class="line">    space[<span class="number">1</span> : layer_label + <span class="number">1</span>] = space[:layer_label]</span><br><span class="line">    space[<span class="number">0</span>, :] = <span class="literal">False</span></span><br><span class="line">    score += <span class="number">100</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">down</span>():</span></span><br><span class="line">    <span class="keyword">if</span> can_down():</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> position:</span><br><span class="line">            space[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">False</span></span><br><span class="line">        position[:, <span class="number">0</span>] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> position:</span><br><span class="line">            space[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">True</span></span><br><span class="line">    show_space()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">can_left</span>():</span></span><br><span class="line">    left_position = deepcopy(position)</span><br><span class="line">    left_position[:, <span class="number">1</span>] -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> left_position[:, <span class="number">1</span>].<span class="built_in">min</span>() &lt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> lp <span class="keyword">in</span> left_position:</span><br><span class="line">        <span class="keyword">if</span> lp.tolist() <span class="keyword">not</span> <span class="keyword">in</span> position.tolist() <span class="keyword">and</span> space[lp[<span class="number">0</span>], lp[<span class="number">1</span>]]:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">left</span>():</span></span><br><span class="line">    <span class="keyword">if</span> can_left():</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> position:</span><br><span class="line">            space[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">False</span></span><br><span class="line">        position[:, <span class="number">1</span>] -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> position:</span><br><span class="line">            space[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">True</span></span><br><span class="line">    show_space()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">can_right</span>():</span></span><br><span class="line">    right_position = deepcopy(position)</span><br><span class="line">    right_position[:, <span class="number">1</span>] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> right_position[:, <span class="number">1</span>].<span class="built_in">max</span>() &gt;= space.shape[<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> rp <span class="keyword">in</span> right_position:</span><br><span class="line">        <span class="keyword">if</span> rp.tolist() <span class="keyword">not</span> <span class="keyword">in</span> position.tolist() <span class="keyword">and</span> space[rp[<span class="number">0</span>], rp[<span class="number">1</span>]]:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">right</span>():</span></span><br><span class="line">    <span class="keyword">if</span> can_right():</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> position:</span><br><span class="line">            space[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">False</span></span><br><span class="line">        position[:, <span class="number">1</span>] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> position:</span><br><span class="line">            space[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">True</span></span><br><span class="line">    show_space()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_space</span>():</span></span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span> * <span class="number">10</span> + <span class="string">&quot;\tNEXT\t&quot;</span> + <span class="string">&quot;=&quot;</span> * <span class="number">10</span>)</span><br><span class="line">    block = np.array(next_block_list[next_block_idx])</span><br><span class="line">    block[:, <span class="number">1</span>] -= block[:, <span class="number">1</span>].<span class="built_in">min</span>()</span><br><span class="line">    next_block = np.zeros((<span class="number">4</span>, <span class="number">4</span>), dtype=np.bool8)</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> block:</span><br><span class="line">        next_block[p[<span class="number">0</span>], p[<span class="number">1</span>]] = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> next_block:</span><br><span class="line">        s = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> line:</span><br><span class="line">            <span class="keyword">if</span> item:</span><br><span class="line">                s += <span class="string">&quot;[X]&quot;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                s += <span class="string">&quot; . &quot;</span></span><br><span class="line">        <span class="built_in">print</span>(s)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span> * <span class="number">10</span> + <span class="string">&quot;\tGAME AREA\t&quot;</span> + <span class="string">&quot;=&quot;</span> * <span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> space:</span><br><span class="line">        s = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> line:</span><br><span class="line">            <span class="keyword">if</span> item:</span><br><span class="line">                s += <span class="string">&quot;[X]&quot;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                s += <span class="string">&quot; . &quot;</span></span><br><span class="line">        <span class="built_in">print</span>(s)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">30</span> + <span class="string">f&quot;\tSCORE: <span class="subst">&#123;score&#125;</span>\t&quot;</span> + <span class="string">&quot;-&quot;</span> * <span class="number">30</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">keyboard_callback</span>(<span class="params">event: keyboard.KeyboardEvent</span>):</span></span><br><span class="line">    <span class="keyword">if</span> event.event_type == <span class="string">&quot;down&quot;</span>:</span><br><span class="line">        <span class="keyword">if</span> event.name == <span class="string">&quot;left&quot;</span>:</span><br><span class="line">            left()</span><br><span class="line">        <span class="keyword">elif</span> event.name == <span class="string">&quot;right&quot;</span>:</span><br><span class="line">            right()</span><br><span class="line">        <span class="keyword">elif</span> event.name == <span class="string">&quot;down&quot;</span>:</span><br><span class="line">            down()</span><br><span class="line">        <span class="keyword">elif</span> event.name == <span class="string">&quot;up&quot;</span>:</span><br><span class="line">            transform()</span><br><span class="line"><span class="meta">@func_set_timeout(<span class="params"><span class="number">1</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">listen_keyboard</span>():</span></span><br><span class="line">    keyboard.hook(callback=keyboard_callback, suppress=<span class="literal">True</span>)</span><br><span class="line">    keyboard.wait()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">while</span> get_block():</span><br><span class="line">        <span class="keyword">while</span> can_down():</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                listen_keyboard()</span><br><span class="line">            <span class="keyword">except</span> FunctionTimedOut:</span><br><span class="line">                down()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            listen_keyboard()</span><br><span class="line">        <span class="keyword">except</span> FunctionTimedOut:</span><br><span class="line">            <span class="keyword">while</span> can_cancel_layer() &gt; -<span class="number">1</span>:</span><br><span class="line">                cancel_layer(can_cancel_layer())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;score&#125;</span>\tgame over !!!&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    space_shape = (<span class="number">20</span>, <span class="number">10</span>)</span><br><span class="line">    score = <span class="number">0</span></span><br><span class="line">    space = np.zeros(shape=space_shape, dtype=np.bool8)</span><br><span class="line">    position = <span class="literal">None</span></span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="遇到的问题"><a class="markdownIt-Anchor" href="#遇到的问题"></a> 遇到的问题</h2>
<ul>
<li>python 监听字符读入（非 input，input 需要回车结束）好困难，所以该程序 <strong>必须用 root 用户下命令行运行…</strong></li>
<li>python 的超时阻塞式监听更难，<code>func_timeout</code> 在 <code>linux</code> 上运行疑似还有 <code>bug</code>：多线程打开文件但没有关闭，超出 <code>OS limit</code>，在玩十分钟可能才会出现…</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/01/16/Semantic-Segmentation-Decode-Head-Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/01/16/Semantic-Segmentation-Decode-Head-Survey/" class="post-title-link" itemprop="url">Semantic Segmentation Algorithms Survey</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-01-16 19:33:11" itemprop="dateCreated datePublished" datetime="2023-01-16T19:33:11+08:00">2023-01-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Semantic-Segmentation/" itemprop="url" rel="index"><span itemprop="name">Semantic Segmentation</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/01/16/Semantic-Segmentation-Decode-Head-Survey/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/01/16/Semantic-Segmentation-Decode-Head-Survey/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="topic"><a class="markdownIt-Anchor" href="#topic"></a> Topic</h2>
<ul>
<li>本文汇总多种 <strong>语义分割算法 <code>decode head</code></strong> 结构和 <strong>部分分割专用 <code>backbone</code></strong>，用于理解语义分割算法的演进过程</li>
<li><code>decode head</code> 模型来源： <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/__init__.py"><code>mmsegmentaion decode head</code></a></li>
<li>本文的语义分割 <code>decode head</code> 是指满足如下要求的网络结构：
<ol>
<li>输入为 <code>backbone / neck</code> 提取的 <code>feature map</code> 或 <code>feature map list</code></li>
<li>输出为 <code>segmentation</code> 结果</li>
</ol>
</li>
</ul>
<h2 id="语义分割推理过程"><a class="markdownIt-Anchor" href="#语义分割推理过程"></a> 语义分割推理过程</h2>
<h3 id="1-原始特征处理"><a class="markdownIt-Anchor" href="#1-原始特征处理"></a> 1. 原始特征处理</h3>
<ul>
<li>输入的原始特征包括两类：
<ul>
<li><code>backbone</code> 输出的 <code>feature map</code>（例如 <code>PSPNet</code> 输出）</li>
<li><code>backbone</code> 不同阶段 / <code>neck</code> (例如 <code>FPN</code>) 输出的不同尺度的 <code>feature map list</code></li>
</ul>
</li>
<li>对于 <code>feature map</code>，可以 <code>resize</code> 到输出大小再送入 <code>decode head</code>，也可以直接送入 <code>decode head</code>，根据具体算法选择</li>
<li>对于 <code>feature map list</code>，一般有两种做法，根据具体算法选择：
<ol>
<li><code>resize concat</code>: 将所有 <code>feature map</code> 全部 <code>resize</code> 到输出大小后再 <code>concat</code>（例如 <code>FCN-8s</code>）</li>
<li><code>multiple select</code>: 根据 <code>index</code> 在 <code>feature map list</code> 中索引并输出对应的 <code>feature map sub list</code></li>
</ol>
</li>
</ul>
<h3 id="2-特征解码"><a class="markdownIt-Anchor" href="#2-特征解码"></a> 2. 特征解码</h3>
<ul>
<li>将 <strong>1</strong> 中输出的 <code>feature map / feature map list</code> 转化成与输出 <strong>宽高一致</strong> 的 <code>feature map</code>，也是本文具体展开讲的内容</li>
</ul>
<h3 id="3-特征映射到分割任务空间"><a class="markdownIt-Anchor" href="#3-特征映射到分割任务空间"></a> 3. 特征映射到分割任务空间</h3>
<ul>
<li>将 <strong>2</strong> 中输出的特征映射到分割空间，具体通道数与任务定义相关（例如：二分类的语义分割输出通道为 <code>1</code> 或 <code>2</code>，<code>N</code> 分类的语义分割输出通道数为 <code>N</code>）</li>
</ul>
<h2 id="演进过程"><a class="markdownIt-Anchor" href="#演进过程"></a> 演进过程</h2>
<h3 id="第一代在-cnn-结构上创新"><a class="markdownIt-Anchor" href="#第一代在-cnn-结构上创新"></a> 第一代：在 <code>CNN</code> 结构上创新</h3>
<ul>
<li><code>FCN</code>: 2014年，出自 <code>UC Berkeley</code>，分割算法起点</li>
<li><code>PSP</code>: 2016年，出自商汤，<code>FCN</code> + 多尺度</li>
<li><code>ASPP</code>: 2017年，出自 <code>Google</code>，<code>PSP</code> 的优雅实现版（<strong><code>DeepLab V2</code></strong>、<strong><code>DeepLab V3</code></strong>）</li>
<li><code>FPN</code>: 2018年，出自 <code>FAIR</code>，<code>UNet</code> 多尺度的升级版</li>
<li><code>UperNet</code>: 2018年，出自旷视，<code>PSP</code> + <code>FPN</code> 更暴力的多尺度</li>
<li><code>DepthwiseSeparableASPP</code>: 2018年，出自 <code>Google</code>，<code>DeepLab V3</code> 结构的小改动（<strong><code>DeepLab V3+</code></strong>）</li>
<li><code>DepthwiseSeparableFCN</code>: 2019年，出自东芝 + 剑桥，<code>FCN</code> 的轻量化改造（<strong><code>Fast-SCNN</code></strong>）</li>
<li><code>PointRend</code>: 2019年，出自 <code>FAIR</code>，在其他 <code>decode head</code> 基础上级联了一个 <code>subnetwork</code> 实现了图像分割边缘的细化</li>
</ul>
<h3 id="第二代self-attention-non-local-channel-attention"><a class="markdownIt-Anchor" href="#第二代self-attention-non-local-channel-attention"></a> 第二代：<code>Self-Attention</code> (<code>Non-local</code> / <code>Channel Attention</code>)</h3>
<ul>
<li><code>Non-Local</code>: 2017年，出自 <code>FAIR</code>，<code>Self Attention</code> 经典</li>
<li><code>PSANet</code>: 2018年，出自商汤，<code>Non-local</code> 的二维 <s>狗尾续貂</s> 版</li>
<li><code>CCNet</code>: 2018年，出自地平线，<code>Non-local</code> 的低算力版，使用两个低算力的 <code>Attention</code> 替代 <code>Non-local Attention</code></li>
<li><code>DANet</code>: 2018年，出自京东，两路 <code>Non-local</code>，一路 <code>attention to postion</code> 一路 <code>attention to channel</code></li>
<li><code>EncNet</code>: 2018年，出自商汤 + <code>Amazon</code>，优化了 <code>SENet</code> 中的暴力编码方式，在分割任务中额外加入了分类辅助监督</li>
<li><code>EMANet</code>: 2019年，出自北大，<code>attention to channel</code> 和 <code>attention to postion</code> 可分离的 <code>attention</code></li>
<li><code>ANN</code>: 2019年，出自华中科技大学，简化 <code>Non-local</code> 同时引入 <code>PPM</code>，极大的降低了 <code>matmul</code> 和 <code>softmax</code> 两类算子的耗时</li>
<li><code>GCNet</code>: 2019年，出自 <code>MSRA</code>，简化版 <code>Non-local</code> + <code>SENet</code> 的缝合怪</li>
<li><code>OCRNet</code>: 2019年，出自 <code>MSRA</code>，级联结构，在其他 <code>decode head</code> 的输出结果上做了 <code>Self-Attention</code>，并在论文中从 <code>Transformer</code> 角度解释了 <code>Self-Attention</code><s>（Transformer 开始觉醒）</s></li>
<li><code>APCNet</code>: 2019年，出自商汤，复杂网络结构 + 简化矩阵乘实现的 <code>Attention</code></li>
<li><code>DMNet</code>: 2019年，出自商汤，根据输入特征的全局信息动态生成卷积核，本质也是 <code>Attention</code></li>
<li><code>LRASPP</code>: 2019年，出自 <code>Google</code>，全局 <code>scale</code> 实现的 <code>Attention</code>（<strong><code>MobileNet V3</code></strong>）</li>
<li><code>ISANet</code>: 2019年，出自 <code>MSAR</code>，使用 <code>feature map shuffle</code> 实现长范围和短范围的稀疏注意力机制</li>
<li><code>DNLNet</code>: 2020年，出自 <code>MSAR</code>，改进 <code>Non-local</code>，加入了归一化和一元分支</li>
<li><code>BiSeNet</code>: 2019年，出自旷视，在 <code>backbone</code> 之外加入了一个 <code>context branch</code>，将特征提取和 <code>attention</code> 解耦，降低了 <code>attention</code> 恐怖的计算量</li>
<li><code>BiSeNet V2</code>: 2020年，出自腾讯，<code>BiSeNet</code> 的改进</li>
<li><code>SDTC</code>: 2021年，出自美团，<code>BiSeNet</code> 系列的改进版，但由于融合了两路分支到一处，不再 <code>Bilateral</code>，所以用特征提取 <code>SDTC block</code> 命名…</li>
</ul>
<h3 id="第三代transformer"><a class="markdownIt-Anchor" href="#第三代transformer"></a> 第三代：<code>Transformer</code></h3>
<ul>
<li><code>SETR</code>: 2020年，出自腾讯，<code>Vit</code> 做 <code>backbone</code> + <code>FCN / FPN decode head</code></li>
<li><code>DPT</code>: 2021年，出自 <code>Intel</code>，<code>SETR</code> 的升级版，<code>backbone</code> 不变，<code>decode head</code> 更 <code>FPN</code> 了一些</li>
<li><code>Segmenter</code>: 2021年，出自法国 <code>INRIA</code> 研究所，用了纯 <code>Transformer</code> 架构而不是像 <code>SETR / DPT</code> 一样用 <code>Transformer Encoder + CNN Decoder</code> 架构</li>
<li><code>SegFormer</code>: 2021年，出自 <code>NVIDIA</code>，<code>SETR</code> 的高效版</li>
<li><code>KNet</code>: 2021年，出自商汤，<code>decode head</code> 融合了 <code>Channel Attention + Multi-head Attention + RNN</code>，统一了语义分割、实例分割、全景分割框架</li>
</ul>
<h2 id="algorithms"><a class="markdownIt-Anchor" href="#algorithms"></a> Algorithms</h2>
<h3 id="1-fcn"><a class="markdownIt-Anchor" href="#1-fcn"></a> 1. FCN</h3>
<ul>
<li><code>FCN</code> 全称是 <code>Fully Convolutional Networks</code></li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1411.4038.pdf">https://arxiv.org/pdf/1411.4038.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/fcn_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/fcn_head.py</a></li>
</ul>
<h4 id="11-原始特征处理"><a class="markdownIt-Anchor" href="#11-原始特征处理"></a> 1.1 原始特征处理</h4>
<ul>
<li>原始特征处理使用了 <code>resize concat</code> 方式，将多个不同尺度（<code>backbone</code> 不同阶段）的 <code>feature map resize concat</code> 到输出尺寸，如下图所示：<br />
<img src="https://s2.loli.net/2023/01/17/95uvgr4wGKpzm8k.png" alt="FCN1.png" /><br />
<img src="https://s2.loli.net/2023/01/17/SueV71rfDNQmTUM.png" alt="FCN2.png" /></li>
</ul>
<blockquote>
<p>实验证明越多尺度融合分割效果越好</p>
</blockquote>
<h4 id="12-特征解码"><a class="markdownIt-Anchor" href="#12-特征解码"></a> 1.2 特征解码</h4>
<ul>
<li>特征解码只使用了几层普通 <code>Conv</code> + 可选择的 <code>concat input</code> （<code>shortcut</code>）结构</li>
</ul>
<h3 id="2-psp"><a class="markdownIt-Anchor" href="#2-psp"></a> 2. PSP</h3>
<ul>
<li><code>PSP</code> 全称是 <strong><code>Pyramid Scene Parsing</code></strong>（金字塔场景理解）</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1612.01105.pdf">https://arxiv.org/pdf/1612.01105.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/psp_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/psp_head.py</a></li>
</ul>
<h4 id="21-原始特征处理"><a class="markdownIt-Anchor" href="#21-原始特征处理"></a> 2.1 原始特征处理</h4>
<ul>
<li><code>PSPNet</code> 的原始特征是 <code>backbone</code> 最后一层的输出，所以无需原始特征处理</li>
</ul>
<h4 id="22-特征解码"><a class="markdownIt-Anchor" href="#22-特征解码"></a> 2.2 特征解码</h4>
<ul>
<li><code>PSPNet</code> 将输入特征通过 <strong><code>Pyramid Pooling Module</code></strong> 结构做了 <code>feature map</code> 不同尺度 <code>down sample</code> + <code>up sample</code>，如下图所示：<br />
<img src="https://s2.loli.net/2023/01/17/DzUsqPOx9ckKui3.png" alt="PSP.png" /></li>
</ul>
<h3 id="3-aspp"><a class="markdownIt-Anchor" href="#3-aspp"></a> 3. ASPP</h3>
<ul>
<li>ASPP 全称是 <strong><code>Atrous Spatial Pyramid Pooling</code></strong>（空洞空间金字塔池化）</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.05587.pdf">https://arxiv.org/pdf/1706.05587.pdf</a> (大名鼎鼎的 <code>DeepLab V3</code>)</li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/aspp_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/aspp_head.py</a></li>
</ul>
<h4 id="31-原始特征处理"><a class="markdownIt-Anchor" href="#31-原始特征处理"></a> 3.1 原始特征处理</h4>
<ul>
<li><code>DeepLabV3</code> 输入为单个单尺度 <code>feature map</code>，所以此步骤可省略</li>
</ul>
<h4 id="32-特征解码"><a class="markdownIt-Anchor" href="#32-特征解码"></a> 3.2 特征解码</h4>
<p><img src="https://s2.loli.net/2023/01/17/hVstSe2EnTfDFuK.png" alt="ASPP.png" /></p>
<blockquote>
<p>与 <code>PSPNet</code> 很像，<code>PSPNet</code> 是使用普通 <code>Conv</code> 去卷积多种尺度的 <code>Pooled feature map</code>；<code>ASPP</code> 是不改变 <code>feature map</code> 而是使用 <strong>不同空洞系数的 <code>Conv</code></strong></p>
</blockquote>
<h3 id="4-fpn"><a class="markdownIt-Anchor" href="#4-fpn"></a> 4. FPN</h3>
<ul>
<li><code>FPN</code> 全称是 <code>Feature Pyramid Network</code>，出自 kaiming 大神，可以用在所有和 <code>feature map scale</code> 大小相关的领域</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1901.02446.pdf">https://arxiv.org/pdf/1901.02446.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/fpn_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/fpn_head.py</a><br />
<img src="https://s2.loli.net/2023/01/18/TioeVzgHl8yfacW.png" alt="FPN.png" /></li>
</ul>
<h3 id="5-upernet"><a class="markdownIt-Anchor" href="#5-upernet"></a> 5. UperNet</h3>
<ul>
<li><code>UperNet</code> 的全称是 <strong><code>Unified Perceptual Parsing Network</code></strong>（统一感知解析网络），本身是多任务模型：
<ul>
<li>场景分类</li>
<li><code>objects</code> 语义分割</li>
<li><code>parts</code> 语义分割</li>
<li><code>materials</code> 语义分割</li>
<li><code>textures</code> 语义分割<br />
本文只讨论其中的 <code>objects</code> 语义分割部分</li>
</ul>
</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1807.10221.pdf">https://arxiv.org/pdf/1807.10221.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/uper_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/uper_head.py</a></li>
</ul>
<h4 id="51-原始特征处理"><a class="markdownIt-Anchor" href="#51-原始特征处理"></a> 5.1 原始特征处理</h4>
<ul>
<li>本算法在 <code>decode head</code> 中内嵌使用 <code>FPN</code>（而不是以网络 <code>neck</code> 方式使用），所以 <code>feature map list</code> 格式的原始特征无需处理，直接透传到特征解码部分</li>
</ul>
<h4 id="52-特征解码"><a class="markdownIt-Anchor" href="#52-特征解码"></a> 5.2 特征解码</h4>
<p><img src="https://s2.loli.net/2023/01/17/kFMbZexCornsY4L.png" alt="UperNet.png" /></p>
<blockquote>
<p>本文只讨论图中蓝色框部分<br />
<img src="https://s2.loli.net/2023/01/17/gzonXcZwR8J9Qy1.png" alt="UperNet_2.png" /><br />
只需要看蓝色框为输出的通路，算法：</p>
<ol>
<li>在最小尺度 <code>feature map</code> 上使用 <code>PPM</code>（全称 <code>Pyramid Pooling Module</code>，来自于 <code>PSPNet</code>）</li>
<li>使用 <code>FPN</code> 融合多尺度特征</li>
</ol>
</blockquote>
<h3 id="6-depthwiseseparableaspp"><a class="markdownIt-Anchor" href="#6-depthwiseseparableaspp"></a> 6. DepthwiseSeparableASPP</h3>
<ul>
<li>在 <code>DeepLab V3</code> 引入的 <code>ASPP</code> 基础上增加了两点改进：
<ol>
<li>使用 <code>DepthwiseSeparable ASPP</code> 替代 <code>ASPP</code>，减小计算量</li>
<li>增加了一个 <code>vanilla FPN</code> 结构，避免了 <code>DeepLab V3</code> 直接上采样 8 倍预测的问题</li>
</ol>
</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.02611.pdf">https://arxiv.org/pdf/1802.02611.pdf</a> （大名鼎鼎的 <code>DeepLab V3+</code>）</li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/sep_aspp_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/sep_aspp_head.py</a><br />
<img src="https://s2.loli.net/2023/01/17/v25PboYguxBfzkR.png" alt="DASPP.png" /></li>
</ul>
<blockquote>
<p>相较于 <code>DeepLab V3</code> 在 8 倍下采样的 <code>feature map</code> 上使用 ASPP，<code>DeepLab V3+</code> 在更小尺度(16 倍下采样) <code>feature map</code> 上使用 <code>DepthwiseSeparable ASPP</code><br />
同时为了解决小尺度预测的问题，加入了一个 <code>vanilla FPN</code> 做不同尺度特征融合</p>
</blockquote>
<h3 id="7-depthwiseseparablefcn"><a class="markdownIt-Anchor" href="#7-depthwiseseparablefcn"></a> 7. DepthwiseSeparableFCN</h3>
<ul>
<li><code>FCN</code> 的轻量化实现，使用 <code>DWConv</code>(<code>Depthwise Conv</code>) 和 <code>DSConv</code>(<code>Depthwise Separable Conv</code>) 替换 <code>FCN</code> 中的普通 <code>Conv</code></li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1902.04502.pdf">https://arxiv.org/pdf/1902.04502.pdf</a> （<code>Fast-SCNN</code>）</li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/sep_fcn_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/sep_fcn_head.py</a><br />
<img src="https://s2.loli.net/2023/01/18/eL8q1laoUYJ4fDg.png" alt="FastSCNN.png" /></li>
</ul>
<blockquote>
<p>图中的 <code>DWConv</code> 是指 <code>Depthwise Conv</code>（<code>ic == oc == group</code>）<br />
图中的 <code>DSConv</code> 是指 <code>Depthwise Separable Conv</code>，<code>DSConv</code> 不是一个 <code>Conv</code> 而是 <code>Depthwise Conv</code> 和 <code>Pointwise Conv</code>（<code>kernel_size == 1 and group == 1</code>） 以及激活函数 / <code>BN</code> 一起组成的一个 <code>block</code></p>
</blockquote>
<h3 id="8-pointrend"><a class="markdownIt-Anchor" href="#8-pointrend"></a> 8. PointRend</h3>
<ul>
<li><code>PointRend</code> 全称是 <code>point-base rendering</code>（基于点的渲染算法），是一个级联分割算法，实例分割和语义分割都可使用，依赖于一个其他完整的 <code>decode head</code> （例如 <code>FCN</code>）的输出，该算法提出了一个 <code>subnetwork</code>，该结构只关心目标边界点的分割，可预测更准确更 <code>sharp</code> 的目标边界</li>
<li>paper： <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1912.08193.pdf">https://arxiv.org/pdf/1912.08193.pdf</a></li>
<li>code： <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/point_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/point_head.py</a><br />
<img src="https://s2.loli.net/2023/01/24/eq1VOcZbPWzRh3G.png" alt="point.png" /></li>
</ul>
<blockquote>
<ul>
<li><strong>渲染</strong>：渲染（<code>render</code>）是指在电脑中使用三维制作软件将制作的模型经过纹理、绑定、动画、灯光处理后得到模型和动画的图像。三维渲染是使用计算机从数字三维场景中生成二维影像的过程</li>
<li><strong>细分表面算法</strong>：细分表面算法（<code>subdivision surface algorithm</code>）在3D计算机图形中使用，通过递归完善基本级多边形网格来创建弯曲表面<br />
<img src="https://s2.loli.net/2023/01/24/4VdwCTUIj6fGonq.png" alt="point2.png" /></li>
</ul>
</blockquote>
<ul>
<li>本文的核心思想：
<ul>
<li>将计算机图形学中的 <code>Subdivision render</code> 思想用于分割，使用 <code>coarse-to-fine</code> 思想，逐级细分，提高分割效果</li>
<li>使用非均匀采样方法，越高频的区域使用越多的采样点，提高边缘分割效果<br />
<img src="https://s2.loli.net/2023/01/24/G84QBmsxMCTFnrK.png" alt="point3.png" /><br />
<img src="https://s2.loli.net/2023/01/24/m4XCq958gt1yiAE.png" alt="point4.png" /></li>
</ul>
</li>
<li><code>Inference</code> 过程（以 <code>FCN</code> 作为 <code>prev_decode_head</code> 为例）:
<ul>
<li>输入：
<ul>
<li><code>backbone</code> 的输出 <code>x</code>，<code>shape = [batch, channels, height, width]</code></li>
<li><code>FCN</code> 的输出 <code>prev_output</code>，<code>shape = [batch, num_cls, height, width]</code></li>
</ul>
</li>
<li>输出：<code>refine</code> 后的输出，<code>shape = [batch, num_cls, 2 * subdivision_steps * height, 2 * subdivision_steps * width]</code></li>
</ul>
<ol>
<li><code>prev_output copy</code> 一份作为 <code>refined_seg_logits</code></li>
<li><code>refined_seg_logits</code> 插值放大两倍，<code>shape = [batch, num_cls, 2 * height, 2 * width]</code></li>
<li>在 <code>refined_seg_logits</code> 上挑选最 <code>hard</code> 的 <code>N</code> 个点（<code>hard</code> 的定义是：如果一个像素的 <code>top1_cls_logitis</code> 和 <code>top2_cls_logits</code> 越接近，则该点越 <code>hard</code>），输出相对坐标，<code>shape = [batch, N, 2]</code></li>
<li>根据选出的 <code>N</code> 个点的坐标在 <code>x</code> 中找到对应的点（需要插值找出），作为 <code>fine_grained_point_feats</code>，<code>shape = [batch, channels, N]</code></li>
<li>根据选出的 <code>N</code> 个点的坐标在 <code>prev_output</code> 中找到对应的点（需要插值找出），作为 <code>coarse_point_feats</code>，<code>shape = [batch, num_cls, N]</code></li>
<li><code>fine_grained_point_feats</code> 和 <code>coarse_point_feats</code> <code>concat</code> 后经过 <code>Subnetwork</code>（几层 <code>MLP</code>）映射到类别空间 <code>point_logits</code>，<code>shape = [batch, num_cls, N]</code></li>
<li>根据 <code>3</code> 中的 <code>point index</code>，将 <code>6</code> 输出的 <code>point_logits</code> 替换到 <code>1</code> 中的 <code>refined_seg_logits</code> 对应位置</li>
<li>重复 <code>2 ~ 7 subdivision_steps</code> 次，输出最终的 <code>refined_seg_logits</code>，<code>shape = [batch, num_cls, 2 * subdivision_steps * height, 2 * subdivision_steps * width]</code></li>
</ol>
</li>
<li><code>Train</code> 过程：
<ul>
<li>输入：
<ul>
<li><code>backbone</code> 的输出 <code>x</code>，<code>shape = [batch, channels, height, width]</code></li>
<li><code>FCN</code> 的输出 <code>prev_output</code>，<code>shape = [batch, num_cls, height, width]</code></li>
<li><code>gt_semantic_seg</code>，<code>shape = [batch, num_cls, height, width]</code></li>
</ul>
</li>
<li>输出：<code>loss</code></li>
<li><code>Train</code> 过程与 <code>Inference</code> 过程基本相同，区别在于：
<ul>
<li>由于 <code>topk</code> 运算对梯度反向传播不友好，所以在 <code>Train</code> 的过程中使用随机采样点的策略，没有挖掘 <code>hard case</code></li>
<li><code>Train</code> 不会引入多尺度，只会在同一尺度学习 <code>subnetwork</code> 对 <code>point</code> 的分类</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="9-non-local"><a class="markdownIt-Anchor" href="#9-non-local"></a> 9. Non-Local</h3>
<ul>
<li>出自 kaiming 大神，原论文是做三维特征理解（视频理解），二维化后用在分割上也很强</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1711.07971.pdf">https://arxiv.org/pdf/1711.07971.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/nl_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/nl_head.py</a><br />
<img src="https://s2.loli.net/2023/01/17/ExnclXJaKFd9qYs.png" alt="nl.png" /></li>
</ul>
<blockquote>
<p>用于 <code>2</code> 维图像，所以 <code>T == 1</code>，通过增加 <code>(HW, HW)</code> 的特征相关性矩阵给特征带来全局相关性（<code>Attention</code>）</p>
</blockquote>
<ul>
<li><code>decode head</code> 前后处理和 <code>FCN</code> 一致</li>
</ul>
<h3 id="10-psanet"><a class="markdownIt-Anchor" href="#10-psanet"></a> 10. PSANet</h3>
<ul>
<li><code>PSA</code> 的全称是 <strong><code>Point-wise Spatial Attention</code></strong></li>
<li>paper: <a target="_blank" rel="noopener" href="https://hszhao.github.io/papers/eccv18_psanet.pdf">https://hszhao.github.io/papers/eccv18_psanet.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/psa_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/psa_head.py</a><br />
<img src="https://s2.loli.net/2023/01/17/x2MNa93RYDqOLo6.png" alt="PSA.png" /></li>
</ul>
<blockquote>
<p>借鉴于 <code>Non-local</code>，强行给了比较牵强的数学解释，推理过程复杂到需要调用 <code>CUDA</code> 而不是使用 <code>pure pytorch</code></p>
</blockquote>
<h3 id="11-ccnet"><a class="markdownIt-Anchor" href="#11-ccnet"></a> 11. CCNet</h3>
<ul>
<li><code>CC</code> 的全称是 <strong><code>Criss-Cross Attention</code></strong> （十字交叉注意力机制）</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1811.11721.pdf">https://arxiv.org/pdf/1811.11721.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/cc_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/cc_head.py</a><br />
<img src="https://s2.loli.net/2023/01/17/ReFg5H3SsImvKMb.png" alt="CC1.png" /></li>
</ul>
<blockquote>
<p>使用两个十字交叉注意力模块的串联替代 <code>Non-local</code>，降低算力<br />
<img src="https://s2.loli.net/2023/01/17/ph7ErWkazxfBgwI.png" alt="CC2.png" /><br />
整体流程平平无奇</p>
</blockquote>
<ul>
<li><code>decode head</code> 前后处理和 <code>FCN</code> 一致</li>
</ul>
<h3 id="12-danet"><a class="markdownIt-Anchor" href="#12-danet"></a> 12. DANet</h3>
<ul>
<li><code>DANet</code> 全称是 <code>Dual Attention Network</code>（双路 <code>Attention</code> 网络）
<ul>
<li>一路在空间维度 <code>Attention</code>，照搬 <code>Non-local</code></li>
<li>一路在通道维度 <code>Attention</code>，通道维度 <code>Non-local</code></li>
</ul>
</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.02983.pdf">https://arxiv.org/pdf/1809.02983.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/da_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/da_head.py</a><br />
<img src="https://s2.loli.net/2023/01/17/NLj9YZ7VFiJe14y.png" alt="DANet.png" /><br />
<img src="https://s2.loli.net/2023/01/17/ndy84EM1mB7gJPX.png" alt="DANet2.png" /></li>
</ul>
<h3 id="13-encnet"><a class="markdownIt-Anchor" href="#13-encnet"></a> 13. EncNet</h3>
<ul>
<li><code>EncNet</code> 的全称是 <strong><code>Context Encoding Network</code></strong>（上下文编码网络），做法是对网络中间层 <code>feature map</code> 编码到分类空间，加入了分类 <code>Loss</code> 监督</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.08904.pdf">https://arxiv.org/pdf/1803.08904.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/enc_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/enc_head.py</a><br />
<img src="https://s2.loli.net/2023/01/18/Lo5XHarWQDOSeyI.png" alt="EncNet.png" /></li>
</ul>
<blockquote>
<p>对于 <code>SE-loss</code>: 监督图中包含哪些类别的像素，使用交叉熵实现<br />
对于 <code>Encode</code>:</p>
<ul>
<li>从本质上看：
<ul>
<li>上图使用的 <code>Encode</code> 和 <code>SENet</code> (<code>Squeeze and Excitation Network</code>) 对 <code>feature map per channel</code> 编码没有区别</li>
</ul>
</li>
<li>从实现层面看：
<ol>
<li><code>Encode</code> 使用了更在数学上更好解释的编码方式（而不是 <code>SENet</code> 粗暴的 <code>Global Average Pooling</code> 编码方式）</li>
<li><code>Encode</code> 编码空间比 <code>SENet</code> 更大（SENet 每个通道使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\mathbb{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbb">R</span></span></span></span></span> 空间编码，<code>Encode</code> 每个通道使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">\mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span> 空间编码）</li>
</ol>
</li>
</ul>
</blockquote>
<h3 id="14-emanet"><a class="markdownIt-Anchor" href="#14-emanet"></a> 14. EMANet</h3>
<ul>
<li><code>EMA</code> 的全称是 <code>Expectation-Maximization Attention</code>（最大期望注意力），从数学角度解释了 <code>Attention</code>，实现上也是通过多个矩阵乘实现的 <code>channel</code> 与 <code>position</code> 分离的 <code>Attention</code></li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1907.13426.pdf">https://arxiv.org/pdf/1907.13426.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/ema_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/ema_head.py</a><br />
<img src="https://s2.loli.net/2023/01/18/8uPSlDdEgFRZAxb.png" alt="EMA.png" /></li>
</ul>
<h3 id="15-ann"><a class="markdownIt-Anchor" href="#15-ann"></a> 15. ANN</h3>
<ul>
<li><code>ANN</code> 全称是 <strong><code>Asymmetric Non-local</code></strong>（非对称 <code>Non-local</code>）, 简化 <code>Non-local</code> 同时引入 <code>PPM</code>，极大的降低了 <code>matmul</code> 和 <code>softmax</code> 两类算子的耗时</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1908.07678.pdf">https://arxiv.org/pdf/1908.07678.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/ann_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/ann_head.py</a><br />
<img src="https://s2.loli.net/2023/01/17/92ZvHBoUJXrEkKS.png" alt="ANN.png" /></li>
</ul>
<blockquote>
<p>在 <code>key</code> / <code>value</code> 上对特征进行了降维 <code>N -&gt; S</code>，由下图可知，上图的 <code>sample</code> 方法具体是指 <code>PPM</code>（<code>Pyramid Pooling Module</code>）<br />
<img src="https://s2.loli.net/2023/01/17/XjqQLEJ85gsKMit.png" alt="ANN2.png" /><br />
<code>AFNB</code> 全称是 <code>Asymmetric Fusion Non-local Block</code><br />
<code>APNB</code> 全称是 <code>Asymmetric Pyramid Non-local Block</code><br />
二者对 <code>Non-local</code> 的 <code>Self-Attention</code> 进行简化，例如 <code>share key value</code></p>
</blockquote>
<h3 id="16-gcnet"><a class="markdownIt-Anchor" href="#16-gcnet"></a> 16. GCNet</h3>
<ul>
<li><code>GCNet</code> 的全称是 <strong><code>Global Context Network</code></strong>，作者认为 <code>Non-local</code> 对全局信息把握的不够好，本文是简化版 <code>Non-local</code> + <code>SENet</code> 的缝合怪，<code>Non-local</code> 的 <code>Spatial Attention</code> 和 <code>SENet</code> 的 <code>Channel Attention</code> 结合</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.11492.pdf">https://arxiv.org/pdf/1904.11492.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/gc_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/gc_head.py</a><br />
<img src="https://s2.loli.net/2023/01/17/2e3AWOGEnfiRqdx.png" alt="GC2.png" /></li>
</ul>
<blockquote>
<p><code>Non-local</code> 结构的化简<br />
<img src="https://s2.loli.net/2023/01/17/wn6iBDPHM9h7pKC.png" alt="GC.png" /><br />
作者认为一个全局上下文建模结构如图 (a) 所示<br />
图 (b) 为简化后的 <code>Non-local</code> 结构<br />
图 © 是 <code>SENet</code> 结构<br />
图 (d) 是本文提出的 <code>GC</code> 结构</p>
</blockquote>
<ul>
<li><code>decode head</code> 前后处理和 <code>FCN</code> 一致</li>
</ul>
<h3 id="17-ocrnet"><a class="markdownIt-Anchor" href="#17-ocrnet"></a> 17. OCRNet</h3>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.11065.pdf">https://arxiv.org/pdf/1909.11065.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/ocr_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/ocr_head.py</a></li>
<li><code>OCR</code> 的全称是 <strong><code>Object Contextual Representations</code></strong>（目标上下文表征）<s>而不是 <code>Optical Character Recognition</code>（光学字符识别）</s>，和前面的模型结构不同，<code>OCRNet</code> 是一种 <code>Cascade Encoder Decoder</code> 结构的 <code>decode head</code> ，该算法依赖于其他算法输出的分割结果，如下图所示（<code>OCRNet</code> 依赖于 <code>FCN</code> 的输出）：<br />
<img src="https://s2.loli.net/2023/01/18/yJZBx2v1YOuPlir.png" alt="OCR.png" /></li>
</ul>
<blockquote>
<p>上图中粉红色的部分即为 <code>OCRNet decode head</code><br />
<img src="https://s2.loli.net/2023/01/18/TQgwaJMGYnSDux6.png" alt="OCR2.png" /><br />
论文中给出的算法架构图，给中间结果赋予了可解释的含义</p>
</blockquote>
<h3 id="18-apcnet"><a class="markdownIt-Anchor" href="#18-apcnet"></a> 18. APCNet</h3>
<ul>
<li><code>APCNet</code> 的全称是 <code>Adaptive Pyramid Context Network</code>（自适应金字塔上下文），该算法引入了 <code>Adaptive Context Modules（ACM）</code>（自适应上下文模块），本质就是通过矩阵乘实现全局 <code>Attention</code></li>
<li>paper: <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Adaptive_Pyramid_Context_Network_for_Semantic_Segmentation_CVPR_2019_paper.pdf">https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Adaptive_Pyramid_Context_Network_for_Semantic_Segmentation_CVPR_2019_paper.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/apc_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/apc_head.py</a><br />
<img src="https://s2.loli.net/2023/01/25/7YmA9BQneXJDS8P.png" alt="APC.png" /></li>
</ul>
<h3 id="19-dmnet"><a class="markdownIt-Anchor" href="#19-dmnet"></a> 19. DMNet</h3>
<ul>
<li><code>DMNet</code> 的全称是 <code>Dynamic Multi-scale Filters Network</code>，本文根据输入特征动态获得多种尺度的卷积核参数，本质也是一种全局 <code>Attention</code> 机制</li>
<li>paper: <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/He_Dynamic_Multi-Scale_Filters_for_Semantic_Segmentation_ICCV_2019_paper.pdf">https://openaccess.thecvf.com/content_ICCV_2019/papers/He_Dynamic_Multi-Scale_Filters_for_Semantic_Segmentation_ICCV_2019_paper.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/dm_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/dm_head.py</a><br />
<img src="https://s2.loli.net/2023/01/25/dlIVOLQYiEtvaJj.png" alt="DMNet2.png" /></li>
</ul>
<blockquote>
<p>之前的网络结构都是通过空洞卷积或大卷积核实现多尺度<br />
<code>DMNet</code> 通过输入特征的 <code>Adaptive Pooling</code> 生成动态卷积核实现多尺度<br />
<img src="https://s2.loli.net/2023/01/25/VCFliXsh2efmM54.png" alt="DMNet.png" /></p>
</blockquote>
<h3 id="20-lraspp"><a class="markdownIt-Anchor" href="#20-lraspp"></a> 20. LRASPP</h3>
<ul>
<li><code>LRASPP</code> 全称是 <code>Lite Reduced Atrous Spatial Pyramid Pooling</code>（轻量简化空洞空间金字塔池化），是在 <code>MobileNet V3</code> 论文中提出的结构，是和 <code>MobileNet V2</code> 提出的 <code>RASPP</code> 结构对比，更轻量效果更好；从实现上看 <code>LRASPP</code> 并没有空洞卷积和空间金字塔池化…，而是通过全局 <code>scale</code> 实现的 <code>Attention</code></li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.02244.pdf">https://arxiv.org/pdf/1905.02244.pdf</a> (<strong><code>MobileNet V3</code></strong>)</li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/dm_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/dm_head.py</a><br />
<img src="https://s2.loli.net/2023/01/25/yF85ZoGsqYIKEDP.png" alt="LRASPP.png" /></li>
</ul>
<h3 id="21-isanet"><a class="markdownIt-Anchor" href="#21-isanet"></a> 21. ISANet</h3>
<ul>
<li><code>ISANet</code> 的全称是 <code>Interlaced Sparse Attention Network</code>（交错稀疏注意力网络），通过 <code>feature map shuffle</code> 实现长范围和短范围的稀疏注意力。</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1907.12273.pdf">https://arxiv.org/pdf/1907.12273.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/isa_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/isa_head.py</a><br />
<img src="https://s2.loli.net/2023/01/26/q2KaO94bMpnQdlu.png" alt="ISANet.png" /></li>
</ul>
<blockquote>
<ul>
<li>利用 <code>feature map</code> 重排实现长范围或短范围的稀疏注意力。</li>
</ul>
</blockquote>
<h3 id="22-dnlnet"><a class="markdownIt-Anchor" href="#22-dnlnet"></a> 22. DNLNet</h3>
<ul>
<li><code>DNL</code> 的全称是 <code>Disentangled Non-Local</code>（分离 <code>Non-local</code>），对原始 <code>Non-local</code> 做了改进，参数量和计算量更高，效果更好</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.06668.pdf">https://arxiv.org/pdf/2006.06668.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/dnl_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/dnl_head.py</a><br />
<img src="https://s2.loli.net/2023/01/18/TDshKaot8xqC2BE.png" alt="DNL.png" /></li>
</ul>
<blockquote>
<p><code>DNL</code> 结构（图 d）在原始 <code>Non-local</code> 结构（图 a）上做了如下改动：</p>
<ol>
<li>加入了一元 <code>Non-local</code> 分支 <code>Unary Non-local</code></li>
<li>在二元分支矩阵乘之前加入了白化操作（ <code>H*W</code> 维度减均值，相当于 <code>instance norm</code>）<br />
<img src="https://s2.loli.net/2023/01/18/f6riCoLFzTYN2RH.png" alt="DNL2.png" /><br />
由于减了均值，所以二元分支上 “+” 这一点在 <code>Attention map</code> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>H</mi><mi>W</mi><mo>×</mo><mi>H</mi><mi>W</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\in \mathbb{R}^{HW\times HW}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span></span></span></span></span></span></span></span> 上的索引 <code>heat map</code> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\in \mathbb{R}^{H\times W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span></span></span></span></span></span></span></span> 变干净很多（相当只学习残差）<br />
这张图也从侧面反映了 <code>Non-local</code> 还是很强的，<code>Attention</code> 不是在讲故事</li>
</ol>
</blockquote>
<h3 id="23-bisenet"><a class="markdownIt-Anchor" href="#23-bisenet"></a> 23. BiSeNet</h3>
<ul>
<li><code>BiSeNet</code> 的全称是 <code>Bilateral Segmentation Network</code>（双边分割网络），是一个分割专用的神经网络（包括专用 <code>backbone</code> 和 <code>decode head</code>）</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1808.00897.pdf">https://arxiv.org/pdf/1808.00897.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/bisenetv1.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/bisenetv1.py</a><br />
<img src="https://s2.loli.net/2023/01/28/VfMGKkSAnR1zwBv.png" alt="BiSenet2.png" /></li>
</ul>
<blockquote>
<ul>
<li><code>backbone</code> 主要分成两个分支 <code>spatial path</code> 和 <code>context path</code>，本质就是在基础 <code>backbone</code> 的基础上加入了一个计算量（通道数）非常小的 <code>attention branch</code> 增加上下文信息，最后融合两通道特征送入 <code>decode head</code></li>
<li><code>decode head</code> 就是基础的 <code>FCN</code></li>
</ul>
</blockquote>
<h3 id="24-bisenet-v2"><a class="markdownIt-Anchor" href="#24-bisenet-v2"></a> 24. BiSeNet V2</h3>
<ul>
<li><code>BiSeNet</code> 的改进版</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2004.02147.pdf">https://arxiv.org/pdf/2004.02147.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/bisenetv2.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/bisenetv2.py</a><br />
<img src="https://s2.loli.net/2023/01/28/zDHs1mFn5Cu43RE.png" alt="BiSenet_v2_1.png" /></li>
</ul>
<blockquote>
<p>对 <code>BiSeNet</code> 主要改进有:</p>
<ul>
<li><code>context branch</code> 上增加了更多更复杂的模块，可更好收集上下文信息</li>
<li><code>context branch</code> 上增加了更多监督，每个尺度上都有监督损失</li>
<li>分支融合模块设计的更加复杂</li>
</ul>
</blockquote>
<h3 id="25-sdtc"><a class="markdownIt-Anchor" href="#25-sdtc"></a> 25. SDTC</h3>
<ul>
<li><code>SDTC</code> 的全称是 <code>Short-Term Dense Concatenate network</code>，在 <code>BiSeNet</code> 系列的基础上将 <code>context branch</code> 变成训练时的监督（或者说融合两路信息到一路上）</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.13188.pdf">https://arxiv.org/pdf/2104.13188.pdf</a></li>
<li>code:
<ul>
<li>backbone: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/SDTC.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/SDTC.py</a></li>
<li>decode head: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/sdtc_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/sdtc_head.py</a><br />
<img src="https://s2.loli.net/2023/01/28/fBdi6THRtnpcYLI.png" alt="SDTC.png" /></li>
</ul>
</li>
</ul>
<blockquote>
<p>很新颖的 Loss 设计，效果和计算量都优于 <code>BiSeNet</code> 系列<br />
<img src="https://s2.loli.net/2023/01/28/9HqMVUDIJQg3fdi.png" alt="SDTC2.png" /><br />
这就是 <code>SDTC</code> 模块</p>
</blockquote>
<h3 id="26-setr"><a class="markdownIt-Anchor" href="#26-setr"></a> 26. SETR</h3>
<ul>
<li><code>SETR</code> 的全称是 <code>Segmentation Transformer</code></li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2012.15840.pdf">https://arxiv.org/pdf/2012.15840.pdf</a></li>
<li>code:
<ul>
<li>backbone: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/vit.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/vit.py</a></li>
<li><code>SETR_PUP_decode_head</code>: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/setr_up_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/setr_up_head.py</a></li>
<li><code>SETR_MLA_decode_head</code>: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/setr_mla_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/setr_mla_head.py</a><br />
<img src="https://s2.loli.net/2023/01/25/MLDcPIBwT8kaoqJ.png" alt="SETR.png" /></li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>本质是 <code>Vit（vision transformer）</code> 做 <code>backbone</code>，<code>FCN</code> / 类似 <code>FPN</code> 做 <code>decode head</code> 的分割算法</li>
<li>为了缩减计算量，<code>Vit</code> 会将原图剪成多个 <code>patch</code>（<code>worth 16x16 words...</code>），每个 <code>patch</code> 单独输入到 24 层 <code>Transformer Encoder</code> 中，每个 <code>patch</code> 内部独立做全局 <code>attention</code></li>
<li>剪 <code>patch</code> 带来的问题是：与其他 <code>CNN backbone + decode head</code> 结构不同，<code>Transformer backbone + decode head</code> 结构中 <code>decode head</code> 需要顺序 <code>inference</code> 每个 <code>patch feature</code>（注意图a <code>Decoder</code> 输入为多个 <code>patch feature</code>），最后拼回到整张图大小</li>
<li><code>SETR_UPU decode head</code> == <code>sequence FCN</code></li>
<li><code>SETR_MLA decode head</code> == <code>sequence FPN</code>（<code>Attention</code> 不改变输入宽高，所以不存在严格意义上的 <strong>多尺度</strong>，只是不同网络深度的特征）</li>
</ul>
</blockquote>
<h3 id="27-dptnet"><a class="markdownIt-Anchor" href="#27-dptnet"></a> 27. DPTNet</h3>
<ul>
<li><code>DPTNet</code> 的全称是 <code>Dense Prediction Transformer Network</code>，本质和 <code>SETR</code> 一样都是使用 <code>Vit</code> 做 <code>backbone</code></li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.13413.pdf">https://arxiv.org/pdf/2103.13413.pdf</a></li>
<li>code:
<ul>
<li>backbone: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/vit.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/vit.py</a></li>
<li>decode head: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/dpt_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/dpt_head.py</a><br />
<img src="https://s2.loli.net/2023/01/25/oSCVpNAwgGI4bBs.png" alt="DPT.png" /></li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>本质和 <code>SETR</code> 一样都是使用 <code>Vit</code> 做 <code>backbone</code></li>
<li>和 <code>SETR</code> 不同的地方在于：
<ul>
<li>不同 <code>backbone</code> 深度特征融合方式更复杂，更接近 <code>FPN</code></li>
<li><code>decode head</code> 不再是输入 <code>sequence patch feature</code>，而是输入融合后的全图 <code>feature</code></li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="28-segmenter"><a class="markdownIt-Anchor" href="#28-segmenter"></a> 28. Segmenter</h3>
<ul>
<li><code>Segmenter</code> 全称是 <code>Segmentation Transformer</code>，用了纯 <code>Transformer</code> 架构而不是 <code>Transformer Encoder + CNN Decoder</code> 架构</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2105.05633.pdf">https://arxiv.org/pdf/2105.05633.pdf</a></li>
<li>code:
<ul>
<li>backbone: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/vit.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/vit.py</a></li>
<li>decode head: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/segmenter_mask_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/segmenter_mask_head.py</a><br />
<img src="https://s2.loli.net/2023/01/25/xhemlYgjH3Vw5ks.png" alt="Segmenter.png" /></li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>用了纯 <code>Transformer</code> 架构（<code>Transformer Encoder + Decoder</code>），<code>SETR</code> 和 <code>DPT</code> 都是 <code>Transformer Encoder + CNN Decoder</code></li>
</ul>
</blockquote>
<h3 id="29-segformer"><a class="markdownIt-Anchor" href="#29-segformer"></a> 29. SegFormer</h3>
<ul>
<li><code>SegFormer</code> 全称也是 <code>Segmentation Transformer</code>…，是 <code>NVIDIA</code> 对 <code>SETR</code> 的高效实现版，<code>backbone</code> 和 <code>decoder head</code> 都进行了轻量化升级</li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2105.15203.pdf">https://arxiv.org/pdf/2105.15203.pdf</a></li>
<li>code:
<ul>
<li>backbone: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/mit.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/backbones/mit.py</a></li>
<li>decoder head: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/segformer_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/segformer_head.py</a><br />
<img src="https://s2.loli.net/2023/01/25/o2VTBwjG8NkUA5H.png" alt="SegFormer.png" /></li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li><code>backbone</code> 不再是标准 <code>Transformer Encoder（Vit）</code>，而是改成了更轻量化的 <code>MixVisionTransformer（Mit）</code>
<ul>
<li><code>Mit</code> 使用了更大的 <code>patch</code> 且 <code>patch</code> 之间存在 <code>overlap</code></li>
<li><code>Mit</code> 使用了 <code>coarse-to-fine</code> 的特征表示，随着 <code>Transformer Encoder</code> 变深 <code>feature map</code> 宽高变小</li>
<li><code>Mit</code> 使用了更简单的 <code>Self-Attention</code> 公式</li>
<li><code>Mit</code> 去掉了 <code>position embeding</code>，使用了 <code>Mix-FFN</code></li>
</ul>
</li>
<li><code>decode head</code> 使用了纯 <code>MLP</code>，且很自然的融合了多尺度（<s>真.多尺度</s>）</li>
</ul>
</blockquote>
<h3 id="30-knet"><a class="markdownIt-Anchor" href="#30-knet"></a> 30. KNet</h3>
<ul>
<li><code>KNet</code> 的全称是 <code>Kernel Network</code>，是一种跳出语义分割、实例分割、全景分割原有框架的一种新分割范式，用一组 <code>kernel</code> 去预测一个分割 <code>mask</code>，最多预测 <code>num_proposals</code> 个（类似 <code>DETR</code> 的策略），训练时用最优匹配的方法计算损失函数；优点是在框架上统一了所有分割任务（语义分割、实例分割、全景分割），缺点 <code>decode head</code> 就是实现复杂，融合了 <code>Channel Attention + Multi-head Attention + RNN</code></li>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.14855.pdf">https://arxiv.org/pdf/2106.14855.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/knet_head.py">https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/decode_heads/knet_head.py</a><br />
<img src="https://s2.loli.net/2023/01/30/WHFi1SLMU6ZQcT5.png" alt="KNet2.png" /></li>
</ul>
<blockquote>
<p>从框架上统一了三种分割方式<br />
<img src="https://s2.loli.net/2023/01/30/D7PkZdmbtJexFjI.png" alt="KNet.png" /><br />
红字标出的是每个张量的 <code>shape</code><br />
绿字标出的是每个计算过程实际是在做什么<br />
上述过程会像 <code>RNN</code> 一样循环多次去更新 <code>kernel</code>，使得结果更好（重复使用 <code>backbone</code> 的输出）</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2022/12/25/Learning-Diverse-and-Discriminative-Representations-via-the-Principle-of-Maximal-Coding-Rate-Reduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/25/Learning-Diverse-and-Discriminative-Representations-via-the-Principle-of-Maximal-Coding-Rate-Reduction/" class="post-title-link" itemprop="url">Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-12-25 09:07:42" itemprop="dateCreated datePublished" datetime="2022-12-25T09:07:42+08:00">2022-12-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MCR2/" itemprop="url" rel="index"><span itemprop="name">MCR2</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/12/25/Learning-Diverse-and-Discriminative-Representations-via-the-Principle-of-Maximal-Coding-Rate-Reduction/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/12/25/Learning-Diverse-and-Discriminative-Representations-via-the-Principle-of-Maximal-Coding-Rate-Reduction/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.08558.pdf">https://arxiv.org/pdf/2006.08558.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/ryanchankh/mcr2.git">https://github.com/ryanchankh/mcr2.git</a></li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h3>
<ul>
<li>本文提出一种 <strong>最大编码率降低（MCR2）</strong> 表征算法，本质是一种表征损失函数，本算法有效优化了表征空间，在有监督学习（分类）与自监督学习（聚类）都取得了不错的效果。</li>
</ul>
<h3 id="maximal-coding-rate-reduction"><a class="markdownIt-Anchor" href="#maximal-coding-rate-reduction"></a> Maximal Coding Rate Reduction</h3>
<ul>
<li>什么是一个好的表征？一个好的表征应该有哪些性质？
<ul>
<li>一个好的表征应该充分利用表征空间。</li>
<li>一个好的表征在同一类下的表征应该尽可能的相似。</li>
</ul>
</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>C</mi><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MCR^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> Loss
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>Z</mi><mo separator="true">,</mo><mi>ϵ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>l</mi><mi>o</mi><mi>g</mi><mi>d</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><mi>I</mi><mo>+</mo><mfrac><mi>d</mi><mrow><mi>m</mi><msup><mi>ϵ</mi><mn>2</mn></msup></mrow></mfrac><mi>Z</mi><msup><mi>Z</mi><mi>T</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R(Z, \epsilon)=\frac{1}{2}logdet(I+\frac{d}{m\epsilon^2}ZZ^T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mtight"><span class="mord mathnormal mtight">ϵ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>R</mi><mi>c</mi></msup><mo stretchy="false">(</mo><mi>Z</mi><mo separator="true">,</mo><mi>ϵ</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">Π</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><mfrac><mrow><mi>t</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi mathvariant="normal">Π</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mn>2</mn><mi>m</mi></mrow></mfrac><mi>l</mi><mi>o</mi><mi>g</mi><mi>d</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><mi>I</mi><mo>+</mo><mfrac><mi>d</mi><mrow><mi>t</mi><mi>r</mi><mo stretchy="false">(</mo><msub><mi mathvariant="normal">Π</mi><mi>j</mi></msub><mo stretchy="false">)</mo><msup><mi>ϵ</mi><mn>2</mn></msup></mrow></mfrac><mi>Z</mi><msub><mi mathvariant="normal">Π</mi><mi>j</mi></msub><msup><mi>Z</mi><mi>T</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R^c(Z,\epsilon|\Pi)=\sum_{j=1}^k\frac{tr(\Pi_j)}{2m}logdet(I+\frac{d}{tr(\Pi_j)\epsilon^2}Z\Pi_j Z^T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϵ</span><span class="mord">∣</span><span class="mord">Π</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.468138em;vertical-align:-0.43581800000000004em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9890079999999999em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.03232em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">m</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.50732em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mtight">Π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.4224279999999998em;vertical-align:-0.5423199999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mtight">Π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mord mtight"><span class="mord mathnormal mtight">ϵ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423199999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord"><span class="mord">Π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo><mi>max</mi><mo>⁡</mo></mo><mrow><mi>θ</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">Π</mi></mrow></msub><mi mathvariant="normal">Δ</mi><mi>R</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi mathvariant="normal">Π</mi><mo separator="true">,</mo><mi>ϵ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>Z</mi><mo separator="true">,</mo><mi>ϵ</mi><mo stretchy="false">)</mo><mo>−</mo><msup><mi>R</mi><mi>c</mi></msup><mo stretchy="false">(</mo><mi>Z</mi><mo separator="true">,</mo><mi>ϵ</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">Π</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\max_{\theta|\Pi} \Delta R(Z(\theta),\Pi,\epsilon)=R(Z, \epsilon)-R^c(Z,\epsilon|\Pi)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mord mtight">∣</span><span class="mord mtight">Π</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϵ</span><span class="mord">∣</span><span class="mord">Π</span><span class="mclose">)</span></span></span></span></li>
<li>其中：
<ul>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">Z\in\mathbb R^{d\times m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span> ，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> 是表征向量的长度，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> 是一个 <code>batch</code> 的大小，典型值是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>=</mo><mn>128</mn><mo separator="true">,</mo><mtext> </mtext><mi>m</mi><mo>=</mo><mn>1000</mn></mrow><annotation encoding="application/x-tex">d=128,\ m=1000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mord">2</span><span class="mord">8</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span></span></span></span> 。</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>e</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">det</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span></span></span></span> 表示行列式的值， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>d</mi><mi>e</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">logdet</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span></span></span></span> 表示行列式的值的自然对数。</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Π</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\Pi_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord">Π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示选择函数，选择属于类 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 的特征向量进行计算。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>C</mi><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MCR^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> Loss 解析
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>e</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">det</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span></span></span></span> 行列式函数可以用于衡量一个矩阵中向量的正交程度，行列式的值越大，矩阵中向量越正交，向量实际利用的表征空间越大。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>a</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>b</mi></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>c</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>d</mi></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">A=\begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">a</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">b</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span></span></span> 矩阵的行列式表示由向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub><mo>=</mo><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">]</mo><mo separator="true">,</mo><mtext> </mtext><msub><mi>v</mi><mn>2</mn></msub><mo>=</mo><mo stretchy="false">[</mo><mi>c</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">v_1 = [a, b],\ v_2=[c, d]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">b</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">d</span><span class="mclose">]</span></span></span></span> 组成的平行四边形的面积，如下图所示，当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><mtext> </mtext><msub><mi>v</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">v_1,\ v_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 向量正交时，面积最大，行列式值最大。<br />
<img src="https://s2.loli.net/2022/12/25/SeQTrFG6RmzghE7.png" alt="det.png" /></li>
<li>同理，在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> 维空间下，当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> 个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> 维空间越正交，组成的 <strong>空间积</strong> 越大。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><msup><mi>Z</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">ZZ^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 是个实对称矩阵，因此是半正定矩阵，因此 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>+</mo><mi>Z</mi><msup><mi>Z</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">I + ZZ^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 是个正定矩阵，因此 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>+</mo><mi>Z</mi><msup><mi>Z</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">I+ZZ^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 的行列式的值 &gt; 0，因此 <code>logdet</code> 有定义。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>C</mi><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MCR^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> Loss 的实际含义是：<strong>所有表征向量尽可能正交，属于同一个类的表征向量尽可能不正交</strong>，因此属于同一个类别的表征向量会尽可能共线，不同类别会尽可能正交。</li>
<li>Loss 中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo separator="true">,</mo><mtext> </mtext><mi>m</mi></mrow><annotation encoding="application/x-tex">d,\ m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">d</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span></span></span></span> 都是平衡因子，平衡因向量的长度和统计集大小引起的数值变化。</li>
</ul>
</li>
<li>在使用 Cifar10 数据集训练后，将输出的 128 维度表征使用任意分类器（SVM / KNN / 单层神经网络）都很容易进行分类，达到 95+ 的准确率。</li>
<li>而且 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>C</mi><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MCR^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> Loss 在分类任务中的一个优势在于：对于存在错误标签的数据，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>C</mi><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MCR^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 比交叉熵对错误标签的敏感度更低，如下图所示：<br />
<img src="https://s2.loli.net/2022/12/25/NIzxw9FZc6BJuW5.png" alt="MCR2 and CE.png" /></li>
<li>面对聚类任务，由于没有类别信息，损失函数变成： <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo><mi>max</mi><mo>⁡</mo></mo><mrow><mi>θ</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">Π</mi></mrow></msub><mi mathvariant="normal">Δ</mi><mi>R</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi mathvariant="normal">Π</mi><mo separator="true">,</mo><mi>ϵ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>Z</mi><mo separator="true">,</mo><mi>ϵ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\max_{\theta|\Pi} \Delta R(Z(\theta),\Pi,\epsilon)=R(Z, \epsilon)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mord mtight">∣</span><span class="mord mtight">Π</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span></span></span></span> ，即：<strong>尽可能充分利用表征空间</strong> 。</li>
</ul>
<h2 id="throught"><a class="markdownIt-Anchor" href="#throught"></a> Throught</h2>
<ul>
<li>本文提出的方法从表征角度讲非常 make sense，但存在的问题是：依然无法摆脱 <strong>维度灾难</strong>，因此 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>C</mi><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MCR^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 也仅仅被用于低维度表征空间中，无法在神经网络的每一层都使用，在分类任务中也仅仅可以被当做一个在交叉熵的升级版本（交叉熵作用于类别维度，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>C</mi><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MCR^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 监督维度更高）。</li>
<li>一个简单的想法确实可以有效提高聚类任务的模型效果，所以为后面的 <strong>Deep (Convolution) Networks from First Principles</strong> 提供了理论基础。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2022/11/21/CUDA-%E5%9F%BA%E7%A1%80%E4%B9%8B%E7%9F%A9%E9%98%B5%E4%B9%98%E4%BC%98%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/21/CUDA-%E5%9F%BA%E7%A1%80%E4%B9%8B%E7%9F%A9%E9%98%B5%E4%B9%98%E4%BC%98%E5%8C%96/" class="post-title-link" itemprop="url">CUDA 基础之矩阵乘优化</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-21 22:14:58" itemprop="dateCreated datePublished" datetime="2022-11-21T22:14:58+08:00">2022-11-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CUDA/" itemprop="url" rel="index"><span itemprop="name">CUDA</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/21/CUDA-%E5%9F%BA%E7%A1%80%E4%B9%8B%E7%9F%A9%E9%98%B5%E4%B9%98%E4%BC%98%E5%8C%96/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/21/CUDA-%E5%9F%BA%E7%A1%80%E4%B9%8B%E7%9F%A9%E9%98%B5%E4%B9%98%E4%BC%98%E5%8C%96/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="cudacompute-unified-device-architecture统一计算设备架构资料"><a class="markdownIt-Anchor" href="#cudacompute-unified-device-architecture统一计算设备架构资料"></a> CUDA（Compute Unified Device Architecture，统一计算设备架构）资料：</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34587739">知乎 CUDA 编程入门极简教程</a></li>
<li><a target="_blank" rel="noopener" href="https://face2ai.com/categories/CUDA/page/4/">谭升的博客</a></li>
<li><a target="_blank" rel="noopener" href="https://www.nvidia.cn/docs/IO/51635/NVIDIA_CUDA_Programming_Guide_1.1_chs.pdf">NVIDIA CUDA 编程指南</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">CUDA C++ 编程指南</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4564726.html">CUDA memory hierarchy</a></li>
</ul>
<h2 id="gpu-体系结构"><a class="markdownIt-Anchor" href="#gpu-体系结构"></a> GPU 体系结构</h2>
<ul>
<li>物理模型<br />
<img src="https://s2.loli.net/2022/11/19/JdMwmXu9oTrE3H4.png" alt="image_1" />
<ul>
<li>典型的 <code>GPU</code> 包含一组流处理器 (<code>stream multi-processors</code>, <code>SM</code>)，每个流处理器都有许多核心，硬件实现上这些核心之间可共享内存（<code>shared memory</code>）</li>
</ul>
</li>
<li>逻辑模型<br />
<img src="https://s2.loli.net/2022/11/19/uEcUSFqiQbpdeHM.png" alt="image_2" />
<ul>
<li>逻辑模型中，引入了 <code>Grid</code> / <code>Block</code> / <code>Thread</code> 三级概念，逻辑模型与物理的对应关系如下：<br />
<img src="https://s2.loli.net/2022/11/19/ovTRipHj94Uemlb.png" alt="image_3" />
<blockquote>
<p>因此：同一个 <code>Block</code> 中的 <code>Thread</code> 可共享 <code>shared memory</code></p>
</blockquote>
</li>
</ul>
</li>
<li>Memory Hierarchy<br />
<img src="https://s2.loli.net/2022/11/19/CXoJct3fqD7ui4P.png" alt="memory_hierarchy.png" />
<blockquote>
<p><code>shared memory</code> 速度几乎和 <strong>L1 cache</strong> 一样，比 <code>local memory</code> 和 <code>global memory</code> 都快的多（在物理上，<code>local memory</code> 和 <code>global memory</code> 是同一块 <code>DRAM</code>）</p>
</blockquote>
</li>
<li>在对 <code>GPU</code> 进行编程时，需要创建一组进程块 (<code>thread blocks</code>)，每个 <code>thread</code> 映射到单个核心，而 <code>block</code> 映射到流式多处理器 (<code>SM</code>)，如下图所示：<br />
<img src="https://s2.loli.net/2025/01/18/WhxUYrjRGDwgt6k.jpg" alt="cuda.jpg" /></li>
<li>每个线程可由 <code>threadIdx</code> 和 <code>blockIdx</code> 索引，在实际应用中，可以有多维线程索引</li>
</ul>
<h2 id="共享内存优化"><a class="markdownIt-Anchor" href="#共享内存优化"></a> 共享内存优化</h2>
<ul>
<li>以矩阵乘为例，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1024</mn><mo>×</mo><mn>1024</mn></mrow></msup><mo separator="true">,</mo><mi>B</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1024</mn><mo>×</mo><mn>1024</mn></mrow></msup></mrow><annotation encoding="application/x-tex">A\in \mathbb{R}^{1024\times 1024},B\in \mathbb{R}^{1024\times 1024}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">2</span><span class="mord mtight">4</span><span class="mbin mtight">×</span><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">2</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">2</span><span class="mord mtight">4</span><span class="mbin mtight">×</span><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">2</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span><br />
<img src="https://s2.loli.net/2025/01/18/dxb5TwzQWVRe8LN.jpg" alt="matmul.jpg" />
<ul>
<li>同一个 <code>block</code> 中的多个 <code>thread</code> 可共享内存，因此可以重排同一个 <code>block</code> 中的 <code>thread</code> 数据，使得尽可能少的数据缓存到 <code>shared memory</code> 中</li>
<li>优化前：
<ul>
<li>每个 <code>thread</code> 需要计算输出矩阵中 <code>8 * 8</code> 的数据，需要从 <code>local memory</code> 中读取 <code>8 * 8 * 1024 * 2</code> 数据</li>
<li>每个 <code>block</code> 中的 <code>thread</code> 之间没有数据共享，所以需要从 <code>local memory</code> 中读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mo>∗</mo><mn>8</mn><mo>∗</mo><mn>8</mn><mo>∗</mo><mn>8</mn><mo>∗</mo><mn>1024</mn><mo>∗</mo><mn>2</mn><mo>=</mo><msup><mn>2</mn><mn>23</mn></msup></mrow><annotation encoding="application/x-tex">8 * 8 * 8 * 8 * 1024 * 2 = 2^{23}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span> 个矩阵元素</li>
</ul>
</li>
<li>优化后：
<ul>
<li>每个 <code>block</code> 计算输出矩阵的 <code>64 * 64</code> 的数据最少需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn><mo>∗</mo><mn>1024</mn><mo>∗</mo><mn>2</mn><mo>=</mo><msup><mn>2</mn><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">64 * 1024 * 2=2^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span> 的数据，可提前将这部分数据缓存到 <code>shared memory</code></li>
<li>然后每个 <code>thread</code> 从 <code>shared memory</code> 读数据计算，需读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn><mo>∗</mo><mn>1024</mn><mo>∗</mo><mn>2</mn><mo>=</mo><msup><mn>2</mn><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">64 * 1024 * 2=2^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span> 个数据</li>
</ul>
</li>
<li>内存优化前后每个 <code>block</code> 读取数据对比：
<ul>
<li>优化前：从 <code>local memory</code> 读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>23</mn></msup></mrow><annotation encoding="application/x-tex">2^{23}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span> 个矩阵元素</li>
<li>优化后：从 <code>local memory</code> 读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">2^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span> 个矩阵元素到 <code>shared memory</code>，再从 <code>shared memory</code> 读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">2^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span> 个数据计算</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2022/11/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">机器学习编译总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-21 22:12:53" itemprop="dateCreated datePublished" datetime="2022-11-21T22:12:53+08:00">2022-11-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91/" itemprop="url" rel="index"><span itemprop="name">机器学习编译</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E6%80%BB%E7%BB%93/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E6%80%BB%E7%BB%93/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><code>TVM</code> 是什么：是 <code>Tensor Virtual Machine</code> 的缩写，是一个 <strong>Open Deep Learning Compiler Stack（深度学习开源编译栈）</strong></li>
<li><code>TVM</code> 想干什么：将机器学习算法从开发阶段形态，通过变换和优化算法，使其变成部署形态</li>
<li><code>TVM</code> 的原则：
<ul>
<li>集成与最小化依赖</li>
<li>利用硬件加速</li>
<li>通用优化</li>
</ul>
</li>
<li><code>TVM Module</code> 层次结构：
<ul>
<li><code>IRModule</code>：包含一个或多个 <strong>元张量函数</strong> 和一个 <strong>高层神经网络执行的抽象</strong>。通常用 <code>@tvm.script.ir_module</code> 装饰器装饰</li>
<li><code>tensorIR</code>: 元张量函数。通常表示一个算子实例的计算过程，包含多个 <strong>计算块</strong>。通常用 <code>@T.prim_func</code> 装饰器装饰</li>
<li>高层神经网络执行的抽象：<code>IRModule</code> 的程序入口。通常用 <code>@R.function</code></li>
<li><code>block</code>: 计算块。张量的基本计算单位，通常包含多个 <strong>计算轴</strong> 上的循环。通常用 <code>with T.block(block_name)</code> 来标明作用域</li>
<li><code>计算轴</code>：
<ul>
<li><strong>空间轴</strong>（<code>spatial axis</code>）：空间轴上循环的每个位置的计算独立于其他位置</li>
<li><strong>规约轴</strong>（<code>reduce axis</code>）：规约轴上的位置不会反映到最后的计算输出上</li>
</ul>
</li>
</ul>
</li>
<li><code>TVM Module</code> 变换过程：
<ul>
<li>自动程序优化</li>
<li>cuda 多线程优化</li>
<li>内存优化</li>
<li>图优化</li>
<li>等等</li>
</ul>
</li>
<li><code>TVM Module</code> 执行过程：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ex = relax.vm.build(MyModule, target=<span class="string">&quot;llvm&quot;</span>)</span><br><span class="line">vm = relax.VirtualMachine(ex, tvm.cpu())</span><br><span class="line">nd_res = vm[<span class="string">&quot;main&quot;</span>](</span><br><span class="line">    data_nd, nd_params[<span class="string">&quot;w0&quot;</span>], nd_params[<span class="string">&quot;b0&quot;</span>], nd_params[<span class="string">&quot;w1&quot;</span>], nd_params[<span class="string">&quot;b1&quot;</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>可执行程序 = build(IR_Module)</li>
<li>虚拟机执行器 = 虚拟机(可执行程序)</li>
<li>运行结果 = 虚拟机执行器(模型输入 + 模型权重)</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2022/11/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91-6-%E2%80%94%E2%80%94GPU%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91-6-%E2%80%94%E2%80%94GPU%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F/" class="post-title-link" itemprop="url">机器学习编译(6)——GPU硬件加速</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-09 09:47:42" itemprop="dateCreated datePublished" datetime="2022-11-09T09:47:42+08:00">2022-11-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91/" itemprop="url" rel="index"><span itemprop="name">机器学习编译</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/11/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91-6-%E2%80%94%E2%80%94GPU%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/11/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91-6-%E2%80%94%E2%80%94GPU%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://mlc.ai/zh/chapter_gpu_acceleration/index.html">https://mlc.ai/zh/chapter_gpu_acceleration/index.html</a></li>
</ul>
<h2 id="背景知识"><a class="markdownIt-Anchor" href="#背景知识"></a> 背景知识</h2>
<ul>
<li>CUDA（Compute Unified Device Architecture，同一计算设备架构）教程：
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34587739">知乎 CUDA 编程入门极简教程</a></li>
<li><a target="_blank" rel="noopener" href="https://face2ai.com/categories/CUDA/page/4/">谭升的博客</a></li>
<li><a target="_blank" rel="noopener" href="https://www.nvidia.cn/docs/IO/51635/NVIDIA_CUDA_Programming_Guide_1.1_chs.pdf">NVIDIA CUDA 编程指南</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">CUDA C++ 编程指南</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/1024incn/p/4564726.html">CUDA memory hierarchy</a></li>
</ul>
</li>
</ul>
<h2 id="gpu-体系结构"><a class="markdownIt-Anchor" href="#gpu-体系结构"></a> GPU 体系结构</h2>
<ul>
<li>物理模型<br />
<img src="https://s2.loli.net/2022/11/19/JdMwmXu9oTrE3H4.png" alt="cuda_hardware.png" />
<ul>
<li>典型的 <code>GPU</code> 包含一组流处理器 (<code>stream multi-processors</code>, <code>SM</code>)，每个流处理器都有许多核心，硬件实现上这些核心之间可共享内存（<code>shared memory</code>）</li>
</ul>
</li>
<li>逻辑模型<br />
<img src="https://s2.loli.net/2022/11/19/uEcUSFqiQbpdeHM.png" alt="cuda.png" />
<ul>
<li>逻辑模型中，引入了 <code>Grid</code> / <code>Block</code> / <code>Thread</code> 三级概念，逻辑模型与物理的对应关系如下图所示：<br />
<img src="https://s2.loli.net/2022/11/19/ovTRipHj94Uemlb.png" alt="cuda_map.png" />
<blockquote>
<p>因此：同一个 <code>Block</code> 中的 <code>Thread</code> 可共享 <code>shared memory</code></p>
</blockquote>
</li>
</ul>
</li>
<li>Memory Hierarchy<br />
<img src="https://s2.loli.net/2022/11/19/CXoJct3fqD7ui4P.png" alt="memory_hierarchy.png" />
<blockquote>
<p><code>shared memory</code> 速度几乎和 <strong>L1 cache</strong> 一样，比 <code>local memory</code> 和 <code>global memory</code> 都快的多（在物理上，<code>local memory</code> 和 <code>global memory</code> 是同一块 <code>DRAM</code>）</p>
</blockquote>
</li>
<li>在对 <code>GPU</code> 进行编程时，需要创建一组进程块 (<code>thread blocks</code>)，每个 <code>thread</code> 映射到单个核心，而 <code>block</code> 映射到流式多处理器 (<code>SM</code>)，如下图所示：<br />
<img src="https://s2.loli.net/2022/11/09/BFIHjXAhY534Sar.png" alt="2.png" /></li>
<li>每个线程可由 <code>threadIdx</code> 和 <code>blockIdx</code> 索引，在实际应用中，可以有多维线程索引</li>
</ul>
<h2 id="element-wise-add-gpu-加速"><a class="markdownIt-Anchor" href="#element-wise-add-gpu-加速"></a> Element-wise Add GPU 加速</h2>
<ul>
<li>两个向量 A 和 B，向量长度都为 1024,执行元素相加，并将结果存储在 C 中  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModuleVecAdd</span>:</span></span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">A: T.Buffer[(<span class="params"><span class="number">1024</span>,</span>), <span class="string">&quot;float32&quot;</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">            B: T.Buffer[(<span class="params"><span class="number">1024</span>,</span>), <span class="string">&quot;float32&quot;</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">            C: T.Buffer[(<span class="params"><span class="number">1024</span>,</span>), <span class="string">&quot;float32&quot;</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        T.func_attr(&#123;<span class="string">&quot;global_symbol&quot;</span>: <span class="string">&quot;main&quot;</span>, <span class="string">&quot;tir.noalias&quot;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> T.grid(<span class="number">1024</span>):</span><br><span class="line">            <span class="keyword">with</span> T.block(<span class="string">&quot;C&quot;</span>):</span><br><span class="line">                vi = T.axis.remap(<span class="string">&quot;S&quot;</span>, [i])</span><br><span class="line">                C[vi] = A[vi] + B[vi]</span><br></pre></td></tr></table></figure>
</li>
<li>首先将循环 i 拆分成两个循环:  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sch = tvm.tir.Schedule(MyModuleVecAdd)</span><br><span class="line">block_C = sch.get_block(<span class="string">&quot;C&quot;</span>)</span><br><span class="line">i, = sch.get_loops(block=block_C)</span><br><span class="line">i0, i1 = sch.split(i, [<span class="literal">None</span>, <span class="number">128</span>])</span><br></pre></td></tr></table></figure>
</li>
<li>将迭代器绑定到 GPU 线程块。 每个线程由两个索引进行表示 <code>threadIdx.x</code> 和 <code>blockIdx.x</code>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sch.bind(i0, <span class="string">&quot;blockIdx.x&quot;</span>)</span><br><span class="line">sch.bind(i1, <span class="string">&quot;threadIdx.x&quot;</span>)</span><br><span class="line">sch.mod.show()</span><br></pre></td></tr></table></figure>
</li>
<li>绑定后的代码：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Module</span>:</span></span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">A: T.Buffer[<span class="number">1024</span>, <span class="string">&quot;float32&quot;</span>], B: T.Buffer[<span class="number">1024</span>, <span class="string">&quot;float32&quot;</span>], C: T.Buffer[<span class="number">1024</span>, <span class="string">&quot;float32&quot;</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># function attr dict</span></span><br><span class="line">        T.func_attr(&#123;<span class="string">&quot;global_symbol&quot;</span>: <span class="string">&quot;main&quot;</span>, <span class="string">&quot;tir.noalias&quot;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="comment"># body</span></span><br><span class="line">        <span class="comment"># with T.block(&quot;root&quot;)</span></span><br><span class="line">        <span class="keyword">for</span> i_0 <span class="keyword">in</span> T.thread_binding(<span class="number">8</span>, thread=<span class="string">&quot;blockIdx.x&quot;</span>):</span><br><span class="line">            <span class="keyword">for</span> i_1 <span class="keyword">in</span> T.thread_binding(<span class="number">128</span>, thread=<span class="string">&quot;threadIdx.x&quot;</span>):</span><br><span class="line">                <span class="keyword">with</span> T.block(<span class="string">&quot;C&quot;</span>):</span><br><span class="line">                    vi = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">128</span> + i_1)</span><br><span class="line">                    T.reads(A[vi], B[vi])</span><br><span class="line">                    T.writes(C[vi])</span><br><span class="line">                    C[vi] = A[vi] + B[vi]</span><br></pre></td></tr></table></figure>
</li>
<li>由于 <code>Element-wise Add</code> 不存在数据依赖，所以可以直接拆分到多个 <code>block</code> 中的多个 <code>thread</code> 中，一个 <code>cycle</code> 全部算完</li>
</ul>
<h2 id="窗口求和-gpu-加速"><a class="markdownIt-Anchor" href="#窗口求和-gpu-加速"></a> 窗口求和 GPU 加速</h2>
<ul>
<li>相邻三个窗口求和，输入向量 A 长度 1026，输出 B 长度 1024。（即无 padding 的权重为 [1, 1, 1] 的 conv1d）  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModuleWindowSum</span>:</span></span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">A: T.Buffer[(<span class="params"><span class="number">1026</span>,</span>), <span class="string">&quot;float32&quot;</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">            B: T.Buffer[(<span class="params"><span class="number">1024</span>,</span>), <span class="string">&quot;float32&quot;</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        T.func_attr(&#123;<span class="string">&quot;global_symbol&quot;</span>: <span class="string">&quot;main&quot;</span>, <span class="string">&quot;tir.noalias&quot;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> T.grid(<span class="number">1024</span>):</span><br><span class="line">            <span class="keyword">with</span> T.block(<span class="string">&quot;C&quot;</span>):</span><br><span class="line">                vi = T.axis.remap(<span class="string">&quot;S&quot;</span>, [i])</span><br><span class="line">                B[vi] = A[vi] + A[vi + <span class="number">1</span>] + A[vi + <span class="number">2</span>]</span><br></pre></td></tr></table></figure>
</li>
<li>拆分循环并绑定到 <code>block</code> 和 <code>thread</code>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sch = tvm.tir.Schedule(MyModuleWindowSum)</span><br><span class="line">nthread = <span class="number">128</span></span><br><span class="line">block_C = sch.get_block(<span class="string">&quot;C&quot;</span>)</span><br><span class="line">i,  = sch.get_loops(block=block_C)</span><br><span class="line">i0, i1 = sch.split(i, [<span class="literal">None</span>, nthread])</span><br><span class="line">sch.bind(i0, <span class="string">&quot;blockIdx.x&quot;</span>)</span><br><span class="line">sch.bind(i1, <span class="string">&quot;threadIdx.x&quot;</span>)</span><br><span class="line">sch.mod.show()</span><br></pre></td></tr></table></figure>
</li>
<li>拆分循环后 <code>IRModule</code>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Module</span>:</span></span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">A: T.Buffer[<span class="number">1027</span>, <span class="string">&quot;float32&quot;</span>], B: T.Buffer[<span class="number">1024</span>, <span class="string">&quot;float32&quot;</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># function attr dict</span></span><br><span class="line">        T.func_attr(&#123;<span class="string">&quot;global_symbol&quot;</span>: <span class="string">&quot;main&quot;</span>, <span class="string">&quot;tir.noalias&quot;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="comment"># body</span></span><br><span class="line">        <span class="comment"># with T.block(&quot;root&quot;)</span></span><br><span class="line">        <span class="keyword">for</span> i_0 <span class="keyword">in</span> T.thread_binding(<span class="number">8</span>, thread=<span class="string">&quot;blockIdx.x&quot;</span>):</span><br><span class="line">            <span class="keyword">for</span> i_1 <span class="keyword">in</span> T.thread_binding(<span class="number">128</span>, thread=<span class="string">&quot;threadIdx.x&quot;</span>):</span><br><span class="line">                <span class="comment"># 启用 8 个 block 并发计算，每个 block 用 16 个 thread 并发</span></span><br><span class="line">                <span class="comment"># 因此每一个 thread 只需要计算 1 次乘加</span></span><br><span class="line">                <span class="keyword">with</span> T.block(<span class="string">&quot;C&quot;</span>):</span><br><span class="line">                    vi = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">128</span> + i_1)</span><br><span class="line">                    T.reads(A[vi : vi + <span class="number">3</span>])</span><br><span class="line">                    T.writes(B[vi])</span><br><span class="line">                    B[vi] = A[vi] + A[vi + <span class="number">1</span>] + A[vi + <span class="number">2</span>]</span><br></pre></td></tr></table></figure>
</li>
<li>提前缓存数据  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A_shared = sch.cache_read(block_C, read_buffer_index=<span class="number">0</span>, storage_scope=<span class="string">&quot;shared&quot;</span>)</span><br><span class="line">sch.compute_at(A_shared, i1)</span><br><span class="line">sch.mod.show()</span><br></pre></td></tr></table></figure>
</li>
<li>提前缓存数据后的 <code>IRModule</code>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Module</span>:</span></span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">A: T.Buffer[<span class="number">1027</span>, <span class="string">&quot;float32&quot;</span>], B: T.Buffer[<span class="number">1024</span>, <span class="string">&quot;float32&quot;</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># function attr dict</span></span><br><span class="line">        T.func_attr(&#123;<span class="string">&quot;global_symbol&quot;</span>: <span class="string">&quot;main&quot;</span>, <span class="string">&quot;tir.noalias&quot;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="comment"># body</span></span><br><span class="line">        <span class="comment"># with T.block(&quot;root&quot;)</span></span><br><span class="line">        A_shared = T.alloc_buffer([<span class="number">1027</span>], dtype=<span class="string">&quot;float32&quot;</span>, scope=<span class="string">&quot;shared&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i_0 <span class="keyword">in</span> T.thread_binding(<span class="number">8</span>, thread=<span class="string">&quot;blockIdx.x&quot;</span>):</span><br><span class="line">            <span class="keyword">for</span> i_1 <span class="keyword">in</span> T.thread_binding(<span class="number">128</span>, thread=<span class="string">&quot;threadIdx.x&quot;</span>):</span><br><span class="line">                <span class="comment"># 由上图 GPU 结构图可知</span></span><br><span class="line">                <span class="comment"># 不同 block 无法共享 share memory</span></span><br><span class="line">                <span class="comment"># 相同 block 的不同 thread 之间可以共享</span></span><br><span class="line">                <span class="comment"># 所以输出 128 个结果需要 130 个输入（本行 128 个加下一行 2 个）</span></span><br><span class="line">                <span class="keyword">for</span> ax0 <span class="keyword">in</span> T.serial(<span class="number">130</span>):</span><br><span class="line">                    <span class="keyword">with</span> T.block(<span class="string">&quot;A_shared&quot;</span>):</span><br><span class="line">                        v0 = T.axis.spatial(<span class="number">1027</span>, i_0 * <span class="number">128</span> + ax0)</span><br><span class="line">                        T.reads(A[v0])</span><br><span class="line">                        T.writes(A_shared[v0])</span><br><span class="line">                        A_shared[v0] = A[v0]</span><br><span class="line">                <span class="keyword">with</span> T.block(<span class="string">&quot;C&quot;</span>):</span><br><span class="line">                    vi = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">128</span> + i_1)</span><br><span class="line">                    T.reads(A_shared[vi : vi + <span class="number">3</span>])</span><br><span class="line">                    T.writes(B[vi])</span><br><span class="line">                    B[vi] = A_shared[vi] + A_shared[vi + <span class="number">1</span>] + A_shared[vi + <span class="number">2</span>]</span><br></pre></td></tr></table></figure>
</li>
<li>缓存数据可以使用多线程优化
<ul>
<li>因为内存是跨线程共享的，所以需要重新拆分循环并将获取过程的内部迭代器绑定到线程索引上，这种技术称为 <code>cooperative fetching</code></li>
</ul>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ax = sch.get_loops(A_shared)[-<span class="number">1</span>]</span><br><span class="line">ax0, ax1 = sch.split(ax, [<span class="literal">None</span>, nthread])</span><br><span class="line">sch.bind(ax1, <span class="string">&quot;threadIdx.x&quot;</span>)</span><br><span class="line">sch.mod.show()</span><br></pre></td></tr></table></figure>
</li>
<li>缓存数据优化后 <code>IRModule</code>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Module</span>:</span></span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">A: T.Buffer[<span class="number">1026</span>, <span class="string">&quot;float32&quot;</span>], B: T.Buffer[<span class="number">1024</span>, <span class="string">&quot;float32&quot;</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># function attr dict</span></span><br><span class="line">        T.func_attr(&#123;<span class="string">&quot;global_symbol&quot;</span>: <span class="string">&quot;main&quot;</span>, <span class="string">&quot;tir.noalias&quot;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="comment"># body</span></span><br><span class="line">        <span class="comment"># with T.block(&quot;root&quot;)</span></span><br><span class="line">        A_shared = T.alloc_buffer([<span class="number">1026</span>], dtype=<span class="string">&quot;float32&quot;</span>, scope=<span class="string">&quot;shared&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i_0 <span class="keyword">in</span> T.thread_binding(<span class="number">8</span>, thread=<span class="string">&quot;blockIdx.x&quot;</span>):</span><br><span class="line">            <span class="keyword">for</span> i_1 <span class="keyword">in</span> T.thread_binding(<span class="number">128</span>, thread=<span class="string">&quot;threadIdx.x&quot;</span>):</span><br><span class="line">                <span class="keyword">for</span> ax0_0 <span class="keyword">in</span> T.serial(<span class="number">2</span>):</span><br><span class="line">                    <span class="keyword">for</span> ax0_1 <span class="keyword">in</span> T.thread_binding(<span class="number">128</span>, thread=<span class="string">&quot;threadIdx.x&quot;</span>):</span><br><span class="line">                        <span class="keyword">with</span> T.block(<span class="string">&quot;A_shared&quot;</span>):</span><br><span class="line">                            <span class="comment"># 由上图 GPU 结构图可知</span></span><br><span class="line">                            <span class="comment"># 不同 block 无法共享 share memory</span></span><br><span class="line">                            <span class="comment"># 相同 block 的不同 thread 之间可以共享</span></span><br><span class="line">                            <span class="comment"># 所以输出 128 个结果需要 130 个输入（本行 128 个加下一行 2 个）</span></span><br><span class="line">                            v0 = T.axis.spatial(<span class="number">1026</span>, i_0 * <span class="number">128</span> + (ax0_0 * <span class="number">128</span> + ax0_1))</span><br><span class="line">                            T.where(ax0_0 * <span class="number">128</span> + ax0_1 &lt; <span class="number">130</span>)</span><br><span class="line">                            T.reads(A[v0])</span><br><span class="line">                            T.writes(A_shared[v0])</span><br><span class="line">                            A_shared[v0] = A[v0]</span><br><span class="line">                <span class="keyword">with</span> T.block(<span class="string">&quot;C&quot;</span>):</span><br><span class="line">                    vi = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">128</span> + i_1)</span><br><span class="line">                    T.reads(A_shared[vi : vi + <span class="number">3</span>])</span><br><span class="line">                    T.writes(B[vi])</span><br><span class="line">                    B[vi] = A_shared[vi] + A_shared[vi + <span class="number">1</span>] + A_shared[vi + <span class="number">2</span>]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="矩阵乘法-gpu-加速"><a class="markdownIt-Anchor" href="#矩阵乘法-gpu-加速"></a> 矩阵乘法 GPU 加速</h2>
<ul>
<li><code>IRModule</code> 基础实现：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModuleMatmul</span>:</span></span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">A: T.Buffer[(<span class="params"><span class="number">1024</span>, <span class="number">1024</span></span>), <span class="string">&quot;float32&quot;</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">            B: T.Buffer[(<span class="params"><span class="number">1024</span>, <span class="number">1024</span></span>), <span class="string">&quot;float32&quot;</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">            C: T.Buffer[(<span class="params"><span class="number">1024</span>, <span class="number">1024</span></span>), <span class="string">&quot;float32&quot;</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        T.func_attr(&#123;<span class="string">&quot;global_symbol&quot;</span>: <span class="string">&quot;main&quot;</span>, <span class="string">&quot;tir.noalias&quot;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="keyword">for</span> i, j, k <span class="keyword">in</span> T.grid(<span class="number">1024</span>, <span class="number">1024</span>, <span class="number">1024</span>):</span><br><span class="line">            <span class="keyword">with</span> T.block(<span class="string">&quot;C&quot;</span>):</span><br><span class="line">                vi, vj, vk = T.axis.remap(<span class="string">&quot;SSR&quot;</span>, [i, j, k])</span><br><span class="line">                <span class="keyword">with</span> T.init():</span><br><span class="line">                    C[vi, vj] = <span class="number">0.0</span></span><br><span class="line">                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj]</span><br></pre></td></tr></table></figure>
</li>
<li>绑定 <code>block</code> 和 <code>thread</code> + 本地存储分块优化<br />
<img src="https://s2.loli.net/2022/11/14/I5wkRrieyxAgFWl.png" alt="3.png" />
<blockquote>
<p>循环拆分，来增加整体内存复用，只需要从 <code>A</code> 和 <code>B</code> 加载一次条形数据（上图中的灰色部分），然后使用它们来计算矩阵乘法结果<br />
下面代码中设置 <code>V = 8</code></p>
</blockquote>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">blocking</span>(<span class="params">sch,</span></span></span><br><span class="line"><span class="params"><span class="function">            tile_local_y,</span></span></span><br><span class="line"><span class="params"><span class="function">            tile_local_x,</span></span></span><br><span class="line"><span class="params"><span class="function">            tile_block_y,</span></span></span><br><span class="line"><span class="params"><span class="function">            tile_block_x,</span></span></span><br><span class="line"><span class="params"><span class="function">            tile_k</span>):</span></span><br><span class="line">    block_C = sch.get_block(<span class="string">&quot;C&quot;</span>)</span><br><span class="line">    C_local = sch.cache_write(block_C, <span class="number">0</span>, <span class="string">&quot;local&quot;</span>)</span><br><span class="line">    i, j, k = sch.get_loops(block=block_C)</span><br><span class="line">    i0, i1, i2 = sch.split(loop=i, factors=[<span class="literal">None</span>, tile_block_y, tile_local_y])</span><br><span class="line">    j0, j1, j2 = sch.split(loop=j, factors=[<span class="literal">None</span>, tile_block_x, tile_local_x])</span><br><span class="line">    k0, k1 = sch.split(loop=k, factors=[<span class="literal">None</span>, tile_k])</span><br><span class="line">    sch.unroll(k1)</span><br><span class="line">    sch.reorder(i0, j0, i1, j1, k0, k1, i2, j2)</span><br><span class="line">    sch.reverse_compute_at(C_local, j1)</span><br><span class="line">    sch.bind(i0, <span class="string">&quot;blockIdx.y&quot;</span>)</span><br><span class="line">    sch.bind(j0, <span class="string">&quot;blockIdx.x&quot;</span>)</span><br><span class="line">    sch.bind(i1, <span class="string">&quot;threadIdx.y&quot;</span>)</span><br><span class="line">    sch.bind(j1, <span class="string">&quot;threadIdx.x&quot;</span>)</span><br><span class="line">    sch.decompose_reduction(block_C, k0)</span><br><span class="line">    <span class="keyword">return</span> sch</span><br><span class="line">sch = tvm.tir.Schedule(MyModuleMatmul)</span><br><span class="line">sch = blocking(sch, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">4</span>)</span><br><span class="line">sch.mod.show()</span><br></pre></td></tr></table></figure>
</li>
<li>输出优化后的 <code>IRModule</code>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Module</span>:</span></span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">A: T.Buffer[(<span class="params"><span class="number">1024</span>, <span class="number">1024</span></span>), <span class="string">&quot;float32&quot;</span>], B: T.Buffer[(<span class="params"><span class="number">1024</span>, <span class="number">1024</span></span>), <span class="string">&quot;float32&quot;</span>], C: T.Buffer[(<span class="params"><span class="number">1024</span>, <span class="number">1024</span></span>), <span class="string">&quot;float32&quot;</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># function attr dict</span></span><br><span class="line">        T.func_attr(&#123;<span class="string">&quot;global_symbol&quot;</span>: <span class="string">&quot;main&quot;</span>, <span class="string">&quot;tir.noalias&quot;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="comment"># body</span></span><br><span class="line">        <span class="comment"># with T.block(&quot;root&quot;)</span></span><br><span class="line">        C_local = T.alloc_buffer([<span class="number">1024</span>, <span class="number">1024</span>], dtype=<span class="string">&quot;float32&quot;</span>, scope=<span class="string">&quot;local&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i_0 <span class="keyword">in</span> T.thread_binding(<span class="number">16</span>, thread=<span class="string">&quot;blockIdx.y&quot;</span>):</span><br><span class="line">            <span class="keyword">for</span> j_0 <span class="keyword">in</span> T.thread_binding(<span class="number">16</span>, thread=<span class="string">&quot;blockIdx.x&quot;</span>):</span><br><span class="line">                <span class="keyword">for</span> i_1 <span class="keyword">in</span> T.thread_binding(<span class="number">8</span>, thread=<span class="string">&quot;threadIdx.y&quot;</span>):</span><br><span class="line">                    <span class="keyword">for</span> j_1 <span class="keyword">in</span> T.thread_binding(<span class="number">8</span>, thread=<span class="string">&quot;threadIdx.x&quot;</span>):</span><br><span class="line">                        <span class="comment"># 一共使用 16 * 16 个 block 并发计算</span></span><br><span class="line">                        <span class="comment"># 每个 block 使用 8 * 8 个 thread 并发</span></span><br><span class="line">                        <span class="comment"># 所以每个 thread 只需计算输出为 8 * 8 的区域，因此只需要加载 A 中 8 行和 B 中 8 列数据</span></span><br><span class="line">                        <span class="comment"># 1. 初始化 8 * 8 的输出区域为 0</span></span><br><span class="line">                        <span class="keyword">for</span> i_2_init, j_2_init <span class="keyword">in</span> T.grid(<span class="number">8</span>, <span class="number">8</span>):</span><br><span class="line">                            <span class="keyword">with</span> T.block(<span class="string">&quot;C_init&quot;</span>):</span><br><span class="line">                                vi = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">64</span> + i_1 * <span class="number">8</span> + i_2_init)</span><br><span class="line">                                vj = T.axis.spatial(<span class="number">1024</span>, j_0 * <span class="number">64</span> + j_1 * <span class="number">8</span> + j_2_init)</span><br><span class="line">                                T.reads()</span><br><span class="line">                                T.writes(C_local[vi, vj])</span><br><span class="line">                                C_local[vi, vj] = T.float32(<span class="number">0</span>)</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># 2. 计算 8 * 8 输出区域的值，共计算 8 * 8 * 1024 次乘加</span></span><br><span class="line">                        <span class="keyword">for</span> k_0 <span class="keyword">in</span> T.serial(<span class="number">256</span>):</span><br><span class="line">                            <span class="keyword">for</span> k_1 <span class="keyword">in</span> T.unroll(<span class="number">4</span>):</span><br><span class="line">                                <span class="keyword">for</span> i_2, j_2 <span class="keyword">in</span> T.grid(<span class="number">8</span>, <span class="number">8</span>):</span><br><span class="line">                                    <span class="keyword">with</span> T.block(<span class="string">&quot;C_update&quot;</span>):</span><br><span class="line">                                        vi = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">64</span> + i_1 * <span class="number">8</span> + i_2)</span><br><span class="line">                                        vj = T.axis.spatial(<span class="number">1024</span>, j_0 * <span class="number">64</span> + j_1 * <span class="number">8</span> + j_2)</span><br><span class="line">                                        vk = T.axis.reduce(<span class="number">1024</span>, k_0 * <span class="number">4</span> + k_1)</span><br><span class="line">                                        T.reads(C_local[vi, vj], A[vi, vk], B[vk, vj])</span><br><span class="line">                                        T.writes(C_local[vi, vj])</span><br><span class="line">                                        C_local[vi, vj] = C_local[vi, vj] + A[vi, vk] * B[vk, vj]</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># 3. 把每个 thread 的 8 * 8 的输出区域拼成最后的 1024 * 1024 的输出</span></span><br><span class="line">                        <span class="keyword">for</span> ax0, ax1 <span class="keyword">in</span> T.grid(<span class="number">8</span>, <span class="number">8</span>):</span><br><span class="line">                            <span class="keyword">with</span> T.block(<span class="string">&quot;C_local&quot;</span>):</span><br><span class="line">                                v0 = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">64</span> + i_1 * <span class="number">8</span> + ax0)</span><br><span class="line">                                v1 = T.axis.spatial(<span class="number">1024</span>, j_0 * <span class="number">64</span> + j_1 * <span class="number">8</span> + ax1)</span><br><span class="line">                                T.reads(C_local[v0, v1])</span><br><span class="line">                                T.writes(C[v0, v1])</span><br><span class="line">                                C[v0, v1] = C_local[v0, v1]</span><br></pre></td></tr></table></figure>
</li>
<li>共享内存优化<br />
<img src="https://s2.loli.net/2022/11/14/exR47Sh82q3tHBa.png" alt="4.png" />
<blockquote>
<p>与上图不同，图中矩阵 C 中 <code>L * L</code> 灰色区域表示一个 <code>block</code> 的计算输出<br />
每个 <code>L * L</code> 灰色区域由多个 <code>V * V</code> 的小区域组成，表示一个 <code>thread</code> 的输出</p>
</blockquote>
<ul>
<li>
<p>同一个 <code>block</code> 中的多个 <code>thread</code> 可共享内存，因此可以重排同一个 <code>block</code> 中的 <code>thread</code> 数据，使得尽可能少的数据缓存到 <code>shared memory</code> 中</p>
</li>
<li>
<p>优化前：</p>
<ul>
<li>每个 <code>thread</code> 需要计算输出矩阵中 <code>8 * 8</code> 的数据，需要从 <code>local memory</code> 中读取 <code>8 * 8 * 1024 * 2</code> 数据</li>
<li>每个 <code>block</code> 中的 <code>thread</code> 之间没有数据共享，所以需要从 <code>local memory</code> 中读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mo>∗</mo><mn>8</mn><mo>∗</mo><mn>8</mn><mo>∗</mo><mn>8</mn><mo>∗</mo><mn>1024</mn><mo>∗</mo><mn>2</mn><mo>=</mo><msup><mn>2</mn><mn>23</mn></msup></mrow><annotation encoding="application/x-tex">8 * 8 * 8 * 8 * 1024 * 2 = 2^{23}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span> 个矩阵元素</li>
</ul>
</li>
<li>
<p>优化后：</p>
<ul>
<li>每个 <code>block</code> 计算输出矩阵的 <code>64 * 64</code> 的数据最少需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn><mo>∗</mo><mn>1024</mn><mo>∗</mo><mn>2</mn><mo>=</mo><msup><mn>2</mn><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">64 * 1024 * 2=2^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span> 的数据，可提前将这部分数据缓存到 <code>shared memory</code></li>
<li>然后每个 <code>thread</code> 从 <code>shared memory</code> 读数据计算，需读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn><mo>∗</mo><mn>1024</mn><mo>∗</mo><mn>2</mn><mo>=</mo><msup><mn>2</mn><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">64 * 1024 * 2=2^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span> 个数据</li>
</ul>
</li>
<li>
<p>内存优化前后每个 <code>block</code> 读取数据对比：</p>
<ul>
<li>优化前：从 <code>local memory</code> 读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>23</mn></msup></mrow><annotation encoding="application/x-tex">2^{23}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span> 个矩阵元素</li>
<li>优化后：从 <code>local memory</code> 读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">2^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span> 个矩阵元素到 <code>shared memory</code>，再从 <code>shared memory</code> 读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">2^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span> 个数据计算</li>
</ul>
</li>
<li>
<p>优化过程：</p>
</li>
</ul>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cache_read_and_coop_fetch</span>(<span class="params">sch, block, nthread, read_idx, read_loc</span>):</span></span><br><span class="line">    read_cache = sch.cache_read(block=block, read_buffer_index=read_idx, storage_scope=<span class="string">&quot;shared&quot;</span>)</span><br><span class="line">    sch.compute_at(block=read_cache, loop=read_loc)</span><br><span class="line">    <span class="comment"># vectorized cooperative fetch</span></span><br><span class="line">    inner0, inner1 = sch.get_loops(block=read_cache)[-<span class="number">2</span>:]</span><br><span class="line">    inner = sch.fuse(inner0, inner1)</span><br><span class="line">    _, tx, vec = sch.split(loop=inner, factors=[<span class="literal">None</span>, nthread, <span class="number">4</span>])</span><br><span class="line">    sch.vectorize(vec)</span><br><span class="line">    sch.bind(tx, <span class="string">&quot;threadIdx.x&quot;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">blocking_with_shared</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    sch,</span></span></span><br><span class="line"><span class="params"><span class="function">    tile_local_y,</span></span></span><br><span class="line"><span class="params"><span class="function">    tile_local_x,</span></span></span><br><span class="line"><span class="params"><span class="function">    tile_block_y,</span></span></span><br><span class="line"><span class="params"><span class="function">    tile_block_x,</span></span></span><br><span class="line"><span class="params"><span class="function">    tile_k</span>):</span></span><br><span class="line">    block_C = sch.get_block(<span class="string">&quot;C&quot;</span>)</span><br><span class="line">    C_local = sch.cache_write(block_C, <span class="number">0</span>, <span class="string">&quot;local&quot;</span>)</span><br><span class="line">    i, j, k = sch.get_loops(block=block_C)</span><br><span class="line">    i0, i1, i2 = sch.split(loop=i, factors=[<span class="literal">None</span>, tile_block_y, tile_local_y])</span><br><span class="line">    j0, j1, j2 = sch.split(loop=j, factors=[<span class="literal">None</span>, tile_block_x, tile_local_x])</span><br><span class="line">    k0, k1 = sch.split(loop=k, factors=[<span class="literal">None</span>, tile_k])</span><br><span class="line">    sch.reorder(i0, j0, i1, j1, k0, k1, i2, j2)</span><br><span class="line">    sch.reverse_compute_at(C_local, j1)</span><br><span class="line">    sch.bind(i0, <span class="string">&quot;blockIdx.y&quot;</span>)</span><br><span class="line">    sch.bind(j0, <span class="string">&quot;blockIdx.x&quot;</span>)</span><br><span class="line">    tx = sch.fuse(i1, j1)</span><br><span class="line">    sch.bind(tx, <span class="string">&quot;threadIdx.x&quot;</span>)</span><br><span class="line">    nthread = tile_block_y * tile_block_x</span><br><span class="line">    cache_read_and_coop_fetch(sch, block_C, nthread, <span class="number">0</span>, k0)</span><br><span class="line">    cache_read_and_coop_fetch(sch, block_C, nthread, <span class="number">1</span>, k0)</span><br><span class="line">    sch.decompose_reduction(block_C, k0)</span><br><span class="line">    <span class="keyword">return</span> sch</span><br><span class="line">sch = tvm.tir.Schedule(MyModuleMatmul)</span><br><span class="line">sch = blocking_with_shared(sch, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">sch.mod.show()</span><br></pre></td></tr></table></figure>
<ul>
<li>优化后 <code>IRModule</code></li>
</ul>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tvm.script.ir_module</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Module</span>:</span></span><br><span class="line"><span class="meta">    @T.prim_func</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">A: T.Buffer[(<span class="params"><span class="number">1024</span>, <span class="number">1024</span></span>), <span class="string">&quot;float32&quot;</span>], B: T.Buffer[(<span class="params"><span class="number">1024</span>, <span class="number">1024</span></span>), <span class="string">&quot;float32&quot;</span>], C: T.Buffer[(<span class="params"><span class="number">1024</span>, <span class="number">1024</span></span>), <span class="string">&quot;float32&quot;</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># function attr dict</span></span><br><span class="line">        T.func_attr(&#123;<span class="string">&quot;global_symbol&quot;</span>: <span class="string">&quot;main&quot;</span>, <span class="string">&quot;tir.noalias&quot;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="comment"># body</span></span><br><span class="line">        <span class="comment"># with T.block(&quot;root&quot;)</span></span><br><span class="line">        C_local = T.alloc_buffer([<span class="number">1024</span>, <span class="number">1024</span>], dtype=<span class="string">&quot;float32&quot;</span>, scope=<span class="string">&quot;local&quot;</span>)</span><br><span class="line">        A_shared = T.alloc_buffer([<span class="number">1024</span>, <span class="number">1024</span>], dtype=<span class="string">&quot;float32&quot;</span>, scope=<span class="string">&quot;shared&quot;</span>)</span><br><span class="line">        B_shared = T.alloc_buffer([<span class="number">1024</span>, <span class="number">1024</span>], dtype=<span class="string">&quot;float32&quot;</span>, scope=<span class="string">&quot;shared&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i_0 <span class="keyword">in</span> T.thread_binding(<span class="number">16</span>, thread=<span class="string">&quot;blockIdx.y&quot;</span>):</span><br><span class="line">            <span class="keyword">for</span> j_0 <span class="keyword">in</span> T.thread_binding(<span class="number">16</span>, thread=<span class="string">&quot;blockIdx.x&quot;</span>):</span><br><span class="line">                <span class="keyword">for</span> i_1_j_1_fused <span class="keyword">in</span> T.thread_binding(<span class="number">64</span>, thread=<span class="string">&quot;threadIdx.x&quot;</span>):</span><br><span class="line">                    <span class="keyword">for</span> i_2_init, j_2_init <span class="keyword">in</span> T.grid(<span class="number">8</span>, <span class="number">8</span>):</span><br><span class="line">                        <span class="keyword">with</span> T.block(<span class="string">&quot;C_init&quot;</span>):</span><br><span class="line">                            vi = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">64</span> + i_1_j_1_fused // <span class="number">8</span> * <span class="number">8</span> + i_2_init)</span><br><span class="line">                            vj = T.axis.spatial(<span class="number">1024</span>, j_0 * <span class="number">64</span> + i_1_j_1_fused % <span class="number">8</span> * <span class="number">8</span> + j_2_init)</span><br><span class="line">                            T.reads()</span><br><span class="line">                            T.writes(C_local[vi, vj])</span><br><span class="line">                            C_local[vi, vj] = T.float32(<span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">for</span> k_0 <span class="keyword">in</span> T.serial(<span class="number">128</span>):</span><br><span class="line">                        <span class="keyword">for</span> ax0_ax1_fused_0 <span class="keyword">in</span> T.serial(<span class="number">2</span>):</span><br><span class="line">                            <span class="keyword">for</span> ax0_ax1_fused_1 <span class="keyword">in</span> T.thread_binding(<span class="number">64</span>, thread=<span class="string">&quot;threadIdx.x&quot;</span>):</span><br><span class="line">                                <span class="keyword">for</span> ax0_ax1_fused_2 <span class="keyword">in</span> T.vectorized(<span class="number">4</span>):</span><br><span class="line">                                    <span class="keyword">with</span> T.block(<span class="string">&quot;A_shared&quot;</span>):</span><br><span class="line">                                        v0 = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">64</span> + (ax0_ax1_fused_0 * <span class="number">256</span> + ax0_ax1_fused_1 * <span class="number">4</span> + ax0_ax1_fused_2) // <span class="number">8</span>)</span><br><span class="line">                                        v1 = T.axis.spatial(<span class="number">1024</span>, k_0 * <span class="number">8</span> + (ax0_ax1_fused_0 * <span class="number">256</span> + ax0_ax1_fused_1 * <span class="number">4</span> + ax0_ax1_fused_2) % <span class="number">8</span>)</span><br><span class="line">                                        T.reads(A[v0, v1])</span><br><span class="line">                                        T.writes(A_shared[v0, v1])</span><br><span class="line">                                        A_shared[v0, v1] = A[v0, v1]</span><br><span class="line">                        <span class="keyword">for</span> ax0_ax1_fused_0 <span class="keyword">in</span> T.serial(<span class="number">2</span>):</span><br><span class="line">                            <span class="keyword">for</span> ax0_ax1_fused_1 <span class="keyword">in</span> T.thread_binding(<span class="number">64</span>, thread=<span class="string">&quot;threadIdx.x&quot;</span>):</span><br><span class="line">                                <span class="keyword">for</span> ax0_ax1_fused_2 <span class="keyword">in</span> T.vectorized(<span class="number">4</span>):</span><br><span class="line">                                    <span class="keyword">with</span> T.block(<span class="string">&quot;B_shared&quot;</span>):</span><br><span class="line">                                        v0 = T.axis.spatial(<span class="number">1024</span>, k_0 * <span class="number">8</span> + (ax0_ax1_fused_0 * <span class="number">256</span> + ax0_ax1_fused_1 * <span class="number">4</span> + ax0_ax1_fused_2) // <span class="number">64</span>)</span><br><span class="line">                                        v1 = T.axis.spatial(<span class="number">1024</span>, j_0 * <span class="number">64</span> + (ax0_ax1_fused_0 * <span class="number">256</span> + ax0_ax1_fused_1 * <span class="number">4</span> + ax0_ax1_fused_2) % <span class="number">64</span>)</span><br><span class="line">                                        T.reads(B[v0, v1])</span><br><span class="line">                                        T.writes(B_shared[v0, v1])</span><br><span class="line">                                        B_shared[v0, v1] = B[v0, v1]</span><br><span class="line">                        <span class="keyword">for</span> k_1, i_2, j_2 <span class="keyword">in</span> T.grid(<span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>):</span><br><span class="line">                            <span class="keyword">with</span> T.block(<span class="string">&quot;C_update&quot;</span>):</span><br><span class="line">                                vi = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">64</span> + i_1_j_1_fused // <span class="number">8</span> * <span class="number">8</span> + i_2)</span><br><span class="line">                                vj = T.axis.spatial(<span class="number">1024</span>, j_0 * <span class="number">64</span> + i_1_j_1_fused % <span class="number">8</span> * <span class="number">8</span> + j_2)</span><br><span class="line">                                vk = T.axis.reduce(<span class="number">1024</span>, k_0 * <span class="number">8</span> + k_1)</span><br><span class="line">                                T.reads(C_local[vi, vj], A_shared[vi, vk], B_shared[vk, vj])</span><br><span class="line">                                T.writes(C_local[vi, vj])</span><br><span class="line">                                C_local[vi, vj] = C_local[vi, vj] + A_shared[vi, vk] * B_shared[vk, vj]</span><br><span class="line">                    <span class="keyword">for</span> ax0, ax1 <span class="keyword">in</span> T.grid(<span class="number">8</span>, <span class="number">8</span>):</span><br><span class="line">                        <span class="keyword">with</span> T.block(<span class="string">&quot;C_local&quot;</span>):</span><br><span class="line">                            v0 = T.axis.spatial(<span class="number">1024</span>, i_0 * <span class="number">64</span> + i_1_j_1_fused // <span class="number">8</span> * <span class="number">8</span> + ax0)</span><br><span class="line">                            v1 = T.axis.spatial(<span class="number">1024</span>, j_0 * <span class="number">64</span> + i_1_j_1_fused % <span class="number">8</span> * <span class="number">8</span> + ax1)</span><br><span class="line">                            T.reads(C_local[v0, v1])</span><br><span class="line">                            T.writes(C[v0, v1])</span><br><span class="line">                            C[v0, v1] = C_local[v0, v1]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="程序自动变换"><a class="markdownIt-Anchor" href="#程序自动变换"></a> 程序自动变换</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tvm <span class="keyword">import</span> meta_schedule <span class="keyword">as</span> ms</span><br><span class="line">sch_tuned = ms.tune_tir(</span><br><span class="line">    mod=MyModuleMatmul,</span><br><span class="line">    target=<span class="string">&quot;nvidia/tesla-p100&quot;</span>,</span><br><span class="line">    config=ms.TuneConfig(</span><br><span class="line">      max_trials_global=<span class="number">64</span>,</span><br><span class="line">      num_trials_per_iter=<span class="number">64</span>,</span><br><span class="line">    ),</span><br><span class="line">    work_dir=<span class="string">&quot;./tune_tmp&quot;</span>,</span><br><span class="line">    task_name=<span class="string">&quot;main&quot;</span></span><br><span class="line">)</span><br><span class="line">sch_tuned.mod.show()</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/10/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/12/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhangzhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">172</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">107</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhangzhe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js', () => {
    // 初始化 Mermaid 配置
    mermaid.initialize({
      theme    : 'dark',  // 设置主题
      logLevel : 3,  // 设置日志等级
      flowchart: { curve: 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 },
      themeVariables: {
        'fontFamily': 'Microsoft YaHei, Arial, sans-serif',  // 设置中文字体
      }
    });

    // 初始化 Mermaid 图表
    mermaid.init(undefined, document.querySelectorAll('pre.mermaid'));
  }, window.mermaid);
}
</script>


  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'eK3W25jybCO5jVUrYBBpAPqM-gzGzoHsz',
      appKey     : 'F4KVyUj9wHI5c80Bhz7O2uhq',
      placeholder: "说点什么再走吧...",
      avatar     : 'hide',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
