<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"real-zhangzhe.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Zhangzhe&#39;s Blog">
<meta property="og:url" content="https://real-zhangzhe.github.io/page/10/index.html">
<meta property="og:site_name" content="Zhangzhe&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhangzhe">
<meta property="article:tag" content="No mistakes in the tango, not like life.">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://real-zhangzhe.github.io/page/10/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Zhangzhe's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhangzhe's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">The projection of my life.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/archives/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/08/16/BEVFormer-Learning-Bird%E2%80%99s-Eye-View-Representation-from-Multi-Camera-Images-via-Spatiotemporal-Transformers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/16/BEVFormer-Learning-Bird%E2%80%99s-Eye-View-Representation-from-Multi-Camera-Images-via-Spatiotemporal-Transformers/" class="post-title-link" itemprop="url">BEVFormer: Learning Bird’s-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-08-16 12:02:58" itemprop="dateCreated datePublished" datetime="2023-08-16T12:02:58+08:00">2023-08-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BEV/" itemprop="url" rel="index"><span itemprop="name">BEV</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/08/16/BEVFormer-Learning-Bird%E2%80%99s-Eye-View-Representation-from-Multi-Camera-Images-via-Spatiotemporal-Transformers/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/08/16/BEVFormer-Learning-Bird%E2%80%99s-Eye-View-Representation-from-Multi-Camera-Images-via-Spatiotemporal-Transformers/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2203.17270.pdf">https://arxiv.org/pdf/2203.17270.pdf</a></li>
<li>chinese paper: <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1dKnD6gUHhBXZ8gT733cIU_A7dHEEzNTP/view?pli=1">https://drive.google.com/file/d/1dKnD6gUHhBXZ8gT733cIU_A7dHEEzNTP/view?pli=1</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/fundamentalvision/BEVFormer">https://github.com/fundamentalvision/BEVFormer</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>传统 <code>BEV</code> 算法中 <code>View Transform</code> 都是通过 <code>LSS</code> 实现 <code>Image View</code> 到 <code>BEV View</code> 的转变，这种视角转换方法依赖于图像视角的深度估计（显式（例如 <code>BEVDepth</code>）或隐式（例如 <code>LSS / BEVDet</code> 等））。</li>
<li>本文提出一种新的通过时空注意力机制实现的 <code>View Transform</code> 方法，在 <code>Neuscenes</code> 数据集上取得了不错的 <code>3D</code> 目标检测成绩（略差于 <code>BEVDet4D</code>）。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2024/10/09/wkgV4SOFjJtncAX.png" alt="bevformer.png" /></p>
<h3 id="整体架构"><a class="markdownIt-Anchor" href="#整体架构"></a> 整体架构</h3>
<h4 id="1-输入"><a class="markdownIt-Anchor" href="#1-输入"></a> 1. 输入</h4>
<ul>
<li>输入包含两部分，分别是：
<ul>
<li>环视图（<code>6</code> 张）</li>
<li><code>BEV Queries</code>（<code>shape = [num_voxel, dim]</code>）</li>
<li><code>History BEV Feature</code>（上一帧的 <code>BEV Feature</code> 输出，<code>shape = [num_voxel, dim]</code>）</li>
</ul>
</li>
</ul>
<h4 id="2-输出"><a class="markdownIt-Anchor" href="#2-输出"></a> 2. 输出</h4>
<ul>
<li>输出为当前帧的 <code>BEV Feature</code>（<code>shape = [num_voxel, dim]</code>），记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">B_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li>暂时不考虑任务头</li>
</ul>
<h4 id="3-网络模块"><a class="markdownIt-Anchor" href="#3-网络模块"></a> 3. 网络模块</h4>
<ol>
<li>图像特征提取
<ul>
<li><code>6</code> 张图片单独做 <code>CNN base</code> 特征提取，输出记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">F_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
<li>时序信息融合：
<ul>
<li>将构造的 <code>BEV Queries</code>（记作 <code>Q</code>），和上一帧的 <code>BEV Feature</code>（记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">B_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>）做 <code>Self-Attention</code></li>
<li>其中 <code>Q</code> 作为 <code>Query</code>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">B_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 作为 <code>Key / value</code>，做 <code>Attention</code> 运算</li>
<li>虽然这里的 <code>Query / Key / Value</code> 并不同源，但依然被称为是 <code>Self-Attention</code> 而不是 <code>Cross-Attention</code>，是因为 <code>Q</code> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">B_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 都属于 <code>BEV</code> 语义</li>
<li>输出记作 <code>Q'</code></li>
</ul>
</li>
<li>空间交叉注意力（<strong>视角转换</strong>）
<ul>
<li>此步骤是本文的重点，<code>BEVFormer</code> 通过这一步将透视图特征转换为俯视图特征</li>
<li>输入为:
<ul>
<li><code>Q'</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">F_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
<li>做 <code>Cross-Attention</code> 运算，其中：
<ul>
<li><code>Q'</code> 作为 <code>Queries</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">F_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 作为 <code>Key / Value</code></li>
</ul>
</li>
<li>用预设的无意义且可学习的 <code>BEV Queries</code> 去查询图片总体特征，得到 <code>BEV Feature</code> 输出，记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">B_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
<li>任务相关头
<ul>
<li>输入为：<code>BEV Feature</code></li>
<li>输出为：<code>BEV</code> 视角下的检测 / 分割等任务预测结果</li>
<li>模型结构：可以是 <code>CNN base</code> 也可以是 <code>Transformer base</code> 的</li>
</ul>
</li>
</ol>
<ul>
<li>以上提到的所有 <code>Attention</code> 过程都需要额外添加 <code>Position embedding</code></li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>过程并不复杂，只要看过经典的 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2005.12872"><code>DETR</code></a>，都熟悉这种套路：<strong>预设一个无意义的（随机初始化但可学习） <code>pattern</code> 序列作为 <code>Query</code> 去查询 <code>image features</code>，得到有意义的结果（或者说是可监督的结果）</strong></li>
<li>后续的部分工作对其改进是：<strong>将随机初始化预设的 <code>Query</code> 有意义化（例如通过一个轻量化 <code>2D</code> 检测头预检测，得到 <code>proposal</code> 并编码为 <code>Query</code>）</strong></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/08/06/BEVDepth-Acquisition-of-Reliable-Depth-for-Multi-view-3D-Object-Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/06/BEVDepth-Acquisition-of-Reliable-Depth-for-Multi-view-3D-Object-Detection/" class="post-title-link" itemprop="url">BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-08-06 20:43:24" itemprop="dateCreated datePublished" datetime="2023-08-06T20:43:24+08:00">2023-08-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BEV/" itemprop="url" rel="index"><span itemprop="name">BEV</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/08/06/BEVDepth-Acquisition-of-Reliable-Depth-for-Multi-view-3D-Object-Detection/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/08/06/BEVDepth-Acquisition-of-Reliable-Depth-for-Multi-view-3D-Object-Detection/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2206.10092.pdf">https://arxiv.org/pdf/2206.10092.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/Megvii-BaseDetection/BEVDepth">https://github.com/Megvii-BaseDetection/BEVDepth</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一种 <code>BEV</code> 视角下的的 <code>3D</code> 目标检测算法，作者认为尽管深度对相机 <code>3D</code> 检测至关重要，但最近的方法中的深度估计却出奇地不足。</li>
<li><code>BEVDepth</code> 通过利用显式深度监督（来自 <code>lidar</code> 点云）来解决这个问题。</li>
<li>同时使用关键帧和过渡帧在 <code>bev feature</code> 维度进行特征融合，引入时序信息，提高模型效果。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2023/08/14/hiLsqmKyRrbajHe.png" alt="bevdepth1.png" /></p>
<ul>
<li>与 <code>BEVDet4D</code> 的 <code>pipeline</code> 很相似，区别是 <code>BEVDepth</code> 使用了 <code>DepthNet</code> 用激光雷达点云数据做了深度监督。</li>
<li><code>DepthNet</code> 深度监督的输入是 <code>6v</code> 图像特征和每个相机的内外参，输出为 <strong>相机相关深度估计（camera_awareness_depth_estimation）</strong><br />
<img src="https://s2.loli.net/2023/08/14/fDwVr9PMLEb1z3Q.png" alt="bevdepth2.png" /></li>
</ul>
<blockquote>
<p>显式监督效果和 baseline 对比还是很赞的！<br />
<img src="https://s2.loli.net/2023/08/15/G9fWVKmtTeawzYQ.png" alt="table.png" /><br />
<code>MAP</code> 和 <code>NDS</code> 吊打了一众基于纯视觉的算法</p>
</blockquote>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>多帧训练中过渡帧使用了 <code>nuScenes</code> 数据集的 <code>Sweep</code> 数据（没有人工标注的原始数据，只包含图像和 lidar 点云），无形中拓展了数据量。</li>
<li>本文创新点不多，基本是 <code>BEVDet4D + DepthNet</code>，更像是一个工程优化，比如：用 <code>cuda</code> 写了 <code>voxel pooling</code> 过程，计算过程非常高效。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/08/06/BEVDet4D-Exploit-Temporal-Cues-in-Multi-camera-3D-Object-Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/06/BEVDet4D-Exploit-Temporal-Cues-in-Multi-camera-3D-Object-Detection/" class="post-title-link" itemprop="url">BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-08-06 15:00:34" itemprop="dateCreated datePublished" datetime="2023-08-06T15:00:34+08:00">2023-08-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BEV/" itemprop="url" rel="index"><span itemprop="name">BEV</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/08/06/BEVDet4D-Exploit-Temporal-Cues-in-Multi-camera-3D-Object-Detection/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/08/06/BEVDet4D-Exploit-Temporal-Cues-in-Multi-camera-3D-Object-Detection/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2203.17054.pdf">https://arxiv.org/pdf/2203.17054.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/HuangJunJie2017/BEVDet">https://github.com/HuangJunJie2017/BEVDet</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>BEVDet4D</code> 是基于 <code>BEVDet</code> 加入了时序信息的一篇论文</li>
<li>具体来说就是将上一帧的 <code>BEV Feature</code> 和本帧的 <code>BEV Feature</code> 对齐后 <code>Concat</code> 到一起送入 <code>BEV Encoder</code> 中进行 <code>BEV</code> 视角下的 <code>3D</code> 目标检测</li>
<li><code>BEVDet</code> 论文中的 <code>image encoder + view transformer</code> 完全保持不变</li>
<li>由于有两帧的信息，所以对速度的预测相较于单帧有较大提升</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="整体流程"><a class="markdownIt-Anchor" href="#整体流程"></a> 整体流程</h3>
<p><img src="https://s2.loli.net/2023/08/06/XwCSmtKiFWJEzQk.png" alt="bevdet4d.png" /><br />
在 <code>BEV Feature</code> 层面（<code>View Transformer</code> 的输出）融合两帧信息</p>
<h3 id="算法的伪代码表示"><a class="markdownIt-Anchor" href="#算法的伪代码表示"></a> 算法的伪代码表示</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BEVDet4D</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 初始化相关的编码器、转换器和其他必要的组件</span></span><br><span class="line">        self.image_view_encoder = ImageViewEncoder()</span><br><span class="line">        self.view_transformer = ViewTransformer()</span><br><span class="line">        self.bev_encoder = BEVEncoder()</span><br><span class="line">        self.head = DetectionHead()</span><br><span class="line">        self.previous_bev_feature = <span class="literal">None</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spatial_alignment</span>(<span class="params">self, feature</span>):</span></span><br><span class="line">        <span class="comment"># 这里执行空间对齐操作，具体细节可能需要根据原始论文进行补充</span></span><br><span class="line">        <span class="comment"># 实际代码中这里似乎没有开，即上一帧的 BEV feature 直接和本帧 BEV feature map concat</span></span><br><span class="line">        aligned_feature = ... </span><br><span class="line">        <span class="keyword">return</span> aligned_feature</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, current_image</span>):</span></span><br><span class="line">        <span class="comment"># 使用图像视图编码器和视图转换器处理当前图像</span></span><br><span class="line">        image_feature = self.image_view_encoder(current_image)</span><br><span class="line">        transformed_feature = self.view_transformer(image_feature)</span><br><span class="line">        <span class="comment"># 使用BEV编码器获取当前帧的BEV特征</span></span><br><span class="line">        current_bev_feature = self.bev_encoder(transformed_feature)</span><br><span class="line">        <span class="comment"># 如果存在前一帧的BEV特征，则进行空间对齐和融合</span></span><br><span class="line">        <span class="keyword">if</span> self.previous_bev_feature:</span><br><span class="line">            aligned_previous_feature = self.spatial_alignment(self.previous_bev_feature)</span><br><span class="line">            fused_feature = concatenate(aligned_previous_feature, current_bev_feature)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fused_feature = current_bev_feature</span><br><span class="line">        <span class="comment"># 使用检测头部进行3D物体检测</span></span><br><span class="line">        detections = self.head(fused_feature)</span><br><span class="line">        <span class="comment"># 保存当前帧的BEV特征以供下一帧使用</span></span><br><span class="line">        self.previous_bev_feature = current_bev_feature</span><br><span class="line">        <span class="keyword">return</span> detections</span><br><span class="line"><span class="comment"># 实例化BEVDet4D并进行前向传递</span></span><br><span class="line">bevdet4d = BEVDet4D()</span><br><span class="line">detections = bevdet4d.forward(current_image)</span><br></pre></td></tr></table></figure>
<h3 id="result"><a class="markdownIt-Anchor" href="#result"></a> result</h3>
<p><img src="https://s2.loli.net/2023/08/06/TgX7qpHDZUjsEGn.png" alt="BEVdet4D2.png" /></p>
<blockquote>
<p>效果比 <code>BEVDet</code> 好了不少，尤其是 <code>mAVE</code> (速度误差)</p>
</blockquote>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>没有很大的创新点，更像是 <code>BEVDet</code> 的一个使用 <code>trick</code></li>
<li><code>BEVDet</code> 的计算量主要分布在 <code>image encoder</code> 和 <code>view transformer</code>，所以复用上一帧的 <code>BEV feature</code> 即充分利用了上一帧的计算量，对当前帧引入的额外计算量也比较可控（<code>BEV encoder</code> 和 <code>task head</code> 都比较轻量）</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/08/06/BEVDet-High-Performance-Multi-Camera-3D-Object-Detection-in-Bird-Eye-View/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/06/BEVDet-High-Performance-Multi-Camera-3D-Object-Detection-in-Bird-Eye-View/" class="post-title-link" itemprop="url">BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-08-06 09:57:25" itemprop="dateCreated datePublished" datetime="2023-08-06T09:57:25+08:00">2023-08-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BEV/" itemprop="url" rel="index"><span itemprop="name">BEV</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/08/06/BEVDet-High-Performance-Multi-Camera-3D-Object-Detection-in-Bird-Eye-View/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/08/06/BEVDet-High-Performance-Multi-Camera-3D-Object-Detection-in-Bird-Eye-View/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.11790.pdf">https://arxiv.org/pdf/2112.11790.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/HuangJunJie2017/BEVDet">https://github.com/HuangJunJie2017/BEVDet</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文介绍了一种 <code>BEV</code> 视角下的 <code>3D</code> 障碍物检测算法，该算法的输入是由多张（6张）图片组成的车身环视视角，输出为车身周围障碍物的 <code>3D bbox</code></li>
<li>与 <code>LSS（lift-splat-shoot）</code> 算法较为相似，但任务不同，<code>LSS</code> 想要解决的是 <code>BEV</code> 视角下的分割问题，<code>BEVDet</code> 想要解决的是 <code>3D</code> 障碍物检测问题</li>
<li>与 <code>FCOS3D</code> 等单目 <code>3D</code> 障碍物检测的任务类型相似，区别在于：单目 <code>3D</code> 障碍物检测对每个视角做 <code>3D</code> 障碍物检测后，需要使用后处理融合跨视角的物体，<code>BEVDet</code> 可以将跨视角融合问题内嵌到模型中（<code>BEV</code>）</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="总体结构"><a class="markdownIt-Anchor" href="#总体结构"></a> 总体结构</h3>
<p><img src="https://s2.loli.net/2023/08/06/pEmYIytkViZeRrv.png" alt="BevDet.png" /><br />
由上图可以看出，模型主要由四个部分组成，分别是：</p>
<ul>
<li><strong><code>Image-view Encoder</code></strong>：图像特征提取（<code>backbone + neck</code>），6个视角分别做特征提取，不做视角间特征融合</li>
<li><strong><code>View Transformer</code></strong>：视角变换（同时也实现了图像间信息融合），从图像视角转换为 <code>BEV</code> 视角，使用的方法和 <code>LSS</code> 方法一样，输出为 <code>BEV feature</code></li>
<li><strong><code>BEV Encoder</code></strong>：对 <code>BEV feature</code> 用一个较小的 <code>BEV backbone</code> 做特征提取</li>
<li><strong><code>Head</code></strong>：任务头，预测 <code>3D bbox</code> 等，本文使用了 <code>CenterPoint Head</code></li>
</ul>
<h3 id="算法流程的伪代码表示"><a class="markdownIt-Anchor" href="#算法流程的伪代码表示"></a> 算法流程的伪代码表示</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义输入，shape: (8, 6, 256, 704, 3) [batch, camera, H, W, C]</span></span><br><span class="line">input_images = get_input_images()</span><br><span class="line"><span class="comment"># 图像视图编码器，输出shape: (8, 6, 16, 44, 256) [batch, camera, H//16, W//16, C]</span></span><br><span class="line">image_view_features = image_view_encoder(input_images)</span><br><span class="line"><span class="comment"># 视图变换器，输出shape: (8, 64, 128, 128) [batch, C, Bev_H, Bev_W]</span></span><br><span class="line">transformed_features = view_transformer(image_view_features)</span><br><span class="line"><span class="comment"># BEV编码器，输出shape: (8, 256, 64, 64) [batch, C, Bev_H//2, Bev_W//2]</span></span><br><span class="line">encoded_bev_features = bev_encoder(transformed_features)</span><br><span class="line"><span class="comment"># 任务特定头部进行3D物体检测，输出shape: (8, num_objects, object_info)</span></span><br><span class="line">detection_results = task_specific_head(encoded_bev_features)</span><br><span class="line"><span class="comment"># 返回3D物体检测结果</span></span><br><span class="line"><span class="keyword">return</span> detection_results</span><br></pre></td></tr></table></figure>
<h3 id="数据增广方法"><a class="markdownIt-Anchor" href="#数据增广方法"></a> 数据增广方法</h3>
<ul>
<li><strong>独立图片空间数据增广</strong>：图片的翻转、裁剪和旋转可以用 <code>3x3</code> 矩阵表示，在 <code>View Transformer</code> 的时候需要做对应逆变换，即 <em>同时更改图片和 View Transformer 过程</em></li>
<li><strong>BEV视角下的数据增广</strong>：在BEV空间的学习中，数据量少于图像视图空间，因为每个样本包含多个摄像机图像，所以更容易过拟合；该增广方法遵循常见的 <code>LiDAR</code> 方法，采用了 <code>2D</code> 空间中的常见数据增广操作，如翻转、缩放和旋转，需要对应修改目标 <code>3D bbox</code>，即 <em>同时更改 BEV Feature 和 3D bbox GT</em></li>
</ul>
<h3 id="scale-nms"><a class="markdownIt-Anchor" href="#scale-nms"></a> <code>Scale-NMS</code></h3>
<ul>
<li>由于 <code>BEV</code> 空间中不同类别的空间分布与图像视图空间中的分布非常不同，所以作者提出了 <code>Scale-NMS</code>，在执行经典的 <code>NMS</code> 算法之前根据每个对象的类别来缩放每个对象的大小，可显著提高了对小面积类别（如行人和交通锥）的预测性能</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>从模型结构和数据增广方式看 <code>BEVDet</code> 本质是一个二阶段算法：
<ul>
<li><code>image Encode + View Transformer</code>：环视图像编码到 <code>BEV</code> 空间</li>
<li><code>BEV Encoder + Task Head</code>：<code>BEV</code> 空间下的 <code>3D</code> 障碍物检测</li>
</ul>
</li>
<li>但第一阶段输出的 <code>BEV Feature</code> 没有用 <code>LiDAR</code> 点云监督就有点怪…（后续的改进算法加了）</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/07/29/MOTR-End-to-End-Multiple-Object-Tracking-with-Transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/29/MOTR-End-to-End-Multiple-Object-Tracking-with-Transformer/" class="post-title-link" itemprop="url">MOTR: End-to-End Multiple-Object Tracking with Transformer</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-07-29 19:12:12" itemprop="dateCreated datePublished" datetime="2023-07-29T19:12:12+08:00">2023-07-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Transformer/" itemprop="url" rel="index"><span itemprop="name">Transformer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/07/29/MOTR-End-to-End-Multiple-Object-Tracking-with-Transformer/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/07/29/MOTR-End-to-End-Multiple-Object-Tracking-with-Transformer/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2105.03247.pdf">https://arxiv.org/pdf/2105.03247.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/megvii-research/MOTR">https://github.com/megvii-research/MOTR</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>提出了一个完全端到端的多目标跟踪框架</li>
<li>将多目标跟踪问题形式化为一组序列预测问题</li>
<li>引入了跟踪感知的标签分配</li>
<li>提出了用于时间建模的集体平均损失和时间聚合网络方法</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="motr-整体流程"><a class="markdownIt-Anchor" href="#motr-整体流程"></a> MOTR 整体流程</h3>
<p><img src="https://s2.loli.net/2023/07/29/d6goYqmnSGXVOW8.png" alt="MOTR.png" /></p>
<ol>
<li><strong>特征提取</strong>：用 <code>CNN backbone</code> 提取连续帧中每一帧的特征（上图中的 <code>Enc</code>）</li>
<li><strong>查询生成</strong>：用 <code>Deformable Transformer</code> 对第一步提取的特征进行查询（上图中的 <code>Dec</code>）
<ul>
<li>对于视频第一帧，只解码 <code>object detection query</code> （上图中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">q_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ）得到 <code>hidden state</code></li>
<li>对于非第一帧，将 <code>object detection query</code> （上图中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">q_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ）和上一帧的 <code>tracking query</code> （上图中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mrow><mi>t</mi><mi>r</mi></mrow></msub></mrow><annotation encoding="application/x-tex">q_{tr}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ）先 <code>concat</code> 再进行解码得到 <code>hidden state</code></li>
</ul>
</li>
<li><strong>预测结果生成</strong>：用一个简单的结构将上一步得到的 <code>hidden state</code> 映射到任务空间，预测结果包含 <code>object detection results</code> 和 <code>tracking results</code></li>
<li><strong>得到下一帧的 tracking query</strong>：用 <code>QIM (Query Interaction Module, 查询交互模块)</code> 将上一步得到的预测结果映射为下一帧的 <code>tracking query</code></li>
<li><strong>计算损失 / 输出预测结果</strong>：对于训练，计算集体平均损失（<code>CAL, Collective Average Loss</code>）;对于预测，直接输出第 3 步得到的结果</li>
</ol>
<ul>
<li>描述 <code>MOTR</code> 过程的伪代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_frame</span>(<span class="params">frame, detect_queries, track_queries=<span class="literal">None</span>, ground_truths=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># 使用CNN提取帧特征</span></span><br><span class="line">    <span class="comment"># frame shape: (height, width, channels)</span></span><br><span class="line">    frame_features = extract_frame_features(frame)  <span class="comment"># Shape: (height, width, channels)</span></span><br><span class="line">    <span class="keyword">if</span> track_queries <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 使用Deformable DETR解码器生成隐藏状态</span></span><br><span class="line">        <span class="comment"># detect_queries shape: (num_queries, query_dim)</span></span><br><span class="line">        <span class="comment"># frame_features shape: (height, width, channels)</span></span><br><span class="line">        hidden_states = deformable_detr_decoder(detect_queries, frame_features)  <span class="comment"># Shape: (num_queries, hidden_dim)</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        queries = concatenate(track_queries, detect_queries)  <span class="comment"># Shape: (num_queries + num_tracks, query_dim)</span></span><br><span class="line">        hidden_states = deformable_detr_decoder(queries, frame_features)  <span class="comment"># Shape: (num_queries + num_tracks, hidden_dim)</span></span><br><span class="line">    <span class="comment"># 生成预测</span></span><br><span class="line">    <span class="comment"># hidden_states shape: (num_queries, hidden_dim)</span></span><br><span class="line">    predictions = predict(hidden_states)  <span class="comment"># Shape: (num_queries + num_tracks, num_classes + 4)</span></span><br><span class="line">    <span class="comment"># 使用Query Interaction Module (QIM)生成下一帧的跟踪查询</span></span><br><span class="line">    <span class="comment"># hidden_states shape: (num_queries, hidden_dim)</span></span><br><span class="line">    track_queries = qim(hidden_states)  <span class="comment"># Shape: (num_tracks, query_dim)</span></span><br><span class="line">    <span class="keyword">if</span> ground_truths <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 使用Collective Average Loss (CAL)进行训练</span></span><br><span class="line">        <span class="comment"># predictions shape: (num_queries, num_classes + 4)</span></span><br><span class="line">        <span class="comment"># ground_truths shape: (num_objects, num_classes + 4)</span></span><br><span class="line">        loss = cal(predictions, ground_truths)</span><br><span class="line">        backpropagate(loss)</span><br><span class="line">    <span class="keyword">return</span> predictions, track_queries  <span class="comment"># Shape: (num_queries + num_tracks, num_classes + 4), (num_tracks, query_dim)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_video</span>(<span class="params">video, ground_truths=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># 初始化检测查询</span></span><br><span class="line">    <span class="comment"># 返回形状：(num_queries, query_dim)</span></span><br><span class="line">    detect_queries = initialize_detect_queries()  </span><br><span class="line">    track_queries = <span class="literal">None</span>  <span class="comment"># Shape: (num_tracks, query_dim)</span></span><br><span class="line">    <span class="keyword">for</span> frame <span class="keyword">in</span> video:</span><br><span class="line">        predictions, track_queries = process_frame(frame, detect_queries, track_queries, ground_truths)</span><br><span class="line">        <span class="keyword">if</span> ground_truths <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">yield</span> predictions</span><br></pre></td></tr></table></figure>
<h3 id="查询交互模块"><a class="markdownIt-Anchor" href="#查询交互模块"></a> 查询交互模块</h3>
<ul>
<li>查询交互模块 <code>Query Interaction Module (QIM)</code> 是 <code>MOTR</code> 中的一个关键组件，它负责处理物体的进入和退出，以及增强长期的时间关系建模</li>
<li><code>QIM</code> 的输入是当前帧预测的 <code>detection result</code> 和 <code>tracking result</code>，输出是下一帧的 <code>tacking query</code></li>
<li>通俗来说，<code>QIM</code> 是根据当前帧预测的结果，给出下一帧的 “提问”</li>
<li><code>QIM</code> 过程的伪代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">query_interaction_module</span>(<span class="params">hidden_states, scores, tau_en, tau_ex, M</span>):</span></span><br><span class="line">    <span class="comment"># hidden_states shape: (num_queries, hidden_dim)</span></span><br><span class="line">    <span class="comment"># scores shape: (num_queries, num_classes)</span></span><br><span class="line">    <span class="comment"># tau_en, tau_ex: entrance and exit thresholds</span></span><br><span class="line">    <span class="comment"># M: number of consecutive frames for exit threshold</span></span><br><span class="line">    <span class="comment"># Object Entrance</span></span><br><span class="line">    entrance_mask = scores.<span class="built_in">max</span>(dim=<span class="number">1</span>) &gt; tau_en  <span class="comment"># Shape: (num_queries,)</span></span><br><span class="line">    hidden_states = hidden_states[entrance_mask]  <span class="comment"># Shape: (num_entrance_queries, hidden_dim)</span></span><br><span class="line">    <span class="comment"># Temporal Aggregation Network (TAN)，主要目的是融合时序信息，本文是用了一个 Multi-Head Self-Attention 实现</span></span><br><span class="line">    hidden_states = temporal_aggregation_network(hidden_states)  <span class="comment"># Shape: (num_entrance_queries, hidden_dim)</span></span><br><span class="line">    <span class="comment"># Object Exit</span></span><br><span class="line">    exit_mask = scores.<span class="built_in">max</span>(dim=<span class="number">1</span>) &lt; tau_ex  <span class="comment"># Shape: (num_entrance_queries,)</span></span><br><span class="line">    exit_mask = exit_mask.rolling(window=M).<span class="built_in">sum</span>() &gt; <span class="number">0</span>  <span class="comment"># Shape: (num_entrance_queries,)</span></span><br><span class="line">    hidden_states = hidden_states[~exit_mask]  <span class="comment"># Shape: (num_track_queries, hidden_dim)</span></span><br><span class="line">    <span class="keyword">return</span> hidden_states  <span class="comment"># Shape: (num_track_queries, hidden_dim)</span></span><br></pre></td></tr></table></figure>
<h3 id="集体平均损失"><a class="markdownIt-Anchor" href="#集体平均损失"></a> 集体平均损失</h3>
<ul>
<li>集体平均损失（Collective Average Loss，CAL）是 <code>MOTR</code> 算法中用于训练的损失函数。不同于传统的逐帧计算损失，<code>CAL</code> 收集整个视频剪辑的所有预测，然后基于整个视频剪辑计算总体损失</li>
<li>集体平均损失的代码描述</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collective_average_loss</span>(<span class="params">predictions, ground_truths, matching_results</span>):</span></span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    total_objects = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predictions)):</span><br><span class="line">        pred_tracked = predictions[i][<span class="string">&#x27;tracked&#x27;</span>]</span><br><span class="line">        pred_detected = predictions[i][<span class="string">&#x27;detected&#x27;</span>]</span><br><span class="line">        gt_tracked = ground_truths[i][<span class="string">&#x27;tracked&#x27;</span>]</span><br><span class="line">        gt_detected = ground_truths[i][<span class="string">&#x27;detected&#x27;</span>]</span><br><span class="line">        match_tracked = matching_results[i][<span class="string">&#x27;tracked&#x27;</span>]</span><br><span class="line">        match_detected = matching_results[i][<span class="string">&#x27;detected&#x27;</span>]</span><br><span class="line">        total_loss += single_frame_loss(pred_tracked, match_tracked, gt_tracked)</span><br><span class="line">        total_loss += single_frame_loss(pred_detected, match_detected, gt_detected)</span><br><span class="line">        total_objects += <span class="built_in">len</span>(gt_tracked) + <span class="built_in">len</span>(gt_detected)</span><br><span class="line">    <span class="keyword">return</span> total_loss / total_objects</span><br></pre></td></tr></table></figure>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>以一种非常优雅的方式解决了端到端多目标追踪的任务，打破了之前 <code>NN detection + Hard logic code tracking</code> 的 <code>tracking</code> 范式</li>
<li>这种非黑盒的（显式监督 <code>detecion bbox</code>）复杂任务端到端训练，启发了后续的许多更复杂的端到端任务，例如 <code>UniAD</code></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/07/29/Deformable-DETR-Deformable-Transformers-for-End-to-end-Object-Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/29/Deformable-DETR-Deformable-Transformers-for-End-to-end-Object-Detection/" class="post-title-link" itemprop="url">Deformable DETR: Deformable Transformers for End-to-end Object Detection</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-07-29 10:47:54" itemprop="dateCreated datePublished" datetime="2023-07-29T10:47:54+08:00">2023-07-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Transformer/" itemprop="url" rel="index"><span itemprop="name">Transformer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/07/29/Deformable-DETR-Deformable-Transformers-for-End-to-end-Object-Detection/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/07/29/Deformable-DETR-Deformable-Transformers-for-End-to-end-Object-Detection/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.04159.pdf">https://arxiv.org/pdf/2010.04159.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/fundamentalvision/Deformable-DETR">https://github.com/fundamentalvision/Deformable-DETR</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><strong>提出了 <code>Deformable DETR</code></strong>：这是一种新的目标检测模型，解决了现有 <code>DETR</code> 模型的收敛速度慢和特征空间分辨率有限的问题。</li>
<li><strong>使用可变形的注意力模块</strong>：这些模块只关注参考点周围的一小部分关键采样点，从而在更少的训练周期内提高了性能，尤其是对小对象的检测。</li>
<li><strong>结合了可变形卷积的稀疏空间采样和 <code>Transformer</code> 的关系建模能力</strong>：这使得模型能够在处理大规模数据时保持高效，同时还能捕捉到复杂的上下文关系。</li>
<li><strong>引入了一种两阶段的变体</strong>：在这个变体中，区域提议由 <code>Deformable DETR</code> 生成，然后进行迭代的细化。这使得模型能够更精确地定位和识别目标。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2023/07/29/zLITUxlAaR7QNJ2.png" alt="deformable_detr.png" /></p>
<blockquote>
<p><code>Deformable DETR</code> 整体结构图</p>
</blockquote>
<h3 id="deformabel-attention-block"><a class="markdownIt-Anchor" href="#deformabel-attention-block"></a> Deformabel Attention Block</h3>
<p><img src="https://s2.loli.net/2023/07/29/9rHe4CBKV1iEAOj.png" alt="deformable_attention.png" /></p>
<ul>
<li><code>Multi-Head Attention</code>:<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>u</mi><mi>l</mi><mi>t</mi><mi>i</mi><mi>H</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>q</mi></msub><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></msubsup><msub><mi>W</mi><mi>m</mi></msub><mo stretchy="false">[</mo><msub><mo>∑</mo><mrow><mi>k</mi><mo>∈</mo><msub><mi mathvariant="normal">Ω</mi><mi>k</mi></msub></mrow></msub><msub><mi>A</mi><mrow><mi>m</mi><mi>q</mi><mi>k</mi></mrow></msub><mo>⋅</mo><msubsup><mi>W</mi><mi>m</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">MultiHeadAtten(z_q, x) = \sum_{m=1}^MW_m[\sum_{k\in\Omega_k}A_{mqk}\cdot W_m&#x27;x_k]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">A</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.386801em;vertical-align:-0.40557em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.18639799999999984em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mtight">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.40557em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.001892em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>
<ul>
<li>
<p>输入为一个 <code>query</code> 的表征 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">z_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> ，以及总特征 <code>x</code>，输出为 <code>query</code> 查询结果向量</p>
</li>
<li>
<p><code>M</code> 表示 <code>number of head</code></p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>m</mi><mi>q</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{mqk}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">softmax(\frac{QK^T}{\sqrt{d}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.627473em;vertical-align:-0.538em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.089473em;"><span style="top:-2.5335085em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.937845em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mathnormal mtight">d</span></span></span><span style="top:-2.8978450000000002em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.102155em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9190928571428572em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>W</mi><mi>m</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">W_m&#x27;x_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.998892em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 实际上就是 <code>self-attention</code> 中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></p>
</li>
</ul>
</li>
<li><code>Deformable Attention</code>:<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mi>e</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>b</mi><mi>l</mi><mi>e</mi><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>q</mi></msub><mo separator="true">,</mo><msub><mi>p</mi><mi>q</mi></msub><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></msubsup><msub><mi>W</mi><mi>m</mi></msub><mo stretchy="false">[</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><msub><mi>A</mi><mrow><mi>m</mi><mi>q</mi><mi>k</mi></mrow></msub><mo>⋅</mo><msubsup><mi>W</mi><mi>m</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mi>x</mi><mo stretchy="false">(</mo><msub><mi>p</mi><mi>q</mi></msub><mo>+</mo><mi mathvariant="normal">Δ</mi><msub><mi>p</mi><mrow><mi>m</mi><mi>q</mi><mi>k</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">DeformableAtten(z_q,p_q,x) = \sum_{m=1}^MW_m[\sum_{k=1}^KA_{mqk}\cdot W_m&#x27;x(p_q + \Delta p_{mqk})]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">A</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.038em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span>
<ul>
<li>输入为一个 <code>query</code> 的表征 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">z_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> ，总特征 <code>x</code>，以及 <code>query</code> 对应的 <strong>预设采样位置</strong>，输出为 <code>query</code> 查询结果向量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><msub><mi>p</mi><mrow><mi>m</mi><mi>q</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\Delta p_{mqk}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示由 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">z_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 计算得到的 <strong>基于预设查询位置的横纵偏移</strong></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>m</mi><mi>q</mi><mi>k</mi></mrow></msub><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>q</mi></msub><msub><mi>W</mi><mi>a</mi></msub><mo stretchy="false">)</mo><mtext>  </mtext><mo separator="true">,</mo><msub><mi>W</mi><mi>a</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi><mo>×</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>p</mi><mi>o</mi><mi>i</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow></msup><mtext>  </mtext><mo separator="true">,</mo><msub><mi>z</mi><mi>q</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A_{mqk} = softmax(z_qW_a)\ \ ,W_a\in\mathbb{R}^{dim\times num\_points}\ \ ,z_q\in\mathbb{R}^{dim}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace"> </span><span class="mspace"> </span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.135216em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">m</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">s</span></span></span></span></span></span></span></span></span><span class="mspace"> </span><span class="mspace"> </span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span> ，即 <strong><code>point position attention</code> 是由 <code>query</code> 线性映射得到的</strong> ，因此 <strong><code>Deformable Attention</code> 没有 <code>Key</code> 的存在，只有 <code>Query</code> 和 <code>Value</code></strong></li>
<li><code>K</code> 表示 <code>number of points</code>，即采样点个数</li>
</ul>
</li>
<li><code>Multi-Scale Deformable Attention</code>：<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>S</mi><mi>D</mi><mi>e</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>b</mi><mi>l</mi><mi>e</mi><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>q</mi></msub><mo separator="true">,</mo><msub><mover accent="true"><mi>p</mi><mo>^</mo></mover><mi>q</mi></msub><mo separator="true">,</mo><mo stretchy="false">{</mo><mi>x</mi><msubsup><mo stretchy="false">}</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></msubsup><msub><mi>W</mi><mi>m</mi></msub><mo stretchy="false">[</mo><msubsup><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></msubsup><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><msub><mi>A</mi><mrow><mi>m</mi><mi>l</mi><mi>q</mi><mi>k</mi></mrow></msub><mo>⋅</mo><msubsup><mi>W</mi><mi>m</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><msup><mi>x</mi><mi>l</mi></msup><mo stretchy="false">(</mo><msub><mi>ϕ</mi><mi>l</mi></msub><mo stretchy="false">(</mo><msub><mover accent="true"><mi>p</mi><mo>^</mo></mover><mi>q</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="normal">Δ</mi><msub><mi>p</mi><mrow><mi>m</mi><mi>l</mi><mi>q</mi><mi>k</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">MSDeformableAtten(z_q,\hat{p}_q,\{x\}_{l=1}^L) = \sum_{m=1}^MW_m[\sum_{l=1}^L\sum_{k=1}^KA_{mlqk}\cdot W_m&#x27;x^l(\phi_l(\hat{p}_q) + \Delta p_{mlqk})]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1274389999999999em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">A</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">{</span><span class="mord mathnormal">x</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.135216em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">ϕ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span>
<ul>
<li>与 <code>Deformable Attention</code> 不同的是，输入的 <code>x</code> 变成了多尺度特征（例如 <code>backbone</code> 不同深度的特征），更贴近实际视觉工程化应用场景</li>
<li><code>point</code> 采样范围是所有 <code>level</code> 的 <code>feature map</code>，即 <code>MSDefromableAttention</code> 有全局 <code>attention</code> 信息</li>
</ul>
</li>
<li><code>Deformable Attention</code> 和 <code>Self Attention</code> 对比</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention</span>(<span class="params">query, key, value</span>):</span></span><br><span class="line">    <span class="comment"># query, key, value shapes: (batch_size, sequence_length, embedding_dim)</span></span><br><span class="line">    scores = torch.matmul(query, key.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(query.size(-<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># scores shape: (batch_size, sequence_length, sequence_length)</span></span><br><span class="line">    probs = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># probs shape: (batch_size, sequence_length, sequence_length)</span></span><br><span class="line">    output = torch.matmul(probs, value)</span><br><span class="line">    <span class="comment"># output shape: (batch_size, sequence_length, embedding_dim)</span></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deformable_attention</span>(<span class="params">query, value, reference_points, num_sampling_points, atten_linear, offset_linear</span>):</span></span><br><span class="line">    <span class="comment"># query shape: (batch_size, sequence_length, embedding_dim)</span></span><br><span class="line">    <span class="comment"># value shape: (batch_size, sequence_length, embedding_dim)</span></span><br><span class="line">    <span class="comment"># reference_points shape: (batch_size, sequence_length, 2)</span></span><br><span class="line">    <span class="comment"># num_sampling_points: integer, number of points to sample around each reference point</span></span><br><span class="line">    </span><br><span class="line">    batch_size, seq_len, embed_dim = query.size()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate offsets</span></span><br><span class="line">    <span class="comment"># offset_linear is a linear layer that predicts the offsets</span></span><br><span class="line">    offsets = offset_linear(reference_points).view(batch_size, seq_len, num_sampling_points, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># offsets shape: (batch_size, sequence_length, num_sampling_points, 2)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate sampling positions based on reference points</span></span><br><span class="line">    sampling_positions = reference_points.unsqueeze(<span class="number">2</span>) + offsets</span><br><span class="line">    <span class="comment"># sampling_positions shape: (batch_size, sequence_length, num_sampling_points, 2)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Sample values (this is simplified; you might need interpolation)</span></span><br><span class="line">    <span class="comment"># Here, we assume value and reference_points are in the same space for simplicity</span></span><br><span class="line">    sampling_values = value.gather(<span class="number">1</span>, sampling_positions.long())</span><br><span class="line">    <span class="comment"># sampling_values shape: (batch_size, sequence_length, num_sampling_points, embedding_dim)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate scores</span></span><br><span class="line">    <span class="comment"># atten_linear is a linear layer that transforms the query for calculating attention scores</span></span><br><span class="line">    scores = atten_linear(query).view(batch_size, seq_len, num_sampling_points)</span><br><span class="line">    <span class="comment"># scores shape: (batch_size, sequence_length, num_sampling_points)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Softmax to get attention probabilities</span></span><br><span class="line">    probs = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># probs shape: (batch_size, sequence_length, num_sampling_points)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate output</span></span><br><span class="line">    output = torch.matmul(probs, sampling_values)</span><br><span class="line">    <span class="comment"># output shape: (batch_size, sequence_length, embedding_dim)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>用 <code>query</code> 线性映射代替 <code>query</code> 和 <code>key</code> 外积做 <code>attention</code> 数学上可解释性会变差，计算复杂度会降低</li>
<li><code>Deformable Conv</code> 是典型的对 <code>NPU</code> 不友好，<code>Deformable Attention</code> 会更复杂，<s>被代季峰支配的恐惧</s></li>
<li>用 <code>Multi-scale</code> 做各特征尺度上的信息融合，开创了一个 <strong>CNN 做 backbone + Deformable Transformer 做 head 的计算机视觉任务模型新范式</strong>，甚至省去了 <code>FPN</code></li>
<li>总之是用各种便宜的计算来近似复杂的全局 <code>attention</code>，复杂度从 <code>H*W</code> --&gt; <code>K</code>，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>−</mo><mo>&gt;</mo><mi>O</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2) -&gt; O(K)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">−</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">)</span></span></span></span></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/07/18/%E4%B8%80%E4%BA%9B%E9%AB%98%E6%95%88backbone%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/18/%E4%B8%80%E4%BA%9B%E9%AB%98%E6%95%88backbone%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/" class="post-title-link" itemprop="url">一些高效backbone设计思想</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-07-18 16:35:50" itemprop="dateCreated datePublished" datetime="2023-07-18T16:35:50+08:00">2023-07-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CNN-Architecture-Design/" itemprop="url" rel="index"><span itemprop="name">CNN Architecture Design</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/07/18/%E4%B8%80%E4%BA%9B%E9%AB%98%E6%95%88backbone%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/07/18/%E4%B8%80%E4%BA%9B%E9%AB%98%E6%95%88backbone%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文介绍了 <code>YOLO</code> 系列几种高效的 <code>backbone</code> 设计，主要包括：<code>VoVNet</code>、<code>PRN</code>、<code>CSPNet</code>、<code>ELAN</code>、<code>E-ELAN</code> 等</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="1-vovnet"><a class="markdownIt-Anchor" href="#1-vovnet"></a> 1. VoVNet</h3>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.09730.pdf">https://arxiv.org/pdf/1904.09730.pdf</a><br />
<img src="https://s2.loli.net/2023/07/18/mhKOv8jGbpPXqJQ.png" alt="vovnet.png" /></li>
<li>作者认为 <code>densenet</code> 存在问题：每一层 <code>Conv</code> 都使用之前所有层的输出，因此会导致当前 <code>Conv</code> 的 <code>input channel</code> 很大，输出到 <code>output channel</code> 却较小</li>
<li>因此，作者只在 <code>VoVNet Block</code> 的最后一个 <code>Conv</code> 才用之前所有层的输出</li>
<li>相同计算量下，效果优于 <code>Resnet</code> 和 <code>DenseNet</code></li>
</ul>
<h3 id="2-prn"><a class="markdownIt-Anchor" href="#2-prn"></a> 2. PRN</h3>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/LPCV/Wang_Enriching_Variety_of_Layer-Wise_Learning_Information_by_Gradient_Combination_ICCVW_2019_paper.pdf">https://openaccess.thecvf.com/content_ICCVW_2019/papers/LPCV/Wang_Enriching_Variety_of_Layer-Wise_Learning_Information_by_Gradient_Combination_ICCVW_2019_paper.pdf</a><br />
<img src="https://s2.loli.net/2023/07/18/3I42vcukOx9QZrm.png" alt="prn.png" /></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/WongKinYiu/PartialResidualNetworks/tree/master">https://github.com/WongKinYiu/PartialResidualNetworks/tree/master</a></li>
<li><code>PRN</code> 全称是 <code>Partial Residule Networks</code>, 在 <code>PRN</code> 中，将 <code>identity</code> 连接乘以二进制 <code>Mask</code>，并且只允许将某些通道的特征映射添加到计算块的输出中</li>
</ul>
<h3 id="3-cspnetyolov5"><a class="markdownIt-Anchor" href="#3-cspnetyolov5"></a> 3. CSPNet（YOLOV5）</h3>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1911.11929.pdf">https://arxiv.org/pdf/1911.11929.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/WongKinYiu/CrossStagePartialNetworks">https://github.com/WongKinYiu/CrossStagePartialNetworks</a><br />
<img src="https://s2.loli.net/2023/07/18/xz1IDSeAFBVncuH.png" alt="CSPNet.png" /></li>
<li><code>CPSNet</code> 的全称是 <code>Cross Stage Partial Networks</code>, 本质是把模型分成两部分，其中一部分经过计算（几层 Conv）后和另外一部分合起来，相当于第二部分和第一部分模型深度不同</li>
</ul>
<h3 id="4-elan"><a class="markdownIt-Anchor" href="#4-elan"></a> 4. ELAN</h3>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2211.04800.pdf">https://arxiv.org/pdf/2211.04800.pdf</a><br />
<img src="https://s2.loli.net/2023/07/18/w4gqVE1Az5Sck9m.png" alt="elan.png" /></li>
<li><code>ELAN</code> 全称是 <code>Efficient Layer Aggregation Network</code>, 作者以 <code>VoVNet</code> 和 <code>ResNet</code> 做对比，<code>VoVNet</code> 在叠加更多 <code>block</code> 时表现要比 <code>ResNet</code> 更差，作者分析是因为 <code>VoVNet</code> 结构中存在过多的 <code>transition layers</code>，这导致在叠加 <code>block</code> 时最短梯度路径（ <code>the shortest gradient path</code> ）不断增加，从而使得 <code>block</code> 增加时训练难度上升</li>
<li><code>PRN</code> 相比 <code>ResNet</code>，使用 <code>mask</code> 让输入只有部分 <code>channel</code> 通过 <code>identity connection</code>，丰富了梯度来源；</li>
<li><code>CSPNet</code> 通过将 <code>channel split</code>，一方面增加了梯度信息（同 <code>PRN</code>），另一方面减少了 <code>computational block</code> 中的计算量；</li>
<li><code>ELAN</code> 的思想是：搭建网络时需要考虑每一层的最短最长梯度路径，还要考虑整个网络的最长梯度路径。</li>
</ul>
<h3 id="5-e-elanyolov7"><a class="markdownIt-Anchor" href="#5-e-elanyolov7"></a> 5. E-ELAN（YOLOV7）</h3>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2207.02696.pdf">https://arxiv.org/pdf/2207.02696.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/WongKinYiu/yolov7">https://github.com/WongKinYiu/yolov7</a><br />
<img src="https://s2.loli.net/2023/07/18/cZANQbK5R7Vmoag.png" alt="eelan.png" /></li>
<li><code>E-ELAN</code> 是 <code>extended ELAN</code>，在不改变 <code>gradient path</code> 的情况下，加入了 <code>Group Conv</code>、<code>Shuffle and merge Conv</code> 等操作，极大的提高了模型表现能力，成就了 <code>YOLOV7</code> 又快又好的效果！</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/07/16/[WIP]UniAD-Planning-oriented-Autonomous-Driving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/16/%5BWIP%5DUniAD-Planning-oriented-Autonomous-Driving/" class="post-title-link" itemprop="url">UniAD: Planning-oriented Autonomous Driving</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-07-16 13:39:51" itemprop="dateCreated datePublished" datetime="2023-07-16T13:39:51+08:00">2023-07-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Autonomous-Driving-Planning/" itemprop="url" rel="index"><span itemprop="name">Autonomous Driving Planning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/07/16/%5BWIP%5DUniAD-Planning-oriented-Autonomous-Driving/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/07/16/%5BWIP%5DUniAD-Planning-oriented-Autonomous-Driving/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2212.10156.pdf">https://arxiv.org/pdf/2212.10156.pdf</a></li>
<li>slides: <a target="_blank" rel="noopener" href="https://opendrivelab.com/e2ead/UniAD_plenary_talk_slides.pdf">https://opendrivelab.com/e2ead/UniAD_plenary_talk_slides.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/OpenDriveLab/UniAD">https://github.com/OpenDriveLab/UniAD</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一种以自动驾驶规划为目的的神经网络架构，该架构对每个感知子任务显式监督，合理的将子任务连接起来，增加了子任务之间的协调性，并增加了模型的可解释性</li>
</ul>
<h1 id="wip"><a class="markdownIt-Anchor" href="#wip"></a> WIP</h1>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/07/03/GPT-4-Technical-Report/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/03/GPT-4-Technical-Report/" class="post-title-link" itemprop="url">GPT-4 Technical Report</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-07-03 09:24:53" itemprop="dateCreated datePublished" datetime="2023-07-03T09:24:53+08:00">2023-07-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Self-Supervised-Learning/" itemprop="url" rel="index"><span itemprop="name">Self-Supervised Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/07/03/GPT-4-Technical-Report/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/07/03/GPT-4-Technical-Report/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.08774.pdf">https://arxiv.org/pdf/2303.08774.pdf</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>使用预测下一个词（语言建模 <code>language modeling</code>）任务进行自监督预训练</li>
<li>预训练的模型需要使用 <code>reinforement learning with human feedback（RLHF）</code> 进行对齐（<code>align</code>），这个过程不会在测试数据集上提高模型表现，但可以更好的对齐人类的意图和三观</li>
<li>模型输入可以是图片和文本，输出为文本</li>
</ul>
<h2 id="details"><a class="markdownIt-Anchor" href="#details"></a> Details</h2>
<ul>
<li>使用了很强大的基建，可以做到准确预测模型训练的最终效果（<code>scaling</code>），可以以较小的代价和较快的时间找到最合适的模型架构和超参数设置</li>
<li>为模型引入了 <code>steerability</code>（操纵性），可以在模型的 <code>prompt</code> 中加入一些 <code>System message</code>，让模型回复风格拥有某种特质（比如老师、政客等）</li>
<li><code>GPT-4</code> 使用了很多机制提高了模型的安全性</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>这篇技术报告更多是对模型效果的分析，基本没有模型细节的描述</li>
<li>大模型逐渐变成大厂垄断，普通研究者能摸到的最后只剩下一个 <code>API</code> …</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/06/30/GPT3-Language-Models-are-Few-Shot-Learners/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/30/GPT3-Language-Models-are-Few-Shot-Learners/" class="post-title-link" itemprop="url">GPT3:Language Models are Few-Shot Learners</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-30 21:41:00" itemprop="dateCreated datePublished" datetime="2023-06-30T21:41:00+08:00">2023-06-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-11 13:48:26" itemprop="dateModified" datetime="2025-12-11T13:48:26+08:00">2025-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Self-Supervised-Learning/" itemprop="url" rel="index"><span itemprop="name">Self-Supervised Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/06/30/GPT3-Language-Models-are-Few-Shot-Learners/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/30/GPT3-Language-Models-are-Few-Shot-Learners/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2005.14165.pdf">https://arxiv.org/pdf/2005.14165.pdf</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>作者团队训练了一个 <code>96</code> 层 <code>Transformer</code> 共 <code>1750</code> 亿参数的超大模型（<code>GPT2</code> 只有约 <code>15</code> 亿参数），在下游任务上无需 <code>fine-tuning</code> 即可得到很好的效果。</li>
<li>本质是 <code>GPT2</code> 的放大版（参数量放大了一百多倍）</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<ul>
<li>在下游任务上，可以使用 <code>Zero Shot</code>、<code>One Shot</code>、<code>Few Shot</code> 三种方式推理模型，下图以英语翻译法语的例子介绍三者的区别：<br />
<img src="https://s2.loli.net/2023/06/30/MaqkjTsZNSCJ8Fb.png" alt="GPT3.png" /></li>
<li>GPT3 系列模型详细设置：<br />
<img src="https://s2.loli.net/2023/06/30/4EYHrsivdgePRlM.png" alt="GP3_1.png" /></li>
<li>GPT3 自监督训练数据：<br />
<img src="https://s2.loli.net/2023/06/30/H9mTFVOyiQnsRhX.png" alt="GP3_2.png" /></li>
</ul>
<blockquote>
<p>使用了 <code>common crawl</code> 数据集，由于 <code>common crawl</code> 数据集很脏，所以训练是数据采样率并不高</p>
</blockquote>
<ul>
<li>下图是在几个下游任务上和 SOTA 算法的比较：<br />
<img src="https://s2.loli.net/2023/06/30/pnz81M7DoCVWbiv.png" alt="GPT3_3.png" /><br />
<img src="https://s2.loli.net/2023/06/30/2EwKHT4BjIo8ecg.png" alt="GPT3_5.png" /><br />
<img src="https://s2.loli.net/2023/06/30/fmSlhbAENVZyBFr.png" alt="GPT3_4.png" /></li>
</ul>
<blockquote>
<p>从普遍表现看，GPT3 few shot 效果 &gt; one shot &gt; zero shot，不一定比 SOTA 点高（SOTA 普遍使用了 fine tuning，直接比较不公平）</p>
</blockquote>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>在某些任务上，<code>GPT3 few shot</code> 效果可媲美 <code>fine tuning SOTA</code>，可以说明 <code>GPT3</code> 还是非常强大的</li>
<li>比上一代参数量提高一百多倍，开启了大模型时代…</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/9/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/11/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhangzhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">173</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">104</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhangzhe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js', () => {
    // 初始化 Mermaid 配置
    mermaid.initialize({
      theme    : 'dark',  // 设置主题
      logLevel : 3,  // 设置日志等级
      flowchart: { curve: 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 },
      themeVariables: {
        'fontFamily': 'Microsoft YaHei, Arial, sans-serif',  // 设置中文字体
      }
    });

    // 初始化 Mermaid 图表
    mermaid.init(undefined, document.querySelectorAll('pre.mermaid'));
  }, window.mermaid);
}
</script>


  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'eK3W25jybCO5jVUrYBBpAPqM-gzGzoHsz',
      appKey     : 'F4KVyUj9wHI5c80Bhz7O2uhq',
      placeholder: "说点什么再走吧...",
      avatar     : 'hide',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
