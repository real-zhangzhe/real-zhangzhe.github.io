<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"real-zhangzhe.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Zhangzhe&#39;s Blog">
<meta property="og:url" content="https://real-zhangzhe.github.io/page/3/index.html">
<meta property="og:site_name" content="Zhangzhe&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhangzhe">
<meta property="article:tag" content="No mistakes in the tango, not like life.">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://real-zhangzhe.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Zhangzhe's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhangzhe's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">The projection of my life.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/archives/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/03/24/CUDA-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-01-%E2%80%94%E2%80%94-CUDA-%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/24/CUDA-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-01-%E2%80%94%E2%80%94-CUDA-%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">CUDA 学习笔记 01 —— CUDA 基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-24 09:57:45" itemprop="dateCreated datePublished" datetime="2025-03-24T09:57:45+08:00">2025-03-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CUDA/" itemprop="url" rel="index"><span itemprop="name">CUDA</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/03/24/CUDA-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-01-%E2%80%94%E2%80%94-CUDA-%E5%9F%BA%E7%A1%80/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/24/CUDA-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-01-%E2%80%94%E2%80%94-CUDA-%E5%9F%BA%E7%A1%80/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="0-学习-cuda-的目的"><a class="markdownIt-Anchor" href="#0-学习-cuda-的目的"></a> 0. 学习 CUDA 的目的</h2>
<ul>
<li>作为一个算法工程师，平时接触 <code>HPC (High Performance Computing)</code> 的机会并不多，那为什么还要学习 <code>CUDA</code> 呢？</li>
<li>学习 <code>CUDA</code> 的目的不是为了用 <code>CUDA</code> 做模型加速，而是从 <code>CUDA</code> 角度理解目前较新的大模型设计理念，这些高性能模型是如何从原理上做到又快又好的。</li>
<li>例如火出圈的 <code>DeepSeek</code> 系列模型，在模型设计角度做了较多创新，并开源了部分 <code>CUDA</code> 代码，对于不了解 <code>CUDA</code> 的工程师，很难 get 到算法设计的优雅之处。</li>
<li>反观某家大模型基座公司，曾开源某个模型结构，论文中一通自夸，分析理论计算量有多低。但很多人实测发现速度并没有很快，究其原因，实际上是这家公司还用的小模型时代的旧思维，即：一个模型理论计算量低，那就是快。</li>
<li>大模型时代不了解硬件，不尊重硬件，在算法创新上不太可能走的远。</li>
</ul>
<h2 id="1-hello-world"><a class="markdownIt-Anchor" href="#1-hello-world"></a> 1. Hello World</h2>
<h3 id="cuda-代码"><a class="markdownIt-Anchor" href="#cuda-代码"></a> cuda 代码</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda_runtime_api.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="comment">// cuda 中 host 表示 cpu 端，device 表示 gpu 端</span></span><br><span class="line"><span class="comment">// __device__ 是设备函数的声明符号，表明该函数在 device 执行，且只能在 device</span></span><br><span class="line"><span class="comment">// 中调用</span></span><br><span class="line"><span class="function">__device__ <span class="keyword">const</span> <span class="keyword">char</span> *<span class="title">device_hello_world</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="string">&quot;GPU: Hello world!\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// __host__ 是主机函数的声明符号，表明该函数在 host 执行，且只能在 host 中调用</span></span><br><span class="line"><span class="function">__host__ <span class="keyword">const</span> <span class="keyword">char</span> *<span class="title">host_hello_world</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;CPU: Hello world!\n&quot;</span>; &#125;</span><br><span class="line"><span class="comment">// __global__ 是核函数的声明符号，表明该函数在 device 执行，且只能在 host 中调用</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">hello_world</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span> *str = <span class="built_in">device_hello_world</span>();</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%s&quot;</span>, str);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%s&quot;</span>, <span class="built_in">host_hello_world</span>());</span><br><span class="line">  <span class="comment">// &lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt; 是核函数的调用符号，表示启动 grid_dim 个 block，</span></span><br><span class="line">  <span class="comment">// 每个 block 有 block_dim 个线程</span></span><br><span class="line">  hello_world&lt;&lt;&lt;<span class="number">1</span>, <span class="number">10</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceReset</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>cuda</code> 的三个函数声明符号：
<ul>
<li><code>__host__</code>：主机函数，表示该函数在 CPU 上执行，且只能在 CPU 中调用</li>
<li><code>__device__</code>：设备函数，表示该函数在 GPU 上执行，且只能在 GPU 中调用</li>
<li><code>__global__</code>：核函数，表示该函数在 GPU 上执行，且只能在 CPU 中调用</li>
</ul>
</li>
<li>其中 <code>__global__</code> 声明的函数类型被称为 <strong>核函数</strong>，是 <code>CUDA</code> 中最重要的函数类型
<ul>
<li>核函数通过 <code>&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;</code> 的方式调用，其中 <code>&lt;&lt;&lt;&gt;&gt;&gt;</code> 是 <code>cuda</code> 扩展关键字</li>
<li><code>grid_dim</code> 表示启动的 <code>block</code> 数量，<code>block_dim</code> 表示每个 <code>block</code> 中的线程数量</li>
<li><code>grid_dim</code> 和 <code>block_dim</code> 都是 <code>dim3</code> 类型的变量，表示三维数组，如果使用整形则模型 <code>y</code> 和 <code>z</code> 维度都为 1</li>
</ul>
</li>
</ul>
<h3 id="编译"><a class="markdownIt-Anchor" href="#编译"></a> 编译</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc hello_world.cu -g -o hello_world</span><br></pre></td></tr></table></figure>
<h3 id="运行"><a class="markdownIt-Anchor" href="#运行"></a> 运行</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">./hello_world</span><br><span class="line"><span class="comment"># CPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br><span class="line"><span class="comment"># GPU: Hello world!</span></span><br></pre></td></tr></table></figure>
<h2 id="2-dimension-测试"><a class="markdownIt-Anchor" href="#2-dimension-测试"></a> 2. dimension 测试</h2>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">checkIndex</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;threadIdx:(%d,%d,%d) blockIdx:(%d,%d,%d) blockDim:(%d,%d,%d)\</span></span><br><span class="line"><span class="string">  gridDim(%d,%d,%d)\n&quot;</span>,</span><br><span class="line">         threadIdx.x, threadIdx.y, threadIdx.z, blockIdx.x, blockIdx.y,</span><br><span class="line">         blockIdx.z, blockDim.x, blockDim.y, blockDim.z, gridDim.x, gridDim.y,</span><br><span class="line">         gridDim.z);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> nElem = <span class="number">6</span>;  <span class="comment">// number of elements</span></span><br><span class="line">  <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">3</span>)</span></span>;  <span class="comment">// block size</span></span><br><span class="line">  <span class="keyword">int</span> nBlock = (nElem + block.x - <span class="number">1</span>) / block.x; <span class="comment">// number of blocks</span></span><br><span class="line">  <span class="function">dim3 <span class="title">grid</span><span class="params">(nBlock)</span></span>;  <span class="comment">// grid size</span></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;grid.x %d grid.y %d grid.z %d\n&quot;</span>, grid.x, grid.y, grid.z);  </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;block.x %d block.y %d block.z %d\n&quot;</span>, block.x, block.y, block.z);</span><br><span class="line">  checkIndex&lt;&lt;&lt;grid, block&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceReset</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>执行结果：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./check_dimension</span><br><span class="line"><span class="comment"># grid.x 2 grid.y 1 grid.z 1</span></span><br><span class="line"><span class="comment"># block.x 3 block.y 1 block.z 1</span></span><br><span class="line"><span class="comment"># threadIdx:(0,0,0) blockIdx:(1,0,0) blockDim:(3,1,1)  gridDim(2,1,1)</span></span><br><span class="line"><span class="comment"># threadIdx:(1,0,0) blockIdx:(1,0,0) blockDim:(3,1,1)  gridDim(2,1,1)</span></span><br><span class="line"><span class="comment"># threadIdx:(2,0,0) blockIdx:(1,0,0) blockDim:(3,1,1)  gridDim(2,1,1)</span></span><br><span class="line"><span class="comment"># threadIdx:(0,0,0) blockIdx:(0,0,0) blockDim:(3,1,1)  gridDim(2,1,1)</span></span><br><span class="line"><span class="comment"># threadIdx:(1,0,0) blockIdx:(0,0,0) blockDim:(3,1,1)  gridDim(2,1,1)</span></span><br><span class="line"><span class="comment"># threadIdx:(2,0,0) blockIdx:(0,0,0) blockDim:(3,1,1)  gridDim(2,1,1)</span></span><br></pre></td></tr></table></figure>
<h2 id="3-cuda-向量加法"><a class="markdownIt-Anchor" href="#3-cuda-向量加法"></a> 3. CUDA 向量加法</h2>
<h3 id="代码"><a class="markdownIt-Anchor" href="#代码"></a> 代码</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;freshman.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function">__host__ <span class="keyword">void</span> <span class="title">sumArrays</span><span class="params">(<span class="keyword">float</span> *a, <span class="keyword">float</span> *b, <span class="keyword">float</span> *res, <span class="keyword">const</span> <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">    res[i] = a[i] + b[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">sumArraysGPU</span><span class="params">(<span class="keyword">float</span> *a, <span class="keyword">float</span> *b, <span class="keyword">float</span> *res, <span class="keyword">const</span> <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="keyword">if</span> (i &lt; size) <span class="comment">// 线程索引越界检查</span></span><br><span class="line">    res[i] = a[i] + b[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// set up device</span></span><br><span class="line">  <span class="built_in">initDevice</span>(<span class="number">0</span>);</span><br><span class="line">  <span class="comment">// allocate host memory</span></span><br><span class="line">  <span class="keyword">int</span> nElem = <span class="number">1</span> &lt;&lt; <span class="number">24</span>;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Vector size:%d\n&quot;</span>, nElem);</span><br><span class="line">  <span class="keyword">int</span> nByte = <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>) * nElem;</span><br><span class="line">  <span class="keyword">float</span> *a_h = (<span class="keyword">float</span> *)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">  <span class="keyword">float</span> *b_h = (<span class="keyword">float</span> *)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">  <span class="keyword">float</span> *res_h = (<span class="keyword">float</span> *)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">  <span class="keyword">float</span> *res_from_gpu_h = (<span class="keyword">float</span> *)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">  <span class="built_in">memset</span>(res_h, <span class="number">0</span>, nByte);</span><br><span class="line">  <span class="built_in">memset</span>(res_from_gpu_h, <span class="number">0</span>, nByte);</span><br><span class="line">  <span class="comment">// allocate device memory</span></span><br><span class="line">  <span class="keyword">float</span> *a_d, *b_d, *res_d;</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>((<span class="keyword">float</span> **)&amp;a_d, nByte));</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>((<span class="keyword">float</span> **)&amp;b_d, nByte));</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>((<span class="keyword">float</span> **)&amp;res_d, nByte));</span><br><span class="line">  <span class="comment">// randomly initialize the input data</span></span><br><span class="line">  <span class="built_in">initialData</span>(a_h, nElem);</span><br><span class="line">  <span class="built_in">initialData</span>(b_h, nElem);</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(a_d, a_h, nByte, cudaMemcpyHostToDevice));</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(b_d, b_h, nByte, cudaMemcpyHostToDevice));</span><br><span class="line">  <span class="comment">// set up execution configuration</span></span><br><span class="line">  <span class="comment">// 1. 计算最佳块大小</span></span><br><span class="line">  <span class="keyword">int</span> minGridSize, bestBlockSize;</span><br><span class="line">  <span class="built_in">cudaOccupancyMaxPotentialBlockSize</span>(&amp;minGridSize, &amp;bestBlockSize,</span><br><span class="line">                                     (<span class="keyword">void</span> *)sumArraysGPU,</span><br><span class="line">                                     <span class="number">0</span>, <span class="comment">// 动态共享内存大小</span></span><br><span class="line">                                     <span class="number">0</span>  <span class="comment">// 无块大小限制</span></span><br><span class="line">  );</span><br><span class="line">  <span class="comment">// 2. 设置网格和块维度</span></span><br><span class="line">  <span class="function">dim3 <span class="title">block</span><span class="params">(bestBlockSize)</span></span>;</span><br><span class="line">  <span class="function">dim3 <span class="title">grid</span><span class="params">((nElem + bestBlockSize - <span class="number">1</span>) / bestBlockSize)</span></span>;</span><br><span class="line">  <span class="comment">// 3. 设备执行并统计耗时</span></span><br><span class="line">  <span class="keyword">double</span> iStart, iElaps;</span><br><span class="line">  iStart = <span class="built_in">cpuSecond</span>();</span><br><span class="line">  sumArraysGPU&lt;&lt;&lt;grid, block&gt;&gt;&gt;(a_d, b_d, res_d, nElem);</span><br><span class="line">  iElaps = <span class="built_in">cpuSecond</span>() - iStart;</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaGetLastError</span>());</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(res_from_gpu_h, res_d, nByte, cudaMemcpyDeviceToHost));</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Execution configuration&lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed %f sec\n&quot;</span>, grid.x,</span><br><span class="line">         block.x, iElaps);</span><br><span class="line">  <span class="comment">// 4. CPU执行并统计耗时</span></span><br><span class="line">  iStart = <span class="built_in">cpuSecond</span>();</span><br><span class="line">  <span class="built_in">sumArrays</span>(a_h, b_h, res_h, nElem);</span><br><span class="line">  iElaps = <span class="built_in">cpuSecond</span>() - iStart;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;CPU Time elapsed %f sec\n&quot;</span>, iElaps);</span><br><span class="line">  <span class="comment">// 5. 检查结果</span></span><br><span class="line">  <span class="built_in">checkResult</span>(res_h, res_from_gpu_h, nElem);</span><br><span class="line">  <span class="comment">// 6. 释放内存</span></span><br><span class="line">  <span class="built_in">cudaFree</span>(a_d);</span><br><span class="line">  <span class="built_in">cudaFree</span>(b_d);</span><br><span class="line">  <span class="built_in">cudaFree</span>(res_d);</span><br><span class="line">  <span class="built_in">free</span>(a_h);</span><br><span class="line">  <span class="built_in">free</span>(b_h);</span><br><span class="line">  <span class="built_in">free</span>(res_h);</span><br><span class="line">  <span class="built_in">free</span>(res_from_gpu_h);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>cudaOccupancyMaxPotentialBlockSize</code> 函数用于计算最佳块大小</li>
<li><code>max thread per block</code> 是 <code>cuda</code> 中的一个限制，表示每个块中最多可以有多少个线程，一般为 <code>1024</code>，当超过这个限制时，<code>CHECK(cudaGetLastError());</code> 会报错</li>
</ul>
<h3 id="运行结果"><a class="markdownIt-Anchor" href="#运行结果"></a> 运行结果</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./sum_arrays</span><br><span class="line"><span class="comment"># Using device 0: NVIDIA GeForce RTX 4060 Laptop GPU</span></span><br><span class="line"><span class="comment"># Vector size:16777216</span></span><br><span class="line"><span class="comment"># Execution configuration&lt;&lt;&lt;21846,768&gt;&gt;&gt; Time elapsed 0.000030 sec</span></span><br><span class="line"><span class="comment"># CPU Time elapsed 0.076604 sec</span></span><br><span class="line"><span class="comment"># Check result success!</span></span><br></pre></td></tr></table></figure>
<ul>
<li>可以看出，<code>cuda</code> 的执行时间远远小于 <code>cpu</code> 的执行时间，相差了 <code>2553</code> 倍</li>
</ul>
<h3 id="总体流程"><a class="markdownIt-Anchor" href="#总体流程"></a> 总体流程</h3>
<pre class="mermaid">graph TD
    A[Host 端申请内存] --> B[Host 端初始化输入数据]
    B --> C[Device 端申请内存]
    C --> D[拷贝 Host 输入数据到 Device 端]
    D --> E[Device 端执行核函数]
    E --> F[拷贝 Device 端输出数据到 Host 端]
    F --> G[Host 端检查结果]
    G --> H[释放 Host 端和 Device 端全部内存]
    B --> J[Host 端执行普通函数] --> G</pre>
<h3 id="细节分析"><a class="markdownIt-Anchor" href="#细节分析"></a> 细节分析</h3>
<h4 id="1-cuda-内存分配是怎么做的"><a class="markdownIt-Anchor" href="#1-cuda-内存分配是怎么做的"></a> 1. <code>cuda</code> 内存分配是怎么做的？</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> *a_d; <span class="comment">// 空指针</span></span><br><span class="line"><span class="built_in">cudaMalloc</span>((<span class="keyword">float</span> **)&amp;a_d, nByte);  <span class="comment">// 将指针的地址转成二级指针（指针的指针）传入内存分配函数</span></span><br></pre></td></tr></table></figure>
<ul>
<li>这里的二级指针应用很巧妙，由于 <code>c++</code> 中的指针是值传递，所以如果是一级指针传入 <code>cudaMalloc</code> 函数时，指针 <code>a_d</code> 的值不会改变，因此只能将指针的地址转成二级指针传入内存分配函数</li>
</ul>
<h4 id="2-cuda-内存拷贝是怎么做的"><a class="markdownIt-Anchor" href="#2-cuda-内存拷贝是怎么做的"></a> 2. <code>cuda</code> 内存拷贝是怎么做的？</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaMemcpy</span>(a_d, a_h, nByte, cudaMemcpyHostToDevice);</span><br></pre></td></tr></table></figure>
<ul>
<li><code>cudaMemcpy</code> 函数的四个参数分别是：
<ul>
<li><code>dst</code>：目标地址</li>
<li><code>src</code>：源地址</li>
<li><code>size</code>：拷贝的字节数</li>
<li><code>kind</code>：拷贝的类型，属于 <code>cudaMemcpyKind</code> 枚举类型
<ul>
<li><code>cudaMemcpyHostToHost          =   0,      /**&lt; Host   -&gt; Host */</code></li>
<li><code>cudaMemcpyHostToDevice        =   1,      /**&lt; Host   -&gt; Device */</code></li>
<li><code>cudaMemcpyDeviceToHost        =   2,      /**&lt; Device -&gt; Host */</code></li>
<li><code>cudaMemcpyDeviceToDevice      =   3,      /**&lt; Device -&gt; Device */</code></li>
<li><code>cudaMemcpyDefault             =   4       /**&lt; Direction of the transfer is inferred from the pointer values. Requires unified virtual addressing */</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="3-cuda-核函数如何解析线程索引"><a class="markdownIt-Anchor" href="#3-cuda-核函数如何解析线程索引"></a> 3. <code>cuda</code> 核函数如何解析线程索引？</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"><span class="keyword">if</span> (i &lt; size) <span class="comment">// 线程索引越界检查</span></span><br><span class="line">  res[i] = a[i] + b[i];</span><br></pre></td></tr></table></figure>
<ul>
<li><code>blockIdx</code>：表示当前块的索引</li>
<li><code>blockDim</code>：表示当前块的维度（每个块中的线程数）</li>
<li><code>threadIdx</code>：表示当前线程的索引</li>
<li>每个线程中计算两个标量的和</li>
<li>由于 <code>gridDim * blockDim</code> 可能大于 <code>size</code>，所以需要判断线程索引是否越界</li>
</ul>
<h4 id="4-如何计算最佳块大小"><a class="markdownIt-Anchor" href="#4-如何计算最佳块大小"></a> 4. 如何计算最佳块大小？</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> minGridSize, bestBlockSize;</span><br><span class="line"><span class="built_in">cudaOccupancyMaxPotentialBlockSize</span>(&amp;minGridSize, &amp;bestBlockSize,</span><br><span class="line">                                     (<span class="keyword">void</span> *)sumArraysGPU,</span><br><span class="line">                                     <span class="number">0</span>, <span class="comment">// 动态共享内存大小</span></span><br><span class="line">                                     <span class="number">0</span>  <span class="comment">// 无块大小限制</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<ul>
<li><code>cudaOccupancyMaxPotentialBlockSize</code> 函数用于计算最佳块大小，五个参数分别是：
<ul>
<li><code>minGridSize</code>：最小网格大小变量地址</li>
<li><code>bestBlockSize</code>：最佳块大小变量地址</li>
<li><code>kernel</code>：核函数指针</li>
<li><code>dynamicSMemSize</code>：动态共享内存大小</li>
<li><code>blockSizeLimit</code>：块大小限制</li>
</ul>
</li>
<li>函数名就是函数地址，可强转为 <code>void *</code> 函数指针（也可以写成：<code>(void *)&amp;sumArraysGPU</code>）</li>
</ul>
<h2 id="4-cuda-编程模型"><a class="markdownIt-Anchor" href="#4-cuda-编程模型"></a> 4. CUDA 编程模型</h2>
<h3 id="线程块"><a class="markdownIt-Anchor" href="#线程块"></a> 线程块</h3>
<ul>
<li>线程块 <code>block</code> 是 <code>CUDA</code> 中的逻辑执行单元，是一个三维逻辑结构：
<ul>
<li><code>block.x</code>：表示块的 x 维度大小</li>
<li><code>block.y</code>：表示块的 y 维度大小</li>
<li><code>block.z</code>：表示块的 z 维度大小</li>
<li>其中 <code>block.x</code> 是最内层的循环，<code>block.y</code> 是第二层循环，<code>block.z</code> 是最外层的循环</li>
<li>用三维数组可以表示为：<code>tread[z][y][x]</code>，即 <code>tid = threadIdx.x + threadIdx.y * blockDim.x + threadIdx.z * blockDim.x * blockDim.y</code></li>
</ul>
</li>
</ul>
<h3 id="线程束"><a class="markdownIt-Anchor" href="#线程束"></a> 线程束</h3>
<ul>
<li>线程束 <code>warp</code> 是 <code>CUDA</code> 基本调度执行单元，一个 <code>warp</code> 由 <code>32</code> 个线程组成
<ul>
<li>一个 <code>warp</code> 中的线程在一个时钟周期内执行同一条指令（单指令多线程，<code>SIMT</code>）</li>
<li>一个 <code>warp</code> 中的线程可以共享指令指针和执行资源（如寄存器、缓存等）</li>
<li><code>Warp</code> 调度器（<code>warp scheduler</code>）负责将 <code>warp</code> 分配到物理执行单元上执行</li>
</ul>
</li>
<li>线程块会被划分为多个 <code>warp</code>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mi>a</mi><mi>r</mi><mi>p</mi><mi>s</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>B</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mo>=</mo><mi>c</mi><mi>e</mi><mi>i</mi><mi>l</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>T</mi><mi>h</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>s</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>B</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi></mrow><mn>32</mn></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">WarpsPerBlock=ceil(\frac{ThreadsPerBlock}{32})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></li>
</ul>
<h3 id="cuda-core"><a class="markdownIt-Anchor" href="#cuda-core"></a> CUDA core</h3>
<ul>
<li><code>CUDA core</code> 是 <code>CUDA</code> 物理执行单元，负责实际的计算任务</li>
<li>一个 <code>CUDA core</code> 一个时钟周期只能计算一个线程的指令</li>
</ul>
<h3 id="streammultiprocessor"><a class="markdownIt-Anchor" href="#streammultiprocessor"></a> StreamMultiprocessor</h3>
<ul>
<li><code>StreamMultiprocessor</code> 流式多处理器（简称 <code>SM</code>），负责执行 <code>CUDA</code> 线程块中的并行计算任务</li>
<li>每个 <code>GPU</code> 包含多个 <code>SM</code>，每个 <code>SM</code> 包含多个 <code>CUDA core</code>，例如：<code>RTX 4060</code> 有 <code>24</code> 个 <code>SM</code>，每个 <code>SM</code> 有 <code>128</code> 个 <code>CUDA core</code></li>
</ul>
<h2 id="5-reduce"><a class="markdownIt-Anchor" href="#5-reduce"></a> 5. Reduce</h2>
<ul>
<li>规约（<code>Reduce</code>）是 <code>CUDA</code> 编程中常见的操作，主要用于将多个数据元素规约为一个数据元素</li>
<li>规约操作通常是一个二元操作，例如：<code>sum</code>、<code>mul</code>、<code>max</code>、<code>min</code> 等，简单的规约可以合并成强大的算子，甚至可以说规约算子是神经网络的基础</li>
</ul>
<h3 id="规约求和"><a class="markdownIt-Anchor" href="#规约求和"></a> 规约求和</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CPU 规约求和</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">recursiveReduce</span><span class="params">(<span class="keyword">int</span> *data, <span class="keyword">int</span> <span class="keyword">const</span> size)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// terminate check</span></span><br><span class="line">  <span class="keyword">if</span> (size == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> data[<span class="number">0</span>];</span><br><span class="line">  <span class="comment">// renew the stride</span></span><br><span class="line">  <span class="keyword">int</span> <span class="keyword">const</span> stride = size / <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">if</span> (size % <span class="number">2</span> == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; stride; i++) &#123;</span><br><span class="line">      data[i] += data[i + stride];</span><br><span class="line">    &#125;</span><br><span class="line">    data[<span class="number">0</span>] += data[size - <span class="number">1</span>];</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; stride; i++) &#123;</span><br><span class="line">      data[i] += data[i + stride];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// call</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">recursiveReduce</span>(data, stride);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// GPU 规约相邻求和</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">reduceNeighbored</span><span class="params">(<span class="keyword">int</span> *g_idata, <span class="keyword">int</span> *g_odata, <span class="keyword">unsigned</span> <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// set thread ID</span></span><br><span class="line">  <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">  <span class="comment">// boundary check</span></span><br><span class="line">  <span class="keyword">if</span> (tid &gt;= n)</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  <span class="comment">// convert global data pointer to local point of this block</span></span><br><span class="line">  <span class="keyword">int</span> *idata = g_idata + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="comment">// in-place reduction in global memory</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> stride = <span class="number">1</span>; stride &lt; blockDim.x; stride *= <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> ((tid % (<span class="number">2</span> * stride)) == <span class="number">0</span>) &#123;</span><br><span class="line">      idata[tid] += idata[tid + stride];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// synchronize within block</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// write result for this block to global mem</span></span><br><span class="line">  <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    g_odata[blockIdx.x] = idata[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// GPU 规约相邻求和（简化版）</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">reduceNeighboredLess</span><span class="params">(<span class="keyword">int</span> *g_idata, <span class="keyword">int</span> *g_odata,</span></span></span><br><span class="line"><span class="params"><span class="function">                                     <span class="keyword">unsigned</span> <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">  <span class="keyword">unsigned</span> idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="comment">// convert global data pointer to the local point of this block</span></span><br><span class="line">  <span class="keyword">int</span> *idata = g_idata + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="keyword">if</span> (idx &gt; n)</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  <span class="comment">// in-place reduction in global memory</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> stride = <span class="number">1</span>; stride &lt; blockDim.x; stride *= <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="comment">// convert tid into local array index</span></span><br><span class="line">    <span class="keyword">int</span> index = <span class="number">2</span> * stride * tid;</span><br><span class="line">    <span class="keyword">if</span> (index &lt; blockDim.x) &#123;</span><br><span class="line">      idata[index] += idata[index + stride];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// write result for this block to global men</span></span><br><span class="line">  <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    g_odata[blockIdx.x] = idata[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// GPU 规约交错求和，主要是 stride 的计算方式不同</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">reduceInterleaved</span><span class="params">(<span class="keyword">int</span> *g_idata, <span class="keyword">int</span> *g_odata, <span class="keyword">unsigned</span> <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">  <span class="keyword">unsigned</span> idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="comment">// convert global data pointer to the local point of this block</span></span><br><span class="line">  <span class="keyword">int</span> *idata = g_idata + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="keyword">if</span> (idx &gt;= n)</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  <span class="comment">// in-place reduction in global memory</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> stride = blockDim.x / <span class="number">2</span>; stride &gt; <span class="number">0</span>; stride &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; stride) &#123;</span><br><span class="line">      idata[tid] += idata[tid + stride];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// write result for this block to global men</span></span><br><span class="line">  <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    g_odata[blockIdx.x] = idata[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="效率分析"><a class="markdownIt-Anchor" href="#效率分析"></a> 效率分析</h3>
<ul>
<li>本代码中使用了三种核函数实现方式做同一个规约操作，分别是：
<ul>
<li><code>reduceNeighbored</code>：相邻线程规约</li>
<li><code>reduceNeighboredLess</code>：相邻线程规约（简化版）</li>
<li><code>reduceInterleaved</code>：交错线程规约</li>
</ul>
</li>
<li>三者效率从高到低依次是：
<ul>
<li><code>reduceInterleaved</code> &gt; <code>reduceNeighboredLess</code> &gt; <code>reduceNeighbored</code></li>
</ul>
</li>
<li>三者的示意图分别如下：
<ul>
<li><code>reduceNeighbored</code>：相邻线程规约的实现<br />
<image src="https://s2.loli.net/2025/04/14/ThePxqG52r3YKCd.png" width=60%/></li>
<li><code>reduceNeighboredLess</code>：相邻线程规约的简化版实现（注意圆圈中的符号已和上图不一致）<br />
<image src="https://s2.loli.net/2025/04/14/9JTkPeCd5u1a7gF.png" width=60%/></li>
<li><code>reduceInterleaved</code>：交错线程规约的实现<br />
<image src="https://s2.loli.net/2025/04/14/dUcei9EZGsbgzRB.png" width=60%/></li>
</ul>
</li>
<li>三者效率差异主要来自于 <strong>线程分支分化</strong>，后续会详细介绍</li>
</ul>
<h2 id="6-循环展开"><a class="markdownIt-Anchor" href="#6-循环展开"></a> 6. 循环展开</h2>
<ul>
<li>循环展开（<code>Loop Unrolling</code>）是 <code>CUDA</code> 中常用的优化手段，主要用于减少循环控制开销和提高指令级并行度</li>
<li>简单说就是一个线程不再只计算一个数据，而是计算多个数据，而且是直接在代码中展开，而不是在编译器中展开</li>
<li>可以简单理解成：启动线程是需要花时间的，启动一个线程只算一个数据，太浪费了，所以我们可以让一个线程计算多个数据，这样就能减少启动线程的时间开销，所以就省时间了</li>
</ul>
<h3 id="代码-2"><a class="markdownIt-Anchor" href="#代码-2"></a> 代码</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 数据总长是 8 * blockDim.x * gridDim.x</span></span><br><span class="line"><span class="comment">// 线程数是 blockDim.x * gridDim.x</span></span><br><span class="line"><span class="comment">// 每个线程计算 8 个数据</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">reduceUnroll8</span><span class="params">(<span class="keyword">int</span> *g_idata, <span class="keyword">int</span> *g_odata, <span class="keyword">unsigned</span> <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">  <span class="keyword">unsigned</span> <span class="keyword">int</span> idx = blockDim.x * blockIdx.x * <span class="number">8</span> + threadIdx.x;</span><br><span class="line">  <span class="keyword">if</span> (tid &gt;= n)</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">int</span> *idata = g_idata + blockIdx.x * blockDim.x * <span class="number">8</span>;</span><br><span class="line">  <span class="comment">// 循环展开，每个线程计算 8 个数据</span></span><br><span class="line">  <span class="comment">// 直接把 8 * blockDim.x * gridDim.x 的数据总长</span></span><br><span class="line">  <span class="comment">// 聚合到了 blockDim.x * gridDim.x 的线程数上</span></span><br><span class="line">  <span class="keyword">if</span> (idx + <span class="number">7</span> * blockDim.x &lt; n) &#123;</span><br><span class="line">    g_idata[idx] += g_idata[idx + blockDim.x];</span><br><span class="line">    g_idata[idx] += g_idata[idx + blockDim.x * <span class="number">2</span>];</span><br><span class="line">    g_idata[idx] += g_idata[idx + blockDim.x * <span class="number">3</span>];</span><br><span class="line">    g_idata[idx] += g_idata[idx + blockDim.x * <span class="number">4</span>];</span><br><span class="line">    g_idata[idx] += g_idata[idx + blockDim.x * <span class="number">5</span>];</span><br><span class="line">    g_idata[idx] += g_idata[idx + blockDim.x * <span class="number">6</span>];</span><br><span class="line">    g_idata[idx] += g_idata[idx + blockDim.x * <span class="number">7</span>];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 这里需要同步，也就是线程阻塞直到所有线程都执行完</span></span><br><span class="line">  __syncthreads();</span><br><span class="line">  <span class="comment">// 然后就是一个最简单的规约操作了，和上面一样</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> stride = blockDim.x / <span class="number">2</span>; stride &gt; <span class="number">0</span>; stride &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; stride) &#123;</span><br><span class="line">      idata[tid] += idata[tid + stride];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// write result for this block to global mem</span></span><br><span class="line">  <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    g_odata[blockIdx.x] = idata[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="7-核函数递归调用"><a class="markdownIt-Anchor" href="#7-核函数递归调用"></a> 7. 核函数递归调用</h2>
<ul>
<li>和 <code>CPU</code> 一样，<code>CUDA</code> 也支持核函数递归调用，调用方式和普通递归函数一样</li>
<li>需要注意的是在编译的时候需要加上 <code>-rdc=true</code> 选项</li>
</ul>
<h3 id="代码-3"><a class="markdownIt-Anchor" href="#代码-3"></a> 代码</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">nesthelloworld</span><span class="params">(<span class="keyword">int</span> iSize, <span class="keyword">int</span> iDepth)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;depth : %d blockIdx: %d,threadIdx: %d\n&quot;</span>, iDepth, blockIdx.x,</span><br><span class="line">         threadIdx.x);</span><br><span class="line">  <span class="keyword">if</span> (iSize == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">int</span> nthread = (iSize &gt;&gt; <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">if</span> (tid == <span class="number">0</span> &amp;&amp; nthread &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// 递归调用核函数</span></span><br><span class="line">    nesthelloworld&lt;&lt;&lt;<span class="number">1</span>, nthread&gt;&gt;&gt;(nthread, ++iDepth);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;-----------&gt; nested execution depth: %d\n&quot;</span>, iDepth);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="8-固定内存"><a class="markdownIt-Anchor" href="#8-固定内存"></a> 8. 固定内存</h2>
<ul>
<li><code>Pinned Memory</code> 是 <code>CUDA</code> 中的一种特殊内存类型（不是显存，是内存），主要用于提高数据传输效率</li>
<li>普通内存是分页管理，分页管理存在两个问题：
<ol>
<li>一页内存逻辑上连续，但物理上不连续</li>
<li>操作系统可能会将内存页交换到磁盘上，导致数据不在物理内存中</li>
</ol>
</li>
<li><code>Pinned Memory</code> 就是解决了这两个问题，分配了一块连续物理地址且固定的主机内存（<code>host</code> 内存），方便整块拷贝数据到显存（<code>DMA</code>）</li>
</ul>
<h3 id="代码-4"><a class="markdownIt-Anchor" href="#代码-4"></a> 代码</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;freshman.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> dev = <span class="number">0</span>;</span><br><span class="line">  <span class="built_in">cudaSetDevice</span>(dev);</span><br><span class="line">  <span class="keyword">int</span> nElem = <span class="number">1</span> &lt;&lt; <span class="number">14</span>;</span><br><span class="line">  <span class="keyword">int</span> nByte = <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>) * nElem;</span><br><span class="line">  <span class="keyword">float</span> *a_h, *b_h, *res_h, *res_from_gpu_h;</span><br><span class="line">  <span class="comment">// 注意这里的 cudaMallocHost 和 cudaMalloc 是不同的</span></span><br><span class="line">  <span class="comment">// 前者申请的是 host 固定内存，后者申请的是 device 显存</span></span><br><span class="line">  <span class="comment">// cudaMallocHost 是 malloc 的一个平替</span></span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocHost</span>((<span class="keyword">float</span> **)&amp;a_h, nByte));</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocHost</span>((<span class="keyword">float</span> **)&amp;b_h, nByte));</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocHost</span>((<span class="keyword">float</span> **)&amp;res_h, nByte));</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocHost</span>((<span class="keyword">float</span> **)&amp;res_from_gpu_h, nByte));</span><br><span class="line">  <span class="comment">// 初始化数据</span></span><br><span class="line">  <span class="built_in">memset</span>(res_h, <span class="number">0</span>, nByte);</span><br><span class="line">  <span class="built_in">memset</span>(res_from_gpu_h, <span class="number">0</span>, nByte);</span><br><span class="line">  <span class="built_in">initialData</span>(a_h, nElem);</span><br><span class="line">  <span class="built_in">initialData</span>(b_h, nElem);</span><br><span class="line">  <span class="comment">// 申请设备显存</span></span><br><span class="line">  <span class="keyword">float</span> *a_d, *b_d, *res_d;</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>((<span class="keyword">float</span> **)&amp;a_d, nByte));</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>((<span class="keyword">float</span> **)&amp;b_d, nByte));</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>((<span class="keyword">float</span> **)&amp;res_d, nByte));</span><br><span class="line">  <span class="comment">// 拷贝数据到设备显存</span></span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(a_d, a_h, nByte, cudaMemcpyHostToDevice));</span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(b_d, b_h, nByte, cudaMemcpyHostToDevice));</span><br><span class="line">  <span class="comment">// 跑核函数</span></span><br><span class="line">  <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1024</span>)</span></span>;</span><br><span class="line">  <span class="function">dim3 <span class="title">grid</span><span class="params">(nElem / block.x)</span></span>;</span><br><span class="line">  sumArraysGPU&lt;&lt;&lt;grid, block&gt;&gt;&gt;(a_d, b_d, res_d);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Execution configuration&lt;&lt;&lt;%d,%d&gt;&gt;&gt;\n&quot;</span>, grid.x, block.x);</span><br><span class="line">  <span class="comment">// 结果拷贝回主机并检查两个设备计算结果是否一致</span></span><br><span class="line">  <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(res_from_gpu_h, res_d, nByte, cudaMemcpyDeviceToHost));</span><br><span class="line">  <span class="built_in">sumArrays</span>(a_h, b_h, res_h, nElem);</span><br><span class="line">  <span class="built_in">checkResult</span>(res_h, res_from_gpu_h, nElem);</span><br><span class="line">  <span class="comment">// 释放内存</span></span><br><span class="line">  <span class="comment">// 注意这里的 cudaFreeHost 和 cudaFree 是不同的</span></span><br><span class="line">  <span class="comment">// 前者释放的是 host 固定内存，后者释放的是 device 显存</span></span><br><span class="line">  <span class="built_in">cudaFree</span>(a_d);</span><br><span class="line">  <span class="built_in">cudaFree</span>(b_d);</span><br><span class="line">  <span class="built_in">cudaFree</span>(res_d);</span><br><span class="line">  <span class="built_in">cudaFreeHost</span>(a_h);</span><br><span class="line">  <span class="built_in">cudaFreeHost</span>(b_h);</span><br><span class="line">  <span class="built_in">cudaFreeHost</span>(res_h);</span><br><span class="line">  <span class="built_in">cudaFreeHost</span>(res_from_gpu_h);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="关键点"><a class="markdownIt-Anchor" href="#关键点"></a> 关键点</h3>
<ol>
<li><strong>主存</strong> <strong>普通内存</strong> 的分配和释放函数是 <code>malloc</code> 和 <code>free</code></li>
<li><strong>主存</strong> <strong>固定内存</strong> 的分配和释放函数是 <code>cudaMallocHost</code> 和 <code>cudaFreeHost</code></li>
<li><strong>显存</strong> 的分配和释放函数是 <code>cudaMalloc</code> 和 <code>cudaFree</code></li>
</ol>
<h2 id="9-零拷贝内存-和-统一虚拟地址"><a class="markdownIt-Anchor" href="#9-零拷贝内存-和-统一虚拟地址"></a> 9. 零拷贝内存 和 统一虚拟地址</h2>
<ul>
<li><code>Zero-Copy Memory</code> 是 <code>CUDA</code> 中一种允许 <code>GPU</code> 直接访问主机内存的技术，避免了显式的数据拷贝操作（不需要用 <code>cudaMemcpy</code> 函数）</li>
<li>实际上，<code>Zero-Copy Memory</code> 在很多时候并不快，因为 <code>GPU</code> 访问主机内存的速度远远低于访问显存的速度，因此，<code>Zero-Copy Memory</code> 只适用于一些特殊的场景，例如：
<ul>
<li>主机内存中的数据只需要被 <code>GPU</code> 使用一次</li>
<li>数据量太大，显存放不下</li>
<li>调试用途</li>
</ul>
</li>
<li><code>Zero-Copy Memory</code> 的实现方式是将主机内存映射到 <code>GPU</code> 的地址空间中，<code>GPU</code> 通过访问这个地址空间来访问主机内存，实际上走的是 <code>PCIe</code> 总线</li>
<li>由于不需要先完成所有数据的拷贝再开始执行核函数，因此 <code>Zero-Copy Memory</code> 使用异步拷贝的方式来实现，可将部分拷贝数据的时间和核函数执行的时间重叠，但并不多</li>
<li><code>Unified Virtual Addressing (UVA)</code> 是 <code>CUDA</code> 中的一种内存管理机制，允许 <code>CPU</code> 和 <code>GPU</code> 共享同一虚拟地址空间</li>
</ul>
<h3 id="代码-5"><a class="markdownIt-Anchor" href="#代码-5"></a> 代码</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> *a_host, *b_host, *res_d;</span><br><span class="line"><span class="comment">// 申请主机固定内存，添加特殊 flag cudaHostAllocMapped</span></span><br><span class="line"><span class="built_in">CHECK</span>(<span class="built_in">cudaMallocHost</span>((<span class="keyword">float</span> **)&amp;a_host, nByte, cudaHostAllocMapped));</span><br><span class="line"><span class="built_in">CHECK</span>(<span class="built_in">cudaMallocHost</span>((<span class="keyword">float</span> **)&amp;b_host, nByte, cudaHostAllocMapped));</span><br><span class="line"><span class="comment">// a_host 和 b_host 是可直接作为核函数的输入参数</span></span><br><span class="line"><span class="comment">// 也可以转成 Device 地址空间，如下：</span></span><br><span class="line"><span class="keyword">float</span> *a_dev, *b_dev;</span><br><span class="line"><span class="comment">// 映射主机内存到设备地址空间</span></span><br><span class="line"><span class="built_in">CHECK</span>(<span class="built_in">cudaHostGetDevicePointer</span>((<span class="keyword">void</span> **)&amp;a_dev, (<span class="keyword">void</span> *)a_host, <span class="number">0</span>));</span><br><span class="line"><span class="built_in">CHECK</span>(<span class="built_in">cudaHostGetDevicePointer</span>((<span class="keyword">void</span> **)&amp;b_dev, (<span class="keyword">void</span> *)b_host, <span class="number">0</span>));</span><br><span class="line"><span class="comment">// 用 a_dev 和 b_dev 作为核函数的输入参数计算</span></span><br></pre></td></tr></table></figure>
<ul>
<li>和 <code>Zero-Copy Memory</code> 一样，<code>UVA</code> 甚至不需要将 <code>a_host</code> 转成 <code>a_dev</code>，直接用 <code>a_host</code> 就可以调用核函数</li>
</ul>
<h2 id="10-aos-和-soa"><a class="markdownIt-Anchor" href="#10-aos-和-soa"></a> 10. Aos 和 SoA</h2>
<ul>
<li><code>CUDA</code> 不仅支持最简单的原生数据类型，还支持自定义数据类型（<code>struct</code>），例如 <code>Aos</code> 和 <code>SoA</code> 等</li>
<li><code>Aos</code>（Array of Structures）和 <code>SoA</code>（Structure of Arrays）是两种不同的数据存储方式，这两种方式由于变量的排布方式不同，导致了访问内存的效率差异</li>
</ul>
<h3 id="aos"><a class="markdownIt-Anchor" href="#aos"></a> Aos</h3>
<ul>
<li><code>Aos</code> 是将多个结构体存储在一个数组中，每个结构体的成员变量是连续存储的</li>
<li>例如：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">AoSStruct</span> &#123;</span></span><br><span class="line">  <span class="keyword">float</span> a;</span><br><span class="line">  <span class="keyword">float</span> b;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">sumArraysGPU</span><span class="params">(<span class="keyword">float</span> *a, <span class="keyword">float</span> *b, struct naiveStruct *res, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="keyword">if</span> (i &lt; n)</span><br><span class="line">    res[i].a = a[i] + b[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>这里的 <code>res</code> 是一个 <strong>结构体数组</strong>，<code>a</code> 和 <code>b</code> 是结构体的成员变量，每个变量都是一个 <code>float</code> 类型的<strong>标量</strong></li>
<li>每个结构体的成员变量是连续存储的，即：<code>a1 b1 a2 b2 a3 b3 ...</code></li>
</ul>
<h3 id="soa"><a class="markdownIt-Anchor" href="#soa"></a> SoA</h3>
<ul>
<li><code>SoA</code> 是将多个结构体的成员变量存储在一个数组中，每个成员变量是连续存储的</li>
<li>例如：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SoAStruct</span> &#123;</span></span><br><span class="line">  <span class="keyword">float</span> a[SIZE];</span><br><span class="line">  <span class="keyword">float</span> b[SIZE];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">sumArraysGPU</span><span class="params">(<span class="keyword">float</span> *a, <span class="keyword">float</span> *b, struct SoAStruct *res, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="keyword">if</span> (i &lt; n)</span><br><span class="line">    res-&gt;a[i] = a[i] + b[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>这里的 <code>res</code> 是一个 <strong>结构体</strong>，<code>a</code> 和 <code>b</code> 是结构体的成员变量，每个变量都是一个 <code>float</code> 类型的<strong>数组</strong></li>
<li>每个成员变量的数组是连续存储的，即：<code>a1 a2 a3 ... b1 b2 b3 ...</code></li>
</ul>
<h2 id="11-行主序和列主序"><a class="markdownIt-Anchor" href="#11-行主序和列主序"></a> 11. 行主序和列主序</h2>
<ul>
<li><code>行主序</code>（Row Major Order）和 <code>列主序</code>（Column Major Order）是两种不同的数组存储方式</li>
<li><code>行主序</code> 是将数组的每一行存储在连续的内存中，<code>列主序</code> 是将数组的每一列存储在连续的内存中</li>
<li>例如：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a[<span class="number">3</span>][<span class="number">4</span>] = &#123;</span><br><span class="line">    &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;,</span><br><span class="line">    &#123;<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;,</span><br><span class="line">    &#123;<span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>&#125;&#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>行主序</code> 存储方式是：<code>1 2 3 4 5 6 7 8 9 10 11 12</code></li>
<li><code>列主序</code> 存储方式是：<code>1 5 9 2 6 10 3 7 11 4 8 12</code></li>
<li>默认情况下，<code>C / C++ / CUDA</code> 语言是 <code>行主序</code> 存储方式</li>
<li>在行主序存储下，如果按行序访问数组元素，访问效率会更高，因为连续的内存访问会提高缓存命中率，反之如果按列序访问数组元素，访问效率会更低</li>
</ul>
<h3 id="速度对比"><a class="markdownIt-Anchor" href="#速度对比"></a> 速度对比</h3>
<p>WIP</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/03/17/Transformers-without-Normalization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/17/Transformers-without-Normalization/" class="post-title-link" itemprop="url">Transformers without Normalization</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-17 13:16:18" itemprop="dateCreated datePublished" datetime="2025-03-17T13:16:18+08:00">2025-03-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Transformer/" itemprop="url" rel="index"><span itemprop="name">Transformer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/03/17/Transformers-without-Normalization/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/17/Transformers-without-Normalization/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2503.10622">https://arxiv.org/pdf/2503.10622</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/jiachenzhu/DyT">https://github.com/jiachenzhu/DyT</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>这是由恺明和杨立昆提出的一篇关于 <code>transformer</code> 算子优化的论文，主要观点是去掉 <code>transformer</code> 结构中的 <code>normalization</code> 层，改成 <code>tanh</code> 层</li>
<li>改用 <code>tanh</code> 算子的 <code>transformer</code> 模型，在大多数任务上可达到使用归一化层的模型相同的性能，甚至更好</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2025/03/18/hYMbytL1A3ZU8nO.png" alt="dyt.png" /></p>
<ul>
<li>简单来说，这篇论文的核心思想是将 <code>transformer</code> 中的 <code>normalization</code> 层（可以是 <code>LayerNorm</code> 或 <code>RMSNorm</code>）替换成 <code>dynamic tanh</code> 层（简称 <code>DyT</code>）</li>
<li><code>normalization</code> 计算公式：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>normalization</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>γ</mi><mo>×</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><msqrt><mrow><msup><mi>σ</mi><mn>2</mn></msup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">\text{normalization}(x) = \gamma \times \frac{x - \mu}{\sqrt{\sigma^2+\epsilon}} + \beta
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">normalization</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.1903300000000003em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603300000000002em;"><span style="top:-2.196611em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.913389em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-2.873389em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.12661100000000003em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span></p>
<blockquote>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">μ</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span> 分别是 <code>mean</code> 和 <code>std</code>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 是 <code>scale</code> 和 <code>shift</code> 参数</p>
</blockquote>
<ul>
<li><code>DyT</code> 计算公式：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>DyT</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>γ</mi><mo>×</mo><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">\text{DyT}(x) = \gamma \times \tanh(\alpha x) + \beta
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">DyT</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">tanh</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span></p>
<blockquote>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 是个可学习参数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 是 <code>scale</code> 和 <code>shift</code> 参数（和 <code>normalization</code> 一样）</p>
</blockquote>
<ul>
<li><code>DyT</code> 实现伪代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># input x has the shape of [B, T, C]</span></span><br><span class="line"><span class="comment"># B: batch size, T: tokens, C: dimension</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DyT</span>(<span class="params">Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, C, init_α</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.α = Parameter(ones(<span class="number">1</span>) * init_α)</span><br><span class="line">        self.γ = Parameter(ones(C))</span><br><span class="line">        self.β = Parameter(zeros(C))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = tanh(self.alpha * x)</span><br><span class="line">        <span class="keyword">return</span> self.γ * x + self.β</span><br></pre></td></tr></table></figure>
<blockquote>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 默认初始化值为 <code>0.5</code></p>
</blockquote>
<h2 id="results"><a class="markdownIt-Anchor" href="#results"></a> Results</h2>
<ul>
<li>作者在多个领域的知名模型上都对比了修改前后训练精度，<code>DyT</code> 的性能和 <code>normalization</code> 的性能基本一致，打的有来有回<br />
<img src="https://s2.loli.net/2025/03/18/DGAE6nMyocKstev.png" alt="dyt2.png" /><br />
<img src="https://s2.loli.net/2025/03/18/Ul9eYLW6zrM43qv.png" alt="dyt3.png" /><br />
<img src="https://s2.loli.net/2025/03/18/Bf1q5NszOU96Pbv.png" alt="dyt4.png" /><br />
<img src="https://s2.loli.net/2025/03/18/lQyRxsAoWcdIbHt.png" alt="dyt5.png" /><br />
<img src="https://s2.loli.net/2025/03/18/Xn1SF2praD5HwRe.png" alt="dyt6.png" /><br />
<img src="https://s2.loli.net/2025/03/18/OleUF7P9XQJKxy4.png" alt="dyt1.png" /></li>
<li>作者还对比了 <code>DyT</code> 和 <code>normalization</code> 的训练/推理速度，<code>DyT</code> 的训练/推理速度要快很多<br />
<img src="https://s2.loli.net/2025/03/18/lVu9axTNIhgjpKB.png" alt="dyt7.png" /></li>
<li>作者同时做 <code>tanh</code> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 做了消融实验，发现 <code>tanh</code> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 都是必要的<br />
<img src="https://s2.loli.net/2025/03/18/v3zIDnFKW6OwV4Z.png" alt="dyt8.png" /><br />
<img src="https://s2.loli.net/2025/03/18/Y6dWnqjsD3PZANt.png" alt="dyt9.png" /></li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>属于是恺明和立昆的梦幻联动了…，这种对最火的结构的优化，非大佬不能为也，想象下如果这篇论文是大学实验室发表的，大家第一反应恐怕是：Who think you are? 😂</li>
<li>之前算是稍微接触过硬件，<code>DyT</code> 这种 <code>element-wise op</code> 比 <code>normalization</code> 这种 <code>reduce op</code> 一定快多了，想怎么 <code>tiling</code> 都行…</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/03/14/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%BA%94%E5%BC%B9-%E2%80%94%E2%80%94-3FS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/14/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%BA%94%E5%BC%B9-%E2%80%94%E2%80%94-3FS/" class="post-title-link" itemprop="url">2025.02 DeepSeek 开源周第五弹 —— 3FS</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-14 11:09:25" itemprop="dateCreated datePublished" datetime="2025-03-14T11:09:25+08:00">2025-03-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/file-system/" itemprop="url" rel="index"><span itemprop="name">file-system</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/03/14/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%BA%94%E5%BC%B9-%E2%80%94%E2%80%94-3FS/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/14/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%BA%94%E5%BC%B9-%E2%80%94%E2%80%94-3FS/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/3FS">https://github.com/deepseek-ai/3FS</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>3FS (Fire-Flyer File System)</code> 是一个高性能的分布式文件系统，旨在提供低延迟和高吞吐量的存储解决方案，利用现代 <code>SSD</code> 和 <code>RDMA</code> 网络带全宽的并行文件系统，解决 <code>AI</code> 训练和推理存储问题</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="效果"><a class="markdownIt-Anchor" href="#效果"></a> 效果</h3>
<ul>
<li><strong>集群高吞吐</strong>：在 <code>180</code> 节点集群中，<code>3FS</code> 实现了高达 <code>6.6 TiB/s</code> 的聚合读取吞吐量</li>
<li><strong>基准测试优异</strong>：在 <code>25</code> 节点集群的 <code>GraySort</code> 基准测试中，<code>3FS</code> 达到了 <code>3.66 TiB /min</code> 的吞吐量</li>
<li><strong>单节点高性能</strong>：每个客户端节点的 <code>KVCache</code> 查找峰值吞吐量超过 <code>40 GiB/s</code></li>
<li><strong>架构先进</strong>： <code>3FS</code> 采用去中心化架构，并具备强一致性语义</li>
</ul>
<h3 id="系统介绍"><a class="markdownIt-Anchor" href="#系统介绍"></a> 系统介绍</h3>
<ul>
<li>还是看大佬讲吧，<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27317616324">传送门</a></li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>这种底层架构一般只有大厂可以做，<code>deepseek</code> 有点东西</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/03/12/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E5%9B%9B%E5%BC%B9-%E2%80%94%E2%80%94-DualPipe-%EF%BC%86-EPLB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E5%9B%9B%E5%BC%B9-%E2%80%94%E2%80%94-DualPipe-%EF%BC%86-EPLB/" class="post-title-link" itemprop="url">2025.02 DeepSeek 开源周第四弹 —— DualPipe ＆ EPLB</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-12 11:35:53" itemprop="dateCreated datePublished" datetime="2025-03-12T11:35:53+08:00">2025-03-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/03/12/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E5%9B%9B%E5%BC%B9-%E2%80%94%E2%80%94-DualPipe-%EF%BC%86-EPLB/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/12/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E5%9B%9B%E5%BC%B9-%E2%80%94%E2%80%94-DualPipe-%EF%BC%86-EPLB/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>DualPipe code: <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DualPipe">https://github.com/deepseek-ai/DualPipe</a></li>
<li>EPLB code: <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/EPLB">https://github.com/deepseek-ai/EPLB</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>DualPipe</code> 是 <code>deepseek</code> 提出的一种 <strong>流水线并行算法</strong>，和之间读过的 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/20/GPipe-Easy-Scaling-with-Micro-Batch-Pipeline-Parallelism/">GPipe</a> 和 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/20/PipeDream-Fast-and-Efficient-Pipeline-Parallel-DNN-Training/">PipeDream</a> 类似，但 <code>DualPipe</code> 的硬件利用率更高，空泡更少</li>
<li><code>DPLB (Expert Parallelism Load Balancer)</code> 是一种 <strong>专家并行负载均衡算法</strong></li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="dualpipe"><a class="markdownIt-Anchor" href="#dualpipe"></a> DualPipe</h3>
<ul>
<li><code>DualPipe</code> 的计算过程<br />
<img src="https://s2.loli.net/2025/05/29/8kwaE7BPzYmGJiK.png" alt="dualpipe.png" /></li>
<li><code>DualPipe-v</code> 的计算过程<br />
<img src="https://s2.loli.net/2025/05/29/lK83UM7YyWsZbDO.png" alt="dualpipev.png" /></li>
</ul>
<blockquote>
<p>上图是民间自己二创的 dualpipe-v 的计算过程，将 dualpipe 对半切开后效果更好，<a target="_blank" rel="noopener" href="https://hackmd.io/@ufotalent/r1lVXsa9Jg">博客地址</a></p>
</blockquote>
<h4 id="dualpipe-核心特点"><a class="markdownIt-Anchor" href="#dualpipe-核心特点"></a> <code>DualPipe</code> 核心特点</h4>
<ol>
<li><strong>计算与通信重叠</strong>：<code>DualPipe</code> 的设计目标是最大化集群设备的计算性能，通过在<code>Forward</code> 和 <code>Backward</code> 阶段实现计算与通信的完全重叠，显著减少传统流水线并行中的 “空泡”（<code>Pipeline Bubble</code>，即空闲等待时间）。这对于需要跨节点协作的专家并行（<code>Expert Parallelism</code>）场景尤为重要。</li>
<li><strong>双向调度</strong>：与传统的单向流水线并行不同，<code>DualPipe</code> 采用双向调度策略，从流水线的两端同时输入微批次（<code>Micro-batches</code>），充分利用硬件资源。这种方法在保持计算通信比例恒定的情况下，即使模型规模进一步扩大，也能维持接近零的通信开销。</li>
<li><strong>高效扩展性</strong>：<code>DualPipe</code> 针对跨节点的混合专家模型（<code>MoE</code>）进行了优化，通过减少通信瓶颈，使得大规模分布式训练能够在相对有限的硬件资源（如 <code>H800 GPU</code>）上高效运行。</li>
<li><strong>显存优化</strong>：<code>DualPipe</code> 将模型的最浅层（包括嵌入层）和最深层（包括输出层）部署在同一流水线级别（<code>PP Rank</code>），实现参数和梯度的物理共享，进一步提升内存效率。这种设计减少了高代价的张量并行（<code>Tensor Parallelism</code>）需求。</li>
</ol>
<h3 id="eplb"><a class="markdownIt-Anchor" href="#eplb"></a> EPLB</h3>
<ul>
<li><code>EPLB (Expert Parallelism Load Balancer)</code> 是一种专家并行负载均衡算法，旨在解决专家并行中的负载不均问题</li>
<li>很简单，仅有 <code>160</code> 行 <code>python</code> 代码</li>
<li>核心思想是预估每个专家的负载，并根据负载设置专家拷贝和放置计划</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li><code>DualPipe</code> 实际上是 <code>deepseek</code> 根据 <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/profile-data"><code>profile-data</code></a> 分析空泡后做的一种流水线并行算法，而且用其强大的工程能力实现了 <code>SMs</code> 通信耗时降低（实际上就是用 <code>PTX</code> 编程把一部分 <code>SM</code> 当做是全职的数据搬运工），这太 <s>crazy</s> 了</li>
<li><code>Transformer</code> 是一种重 <code>IO</code> 轻计算的架构，在 <code>Hopper</code> 硬件架构上，不改变 <code>SM</code> 是不可能做到通信和计算完全重叠的，所以 <code>deepseek</code> 做了非常底层的优化</li>
<li><code>EPLB</code> 作为一种专家并行负载均衡算法，虽然简单，但在实际应用中可以显著提升专家并行的效率</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/03/10/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%B8%89%E5%BC%B9-%E2%80%94%E2%80%94-DeepGEMM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/10/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%B8%89%E5%BC%B9-%E2%80%94%E2%80%94-DeepGEMM/" class="post-title-link" itemprop="url">2025.02 DeepSeek 开源周第三弹 —— DeepGEMM</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-10 11:51:21" itemprop="dateCreated datePublished" datetime="2025-03-10T11:51:21+08:00">2025-03-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/03/10/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%B8%89%E5%BC%B9-%E2%80%94%E2%80%94-DeepGEMM/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/10/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%B8%89%E5%BC%B9-%E2%80%94%E2%80%94-DeepGEMM/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepGEMM">https://github.com/deepseek-ai/DeepGEMM</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>DeepGEMM</code> 是一个简单但功能强大的 <code>Hopper GPU （H100/H800）</code> 矩阵计算加速库</li>
<li>包含大约 <code>300</code> 行核心代码，可以做到在绝大多数大小的矩阵乘法均优于专家调优的内核，<code>hopper GPU</code> 上最高可达 <code>1350+ FP8 TFLOPS</code></li>
<li>完全即时编译，没有过多依赖，就像教程一样简洁，支持 <code>dense</code> 和 <code>moe</code> 架构</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<ul>
<li>这 <code>HPC</code> 相关的内容对于我确实超纲了，<code>CPU</code> 快给我干烧了</li>
<li>还是看大佬的讲解吧，<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26437292382">传送门走你</a></li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li><code>deepseek</code> 牛逼，为 <code>LLM</code> 平权做了不可磨灭的贡献</li>
<li>而且如此技术信仰，是算法工程师应有的样子，打 call</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/03/06/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%BA%8C%E5%BC%B9-%E2%80%94%E2%80%94-DeepEP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/06/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%BA%8C%E5%BC%B9-%E2%80%94%E2%80%94-DeepEP/" class="post-title-link" itemprop="url">2025.02 DeepSeek 开源周第二弹 —— DeepEP</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-06 16:27:24" itemprop="dateCreated datePublished" datetime="2025-03-06T16:27:24+08:00">2025-03-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/03/06/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%BA%8C%E5%BC%B9-%E2%80%94%E2%80%94-DeepEP/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/06/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%BA%8C%E5%BC%B9-%E2%80%94%E2%80%94-DeepEP/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepEP">https://github.com/deepseek-ai/DeepEP</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>目前大模型常用的三种并行：
<ul>
<li><code>DP</code>: <code>Data Parallelism</code>，数据并行，将数据分成多份，每个 <code>GPU</code> 处理一份数据</li>
<li><code>PP</code>: <code>Pipeline Parallelism</code>，管道并行，将模型分成多个阶段（连续一层或多层为一个阶段），每个 <code>GPU</code> 处理一个阶段</li>
<li><code>TP</code>: <code>Tensor Parallelism</code>，张量并行，将模型分成多份（通常是一层/一个算子/一个张量分成多份，主要解决超长序列引起的超大张量问题），每个 <code>GPU</code> 处理一部分张量</li>
</ul>
</li>
<li>对于 <code>MoE</code> 结构，<code>EP (Expert Parallelism)</code> 是一种新的并行策略，将 <code>MoE</code> 中的 <code>Expert</code> 分配到不同的 <code>GPU</code> 上</li>
<li><code>DeepEP</code> 是一个 用 <code>cuda</code> 实现的 <code>MoE</code> 模型的并行库，重点在于对 <code>All-to-All</code> 通信的优化</li>
</ul>
<h2 id="背景知识"><a class="markdownIt-Anchor" href="#背景知识"></a> 背景知识</h2>
<h3 id="节点内通信"><a class="markdownIt-Anchor" href="#节点内通信"></a> 节点内通信</h3>
<ul>
<li>通俗讲：一台服务器被称为一个节点，一个节点上的多个 <code>GPU</code> 之间的通信被称为节点内通信</li>
<li>通信协议：
<ul>
<li><code>PCIe</code>：比较通用的通信协议，目前最新的 <code>PCIe 6.0</code> 的带宽为 <code>32GB/s</code> 的双向带宽</li>
<li><code>NVLink</code>：<code>NVIDIA</code> 自家的通信协议，目前最新的 <code>NVLink 5.0</code> 的带宽约为 <code>800GB/s</code> 的双向带宽</li>
</ul>
</li>
</ul>
<h3 id="节点间通信"><a class="markdownIt-Anchor" href="#节点间通信"></a> 节点间通信</h3>
<ul>
<li>多台服务器组成一个集群，集群中的服务器之间的通信被称为节点间通信</li>
<li>通信协议：
<ul>
<li><code>InfiniBand</code>：<code>HPC</code> 领域常用的通信协议，目前最新的 <code>InfiniBand NDR</code> 可达 <code>400Gbps</code> 的双向带宽</li>
<li><code>Ethernet</code>：通用的通信协议，速度低于 <code>InfiniBand</code></li>
</ul>
</li>
<li>通信技术：
<ul>
<li><code>RDMA</code>：<code>Remote Direct Memory Access</code>，远程直接内存访问，<code>RDMA</code> 通过 <code>DMA</code> 直接访问远程内存，减少了 <code>CPU</code> 的参与，提高了通信效率</li>
</ul>
</li>
</ul>
<h3 id="通信视角下-moe-结构的特殊性"><a class="markdownIt-Anchor" href="#通信视角下-moe-结构的特殊性"></a> 通信视角下 MoE 结构的特殊性</h3>
<ul>
<li><code>MoE</code> 结构的本质是超大规模参数量 + 小规模激活参数量（实际计算量）来让模型更强大同时推理效率高</li>
<li>由于 <code>MoE</code> 结构在实际推理过程中，每个 <code>token</code> 激活的专家 <code>id</code> 是无法提前预测的，而是一个纯 <code>runtime</code> 的行为</li>
<li>对此，为了降低 <code>EP</code> 通信压力，<code>MoE</code> 结构通常会限制每个 <code>token</code> 实际激活的节点数量。例如，<code>DeepSeek V3</code> 有 <code>1</code> 个共享专家和 <code>256</code> 个路由专家，每个 <code>token</code> 会激活 <code>1</code> 个共享专家和 <code>8</code> 个路由专家，但同时限制最多只能激活 <code>4</code> 个节点，假如得分最高的 <code>8</code> 个路由专家来自超过 <code>4</code> 个节点，那么会牺牲部分高分专家，在节点数不超过 <code>4</code> 的情况下，用贪心算法选择得分最高的 <code>4</code> 个专家</li>
<li>虽然 <code>DP / TP / PP</code> 都存在通信问题，但都是可提前规划好的通信数据量和通信模式，只要调度得当，即可重叠计算和通信耗时，而 <code>MoE</code> 结构的通信是无法提前规划的，因此 <code>MoE</code> 结构的通信是最难优化的</li>
</ul>
<h2 id="关键特性和能力"><a class="markdownIt-Anchor" href="#关键特性和能力"></a> 关键特性和能力</h2>
<p><code>DeepEP</code> 的关键特性和能力包括：</p>
<ul>
<li><strong>高吞吐量节点内通信</strong>：使用 <code>NVLink</code> 优化节点内所有到所有通信的内核，实现高达 <code>155 GB/s</code> 的带宽。</li>
<li><strong>高吞吐量节点间通信</strong>：使用 <code>RDMA</code> 实现高效的跨节点所有到所有通信，在不同的 <code>EP</code> 配置中保持大约 <code>45 GB/s</code> 的带宽。</li>
<li><strong>低延迟内核</strong>：专用推理解码内核，分发操作延迟低至 <code>163</code> 微秒，组合操作延迟低至 <code>318</code> 微秒。</li>
<li><strong>FP8 支持</strong>：原生支持低精度操作，包括 <code>FP8</code> 分发，与大型模型中量化趋势一致。</li>
<li><strong>灵活的 GPU 资源控制</strong>：可配置的 <code>SM</code> 使用，用于计算 - 通信重叠，允许精细调整性能优化。</li>
<li><strong>自适应路由支持</strong>：在低延迟内核中支持自适应路由，使复杂拓扑中的网络利用更高效。</li>
</ul>
<h2 id="技术实现"><a class="markdownIt-Anchor" href="#技术实现"></a> 技术实现</h2>
<p><code>DeepEP</code> 是用 <code>C++</code> 和 <code>CUDA</code> 组件实现的，并带有 <code>Python</code> 接口。实现包括几个关键组件：</p>
<ul>
<li><strong>缓冲管理</strong>：核心 <code>Buffer</code> 类管理 <code>NVLink</code> 和 <code>RDMA</code> 的通信缓冲区，处理内存分配和同步。</li>
<li><strong>通信内核</strong>：
<ul>
<li>训练和推理预填充的高吞吐量内核</li>
<li>推理解码的低延迟内核</li>
<li>支持节点内（<code>NVLink</code>）和节点间（<code>RDMA</code>）通信</li>
</ul>
</li>
<li><strong>事件管理</strong>：<code>EventOverlap</code> 类提供 <code>CUDA</code> 事件处理和计算 - 通信重叠的工具。</li>
<li><strong>分发和组合操作</strong>：
<ul>
<li><code>dispatch</code>：将令牌特征发送到跨 <code>GPU</code> 的对应专家</li>
<li><code>combine</code>：从专家收集处理后的特征并返回到原始位置</li>
</ul>
</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>大模型，尤其是基座大模型，拼的是基建</li>
<li>大模型时代不会再出现小模型时代经常出现的 <strong>理论计算量低但实际很慢的算法</strong> 了，<code>GPU</code> 上快才是真的快，不光要考虑计算，存储 / 通信也同时需要认真考虑</li>
<li>软硬件 <code>co-design</code> 是未来趋势，<code>People who're serious about software should make their own hardware.</code> 这句名言的含金量还在上升</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/03/06/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%B8%80%E5%BC%B9-%E2%80%94%E2%80%94-FlashMLA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/06/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%B8%80%E5%BC%B9-%E2%80%94%E2%80%94-FlashMLA/" class="post-title-link" itemprop="url">2025.02 DeepSeek 开源周第一弹 —— FlashMLA</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-06 13:05:31" itemprop="dateCreated datePublished" datetime="2025-03-06T13:05:31+08:00">2025-03-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/03/06/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%B8%80%E5%BC%B9-%E2%80%94%E2%80%94-FlashMLA/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/03/06/2025-02-DeepSeek-%E5%BC%80%E6%BA%90%E5%91%A8%E7%AC%AC%E4%B8%80%E5%BC%B9-%E2%80%94%E2%80%94-FlashMLA/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/FlashMLA">https://github.com/deepseek-ai/FlashMLA</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>FlashMLA</code> 是针对 <code>DeepSeek</code> 提出的 <code>MLA (Multi-head Latent Attention)</code> 模块，在 <code>Nvidia Hopper</code> 架构 <code>GPU</code> 上的加速算法，尤其对边长序列推理做了优化</li>
<li><code>FlashMLA</code> 和 <code>MLA</code> 的关系大概可以类比到 <code>FlashAttention</code> 和 <code>Attention</code> 的关系</li>
</ul>
<h2 id="关键特性和能力"><a class="markdownIt-Anchor" href="#关键特性和能力"></a> 关键特性和能力</h2>
<ol>
<li><strong>仅对 <code>Hopper (sm_90)</code> 架构做优化</strong>：充分挖掘了硬件 (<code>sm</code>) 的计算能力和 <code>Memory Hierachy</code> 的 存储 / <code>IO</code> 能力</li>
<li><strong>支持可变长度序列</strong>：和现实世界中推理场景更贴合</li>
<li><strong>分页 KV cache</strong>：使用 <code>block size = 64</code> 的分页存储（这里的 <code>64</code> 的含义是：一个 <code>block</code> 存储某一层某个头的连续 <code>64</code> 个 <code>token</code> 对应的 <code>kv cache</code>）</li>
<li><strong>高性能带宽和算力</strong>：在 <code>H800 SXM5</code> 设备上，在内存带宽受限配置环境下，内存带宽可达 <code>3000 GB/s</code>，在算力受限配置下，算力可达 <code>580 TFLOPS</code></li>
<li><strong>支持多种精度</strong>：支持 <code>BF16</code> 和 <code>FP16</code></li>
</ol>
<h2 id="技术实现"><a class="markdownIt-Anchor" href="#技术实现"></a> 技术实现</h2>
<ol>
<li>基于 <code>Nvidia cutlass</code> 库 + <code>cuda</code> 实现主要计算</li>
<li>用干净的 <code>python API</code> 包装，方便集成到 <code>PyTorch-base</code> 框架中</li>
<li>用元数据管理的方式支持变长序列</li>
</ol>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>做大模型不懂 <code>cuda</code> 是不行了，<code>cutlass</code> 要开始学起来了…</li>
<li><code>FlashMLA</code> 只在 <code>sm_90</code> 上实现了，其他显卡编译不通，<s><code>DeepSeek</code> 只打高端局</s></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/02/20/Native-Sparse-Attention-Hardware-Aligned-and-Natively-Trainable-Sparse-Attention/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/20/Native-Sparse-Attention-Hardware-Aligned-and-Natively-Trainable-Sparse-Attention/" class="post-title-link" itemprop="url">Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-02-20 15:44:48" itemprop="dateCreated datePublished" datetime="2025-02-20T15:44:48+08:00">2025-02-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/02/20/Native-Sparse-Attention-Hardware-Aligned-and-Natively-Trainable-Sparse-Attention/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/02/20/Native-Sparse-Attention-Hardware-Aligned-and-Natively-Trainable-Sparse-Attention/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.11089">https://arxiv.org/pdf/2502.11089</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出了一种新的稀疏注意力机制，称为 <code>Native Sparse Attention</code>，该机制在硬件上对齐，并且可以直接训练，而无需额外的稀疏化技术</li>
<li>目前没有开源代码，只能通过论文中的公式和描述来实现</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="总体流程"><a class="markdownIt-Anchor" href="#总体流程"></a> 总体流程</h3>
<p><img src="https://s2.loli.net/2025/02/21/o5uIEHCaKlJA2ft.png" alt="nsa.png" /></p>
<ul>
<li>本质上是用不同的 <code>pattern</code> 组合来替代 <code>full attention</code>，以减少计算量</li>
</ul>
<h3 id="代码实现"><a class="markdownIt-Anchor" href="#代码实现"></a> 代码实现</h3>
<ul>
<li>由 <code>DeepSeek-R1</code> 根据论文中的公式和描述实现</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NSAModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        d_model,</span></span></span><br><span class="line"><span class="params"><span class="function">        n_heads,</span></span></span><br><span class="line"><span class="params"><span class="function">        compress_block=<span class="number">32</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        select_block=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        select_topk=<span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        window_size=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dropout=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.n_heads = n_heads</span><br><span class="line">        self.head_dim = d_model // n_heads</span><br><span class="line">        <span class="comment"># 参数设置</span></span><br><span class="line">        self.compress_block = compress_block</span><br><span class="line">        self.select_block = select_block</span><br><span class="line">        self.select_topk = select_topk</span><br><span class="line">        self.window_size = window_size</span><br><span class="line">        <span class="comment"># 压缩用MLP</span></span><br><span class="line">        self.compress_mlp = nn.Sequential(</span><br><span class="line">            nn.Linear(self.head_dim * compress_block, <span class="number">256</span>),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, self.head_dim),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 门控机制</span></span><br><span class="line">        self.gate_mlp = nn.Sequential(nn.Linear(d_model, <span class="number">3</span> * n_heads), nn.Sigmoid())</span><br><span class="line">        <span class="comment"># 投影层</span></span><br><span class="line">        self.q_proj = nn.Linear(d_model, d_model)</span><br><span class="line">        self.k_proj = nn.Linear(d_model, d_model)</span><br><span class="line">        self.v_proj = nn.Linear(d_model, d_model)</span><br><span class="line">        self.out_proj = nn.Linear(d_model, d_model)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_compress_tokens</span>(<span class="params">self, k, v</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;压缩KV序列到块级别&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 调整输入维度 (batch, seq_len, n_heads, head_dim)</span></span><br><span class="line">        b, t, nh, hd = k.shape  <span class="comment"># 修改为四维解包</span></span><br><span class="line">        block_size = self.compress_block</span><br><span class="line">        num_blocks = (t + block_size - <span class="number">1</span>) // block_size</span><br><span class="line">        pad_len = num_blocks * block_size - t</span><br><span class="line">        <span class="comment"># 填充并分块</span></span><br><span class="line">        k = F.pad(k, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, pad_len))  <span class="comment"># 添加头部维度的填充</span></span><br><span class="line">        v = F.pad(v, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, pad_len))</span><br><span class="line">        <span class="comment"># 调整维度: [batch, num_blocks, block_size, n_heads, head_dim]</span></span><br><span class="line">        k_blocks = k.view(b, num_blocks, block_size, nh, hd)</span><br><span class="line">        v_blocks = v.view(b, num_blocks, block_size, nh, hd)</span><br><span class="line">        <span class="comment"># 压缩处理 (保持头部分离)</span></span><br><span class="line">        k_compressed = self.compress_mlp(</span><br><span class="line">            k_blocks.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>).flatten(<span class="number">3</span>)</span><br><span class="line">        )  <span class="comment"># [b, num_blocks, nh, hd]</span></span><br><span class="line">        v_compressed = self.compress_mlp(v_blocks.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>).flatten(<span class="number">3</span>))</span><br><span class="line">        <span class="keyword">return</span> k_compressed, v_compressed</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_select_blocks</span>(<span class="params">self, q, k_compressed, v_compressed</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;基于注意力分数选择关键块&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 计算压缩注意力分数</span></span><br><span class="line">        scores = torch.einsum(<span class="string">&quot;bthd,bkhd-&gt;bthk&quot;</span>, q, k_compressed) / (</span><br><span class="line">            self.head_dim ** <span class="number">0.5</span></span><br><span class="line">        )</span><br><span class="line">        probs = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 选择topk块</span></span><br><span class="line">        topk_scores, topk_indices = torch.topk(</span><br><span class="line">            probs.mean(dim=<span class="number">2</span>), self.select_topk, dim=-<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 收集选中的块</span></span><br><span class="line">        k_selected = torch.gather(</span><br><span class="line">            k_compressed,</span><br><span class="line">            <span class="number">1</span>,</span><br><span class="line">            topk_indices.unsqueeze(-<span class="number">1</span>).expand(-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, self.head_dim),</span><br><span class="line">        )</span><br><span class="line">        v_selected = torch.gather(</span><br><span class="line">            v_compressed,</span><br><span class="line">            <span class="number">1</span>,</span><br><span class="line">            topk_indices.unsqueeze(-<span class="number">1</span>).expand(-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, self.head_dim),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> k_selected, v_selected</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, attn_mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        b, t, d = x.shape</span><br><span class="line">        <span class="comment"># 投影QKV并保持四维结构</span></span><br><span class="line">        q = self.q_proj(x).view(b, t, self.n_heads, self.head_dim)</span><br><span class="line">        k = self.k_proj(x).view(b, t, self.n_heads, self.head_dim)</span><br><span class="line">        v = self.v_proj(x).view(b, t, self.n_heads, self.head_dim)</span><br><span class="line">        <span class="comment"># 压缩路径</span></span><br><span class="line">        k_compressed, v_compressed = self._compress_tokens(k, v)</span><br><span class="line">        <span class="comment"># 选择路径</span></span><br><span class="line">        k_selected, v_selected = self._select_blocks(q, k_compressed, v_compressed)</span><br><span class="line">        <span class="comment"># 滑动窗口</span></span><br><span class="line">        k_window = k[:, <span class="built_in">max</span>(<span class="number">0</span>, t - self.window_size) :]</span><br><span class="line">        v_window = v[:, <span class="built_in">max</span>(<span class="number">0</span>, t - self.window_size) :]</span><br><span class="line">        <span class="comment"># 门控权重</span></span><br><span class="line">        gate = self.gate_mlp(x).view(b, t, <span class="number">3</span>, self.n_heads).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 三路注意力计算</span></span><br><span class="line">        attn_outputs = []</span><br><span class="line">        <span class="keyword">for</span> branch_k, branch_v <span class="keyword">in</span> [</span><br><span class="line">            (k_compressed, v_compressed),</span><br><span class="line">            (k_selected, v_selected),</span><br><span class="line">            (k_window, v_window),</span><br><span class="line">        ]:</span><br><span class="line">            scores = torch.einsum(<span class="string">&quot;bthd,bkhd-&gt;bthk&quot;</span>, q, branch_k) / (</span><br><span class="line">                self.head_dim ** <span class="number">0.5</span></span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">if</span> attn_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                scores = scores.masked_fill(attn_mask == <span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line">            probs = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">            probs = self.dropout(probs)</span><br><span class="line">            output = torch.einsum(<span class="string">&quot;bthk,bkhd-&gt;bthd&quot;</span>, probs, branch_v)</span><br><span class="line">            attn_outputs.append(output)</span><br><span class="line">        <span class="comment"># 门控融合</span></span><br><span class="line">        weighted = <span class="built_in">sum</span>(g * o <span class="keyword">for</span> g, o <span class="keyword">in</span> <span class="built_in">zip</span>(gate, attn_outputs))</span><br><span class="line">        output = weighted.contiguous().view(b, t, d)</span><br><span class="line">        <span class="keyword">return</span> self.out_proj(output)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_nsa_attention_shapes</span>():</span></span><br><span class="line">    <span class="comment"># 测试参数</span></span><br><span class="line">    batch_size = <span class="number">2</span></span><br><span class="line">    seq_len = <span class="number">128</span></span><br><span class="line">    d_model = <span class="number">256</span></span><br><span class="line">    n_heads = <span class="number">8</span></span><br><span class="line">    nsa_attn = NSAModule(d_model, n_heads)</span><br><span class="line">    x = torch.randn(batch_size, seq_len, d_model)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输入形状:&quot;</span>, x.shape)</span><br><span class="line">    <span class="comment"># 打印中间形状</span></span><br><span class="line">    q = nsa_attn.q_proj(x).view(batch_size, seq_len, n_heads, -<span class="number">1</span>)</span><br><span class="line">    k = nsa_attn.k_proj(x).view(batch_size, seq_len, n_heads, -<span class="number">1</span>)</span><br><span class="line">    v = nsa_attn.v_proj(x).view(batch_size, seq_len, n_heads, -<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nQ/K/V形状:&quot;</span>, q.shape)  <span class="comment"># 应该输出 [2, 128, 8, 32]</span></span><br><span class="line">    k_comp, v_comp = nsa_attn._compress_tokens(k, v)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;压缩后KV形状:&quot;</span>, k_comp.shape)  <span class="comment"># [2, 4, 8, 32]</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    test_nsa_attention_shapes()</span><br></pre></td></tr></table></figure>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>速度快并不惊讶，但效果竟然比 <code>Full Attention</code> 还好，如果实验比较 <code>solid</code>，那么 <code>NSA</code> 确实比较有前途</li>
<li>由于没有开源代码，所以只能通过论文中的公式和描述来实现，这对于一些实验复现和工程应用来说是一个挑战</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/02/18/DeepSeek-R1-Incentivizing-Reasoning-Capability-in-LLMs-via-Reinforcement-Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/18/DeepSeek-R1-Incentivizing-Reasoning-Capability-in-LLMs-via-Reinforcement-Learning/" class="post-title-link" itemprop="url">DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-02-18 13:41:31" itemprop="dateCreated datePublished" datetime="2025-02-18T13:41:31+08:00">2025-02-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/02/18/DeepSeek-R1-Incentivizing-Reasoning-Capability-in-LLMs-via-Reinforcement-Learning/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/02/18/DeepSeek-R1-Incentivizing-Reasoning-Capability-in-LLMs-via-Reinforcement-Learning/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.12948">https://arxiv.org/pdf/2501.12948</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-R1">https://github.com/deepseek-ai/DeepSeek-R1</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出了三个模型和其对应的训练方法，目的是提高大模型的 <code>CoT</code> 推理能力，三个模型分别是：
<ul>
<li><code>DeepSeek-R1-Zero</code>：由 <code>DeepSeek V3 base</code> 直接通过 <code>RL</code> 训练得到（<code>DeepSeek V3 base</code> 是 <code>DeepSeek V3</code> 只经过 <code>pretrain</code> 的版本，即 <code>DeepSeek V3 = DeepSeek V3 base + post-train</code> ）</li>
<li><code>DeepSeek-R1</code>：由 <code>DeepSeek V3 base</code> 在合成的高质量 <code>CoT</code> 数据集上 <code>SFT + RL</code> 训练得到，效果优于 <code>DeepSeek-R1-Zero</code></li>
<li><code>Distill model</code>：用相同的合成高质量 <code>CoT</code> 数据训练的开源模型（参数量小且非 <code>MoE</code>）</li>
</ul>
</li>
<li>其中训练方法是本文讲述的重点，<code>DeepSeek R1</code> 中的 <code>R</code> 表示 <code>Reasoning</code>（推导）</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="总体流程"><a class="markdownIt-Anchor" href="#总体流程"></a> 总体流程</h3>
<p><img src="https://s2.loli.net/2025/02/20/3lZt9Y7RPhiaKW6.jpg" alt="deepseek_r1.jpg" /></p>
<h3 id="benchmark"><a class="markdownIt-Anchor" href="#benchmark"></a> Benchmark</h3>
<p><img src="https://s2.loli.net/2025/02/20/PzZcEaqSpBvW5D4.png" alt="deepseek.png" /></p>
<h3 id="deepseek-r1-zero"><a class="markdownIt-Anchor" href="#deepseek-r1-zero"></a> DeepSeek-R1-Zero</h3>
<ul>
<li><code>DeepSeek-R1-Zero</code> 是用 <code>DeepSeek v3 base (pre-train)</code> 直接通过 <code>RL</code> 训练得到的，不经过 <code>SFT</code></li>
<li>用了以下的 <code>Template</code> 让模型生成 <code>CoT</code> 推理结果：<br />
<img src="https://s2.loli.net/2025/02/20/XExDYc9MbfkvJ76.png" alt="deepseekr1zero.png" /></li>
<li>奖励建模分成两个部分：
<ul>
<li><code>Accuracy rewards</code>: 用于评估模型生成的 <code>CoT</code> 推理结果的准确性</li>
<li><code>Format rewards</code>: 用于评估模型生成的 <code>CoT</code> 推理结果的格式是否符合上述 <code>prompt</code> 要求的 <code>CoT</code> 的格式</li>
</ul>
</li>
<li>且 <code>RL</code> 过程不使用 <code>NN reward model</code>，而是使用了 <code>Rule base reward</code></li>
<li><code>RL</code> 过程中使用了 <code>GRPO</code> 算法</li>
<li><code>DeepSeek-R1-Zero</code> 仅仅用上述简单的 <code>CoT</code> 性能提升流程，即可大幅提高 <code>benchmark</code> 上的指标（相比于 <code>DeepSeek v3</code>），但仍然存在一些问题，例如可读性差和语言混合</li>
</ul>
<h3 id="deepseek-r1"><a class="markdownIt-Anchor" href="#deepseek-r1"></a> DeepSeek-R1</h3>
<ul>
<li><code>DeepSeek-R1</code> 用了更复杂的数据处理流程和训练流程，主要分成四个阶段（流程图上的四个 <code>stage</code>）：
<ul>
<li><strong>冷启动</strong>：用数千个来自于 <code>DeepSeek-R1-Zero</code> 输出且经过人工处理的 <code>CoT</code> 数据，对 <code>DeepSeek V3 base</code> 进行 <code>SFT</code></li>
<li><strong>面向推导的强化学习</strong>：用编码、数学、科学和逻辑推理等推理密集型任务数据，对冷启动微调后的模型进行 <code>RL</code> 训练，同时引入了语言一致性和可读性的奖励</li>
<li><strong>拒绝采样和监督微调</strong>：用上一个 <code>stage</code> 得到的模型生成更广泛领域的推导 <code>CoT</code> 数据 <code>600K</code> 条，用 <code>DeepSeek V3</code> 模型推理部分非推导数据（例如：写作、翻译等）得到潜在的思维链数据 <code>200K</code> 条，用这 <code>800K</code> 条数据对 <strong><code>DeepSeek V3 base</code></strong> 进行 <code>SFT</code></li>
<li><strong>所有场景的强化学习</strong>：用了和 <code>DeepSeek V3</code> 中使用的 <code>RL</code> 相同的 <code>pipeline</code>，数据和 <code>DeepSeek-R1-Zero</code> 中的 <code>RL</code> 数据相同，对上一个 <code>stage</code> 得到的模型进行 <code>RL</code> 训练</li>
</ul>
</li>
<li>综上所述，<strong><code>DeepSeek-R1</code> 最重要的是 <code>800K</code> 包含 <code>CoT</code> 的 <code>SFT</code> 数据</strong></li>
</ul>
<h3 id="distill-model"><a class="markdownIt-Anchor" href="#distill-model"></a> Distill model</h3>
<ul>
<li>由于 <code>DeepSeek R1</code> 使用了 <code>DeepSeek V3</code> 相同的模型结构，因此包含 <code>671B</code> 参数，每个 <code>token</code> 激活 <code>34B</code> 参数，因此这个模型非常大，不适合部署</li>
<li>为了解决这个问题，本文提出了 <code>Distill model</code>，用开源的较小参数量的稠密模型（非 <code>MoE</code> 模型）在 <strong><code>800K</code> 包含 <code>CoT</code> 的 <code>SFT</code> 数据</strong> 进行 <strong><code>SFT</code></strong> 微调</li>
<li>主要蒸馏了 <code>Qwen</code> 和 <code>llama</code> 模型，且<strong>完全不做 <code>RL</code></strong>，即可大幅提高原模型在 <code>Benchmark</code> 上的指标<br />
<img src="https://s2.loli.net/2025/02/20/vkXcx7wr9TPK3NM.png" alt="distill.png" /></li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>需要重点关注本论文提到的 <code>CoT</code> 数据合成方式，这是 <code>DeepSeek R1</code> 的核心</li>
<li>能从本文中可以看出 <strong>数据重要性远大于模型</strong> 和 <strong><code>Post-train</code> 只包含一次 <code>SFT</code> 和 一次 <code>RL</code></strong>，比如论文中 <code>stage 1</code> 模型会大胆抛弃 <code>DeepSeek R1 Zero</code> 模型，而是退回到了 <code>DeepSeek V3 base</code> 模型，只用了 <code>Zero</code> 生成数据；<code>stage 3</code> 模型会大胆抛弃之前 <code>stage</code> 的模型，而是退回到了 <code>DeepSeek V3 base</code> 模型，只用了 <code>stage 2</code> 模型生成数据</li>
<li>合成数据是最重要的，合成高质量的数据是 <code>DeepSeek R1</code> 成功的关键，甚至可以说如果 <code>DeepSeek</code> 开源了 <code>80K</code> 条合成数据，那么 <code>CoT</code> 领域的研究将会有一个新的起点</li>
</ul>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/22103896675">https://zhuanlan.zhihu.com/p/22103896675</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/02/02/DeepSeek-V3-Technical-Report/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/02/DeepSeek-V3-Technical-Report/" class="post-title-link" itemprop="url">DeepSeek-V3 Technical Report</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-02-02 16:17:41" itemprop="dateCreated datePublished" datetime="2025-02-02T16:17:41+08:00">2025-02-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/02/02/DeepSeek-V3-Technical-Report/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/02/02/DeepSeek-V3-Technical-Report/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.19437">https://arxiv.org/pdf/2412.19437</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-V3">https://github.com/deepseek-ai/DeepSeek-V3</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出了一种新的混合专家语言模型 <code>DeepSeek-V3</code>，共计 <code>671B</code> 总参数，对于每个 <code>token</code> 仅仅激活 <code>37B</code> 个参数，可以说又强又快。</li>
<li>主要的改进点包括：
<ul>
<li><code>Multi-head Latent Attention (MLA)</code>：<code>MLA</code> 是 <code>DeepSeek</code> 系列的核心模块（<code>Deepseek v2</code> 就有了），通过 <code>MLP</code> 将 <code>hidden state</code> 映射到 <code>latent space</code>，降低计算和存储复杂度。可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/12/27/DeepSeek-V2-A-Strong-Economical-and-Efficient-Mixture-of-Experts-Language-Model/"><code>Deepseek v2 MLA</code> 详解</a>。</li>
<li><code>Deepseek MOE</code>：一种比 <code>Gshard</code> 更优的 <code>MoE</code> 架构，可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/12/27/DeepSeekMoE-Towards-Ultimate-Expert-Specialization-in-Mixture-of-Experts-Language-Models/"><code>Deepseek MoE</code> 详解</a>。</li>
<li><code>Multi-token predicition (MTP)</code>：一种新的 <code>token</code> 预测方式，与传统的 <code>predict next token</code> 自回归预训练方式不同，<code>MTP</code> 通过一次预测多个 <code>token</code>（例如一次预测 <code>next token</code> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>x</mi><msup><mi>t</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">next^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> <code>token</code> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>x</mi><msup><mi>t</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">next^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> <code>token</code>），仅在训练阶段使用 <code>MTP</code>，推理阶段只使用 <code>next token</code> 的预测结果，即可大幅提高模型在 <code>benchmark</code> 上的综合表现。</li>
<li><code>auxiliary-loss-free strategy for load balancing</code>：一种新的 <code>MoE</code> 间负载均衡策略，无需额外的辅助损失，简化了训练过程，提高了训练效率。</li>
</ul>
</li>
<li>性能与稳定性：
<ul>
<li>性能：<code>DeepSeek-V3</code> 的表现超过了其他开源模型，其性能已经可以与一些领先的闭源模型相媲美。</li>
<li>稳定性：尽管性能卓越，模型全程训练仅花费了 <code>278.8</code> 万 <code>H800 GPU</code> 小时，而且在整个训练过程中表现出极高的稳定性，没有出现不可恢复的损失暴增或需要回滚的情况。</li>
</ul>
</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="总体流程"><a class="markdownIt-Anchor" href="#总体流程"></a> 总体流程</h3>
<ul>
<li><code>Pre-Training</code></li>
<li><code>Context Extension</code></li>
<li><code>Post-Training</code><br />
<img src="https://s2.loli.net/2025/02/17/wFn31BKPxOYgvRL.png" alt="deepseekv3_table_1.png" /></li>
</ul>
<h3 id="multi-token-predicition-mtp"><a class="markdownIt-Anchor" href="#multi-token-predicition-mtp"></a> Multi-token predicition (MTP)</h3>
<p><img src="https://s2.loli.net/2025/02/02/XS6dgw9mEotBKn5.png" alt="deepseekv3.png" /></p>
<ul>
<li>上图给出了一次预测 <code>next token</code> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>x</mi><msup><mi>t</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">next^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> <code>token</code> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>x</mi><msup><mi>t</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">next^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> <code>token</code> 的 <code>MTP</code> 模型结构。</li>
<li>具体来说，<code>MTP</code> 是在标准 <code>Decoder only Transformer</code> 的基础上，额外引入了 <code>k-1</code> 个 <code>token</code> 预测头，每个 <code>token</code> 预测头都是一个 <code>Norm + Concat + Projection + Transformer block</code> 结构。</li>
<li>假设图上从左到右的 <code>token head</code> 分别记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">head_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">head_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">head_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，则 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">head_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 预测的是 <code>next token</code>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">head_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 预测的是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>x</mi><msup><mi>t</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">next^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> <code>token</code>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">head_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 预测的是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>x</mi><msup><mi>t</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">next^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> <code>token</code>。</li>
<li><code>MTP</code> 过程必须要保持因果性：
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">head_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><msub><mi>n</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">token_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，主干网络输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<code>output layer</code> 将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 映射为 <code>next token</code> 预测，记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><msubsup><mi>n</mi><mn>1</mn><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">token_1&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.24810799999999997em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">head_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><msub><mi>n</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">token_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，提取特征记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<code>output layer</code> 将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 映射为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>x</mi><msup><mi>t</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">next^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> <code>token</code> 预测，记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><msubsup><mi>n</mi><mn>2</mn><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">token_2&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.24810799999999997em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">head_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><msub><mi>n</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">token_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，提取特征记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">h_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<code>output layer</code> 将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">h_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 映射为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>e</mi><mi>x</mi><msup><mi>t</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">next^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> <code>token</code> 预测，记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><msubsup><mi>n</mi><mn>3</mn><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">token_3&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.24810799999999997em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span></span>。</li>
</ul>
</li>
<li><code>embedding layer</code> 和 <code>output layer</code> 在 <code>MTP</code> 中是共享的。</li>
<li><code>MTP</code> 通常只用在训练阶段，即在推理阶段只使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">head_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的输出。</li>
<li>也可以将 <code>inference MTP</code> 和 <code>speculative decoding</code> 结合，提高模型生成效率。</li>
</ul>
<h3 id="auxiliary-loss-free-strategy-for-load-balancing"><a class="markdownIt-Anchor" href="#auxiliary-loss-free-strategy-for-load-balancing"></a> Auxiliary-loss-free strategy for load balancing</h3>
<h4 id="训练阶段负载均衡策略"><a class="markdownIt-Anchor" href="#训练阶段负载均衡策略"></a> 训练阶段负载均衡策略</h4>
<ul>
<li>训练阶段负载均衡策略并不是本文原创，而是来自于 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2408.15664">Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts</a></li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>g</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>i</mi></msub><mo>∈</mo><mi>T</mi><mi>o</mi><mi>p</mi><mi>k</mi><mo stretchy="false">(</mo><mo stretchy="false">{</mo><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><msub><mi>N</mi><mi>r</mi></msub><mo stretchy="false">}</mo><mo separator="true">,</mo><msub><mi>K</mi><mi>r</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>e</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">g&#x27;_{i,t}=\begin{cases}s_{i,t},&amp;s_{i,t}+b_i\in Topk(\{s_{i,t}+b_j|1\le j\le N_r\},K_r)\\0,&amp; otherwise\end{cases}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">o</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mopen">(</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<ul>
<li>其中：
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>=</mo><mi>S</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy="false">(</mo><msubsup><mi>u</mi><mi>t</mi><mi>T</mi></msubsup><msub><mi>e</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s_{i,t}=Sigmoid(u_t^Te_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 <code>bias</code> 参数</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">N_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 <code>Expert</code> 的数量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">K_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是每个 <code>token</code> 保留的 <code>Expert</code> 数量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">b_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 是根据每一个 <code>Expert</code> 被激活的次数动态调整的
<ul>
<li>如果一个 <code>Expert</code> 被激活的次数过多（大于专家激活平均值），则 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>j</mi></msub><mo>=</mo><msub><mi>b</mi><mi>j</mi></msub><mo>−</mo><mi>γ</mi></mrow><annotation encoding="application/x-tex">b_j=b_j-\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span></li>
<li>如果一个 <code>Expert</code> 被激活的次数过少（小于专家激活平均值），则 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>j</mi></msub><mo>=</mo><msub><mi>b</mi><mi>j</mi></msub><mo>+</mo><mi>γ</mi></mrow><annotation encoding="application/x-tex">b_j=b_j+\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span></li>
<li>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span> 是一个超参数，表示 <code>bias update speed</code></li>
</ul>
</li>
</ul>
</li>
<li>关于 <code>bias</code> 的详细更新策略，可参考下图<br />
<img src="https://s2.loli.net/2025/02/03/UjGwdLF2n9mD8Pb.png" alt="auxiliary_loss_free.png" />
<ul>
<li><code>u</code> 和本文中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span> 等价</li>
</ul>
</li>
</ul>
<h4 id="推理阶段"><a class="markdownIt-Anchor" href="#推理阶段"></a> 推理阶段</h4>
<ul>
<li>推理阶段无需额外的负载均衡策略，直接使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{i,t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 即可。</li>
</ul>
<h3 id="complementary-sequence-wise-auxiliary-loss"><a class="markdownIt-Anchor" href="#complementary-sequence-wise-auxiliary-loss"></a> Complementary Sequence-Wise Auxiliary Loss</h3>
<ul>
<li>上面提到的 <code>Auxiliary-loss-free strategy for load balancing</code> 损失只能保证 <code>Expert</code> 的负载均衡，但可能出现一个 <code>Sequence</code> 中每一个 <code>token</code> 都激活了相同的 <code>Expert</code>，这种情况下，<code>Expert</code> 之间的负载仍然不均衡。因此 <code>Complementary Sequence-Wise Auxiliary Loss</code> 通过引入 <code>Auxiliary Loss</code> 来保证 <code>Sequence</code> 内部 <code>token</code> 之间的负载均衡。</li>
<li>具体来说，需要关注：
<ul>
<li><strong>离散选择频率</strong>：每一个 <code>Expert</code> 在 <code>Sequence</code> 中的激活次数</li>
<li><strong>连续激活强度</strong>：每一个 <code>Expert</code> 在 <code>Sequence</code> 中平均专家分数</li>
</ul>
</li>
<li>公式表述：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>B</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>=</mo><mi>α</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>r</mi></msub></munderover><msub><mi>f</mi><mi>i</mi></msub><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">L_{Bal}=\alpha\sum_{i=1}^{N_r}f_iP_i
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.1171050000000005em;vertical-align:-1.277669em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8394360000000003em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.311105em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>=</mo><mfrac><msub><mi>N</mi><mi>r</mi></msub><mrow><msub><mi>K</mi><mi>r</mi></msub><mi>T</mi></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi mathvariant="double-struck">I</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mo>∈</mo><mi>T</mi><mi>o</mi><mi>p</mi><mi>k</mi><mo stretchy="false">(</mo><mo stretchy="false">{</mo><msub><mi>s</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mi mathvariant="normal">∣</mi><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><msub><mi>N</mi><mi>r</mi></msub><mo stretchy="false">}</mo><mo separator="true">,</mo><msub><mi>K</mi><mi>r</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f_i=\frac{N_r}{K_rT}\sum_{t=1}^{T}\mathbb I(s_{i,t}\in Topk(\{s_{j,t}|1\le j\le N_r\},K_r))
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0954490000000003em;vertical-align:-1.267113em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathbb">I</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">o</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mopen">(</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mfrac><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>r</mi></msub></munderover><msub><mi>s</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">s_{i,t}&#x27;=\frac{s_{i,t}}{\sum_{j=1}^{N_r}s_{j,t}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.414609em;vertical-align:-1.3070490000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.128769em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3070490000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><msubsup><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">P_i=\frac{1}{T}\sum_{t=1}^{T}s_{i,t}&#x27;
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0954490000000003em;vertical-align:-1.267113em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>其中：
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>B</mi><mi>a</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{Bal}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 <code>Complementary Sequence-Wise Auxiliary Loss</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 是一个超参数，是一个很小的权重</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 <code>Expert</code> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 的离散选择频率</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 <code>Expert</code> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 的连续激活强度</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 是 <code>Sequence</code> 的长度</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">N_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 <code>Expert</code> 的数量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">K_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是每个 <code>token</code> 激活的 <code>Expert</code> 数量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">I</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbb I(\cdot)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathbb">I</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span> 是指示函数</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{i,t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy="false">(</mo><msubsup><mi>u</mi><mi>t</mi><mi>T</mi></msubsup><msub><mi>e</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Sigmoid(u_t^Te_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，表示专家的分数</li>
</ul>
</li>
<li>道理也很简单，就是希望在一个 <code>Sequence</code> 中，每一个 <code>Expert</code> 被激活的次数和激活的强度都是均衡的。</li>
</ul>
<h3 id="训练框架设计"><a class="markdownIt-Anchor" href="#训练框架设计"></a> 训练框架设计</h3>
<ul>
<li>模型训练基于自主研发的 <code>HAI-LLM</code> 框架，这是一个经过优化的高效轻量级训练系统，目前没有开源。</li>
<li><code>DeepSeek-V3</code> 的并行策略包含三个层面：
<ul>
<li><code>16</code> 路流水线并行(<code>Pipeline Parallelism, PP</code>)</li>
<li>跨 <code>8</code> 个节点的 <code>64</code> 路专家并行(<code>Expert Parallelism, EP</code>)</li>
<li><code>ZeRO-1</code> 数据并行(<code>Data Parallelism, DP</code>)</li>
</ul>
</li>
<li>开发了 <code>DualPipe</code> 流水线并行算法，相比于现有的 <code>PP</code> 算法，减少了空泡，基本上实现了计算和通信的高度重叠。<br />
<img src="https://s2.loli.net/2025/02/17/pvNqiXQKd9I2Vul.png" alt="dualpipe.png" /></li>
<li>优化了跨节点全对全通信内核，充分利用节点内 <code>GPU</code> 间的 <code>NVLink</code> 带宽和节点间 <code>InfiniBand</code> 带宽，同时减少了通信所需的流式多处理器(<code>SMs</code>)资源占用</li>
<li>通过精细的内存管理优化，使得模型训练无需依赖开销较大的张量并行(<code>Tensor Parallelism, TP</code>)技术</li>
</ul>
<h3 id="fp8"><a class="markdownIt-Anchor" href="#fp8"></a> FP8</h3>
<ul>
<li><code>DeepSeek-V3</code> 开发了 <code>FP8 (E4M3)</code> 混合精度训练框架，首次在超大规模模型上验证了 <code>FP8</code> 训练的可行性和效果。</li>
<li>通过算法、框架和硬件的综合优化，突破了跨节点 MoE 训练中的通信瓶颈，实现了计算与通信的高度重叠。这种优化大幅提升了训练效率，降低了训练成本，同时支持了更大规模模型的训练而无需额外开销。<br />
<img src="https://s2.loli.net/2025/02/17/JpucFYTPglXm24v.png" alt="fp8.png" /></li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>实际上 <code>DeepSeek V3</code> 技术报告中还有很多细节，尤其是很多关于工程优化的部分，此处不再一一列举</li>
<li>工程能力，尤其是开发一套分布式训练框架且根据模型特性对其深度优化的能力，是一个大模型成功的不可或缺因素</li>
<li>如果想要在大模型领域有所建树，不仅需要有强大的算法研究能力，还需要有强大的工程能力，比如 <code>CUDA</code> 编程能力等</li>
</ul>
<h2 id="references"><a class="markdownIt-Anchor" href="#references"></a> References</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/14890557782">https://zhuanlan.zhihu.com/p/14890557782</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhangzhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">170</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">106</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhangzhe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js', () => {
    // 初始化 Mermaid 配置
    mermaid.initialize({
      theme    : 'dark',  // 设置主题
      logLevel : 3,  // 设置日志等级
      flowchart: { curve: 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 },
      themeVariables: {
        'fontFamily': 'Microsoft YaHei, Arial, sans-serif',  // 设置中文字体
      }
    });

    // 初始化 Mermaid 图表
    mermaid.init(undefined, document.querySelectorAll('pre.mermaid'));
  }, window.mermaid);
}
</script>


  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'eK3W25jybCO5jVUrYBBpAPqM-gzGzoHsz',
      appKey     : 'F4KVyUj9wHI5c80Bhz7O2uhq',
      placeholder: "说点什么再走吧...",
      avatar     : 'hide',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
