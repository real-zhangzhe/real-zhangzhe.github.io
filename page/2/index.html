<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"real-zhangzhe.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Zhangzhe&#39;s Blog">
<meta property="og:url" content="https://real-zhangzhe.github.io/page/2/index.html">
<meta property="og:site_name" content="Zhangzhe&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhangzhe">
<meta property="article:tag" content="No mistakes in the tango, not like life.">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://real-zhangzhe.github.io/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Zhangzhe's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhangzhe's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">The projection of my life.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/archives/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/08/10/On-the-Generalization-of-SFT-A-Reinforcement-Learning-Perspective-with-Reward-Rectification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/10/On-the-Generalization-of-SFT-A-Reinforcement-Learning-Perspective-with-Reward-Rectification/" class="post-title-link" itemprop="url">On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-10 15:14:11" itemprop="dateCreated datePublished" datetime="2025-08-10T15:14:11+08:00">2025-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/SFT/" itemprop="url" rel="index"><span itemprop="name">SFT</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/08/10/On-the-Generalization-of-SFT-A-Reinforcement-Learning-Perspective-with-Reward-Rectification/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/08/10/On-the-Generalization-of-SFT-A-Reinforcement-Learning-Perspective-with-Reward-Rectification/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2508.05629">https://arxiv.org/pdf/2508.05629</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/yongliang-wu/DFT">https://github.com/yongliang-wu/DFT</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文证明传统 <code>SFT</code> 过程常用的 <code>Cross Entropy Loss</code> 的梯度等价于 <code>Reinforcement Learning</code> 中策略梯度更新，但隐含一个病态的奖励结构：稀疏奖励和逆概率权重结合，导致 <font color=red>模型对低概率样本过拟合</font>。</li>
<li>解决方案特别简单：<font color=red>在每个 <code>token</code> 的损失前乘当前 <code>token</code> 的概率作为权重</font>。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="公式角度"><a class="markdownIt-Anchor" href="#公式角度"></a> 公式角度</h3>
<ul>
<li>传统 <code>SFT</code> 过程的损失函数：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="normal">∇</mi><mi mathvariant="bold-italic">θ</mi></msub><msub><mi mathvariant="script">L</mi><mrow><mi mathvariant="normal">S</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">T</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">θ</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>∼</mo><msub><mi>π</mi><mi mathvariant="bold-italic">θ</mi></msub></mrow></msub><mrow><mo fence="true">[</mo><munder><munder><mfrac><mn>1</mn><mrow><msub><mi>π</mi><mi mathvariant="bold-italic">θ</mi></msub><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="true">⏟</mo></munder><mtext>逆概率权重</mtext></munder><mo>⋅</mo><munder><munder><mrow><mn mathvariant="double-struck">1</mn><mo stretchy="false">[</mo><mi>y</mi><mo>=</mo><msup><mi>y</mi><mo lspace="0em" rspace="0em">∗</mo></msup><mo stretchy="false">]</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>稀疏奖励</mtext></munder><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi mathvariant="bold-italic">θ</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi mathvariant="bold-italic">θ</mi></msub><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\nabla_{\boldsymbol{\theta}}\mathcal{L}_{\mathrm{SFT}}(\boldsymbol{\theta}) = 
- \mathbb{E}_{x,y \sim \pi_{\boldsymbol{\theta}}}
\left[ 
    \underbrace{\frac{1}{\pi_{\boldsymbol{\theta}}(y \mid x)}}_{\text{逆概率权重}}
    \cdot 
    \underbrace{\mathbb{1}[y = y^{*}]}_{\text{稀疏奖励}}
    \cdot 
    \nabla_{\boldsymbol{\theta}} \log \pi_{\boldsymbol{\theta}}(y \mid x)
\right]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord boldsymbol mtight" style="margin-right:0.03194em;">θ</span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">S</span><span class="mord mathrm mtight">F</span><span class="mord mathrm mtight">T</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.03194em;">θ</span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:4.915331em;vertical-align:-2.262331em;"></span><span class="mord">−</span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord boldsymbol mtight" style="margin-right:0.03194em;">θ</span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6529999999999996em;"><span style="top:-1.6499900000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-2.79999em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.3959900000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.4119800000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.653em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15003em;"><span></span></span></span></span></span></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214399999999997em;"><span style="top:-1.0591089999999999em;"><span class="pstrut" style="height:3.32144em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord cjk_fallback mtight">逆概率权重</span></span></span></span></span><span style="top:-3.32144em;"><span class="pstrut" style="height:3.32144em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span class="svg-align" style="top:-1.7374399999999999em;"><span class="pstrut" style="height:3.32144em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z'/></svg></span><span class="brace-center" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z'/></svg></span><span class="brace-right" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z'/></svg></span></span></span><span style="top:-3.32144em;"><span class="pstrut" style="height:3.32144em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord boldsymbol mtight" style="margin-right:0.03194em;">θ</span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.584em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.262331em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7499999999999998em;"><span style="top:-1.4236689999999999em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord cjk_fallback mtight">稀疏奖励</span></span></span></span></span><span style="top:-2.9999999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z'/></svg></span><span class="brace-center" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z'/></svg></span><span class="brace-right" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z'/></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">1</span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5763310000000001em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord boldsymbol mtight" style="margin-right:0.03194em;">θ</span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord boldsymbol mtight" style="margin-right:0.03194em;">θ</span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6529999999999996em;"><span style="top:-1.6499900000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-2.79999em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.3959900000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.4119800000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.653em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15003em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li><code>DFT</code> 损失函数：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi mathvariant="normal">D</mi><mi mathvariant="normal">F</mi><mi mathvariant="normal">T</mi></mrow></msub><mo>=</mo><mo>−</mo><msub><mi>E</mi><mrow><mrow><mo fence="true">(</mo><mi>x</mi><mo separator="true">,</mo><msup><mi>y</mi><mo lspace="0em" rspace="0em">∗</mo></msup><mo fence="true">)</mo></mrow><mo>∼</mo><mi mathvariant="script">D</mi></mrow></msub><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo fence="true">∣</mo><msup><mi>y</mi><mo lspace="0em" rspace="0em">∗</mo></msup><mo fence="true">∣</mo></mrow></munderover><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">g</mi></mrow><mrow><mo fence="true">(</mo><msub><mi>π</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msubsup><mi>y</mi><mi>t</mi><mo lspace="0em" rspace="0em">∗</mo></msubsup><mo>∣</mo><msubsup><mi>y</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow><mo lspace="0em" rspace="0em">∗</mo></msubsup><mo separator="true">,</mo><mi>x</mi><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msubsup><mi>y</mi><mi>t</mi><mo lspace="0em" rspace="0em">∗</mo></msubsup><mo>∣</mo><msubsup><mi>y</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow><mo lspace="0em" rspace="0em">∗</mo></msubsup><mo separator="true">,</mo><mi>x</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}_{\mathrm{DFT}} = - E_{\left(x, y^{*}\right)\sim\mathcal{D}} \sum_{t=1}^{\left|y^{*}\right|} \mathrm{sg}\left(\pi_{\theta}\left(y_{t}^{*}\mid y_{&lt;t}^{*},x\right)\right) \log\pi_{\theta}\left(y_{t}^{*}\mid y_{&lt;t}^{*},x\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">D</span><span class="mord mathrm mtight">F</span><span class="mord mathrm mtight">T</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.237458em;vertical-align:-1.267113em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0em;"><span class="mtight">(</span></span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mclose mtight delimcenter" style="top:0em;"><span class="mtight">)</span></span></span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9703450000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.386005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0em;"><span class="mtight">∣</span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7633428571428571em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mclose mtight delimcenter" style="top:0em;"><span class="mtight">∣</span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathrm">s</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7386959999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-2.453em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.27437em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7386959999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-2.453em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.27437em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p>
<ul>
<li>注意：这里的 <code>sg</code> 是 <code>stop gradient</code> 操作，即不计算梯度 <font color=red>对应 pytorch 中常用的 .detach() 操作</font>。</li>
</ul>
<h3 id="代码角度"><a class="markdownIt-Anchor" href="#代码角度"></a> 代码角度</h3>
<p><img src="https://s2.loli.net/2025/08/10/GdIl2HrfgcnFa5m.png" alt=" 2025-08-10 154116.png" /></p>
<ul>
<li><code>a</code> 表示预测序列中某个位置的的 <code>logits</code></li>
<li><code>b</code> 表示对应位置的 <code>GT</code></li>
<li><code>cross entropy loss</code> 就是 <code>-log(softmax(a))[b]</code></li>
<li><code>DFT</code> 损失函数就是 <code>-(softmax(a) * log(softmax(a)))[b]</code>，但注意要 <code>stop gradient</code>，<code>softmax(a)</code> 只作为系数，反向传播不优化。</li>
</ul>
<h3 id="函数角度"><a class="markdownIt-Anchor" href="#函数角度"></a> 函数角度</h3>
<p><img src="https://s2.loli.net/2025/08/10/GI2Eb76vr4zp1Zo.png" alt="dft2.png" /></p>
<ul>
<li>蓝色是标准 <code>SFT</code> 过程的损失函数（交叉熵）</li>
<li>红色是本文提出的 <code>DFT</code> 损失函数</li>
<li>绿色是我自己脑补的 <code>DFT</code> 函数扩展之后的损失函数，优点是比 <code>DFT</code> 对称性更好，效果怎么样不知道…</li>
<li>从函数角度看，<code>SFT</code> 在某个位置 <code>GT</code> 非常冷门的情况下，<code>-log(softmax(a))</code> 会趋向于 <code>inf</code>，导致模型对这个冷门的 <code>token</code> 做了过大的参数更新，这是不合理的（因为模型已经经过了预训练，用非常低的概率预测 <code>GT</code> 说明这个 <code>GT</code> 可能是噪声）。</li>
<li>而 <code>DFT</code> 的函数可以看出，模型 <font color=red>优先关注不过分难或过分简单的 token</font>，太难的可能是数据噪声，太简单的本身就没什么好学的。</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>从函数角度看：太难的我不学，因为太难；太简单的我不学，因为太简单。</li>
<li><s>郭德纲：我有四不吃…</s>😂😂😂</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/07/24/%E7%94%A8-langchain-%E5%AE%9E%E7%8E%B0-RAG-%E7%9A%84-demo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/07/24/%E7%94%A8-langchain-%E5%AE%9E%E7%8E%B0-RAG-%E7%9A%84-demo/" class="post-title-link" itemprop="url">用 langchain 实现 RAG 的 demo</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-07-24 20:59:47" itemprop="dateCreated datePublished" datetime="2025-07-24T20:59:47+08:00">2025-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Agent/" itemprop="url" rel="index"><span itemprop="name">Agent</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/07/24/%E7%94%A8-langchain-%E5%AE%9E%E7%8E%B0-RAG-%E7%9A%84-demo/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/07/24/%E7%94%A8-langchain-%E5%AE%9E%E7%8E%B0-RAG-%E7%9A%84-demo/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li><code>langchain Semi-structured RAG cookbook</code>：<a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb">https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>langchain</code> 的 <code>Semi-structured RAG</code> 的 <code>demo</code>，包含 <code>PDF</code> 的 解析 -&gt; 向量化 -&gt; 存储 -&gt; 检索 -&gt; 回答 的全流程</li>
<li>来自 <code>langchain</code> 官方的 <code>cookbook</code>，值得参考</li>
</ul>
<h2 id="总体流程"><a class="markdownIt-Anchor" href="#总体流程"></a> 总体流程</h2>
<p><img src="https://s2.loli.net/2025/07/24/pPAL3JkjGKb5ohH.png" alt="langchain_rag_demo.png" /></p>
<ol>
<li><strong>解析 <code>PDF</code> 文件</strong>。用 <code>partition_pdf</code> 工具，将 <code>PDF</code> 文件解析为 <code>chunks</code>，分成文本和表格两种</li>
<li><strong>总结 <code>chunks</code></strong>。用大模型 <code>API</code> 总结 <code>chunks</code>，得到 <code>summary</code>，用哪家的模型都行</li>
<li><strong>向量化 <code>summary</code></strong>。调用 <code>embedding</code> 模型 <code>API</code> 对 <code>summary</code> 进行向量化，作为索引的 <code>key</code>（<code>value</code> 是原始文本/表格），存到 <code>Chroma</code> 数据库中</li>
<li><strong>问答时自动检索</strong>。在问答时，会自动根据问题向量在 <code>Chroma</code> 数据库中检索出最相似的 <code>summary</code>，将 <code>summary</code> 向量对应的原始文本/表格作为 <code>prompt</code> 中的 <code>context</code> 域传给大模型，得到回答</li>
</ol>
<h2 id="具体实现代码"><a class="markdownIt-Anchor" href="#具体实现代码"></a> 具体实现代码</h2>
<h3 id="1-解析-pdf-文件"><a class="markdownIt-Anchor" href="#1-解析-pdf-文件"></a> 1. 解析 <code>PDF</code> 文件</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Any</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> unstructured.partition.pdf <span class="keyword">import</span> partition_pdf</span><br><span class="line"></span><br><span class="line">path = <span class="string">&quot;/Users/rlm/Desktop/Papers/LLaMA2/&quot;</span></span><br><span class="line"><span class="comment"># Get elements</span></span><br><span class="line">raw_pdf_elements = partition_pdf(</span><br><span class="line">    filename=path + <span class="string">&quot;LLaMA2.pdf&quot;</span>,</span><br><span class="line">    <span class="comment"># Unstructured first finds embedded image blocks</span></span><br><span class="line">    extract_images_in_pdf=<span class="literal">False</span>,</span><br><span class="line">    <span class="comment"># Use layout model (YOLOX) to get bounding boxes (for tables) and find titles</span></span><br><span class="line">    <span class="comment"># Titles are any sub-section of the document</span></span><br><span class="line">    infer_table_structure=<span class="literal">True</span>,</span><br><span class="line">    <span class="comment"># Post processing to aggregate text once we have the title</span></span><br><span class="line">    chunking_strategy=<span class="string">&quot;by_title&quot;</span>,</span><br><span class="line">    <span class="comment"># Chunking params to aggregate text blocks</span></span><br><span class="line">    <span class="comment"># Attempt to create a new chunk 3800 chars</span></span><br><span class="line">    <span class="comment"># Attempt to keep chunks &gt; 2000 chars</span></span><br><span class="line">    max_characters=<span class="number">4000</span>,</span><br><span class="line">    new_after_n_chars=<span class="number">3800</span>,</span><br><span class="line">    combine_text_under_n_chars=<span class="number">2000</span>,</span><br><span class="line">    image_output_dir_path=path,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="2-总结-chunks-得到-summary"><a class="markdownIt-Anchor" href="#2-总结-chunks-得到-summary"></a> 2. 总结 <code>chunks</code> 得到 <code>summary</code></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prompt</span></span><br><span class="line">prompt_text = <span class="string">&quot;&quot;&quot;You are an assistant tasked with summarizing tables and text. \ </span></span><br><span class="line"><span class="string">Give a concise summary of the table or text. Table or text chunk: &#123;element&#125; &quot;&quot;&quot;</span></span><br><span class="line">prompt = ChatPromptTemplate.from_template(prompt_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Summary chain</span></span><br><span class="line">model = ChatOpenAI(temperature=<span class="number">0</span>, model=<span class="string">&quot;gpt-4&quot;</span>)</span><br><span class="line">summarize_chain = &#123;<span class="string">&quot;element&quot;</span>: <span class="keyword">lambda</span> x: x&#125; | prompt | model | StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply to tables</span></span><br><span class="line">tables = [i.text <span class="keyword">for</span> i <span class="keyword">in</span> table_elements]</span><br><span class="line">table_summaries = summarize_chain.batch(tables, &#123;<span class="string">&quot;max_concurrency&quot;</span>: <span class="number">5</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply to texts</span></span><br><span class="line">texts = [i.text <span class="keyword">for</span> i <span class="keyword">in</span> text_elements]</span><br><span class="line">text_summaries = summarize_chain.batch(texts, &#123;<span class="string">&quot;max_concurrency&quot;</span>: <span class="number">5</span>&#125;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>langchain</code> 用 <code>|</code> 符号就可以把多个工具串成一个 <code>chain</code>，非常方便</p>
</blockquote>
<h3 id="3-向量化-summary-并存到-chroma-数据库中"><a class="markdownIt-Anchor" href="#3-向量化-summary-并存到-chroma-数据库中"></a> 3. 向量化 <code>summary</code> 并存到 <code>Chroma</code> 数据库中</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> uuid</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.retrievers.multi_vector <span class="keyword">import</span> MultiVectorRetriever</span><br><span class="line"><span class="keyword">from</span> langchain.storage <span class="keyword">import</span> InMemoryStore</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"></span><br><span class="line"><span class="comment"># The vectorstore to use to index the child chunks</span></span><br><span class="line">vectorstore = Chroma(collection_name=<span class="string">&quot;summaries&quot;</span>, embedding_function=OpenAIEmbeddings())</span><br><span class="line"></span><br><span class="line"><span class="comment"># The storage layer for the parent documents</span></span><br><span class="line">store = InMemoryStore()</span><br><span class="line">id_key = <span class="string">&quot;doc_id&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The retriever (empty to start)</span></span><br><span class="line">retriever = MultiVectorRetriever(</span><br><span class="line">    vectorstore=vectorstore,</span><br><span class="line">    docstore=store,</span><br><span class="line">    id_key=id_key,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add texts</span></span><br><span class="line">doc_ids = [<span class="built_in">str</span>(uuid.uuid4()) <span class="keyword">for</span> _ <span class="keyword">in</span> texts]</span><br><span class="line">summary_texts = [</span><br><span class="line">    Document(page_content=s, metadata=&#123;id_key: doc_ids[i]&#125;)</span><br><span class="line">    <span class="keyword">for</span> i, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(text_summaries)</span><br><span class="line">]</span><br><span class="line">retriever.vectorstore.add_documents(summary_texts)</span><br><span class="line">retriever.docstore.mset(<span class="built_in">list</span>(<span class="built_in">zip</span>(doc_ids, texts)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add tables</span></span><br><span class="line">table_ids = [<span class="built_in">str</span>(uuid.uuid4()) <span class="keyword">for</span> _ <span class="keyword">in</span> tables]</span><br><span class="line">summary_tables = [</span><br><span class="line">    Document(page_content=s, metadata=&#123;id_key: table_ids[i]&#125;)</span><br><span class="line">    <span class="keyword">for</span> i, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(table_summaries)</span><br><span class="line">]</span><br><span class="line">retriever.vectorstore.add_documents(summary_tables)</span><br><span class="line">retriever.docstore.mset(<span class="built_in">list</span>(<span class="built_in">zip</span>(table_ids, tables)))</span><br></pre></td></tr></table></figure>
<h3 id="4-问答时自动检索"><a class="markdownIt-Anchor" href="#4-问答时自动检索"></a> 4. 问答时自动检索</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.runnables <span class="keyword">import</span> RunnablePassthrough</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prompt template</span></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;Answer the question based only on the following context, which can include text and tables:</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">Question: &#123;question&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">prompt = ChatPromptTemplate.from_template(template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># LLM</span></span><br><span class="line">model = ChatOpenAI(temperature=<span class="number">0</span>, model=<span class="string">&quot;gpt-4&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># RAG pipeline</span></span><br><span class="line">chain = (</span><br><span class="line">    &#123;<span class="string">&quot;context&quot;</span>: retriever, <span class="string">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class="line">    | prompt</span><br><span class="line">    | model</span><br><span class="line">    | StrOutputParser()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run the chain</span></span><br><span class="line">chain.invoke(<span class="string">&quot;What is the number of training tokens for LLaMA2?&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<ol>
<li><code>langchain</code> 做了非常多的工具，并给出一种将这些工具非常容易组合使用的方法</li>
<li>更重要的是，<code>langsmith</code> 提供了非常方便的 <code>trace</code> 功能，可以非常方便地追踪一次问答过程中经过了哪些模型/工具/行为，以及这些模型/工具/行为的 <code>input</code> / <code>output</code> / 耗时等，非常方便</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/07/21/Qwen2-5-VL-Technical-Report/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/07/21/Qwen2-5-VL-Technical-Report/" class="post-title-link" itemprop="url">Qwen2.5-VL Technical Report</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-07-21 10:47:30" itemprop="dateCreated datePublished" datetime="2025-07-21T10:47:30+08:00">2025-07-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/VLM/" itemprop="url" rel="index"><span itemprop="name">VLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/07/21/Qwen2-5-VL-Technical-Report/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/07/21/Qwen2-5-VL-Technical-Report/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.13923">https://arxiv.org/pdf/2502.13923</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen2.5-VL">https://github.com/QwenLM/Qwen2.5-VL</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>Qwen2.5-VL</code> 是 <code>Qwen</code> 团队推出的一个多模态大模型，在 <code>Qwen2.5</code> 的基础上，增加了视觉模态的支持，输入支持 <code>text</code> 和 <code>image</code> 和 <code>video</code> 的混合输入，输出为 <code>text</code></li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2025/07/21/BYQy9KAc4oCdSJX.png" alt="qwen2.5-vl.png" /></p>
<h3 id="模型架构"><a class="markdownIt-Anchor" href="#模型架构"></a> 模型架构</h3>
<ul>
<li>视觉编码器（<code>Vision Encoder</code>）：基于重新设计的 <code>Vision Transformer</code>（<code>ViT</code>），处理原生分辨率的图像和视频输入</li>
<li>语言模型（<code>Large Language Model</code>，<code>LLM</code>）：基于 <code>Qwen2.5</code> <code>LLM</code>，负责文本理解和生成，初始化时预训练权重被微调以支持多模态任务</li>
<li>视觉-语言合并器（<code>Vision-Language Merger</code>）：一个 <code>MLP-based</code> 模块，压缩视觉特征以匹配文本嵌入维度，减少计算开销</li>
</ul>
<h3 id="三阶段训练"><a class="markdownIt-Anchor" href="#三阶段训练"></a> 三阶段训练</h3>
<h4 id="第一阶段"><a class="markdownIt-Anchor" href="#第一阶段"></a> 第一阶段</h4>
<ul>
<li>随机初始化 <code>Vision Encoder</code> 开始训练</li>
<li>使用的 <code>(text, image)</code> 数据如下：
<ul>
<li><code>Image captions</code>：图像和对应的文本描述</li>
<li><code>Visual knowledge</code>: 涵盖名人、地标、动植物等识别数据，帮助模型积累视觉常识</li>
<li><code>OCR</code> 数据：从图像中提取的文本信息</li>
</ul>
</li>
<li>用了 <code>CLIP</code> 作为优化目标，对齐 <code>ViT</code> 和 <code>Qwen2.5</code> 的 <code>text</code> 模态</li>
<li><code>token</code> 长度为 <code>8k</code>，数据规模为 <code>1.5T tokens</code></li>
</ul>
<h4 id="第二阶段"><a class="markdownIt-Anchor" href="#第二阶段"></a> 第二阶段</h4>
<ul>
<li><code>ViT</code> 和 <code>Qwen2.5</code> 的联合预训练</li>
<li><code>token</code> 长度为 <code>8k</code>，数据规模为 <code>2T tokens</code></li>
</ul>
<h4 id="第三阶段"><a class="markdownIt-Anchor" href="#第三阶段"></a> 第三阶段</h4>
<ul>
<li>长上下文优化，目标是视频/文档序列理解</li>
<li><code>token</code> 长度为 <code>32k</code>，数据规模为 <code>0.6T tokens</code></li>
</ul>
<h3 id="关键技术解析"><a class="markdownIt-Anchor" href="#关键技术解析"></a> 关键技术解析</h3>
<h4 id="1-动态-vit-架构"><a class="markdownIt-Anchor" href="#1-动态-vit-架构"></a> 1. 动态 <code>ViT</code> 架构</h4>
<ul>
<li>输入尺寸自适应：图像按 <code>14×14</code> 分块，尺寸调整为 <code>28</code> 的倍数</li>
<li>窗口注意力：<code>32</code> 层中仅 <code>4</code> 层用全局注意力，其余用 <code>112×112</code> 窗口注意力（计算复杂度从 <code>O(n²)</code> 降至 <code>O(n)</code>）</li>
<li>位置编码：<code>2D</code> 旋转位置嵌入（<code>RoPE</code>）保留空间关系</li>
</ul>
<h4 id="2-多模态动态处理"><a class="markdownIt-Anchor" href="#2-多模态动态处理"></a> 2. 多模态动态处理</h4>
<ul>
<li>空间维度：
<ul>
<li>原生分辨率坐标：直接使用图像实际尺寸表示物体位置（非相对坐标）</li>
<li>支持 <code>JSON/XML</code> 格式输出，兼容开放词汇检测（<code>10,000+</code> 类别）</li>
</ul>
</li>
<li>时间维度：
<ul>
<li>动态帧率采样：适应不同速度的视频内容</li>
<li>绝对时间对齐：<code>RoPE</code> 时间 <code>ID</code> 与时间戳直接绑定，理解事件节奏（图1机制）</li>
</ul>
</li>
</ul>
<h4 id="3-多模态位置编码mrope"><a class="markdownIt-Anchor" href="#3-多模态位置编码mrope"></a> 3. 多模态位置编码（<code>MRoPE</code>）​</h4>
<ul>
<li>三维分解：时间、高度、宽度独立位置 <code>ID</code></li>
<li>视频处理：时间 <code>ID</code> 按帧递增，空间 <code>ID</code> 与静态图像一致</li>
<li>升级点：时间 <code>ID</code> 关联绝对时间戳，解决 <code>Qwen2-VL</code> 的时序理解局限</li>
</ul>
<h3 id="性能"><a class="markdownIt-Anchor" href="#性能"></a> 性能</h3>
<ul>
<li>共有 <code>3B / 7B / 72B</code> 三个尺寸<br />
<img src="https://s2.loli.net/2025/07/21/2tXRI65vpe9wcUH.png" alt="qwen2.5-vl_2.png" /></li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li><code>VLM</code> 将视觉信息融入语言模态，重点还是 <code>LM</code></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/07/15/Dynamic-Chunking-for-End-to-End-Hierarchical-Sequence-Modeling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/07/15/Dynamic-Chunking-for-End-to-End-Hierarchical-Sequence-Modeling/" class="post-title-link" itemprop="url">Dynamic Chunking for End-to-End Hierarchical Sequence Modeling</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-07-15 15:23:27" itemprop="dateCreated datePublished" datetime="2025-07-15T15:23:27+08:00">2025-07-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/SSM/" itemprop="url" rel="index"><span itemprop="name">SSM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/07/15/Dynamic-Chunking-for-End-to-End-Hierarchical-Sequence-Modeling/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/07/15/Dynamic-Chunking-for-End-to-End-Hierarchical-Sequence-Modeling/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.07955">https://arxiv.org/pdf/2507.07955</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/goombalab/hnet">https://github.com/goombalab/hnet</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>标题是 “用于端到端分层序列建模的动态分块” ，实际上包含了不少信息量：
<ul>
<li>“端到端”：意味着 <code>token free</code>，真正的端到端语言模型，输入输出都是字节流，不需要 <code>tokenization</code> 过程</li>
<li>“分层”：意味着 <code>H-Net</code> 模型结构是 <strong>递归</strong> 的，<code>H-Net</code> 模型由 <code>encoder</code> + <code>main network</code> + <code>decoder</code> 组成，其中 <code>main network</code> 还可以是 <code>H-Net</code> 模型</li>
<li>“动态分块”：意味着 <code>H-Net</code> 模型可以动态地调整 <code>chunk</code> 的大小，可以理解为维护了一个隐式的动态 <code>tokenizer</code>，模型会在学习过程中找到最优的隐式分词方法</li>
</ul>
</li>
<li>本质是一个基于 <code>SSM + Transformer</code> 结构的大模型，抛弃了 <code>tokenization</code> 过程，直接在字节流上进行训练和推理</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="h-net-总体结构"><a class="markdownIt-Anchor" href="#h-net-总体结构"></a> H-Net 总体结构</h3>
<p><img src="https://s2.loli.net/2025/07/15/l7re8zg3QYXJEq6.png" alt="hnet.png" /></p>
<h3 id="现有的分词机制的缺陷"><a class="markdownIt-Anchor" href="#现有的分词机制的缺陷"></a> 现有的分词机制的缺陷</h3>
<ul>
<li>当前主流语言模型（如 <code>ChatGPT</code> ）依赖预定义的分词器（如 <code>BPE</code> ），存在以下问题：
<ul>
<li>语义割裂​​：分词器基于统计规则，无法根据上下文动态调整边界（如将 “product” 错误拆分为 “pro-duct” ）</li>
<li>跨语言/模态适配性差​​：在中文、代码或 <code>DNA</code> 序列等缺乏显式分隔符的领域表现不佳</li>
</ul>
</li>
<li>直接字节级建模（如 <code>MambaByte</code> ），计算开销巨大，且性能低于分词模型</li>
<li>一些启发式分块规则（如 <code>MegaByte</code> 和 <code>SpaceByte</code>）依赖​​启发式分块规则​​（如固定步长或空格分隔），无法学习数据驱动的分块策略，限制了模型对复杂信息的表达能力</li>
</ul>
<h3 id="h-net-的解决方案"><a class="markdownIt-Anchor" href="#h-net-的解决方案"></a> H-Net 的解决方案</h3>
<h4 id="层级化处理架构u-net-式设计"><a class="markdownIt-Anchor" href="#层级化处理架构u-net-式设计"></a> 层级化处理架构（<code>U-Net</code> 式设计）​​</h4>
<ul>
<li>三级模块
<ul>
<li>编码器（<code>E</code>）​​：处理原始字节（小规模 <code>SSM</code> 层，高效捕获细粒度特征）</li>
<li>主网络（<code>M</code>）​​：处理压缩后的语义块（大规模 <code>Transformer</code> 层，学习高层抽象）</li>
<li>解码器（<code>D</code>）​​：恢复原始分辨率（<code>SSM</code> 层）</li>
</ul>
</li>
<li>递归扩展​​：主网络可嵌套 <code>H-Net</code> 自身，形成多级抽象（如字符 → 词 → 短语）</li>
</ul>
<h4 id="encoder-network"><a class="markdownIt-Anchor" href="#encoder-network"></a> Encoder Network</h4>
<ol>
<li>路由模块（<code>Routing Module</code>）
<ul>
<li>用相邻向量的余弦相似度判断是否需要分块</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>t</mi></msub><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>k</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_t=\frac{1}{2}(1-sim(q_t,k_{t-1}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> 表示 <code>position</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 表示 <code>query</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 表示 <code>key</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>i</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">sim</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span></span></span></span> 表示余弦相似度</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">p_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示当前位置分块概率</li>
</ul>
</li>
<li>当相邻向量语义变化大时，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">p_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 会趋近于 1，表示需要分块</li>
</ul>
</li>
<li>下采样模块（<code>Downsampler</code>）
<ul>
<li>将上一步分块的序列下采样</li>
<li>具体使用的下采样方式是 <strong>只保留路由模块选定的边界向量</strong>，其他向量直接丢弃</li>
</ul>
</li>
</ol>
<h4 id="main-network"><a class="markdownIt-Anchor" href="#main-network"></a> Main Network</h4>
<ul>
<li>一个最常见的 <code>Transformer</code> 结构</li>
<li>输入是 <code>Encoder Network</code> 输出的下采样后的向量</li>
<li>输出和输入的 <code>shape</code> 相同</li>
</ul>
<h4 id="decoder-network"><a class="markdownIt-Anchor" href="#decoder-network"></a> Decoder Network</h4>
<ol>
<li>平滑模块（<code>Smoothing Module</code>）
<ul>
<li>用指数移动平均法解决离散决策的梯度不可导问题</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>z</mi><mo>ˉ</mo></mover><mi>t</mi></msub><mo>=</mo><mi>P</mi><mo>⋅</mo><msub><mover accent="true"><mi>z</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>P</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><msub><mover accent="true"><mi>z</mi><mo>ˉ</mo></mover><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\bar z_t=P\cdot \hat z_{t-1}+(1-P_t)\cdot \bar z_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.71778em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.776111em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">P_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示当前位置分块概率</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>z</mi><mo>^</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\hat z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示主网络输出的压缩向量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>z</mi><mo>ˉ</mo></mover><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\bar z_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.776111em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 表示上一步平滑后的向量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>z</mi><mo>ˉ</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\bar z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.71778em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示平滑后的向量</li>
</ul>
</li>
</ul>
</li>
<li>上采样模块（<code>Upsampler</code>）<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>c</mi><mi>t</mi></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.15999999999999992em" columnalign="left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>p</mi><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mi>b</mi><mi>t</mi></msub><mo>=</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo>−</mo><msub><mi>p</mi><mi>t</mi></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mi>b</mi><mi>t</mi></msub><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">c_t=\left\{
\begin{array}{l}
p_t &amp; \text{if}\ b_t=1 \\
1- p_t &amp; \text{if}\ b_t=0
\end{array}
\right.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">{</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">if</span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">1</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">if</span></span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>Upsampler</mtext><mi>t</mi></msub><mo>=</mo><mi>S</mi><mi>T</mi><mi>E</mi><mo stretchy="false">(</mo><msub><mi>c</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><msub><mover accent="true"><mi>z</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\text{Upsampler}_t = STE(c_t)\cdot \tilde z_t
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93858em;vertical-align:-0.24414em;"></span><span class="mord"><span class="mord text"><span class="mord">Upsampler</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.18641599999999994em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8178599999999999em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">b_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示当前位置是否分块，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>t</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">b_t=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 表示分块，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>t</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">b_t=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> 表示不分块</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">p_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示当前位置分块概率</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">c_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示当前位置 <code>main network</code> <strong>输出的置信度</strong></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>z</mi><mo>~</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\tilde z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8178599999999999em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示当前位置 <code>main network</code> 输出的向量 <strong>复制到原始分辨率</strong></li>
</ul>
</li>
</ol>
<h3 id="效果"><a class="markdownIt-Anchor" href="#效果"></a> 效果</h3>
<ul>
<li>效果比 <code>tokenization</code> 更好</li>
<li>在语言、代码、DNA等异构数据中验证普适性，为多模态基础模型提供新范式</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>能看出 <code>SSM</code> 模型已经开始改变战略，从正面和 <code>Transformer</code> 硬刚到 <strong>曲线救国</strong></li>
<li><code>STE</code> 真是个万金油，哪哪都有它</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/07/13/CacheBlend-Fast-Large-Language-Model-Serving-for-RAG-with-Cached-Knowledge-Fusion/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/07/13/CacheBlend-Fast-Large-Language-Model-Serving-for-RAG-with-Cached-Knowledge-Fusion/" class="post-title-link" itemprop="url">CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-07-13 15:33:34" itemprop="dateCreated datePublished" datetime="2025-07-13T15:33:34+08:00">2025-07-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/RAG/" itemprop="url" rel="index"><span itemprop="name">RAG</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/07/13/CacheBlend-Fast-Large-Language-Model-Serving-for-RAG-with-Cached-Knowledge-Fusion/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/07/13/CacheBlend-Fast-Large-Language-Model-Serving-for-RAG-with-Cached-Knowledge-Fusion/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.16444">https://arxiv.org/pdf/2405.16444</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/LMCache/LMCache">https://github.com/LMCache/LMCache</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一种新的缓存利用机制 <code>CacheBlend</code>，旨在解决 <code>RAG</code> 系统中知识 <code>KV Cache</code> 的可用性，通过一种稀疏近似的方式平衡速度和准确性。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="知识注入的两种常见方式"><a class="markdownIt-Anchor" href="#知识注入的两种常见方式"></a> 知识注入的两种常见方式</h3>
<h4 id="1-微调"><a class="markdownIt-Anchor" href="#1-微调"></a> 1. 微调</h4>
<ul>
<li>收集知识库中的文档数据，微调模型，使其能够在生成文本时利用这些知识。</li>
<li>优点：推理时不会有额外的延迟。</li>
<li>缺点：
<ol>
<li>动态更新困难</li>
<li>模块化困难（无法要求模型使用哪些知识，不用哪些知识）</li>
</ol>
</li>
</ul>
<h4 id="2-知识检索"><a class="markdownIt-Anchor" href="#2-知识检索"></a> 2. 知识检索</h4>
<ul>
<li>在推理时，检索相关文档并将其作为上下文输入到模型中。</li>
<li>优点：动态更新知识库，模块化。</li>
<li>缺点：推理时需要额外的延迟，一是因为检索本身的延迟，二是因为模型需要计算额外的上下文注意力。</li>
</ul>
<h3 id="如何同时解决模块化和速度的问题"><a class="markdownIt-Anchor" href="#如何同时解决模块化和速度的问题"></a> 如何同时解决模块化和速度的问题？</h3>
<ul>
<li>如果在知识检索技术的基础上，检索系统提前缓存了 <strong>知识库中文档对应的 <code>KV Cache</code></strong>，那么就可以在推理时直接使用这些 <code>KV Cache</code> 无需计算这部分的注意力（只需要检索延迟）。</li>
</ul>
<h3 id="这样做有什么问题"><a class="markdownIt-Anchor" href="#这样做有什么问题"></a> 这样做有什么问题？</h3>
<ul>
<li>一个很重要的问题是：优于现如今绝大多数 <code>LLM</code> 的 <code>decoder only</code> 架构，缓存的知识库的 <code>KV Cache</code> 必须作为 <code>prefix</code> 注入到模型中，且只能用一个，否则模型无法利用这些知识。</li>
<li>例如：
<ul>
<li>记检索到的文档的 <code>KV Cache</code> 为 <code>A</code>，历史对话信息和用户输入为 <code>B</code></li>
<li>那么模型的输入应该是 <code>A + B</code>，而不是 <code>B + A</code></li>
<li>因为 <code>KV Cache</code> 位置 <code>i</code> 的值依赖于 <code>0 ~ i-1</code> 位置的值，如果不作为 <code>prefix</code> 注入，那么模型无法利用这些知识。</li>
</ul>
</li>
</ul>
<p><img src="https://s2.loli.net/2025/07/13/m6c3r9KLCEgIdJY.png" alt="cacheblend_2.png" /><br />
<img src="https://s2.loli.net/2025/07/13/vai4cwZmEIR1sSJ.png" alt="cacheblend_3.png" /></p>
<h3 id="cacheblend-想要解决的问题"><a class="markdownIt-Anchor" href="#cacheblend-想要解决的问题"></a> CacheBlend 想要解决的问题</h3>
<ul>
<li><code>CacheBlend</code> 目的就是为了 <strong>解决 <code>RAG</code> 系统中知识 <code>KV Cache</code> 只能作为 <code>prefix</code> 注入的问题</strong></li>
<li><code>CacheBlend</code> 做不到和完全重新计算数学上等价，只能是近似</li>
<li>原理本质上讲是平衡，即 <strong>在完全重新计算 <code>KV Cache</code> 和完全使用缓存的 <code>KV Cache</code> 之间进行平衡</strong>，如下图：</li>
</ul>
<p><img src="https://s2.loli.net/2025/07/13/D1MyroxV3ZhLUlk.png" alt="cacheblend.png" /></p>
<h3 id="cacheblend-的解决方案"><a class="markdownIt-Anchor" href="#cacheblend-的解决方案"></a> CacheBlend 的解决方案</h3>
<p><img src="https://s2.loli.net/2025/07/13/NbGWP4zluwV8tOm.png" alt="cacheblend_4.png" /></p>
<ul>
<li><code>CacheBlend</code> 通过 <strong>稀疏近似</strong> 的方式，平衡速度和准确性，具体来说，对非 <code>prefix</code> 的 <code>KV Cache</code>，做：
<ol>
<li>第 <code>1</code> 层​​：计算所有 <code>Token</code> 的 <code>KV</code> 偏差，选择 <code>Top 20%</code> 作为候选 <code>HKVD (High-KV-Deviation) Token</code></li>
<li>​后续层​​：仅对前一层的 <code>HKVD Token</code> 计算偏差，从中选择 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>o</mi><mi>p</mi><mtext> </mtext><msub><mi>r</mi><mi>i</mi></msub><mi mathvariant="normal">%</mi><mtext> </mtext><mo stretchy="false">(</mo><msub><mi>r</mi><mi>i</mi></msub><mo>&lt;</mo><msub><mi>r</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Top\ r_i\%\  (r_i &lt; r_{i-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">o</span><span class="mord mathnormal">p</span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">%</span><span class="mspace"> </span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 作为当前层 <code>HKVD Token</code></li>
<li>​​终止​​：最终每层仅更新约 <code>10-15% Token</code>，偏差显著降低</li>
</ol>
</li>
<li>总体上就是用逐层用新的 <code>KV Cache</code> 替换旧的 <code>KV Cache</code>，替换依据是 <code>KV</code> 偏差，偏差越大的 <code>Token</code> 替换的优先级越高。</li>
</ul>
<h3 id="cacheblend-的优势"><a class="markdownIt-Anchor" href="#cacheblend-的优势"></a> CacheBlend 的优势</h3>
<ul>
<li><strong>质量保障</strong>​​：仅更新 <code>10-15% Token</code> 即可达到 <code>Full KV Recompute</code> 的质量（<code>F1/Rouge-L</code> 偏差 <code>&lt;0.02</code>）</li>
<li><strong>​​延迟隐藏</strong>​​：<code>KV</code> 重新计算与 <code>KV</code> 缓存加载流水线并行，使额外延迟近乎为零</li>
<li>​<strong>提速</strong>​​：<code>TTFT (Time To First Token)</code> 降低 <code>2.2 ~ 3.3</code> 倍，吞吐量提升 <code>2.8 ~ 5</code> 倍</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>稀疏无处不在</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/07/04/Toolformer-Language-Models-Can-Teach-Themselves-to-Use-Tools/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/07/04/Toolformer-Language-Models-Can-Teach-Themselves-to-Use-Tools/" class="post-title-link" itemprop="url">Toolformer: Language Models Can Teach Themselves to Use Tools</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-07-04 19:46:11" itemprop="dateCreated datePublished" datetime="2025-07-04T19:46:11+08:00">2025-07-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Agent/" itemprop="url" rel="index"><span itemprop="name">Agent</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/07/04/Toolformer-Language-Models-Can-Teach-Themselves-to-Use-Tools/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/07/04/Toolformer-Language-Models-Can-Teach-Themselves-to-Use-Tools/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2302.04761">https://arxiv.org/pdf/2302.04761</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>大模型并不是全能的，大模型 + 工具可以更好地解决问题，本文提出一种新的训练方法，让大模型可以自我学习使用如何工具。</li>
<li>本文的主要贡献是提出了一种新的训练方法，包括通过大模型构造工具调用数据集、清洗数据集、使用工具调用数据集微调大模型。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="toolformer-的意义"><a class="markdownIt-Anchor" href="#toolformer-的意义"></a> ToolFormer 的意义</h3>
<ol>
<li>众所周知，大模型在很多任务上表现出色，但它们并不是全能的，比如去数 “strawberry” 这个单词中有多少个 “r”。</li>
<li>工具可以帮助大模型更好地解决问题，比如计算器、日历、知识库等。</li>
<li>一种常见的大模型和工具结合的方式是：通过 <code>Agent</code> <strong>多角色（user / llm / function）多轮对话</strong> 形式调用，简单来说就是：
<ol>
<li>大模型在需要调用工具的时候，输出一段特定格式的文本</li>
<li>外部程序解析这段文本，调用相应的工具，调用得到结果</li>
<li>新的结果作为 <code>Function</code> 角色的输入，继续和大模型对话</li>
</ol>
</li>
<li>而 <code>ToolFormer</code> 采用的方式和 <code>Agent</code> 有相似之处，也有不同的地方：
<ul>
<li>相似点：
<ol>
<li>都需要大模型输出一段特定格式的文本来调用工具</li>
<li>都需要一段 <code>endless loop</code> 程序来解析大模型的输出，调用工具</li>
</ol>
</li>
<li>不同点：
<ol>
<li><code>ToolFormer</code> 不是通过 <strong>多角色多轮对话</strong> 的方式调用工具，而是通过 <strong>单角色单轮对话</strong> 的方式调用工具</li>
<li><code>ToolFormer</code> 需要对大模型进行 <strong>微调</strong>，而 <code>Agent</code> 不需要</li>
</ol>
</li>
</ul>
</li>
<li><code>ToolFormer</code> 可以将存在确定答案的 <strong>专用</strong> 任务转化为工具调用任务（例如：计算、翻译、问答等），让大模型可以更专注在 <strong>通用</strong> 任务上（例如：上下文理解、常识知识运用等）。</li>
</ol>
<h3 id="toolformer-的工作方式"><a class="markdownIt-Anchor" href="#toolformer-的工作方式"></a> ToolFormer 的工作方式</h3>
<ol>
<li><code>ToolFormer</code> 是经过工具调用微调的大模型，知道有哪些工具可以调用，也知道如何调用这些工具。</li>
<li>假设模型输入的问题是：<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pittsburgh <span class="keyword">is</span> <span class="keyword">also</span> known <span class="keyword">as</span></span><br></pre></td></tr></table></figure>
</li>
<li>这个时候，模型会意识到这个问题可以通过调用 <code>Question Answering</code> 工具来解决，于是模型会续写：<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pittsburgh <span class="keyword">is</span> <span class="keyword">also</span> known <span class="keyword">as</span> &lt;API&gt;QA(Pittsburgh <span class="keyword">is</span> <span class="keyword">also</span> known <span class="keyword">as</span>)&lt;/API&gt;</span><br></pre></td></tr></table></figure>
</li>
<li>输出 <code>&lt;/API&gt;</code> 之后，推理进程会暂停推理模型，等待外部监听程序的调用结束。</li>
<li>外部监听程序会解析模型输出文本中的工具调用指令（通过 <code>&lt;API&gt; &lt;/API&gt;</code> 格式），然后调用 <code>Question Answering</code> 工具，得到结果：<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">the Steel City</span></span><br></pre></td></tr></table></figure>
</li>
<li>推理程序将工具调用结果和模型的历史输出（去掉调用相关信息）拼接起来，继续推理模型：<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pittsburgh <span class="keyword">is</span> <span class="keyword">also</span> known <span class="keyword">as</span> the Steel City.</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="应该怎么得到-toolformer"><a class="markdownIt-Anchor" href="#应该怎么得到-toolformer"></a> 应该怎么得到 ToolFormer</h3>
<ol>
<li>假设上面提到的 <code>ToolFormer</code> 工作方式是一个愿景，那么接下来就是考虑应该如何得到一个这样的模型。</li>
<li>显然，直接拿一个预训练或经过微调的大模型来使用是行不通的，因为它并不知道哪些工具可以用，以及如何调用。</li>
<li>那么需要做的事就是：<strong>通过微调，让大模型自己学习如何使用工具</strong></li>
<li>最困难的部分就是：<strong>如何构造工具调用数据集</strong>，因为不存在现成的工具调用数据集，需要自己构造。</li>
<li>这篇论文花了很大的篇幅就在讲一件事：<strong>如何用大模型来构造工具调用数据集</strong></li>
</ol>
<h3 id="如何构造工具调用数据集"><a class="markdownIt-Anchor" href="#如何构造工具调用数据集"></a> 如何构造工具调用数据集</h3>
<p><img src="https://s2.loli.net/2025/07/07/6cHrSKzkAD7agLl.png" alt="toolformer_1.png" /></p>
<blockquote>
<p>上面这张图展示了如何用大模型来构造工具调用数据集的流程。</p>
</blockquote>
<ol>
<li>首先，还是用预训练数据做为基础，假设一条预训练数据是：<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pittsburgh <span class="keyword">is</span> <span class="keyword">also</span> known <span class="keyword">as</span> the Steel City.</span><br></pre></td></tr></table></figure>
</li>
<li>然后，使用大模型（例如：GPT-3）来在数据中找到可以调用工具的位置和工具类型，并给出调用工具的参数，例如：<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pittsburgh <span class="keyword">is</span> also known <span class="keyword">as</span> &lt;API&gt;QA<span class="function"><span class="params">(What other name <span class="keyword">is</span> Pittsburgh known <span class="keyword">by</span>?)</span> -&gt;</span> Steel City&lt;/API&gt; the Steel City.</span><br></pre></td></tr></table></figure>
<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pittsburgh <span class="keyword">is</span> also known <span class="keyword">as</span> &lt;API&gt;QA<span class="function"><span class="params">(Which country <span class="keyword">is</span> Pittsburgh <span class="keyword">in</span>?)</span> -&gt;</span> United States&lt;/API&gt; the Steel City.</span><br></pre></td></tr></table></figure>
</li>
<li>计算调用工具带来的损失收益，剔除负收益的数据，保留正收益的数据。
<ul>
<li>损失的计算方式（离调用工具位置越远，损失权重 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>j</mi><mo>−</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{j-i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 越小）：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>i</mi></mrow><mi>n</mi></munderover><msub><mi>w</mi><mrow><mi>j</mi><mo>−</mo><mi>i</mi></mrow></msub><mo>⋅</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>M</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><mi>z</mi><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo separator="true">;</mo><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_i(z) = -\sum_{j=i}^n w_{j-i}\cdot \log p_M(x_j|z,x_{i;j-1})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0651740000000007em;vertical-align:-1.4137769999999998em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000007em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">;</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li>调用工具的损失：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>L</mi><mi>i</mi><mo>+</mo></msubsup><mo>=</mo><msub><mi>L</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>e</mi><mo stretchy="false">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>r</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_i^+=L_i(e(c_i,r_i))
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.088326em;vertical-align:-0.266995em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213309999999999em;"><span style="top:-2.433005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.266995em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li>不调用工具 / 调用工具没有返回的损失：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>L</mi><mi>i</mi><mo>−</mo></msubsup><mo>=</mo><mi>min</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>L</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>ϵ</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>L</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>e</mi><mo stretchy="false">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>ϵ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_i^- = \min(L_i(\epsilon),L_i(e(c_i,\epsilon)))
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.088326em;vertical-align:-0.266995em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213309999999999em;"><span style="top:-2.433005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.266995em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">min</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li>只保留调用工具损失收益大于阈值的样本：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>L</mi><mi>i</mi><mo>−</mo></msubsup><mo>−</mo><msubsup><mi>L</mi><mi>i</mi><mo>+</mo></msubsup><mo>&gt;</mo><msub><mi>τ</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">L_i^- - L_i^+ &gt; \tau_f
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.088326em;vertical-align:-0.266995em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213309999999999em;"><span style="top:-2.433005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.266995em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.088326em;vertical-align:-0.266995em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213309999999999em;"><span style="top:-2.433005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.266995em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.1132em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></span></p>
</li>
<li>用筛选后的数据来微调大模型，得到 <code>ToolFormer</code>。</li>
</ol>
<p><img src="https://s2.loli.net/2025/07/07/8UkSBFT5zjZbCe3.png" alt="toolformer_2.png" /></p>
<ul>
<li>上图展示了 <code>ToolFormer</code> 支持的五种工具类型：
<ol>
<li><code>Question Answering</code>：问答工具</li>
<li><code>Wikipedia Search</code>：维基百科搜索工具</li>
<li><code>Calculator</code>：计算器工具</li>
<li><code>Calendar</code>：日历工具</li>
<li><code>Machine Translation</code>：机器翻译工具</li>
</ol>
</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li><code>ToolFormer</code> 这种通过大模型自我学习使用工具的方式感觉挺好的，但似乎在实际使用中没有得到大范围推广，目前主流外挂工具的方式基本还是 <code>Agent</code> 的多角色多轮对话方式。</li>
<li>可能是因为 <code>ToolFormer</code> 的方式需要对大模型进行微调，而 <code>Agent</code> 的方式不需要做工具适配微调，直接使用原模型就可以。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/07/04/ReAct-Synergizing-Reasoning-and-Acting-in-Language-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/07/04/ReAct-Synergizing-Reasoning-and-Acting-in-Language-Models/" class="post-title-link" itemprop="url">ReAct: Synergizing Reasoning and Acting in Language Models</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-07-04 15:35:30" itemprop="dateCreated datePublished" datetime="2025-07-04T15:35:30+08:00">2025-07-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Agent/" itemprop="url" rel="index"><span itemprop="name">Agent</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/07/04/ReAct-Synergizing-Reasoning-and-Acting-in-Language-Models/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/07/04/ReAct-Synergizing-Reasoning-and-Acting-in-Language-Models/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2210.03629">https://arxiv.org/pdf/2210.03629</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/ysymyth/ReAct">https://github.com/ysymyth/ReAct</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>人类通过语言推理（分解目标、调整计划）与行动（获取外部信息）的​​协同机制​​高效完成任务（如烹饪时动态调整步骤）。</li>
<li>受到人类智能启发，本文提出一种 <code>Reasoning</code> 和 <code>Acting</code> 相结合的框架，称为 <code>ReAct</code>，这种新的推理范式可以使语言模型在复杂任务中表现更好。</li>
<li>主要优势包括：
<ul>
<li><strong>事实性</strong>：减少模型幻觉（虚构信息）。</li>
<li><strong>决策鲁棒性</strong>：增强模型在复杂环境中的泛化能力。</li>
<li><strong>可解释性</strong>：人类可以追踪模型的推理轨迹。</li>
</ul>
</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="react-框架"><a class="markdownIt-Anchor" href="#react-框架"></a> ReAct 框架</h3>
<p><img src="https://s2.loli.net/2025/07/04/RZwUfVm3oxDlABc.png" alt="ReACT.png" /></p>
<ul>
<li>纯推理模型（如 <code>Chain-of-Thought</code>）​​：易产生事实幻觉（如虚构信息）和错误传播（如算术推理错误），缺乏实时环境交互能力（图 <code>1b</code>）。</li>
<li>​​纯行动模型（如 <code>WebGPT</code>）​​：缺乏高层规划能力，难以处理多步决策（图<code>1c</code>）。</li>
<li><code>ReAct</code> 模型：交替进行推理和行动，能够在复杂任务中表现更好（图 <code>1d</code>）。</li>
</ul>
<h3 id="核心贡献"><a class="markdownIt-Anchor" href="#核心贡献"></a> 核心贡献​​</h3>
<ul>
<li>首提协同框架​​：统一推理与行动，解决静态推理与无规划行动的缺陷。</li>
<li>实践价值​​：
<ul>
<li>提升模型​​事实性​​（减少幻觉）与​​决策鲁棒性​​（复杂环境泛化）。</li>
<li>增强​​可解释性​​：人类可追踪推理轨迹。</li>
</ul>
</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>论文提出的算法一眼开门，非常符合直觉，从哲学角度讲，一个事物的超集一般都优于其本身，因为最差的情况就是超集退化为本身（因此常见的一个情况是：新的论文称一篇老的论文是其某个参数设置下的一个特例）。</li>
<li>这些所有的 <code>Reasoning</code> 和 <code>Acting</code> 等 <code>Agent</code> 功能，都建立在大模型超长上下文的基础上，因此模型支持超长上下文长度是模型是否具有高级智能潜质的先决条件（至少现有范式是这样）。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/07/01/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/07/01/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models/" class="post-title-link" itemprop="url">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-07-01 11:16:29" itemprop="dateCreated datePublished" datetime="2025-07-01T11:16:29+08:00">2025-07-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/07/01/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/07/01/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2201.11903">https://arxiv.org/pdf/2201.11903</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文是 <code>Google Research</code> 团队发表的一篇论文，这篇论文是在已开源的 <strong>非推理</strong> 模型上，不做微调，而是通过 <code>Chain-of-Thought Prompting</code> 的方式来引导模型进行推理，取得了很好的效果。</li>
<li>具体来说，就是在输入 <code>prompt</code> 中加入少量的 <strong>输入-思维链-输出</strong> 三元组示例，引导模型生成中间推理步骤，最终给出答案。</li>
<li>在算术、常识和符号推理等任务上，<code>Chain-of-Thought Prompting</code> 的效果都非常好，比直接给出答案的效果好很多。</li>
<li><code>Chain-of-Thought Prompting</code> 是在模型规模达到一定程度（<code>&gt;= 100B</code>）后，才涌现出的能力，小模型没有这个能力。</li>
</ul>
<h2 id="论文详情"><a class="markdownIt-Anchor" href="#论文详情"></a> 论文详情</h2>
<h3 id="1-核心方法思维链提示chain-of-thought-prompting"><a class="markdownIt-Anchor" href="#1-核心方法思维链提示chain-of-thought-prompting"></a> 1. 核心方法：思维链提示（Chain-of-Thought Prompting）</h3>
<ul>
<li>论文提出一种简单方法：在提示（<code>prompt</code>）中提供 <strong>输入-思维链-输出</strong> 的三元组示例，引导大型语言模型生成一系列中间推理步骤（称为 “思维链”），再得出最终答案。</li>
<li>思维链类似于人类逐步推理的过程（例如，解决数学题时先分解步骤：“先计算A，再计算B，最后得出答案”）。</li>
</ul>
<h3 id="2-关键优势"><a class="markdownIt-Anchor" href="#2-关键优势"></a> 2. 关键优势</h3>
<ul>
<li>提升复杂推理能力：在算术（如数学题 <code>GSM8K</code>）、常识（如 <code>CSQA</code>）和符号推理（如字母拼接游戏）任务上，思维链提示显著优于标准提示（<code>standard prompting</code>）。</li>
<li>在 <code>GSM8K</code> 数学题基准上，<code>PaLM 540B</code> 模型使用思维链提示后，准确率从 <code>17.9%</code> 提升至 <code>56.9%</code>，甚至超过微调的 <code>GPT-3</code> 模型。</li>
<li>在常识推理任务（如 <code>StrategyQA</code>）上，准确率从 <code>68.6%</code> 提升至 <code>77.8%</code>。</li>
<li>模型规模涌现特性：思维链推理是大型模型（约 <code>100B</code> 参数以上）的 “涌现能力” —— <strong>小模型无法生成逻辑思维链</strong>，但足够大的模型（如 <code>GPT-3 175B</code>、<code>PaLM 540B</code>）能自然学习此模式。</li>
<li>无需微调：仅需在提示中添加少量示例（如 <code>8</code> 个），即可激发模型能力，无需额外训练或数据标注。</li>
<li>可解释性与泛化性：思维链提供透明推理路径，便于调试；且适用于多种任务（数学、常识、符号等），甚至能泛化到更长序列。</li>
</ul>
<h3 id="3-实验验证"><a class="markdownIt-Anchor" href="#3-实验验证"></a> 3. 实验验证</h3>
<ul>
<li>任务覆盖：
<ul>
<li>算术推理：在 <code>GSM8K</code>、<code>SVAMP</code> 等数据集上，思维链提示将性能提升高达 <code>39%</code>（<code>PaLM 540B</code>）。</li>
<li>常识推理：在 <code>StrategyQA</code>、<code>Date Understanding</code> 等任务上，模型表现接近或超越人类水平。</li>
<li>符号推理：在硬币翻转（<code>coin flip</code>）和字母拼接（<code>last letter concatenation</code>）任务中，模型能处理未见过的长序列。</li>
</ul>
</li>
<li>鲁棒性：不同注释者编写的思维链示例均有效，且对示例顺序、数量变化不敏感。</li>
</ul>
<h3 id="4-局限性与启示"><a class="markdownIt-Anchor" href="#4-局限性与启示"></a> 4. 局限性与启示</h3>
<ul>
<li>模型规模依赖：思维链仅在大型模型（<code>≥100B</code> 参数）中有效，小模型生成逻辑混乱。</li>
<li>潜在错误：生成的推理路径可能不准确（如算术计算错误或语义误解），需外部验证（如添加计算器）。</li>
<li>应用意义：该方法拓展了提示技术的边界，证明大型模型能通过自然语言示例学习复杂推理，减少对标注数据的依赖。</li>
</ul>
<h3 id="论文核心贡献"><a class="markdownIt-Anchor" href="#论文核心贡献"></a> 论文核心贡献</h3>
<ul>
<li>思维链提示是一种低成本、高效的方法，通过模拟人类逐步推理过程，释放大型语言模型在复杂任务上的潜力。论文强调，这是 “模型规模涌现” 的典型例子——推理能力随模型增大而自然出现，为未来 <code>AI</code> 推理研究提供了新方向。</li>
</ul>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>一定要注意，这篇论文讨论的对象 <strong>不是 Reasoning 模型</strong>（这个论文出来的时候还没有 <code>Reasoning</code> 模型的概念），而是普通的 <code>LLM</code> 模型。</li>
<li>本质是一种通过 <code>prompt</code> 引导模型通过增加推理计算预算的方式，来提升模型的推理能力的方法。</li>
<li>依托于 <code>LLM</code> 恐怖的指令遵循和上下文学习能力。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/05/28/Large-Language-Diffusion-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/05/28/Large-Language-Diffusion-Models/" class="post-title-link" itemprop="url">Large Language Diffusion Models</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-05-28 22:19:52" itemprop="dateCreated datePublished" datetime="2025-05-28T22:19:52+08:00">2025-05-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-27 11:31:40" itemprop="dateModified" datetime="2025-10-27T11:31:40+08:00">2025-10-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/05/28/Large-Language-Diffusion-Models/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/05/28/Large-Language-Diffusion-Models/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.09992">https://arxiv.org/pdf/2502.09992</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://ml-gsai.github.io/LLaDA-demo/">https://ml-gsai.github.io/LLaDA-demo/</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>LLaDA</code> 提出了一个新概念，叫 “扩散语言模型”，和主流的自回归语言模型 <code>predict next token</code> 的方式不同，<code>LLaDA</code> 使用类似 <code>Diffusion</code> 去噪的方法，一次性生成多个 <code>token</code>，通过多次生成，得到一个完整的生成文本。</li>
<li>但细看就会发现，<code>Diffusion</code> 就是一个彻头彻尾的噱头，和经典的热力学扩散过程没有鸡毛关系，<code>LLaDA</code> 本质就是一个大 <code>BERT</code> 模型，用完形填空的方式来生成文本（一次可以做多个完形填空），只是下图所示的每轮迭代的过程看起来有点像 <code>Diffusion</code> 的去噪（没关系硬蹭）。<br />
<img src="https://github.com/ML-GSAI/LLaDA/raw/main/imgs/example_gradio.gif" alt="llada" /></li>
</ul>
<blockquote>
<p>上图来自官方 <code>repo</code> 的 <code>README</code></p>
</blockquote>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="总体流程"><a class="markdownIt-Anchor" href="#总体流程"></a> 总体流程</h3>
<ul>
<li>虽然多少有点标题党，但这篇论文本身是值得一读的，将文本生成任务做了重新定义，确实可大幅提高生成速度。</li>
</ul>
<h4 id="模型架构"><a class="markdownIt-Anchor" href="#模型架构"></a> 模型架构</h4>
<ul>
<li>纯纯 <code>Transformer encoder</code> 架构，和 <code>BERT</code> 类似，双向注意力，模型参数规模达 <code>8B</code></li>
</ul>
<h4 id="训练过程"><a class="markdownIt-Anchor" href="#训练过程"></a> 训练过程</h4>
<ol>
<li>预训练
<ul>
<li>使用随机 <code>mask</code> 一定比例的 <code>token</code>，然后使用 <code>Transformer</code> 预测被 <code>mask</code> 的 <code>token</code>（完形填空）</li>
<li>损失函数：<code>mask</code> 部分的 <code>cross-entropy</code> 损失</li>
<li>数据规模：<code>2.3</code> 万亿 <code>token</code>，包含通用文本、代码和多语言数据</li>
</ul>
</li>
<li><code>SFT</code>
<ul>
<li>目标：使模型具备指令跟随能力</li>
<li>数据格式：成对数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>p</mi><mi>θ</mi></msub><mo separator="true">,</mo><msub><mi>r</mi><mi>θ</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(p_\theta,r_\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">p_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是指令，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">r_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是响应</li>
<li>掩码策略：仅对响应部分掩码，保持指令完整</li>
<li>损失函数：仅对响应部分计算 <code>cross-entropy</code> 损失</li>
<li>数据规模：<code>450</code> 万对指令响应对，涵盖代码、数学和多轮对话</li>
</ul>
</li>
</ol>
<h4 id="推理与生成"><a class="markdownIt-Anchor" href="#推理与生成"></a> 推理与生成</h4>
<ul>
<li>过程：从全掩码的响应开始，逐步预测并更新掩码 <code>token</code>，直到生成完整响应</li>
<li>重掩码策略（预测之后 <code>mask</code> 一部分生成结果做二次生成）：
<ul>
<li>随机重掩码：基础策略，与扩散过程对齐</li>
<li>低置信度重掩码：优先掩码预测置信度低的 <code>token</code></li>
<li>半自回归策略（<code>SFT</code>后）：分块生成，块内并行预测以提高效率</li>
</ul>
</li>
<li>生成效果：支持多轮对话、多语言翻译和复杂推理任务</li>
</ul>
<h3 id="和自回归模型对比"><a class="markdownIt-Anchor" href="#和自回归模型对比"></a> 和自回归模型对比</h3>
<table>
<thead>
<tr>
<th style="text-align:center">特性</th>
<th style="text-align:center">自回归模型（如<code>GPT</code>）</th>
<th style="text-align:center"><code>LLaDA</code></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">生成顺序</td>
<td style="text-align:center">严格从左到右逐 <code>token</code> 生成</td>
<td style="text-align:center">并行预测 + 动态调整</td>
</tr>
<tr>
<td style="text-align:center">计算效率</td>
<td style="text-align:center">需串行预测多次</td>
<td style="text-align:center">仅需少量迭代（块级并行）</td>
</tr>
<tr>
<td style="text-align:center">错误修正能力</td>
<td style="text-align:center">无法修改已生成 <code>token</code></td>
<td style="text-align:center">通过重掩码可修正低置信度位置</td>
</tr>
<tr>
<td style="text-align:center">逆向推理支持</td>
<td style="text-align:center">受限于单向建模</td>
<td style="text-align:center">双向注意力机制支持逆向推理</td>
</tr>
</tbody>
</table>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>预测下一个词的大模型范式是否一定是最优的？可能未必。这篇论文就提出了一个不错的思路</li>
<li><code>make bert great again</code> <s>手动滑稽</s></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2025/05/11/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/05/11/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models/" class="post-title-link" itemprop="url">High-Resolution Image Synthesis with Latent Diffusion Models</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-05-11 17:00:32" itemprop="dateCreated datePublished" datetime="2025-05-11T17:00:32+08:00">2025-05-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/stable-diffusion/" itemprop="url" rel="index"><span itemprop="name">stable diffusion</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2025/05/11/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/05/11/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.10752">https://arxiv.org/pdf/2112.10752</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/CompVis/latent-diffusion">https://github.com/CompVis/latent-diffusion</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>LDM</code> 是 <code>stable diffusion</code> 系列的开山之作，让 <code>Diffusion Model</code> 在 <code>Image Synthesis</code> 领域大放异彩</li>
<li>传统的 <code>Diffusion Model</code> 有两大问题：
<ol>
<li>没办法控制生成内容，只能确保生成的内容和训练数据集风格比较类似</li>
<li>在像素尺度上做去噪，计算量大，导致只能生成较小分辨率的图，且很慢</li>
</ol>
</li>
<li><code>LDM</code> 解决了上述的两个问题：
<ol>
<li>通过编码器将 文本 / <code>mask</code> / <code>bbox</code> 等条件信息转成 <code>conditioning embedding</code>，再通过 <code>cross attention</code> 机制将条件信息和 <code>latent space</code> 中的噪声结合起来做去噪，让条件信息可引导图片生成</li>
<li>通过 <code>VAE</code> 将图片压缩到 <code>latent space</code> 中，再进行去噪，计算量小，速度快</li>
</ol>
</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="总体流程"><a class="markdownIt-Anchor" href="#总体流程"></a> 总体流程</h3>
<p><img src="https://s2.loli.net/2025/05/22/Vlkz7YnqIDxTWhH.png" alt="LDM.png" /></p>
<ol>
<li>生成隐空间下的随机噪声</li>
<li>将条件信息通过各自类型的编码器编码成 <code>conditioning embedding</code>，例如文本编码使用 <code>CLIP text encoder</code></li>
<li>将 <code>latent noise</code> 和 <code>conditioning embedding</code> 和 <code>timestep embedding</code> 输入到 <code>UNet</code> 中进行多轮迭代去噪（<code>50</code> step）</li>
<li>去噪后的 <code>latent</code> 通过 <code>VAE decoder</code> 解码成图片</li>
</ol>
<h3 id="conditioning-unet"><a class="markdownIt-Anchor" href="#conditioning-unet"></a> Conditioning UNet</h3>
<ul>
<li>通过 <strong>交叉注意力机制</strong> 将 <strong>文本条件</strong> 和 <strong>时序</strong> 通过 <code>UNet</code> 嵌入到 <code>Noised Latent</code> 中</li>
<li>具体来说：<strong>TimeEmbedding 直接和图像特征相加，TextEmbedding 和图像特征做 CrossAttention，（TextEmbedding 作为 KV，图像特征作为 Q）</strong></li>
<li><code>Conditioning UNet</code> 示意图，两次下采样 + 中间块 + 两次上采样</li>
</ul>
<pre class="mermaid">graph TD
    Input[Noised Latent: 32x32x4] --> DownBlock1[CrossAttnDownBlock2D]
    DownBlock1 --> DownBlock2[CrossAttnDownBlock2D]
    DownBlock2 --> MidBlock[UNetMidBlock2DCrossAttn]
    MidBlock --> UpBlock1[CrossAttnUpBlock2D]
    UpBlock1 --> UpBlock2[CrossAttnUpBlock2D]
    UpBlock2 --> Output[Denoised Latent: 32x32x4]
  
    TextEncoder[Text Encoder] -->|Text Embedding| DownBlock1
    TextEncoder -->|Text Embedding| DownBlock2
    TextEncoder -->|Text Embedding| MidBlock
    TextEncoder -->|Text Embedding| UpBlock1
    TextEncoder -->|Text Embedding| UpBlock2
  
    Time[Timestep] -->|Time Embedding| DownBlock1
    Time -->|Time Embedding| DownBlock2
    Time -->|Time Embedding| MidBlock
    Time -->|Time Embedding| UpBlock1
    Time -->|Time Embedding| UpBlock2</pre>
<ul>
<li><code>CrossAttnBlock2D</code> 结构示意</li>
</ul>
<pre class="mermaid">graph TD
    %% 输入节点
    Input[输入特征图 h_in] --> ResNet
    TimeEmb[时间嵌入 t_emb] --> MLP
    TextEmb[文本条件 y_text] --> ProjText
  
    %% 主干计算路径
    ResNet[ResNet块] --> Add
    MLP[MLP时间投影] --> Add
    Add[逐元素相加] --> GroupNorm
    GroupNorm[GroupNorm] --> Conv1
    Conv1[Conv2D 1x1] --> CrossAttn
  
    %% 交叉注意力分支
    ProjText[文本投影 W_k/W_v] --> CrossAttn
    Conv2[Conv2D 1x1] --> Merge
    CrossAttn[交叉注意力层] --> Merge
  
    %% 残差连接
    Input --> Conv2
    Merge[特征合并] --> LayerNorm
    LayerNorm[LayerNorm] --> Output[输出特征图 h_out]</pre>
<ul>
<li><code>DecoderAttentionBlock2D</code> 结构示意</li>
</ul>
<pre class="mermaid">graph TD
    X[("Input x<br>Shape: 1,512,32,32")] --> Norm["Normalize (GroupNorm)<br>Output: 1,512,32,32"]
  
    Norm --> Q["Q Conv2d(1x1)<br>Output: 1,512,32,32"]
    Norm --> K["K Conv2d(1x1)<br>Output: 1,512,32,32"]
    Norm --> V["V Conv2d(1x1)<br>Output: 1,512,32,32"]
  
    Q --> ReshapeQ["Reshape & Permute<br>1,512,32,32 → 1,1024,512"]
    K --> ReshapeK["Reshape<br>1,512,32,32 → 1,512,1024"]
  
    ReshapeQ --> MatmulQK["Matmul(Q,K)<br>1,1024,512 × 1,512,1024 → 1,1024,1024"]
    ReshapeK --> MatmulQK
  
    MatmulQK --> Scale["Scale (×1/√512)<br>1,1024,1024"]
    Scale --> Softmax["Softmax<br>1,1024,1024"]
  
    V --> ReshapeV["Reshape<br>1,512,32,32 → 1,512,1024"]
    Softmax --> PermuteSoftmax["Permute<br>1,1024,1024 → 1,1024,1024"]
  
    ReshapeV --> MatmulVW["Matmul(V, Softmax)<br>1,512,1024 × 1,1024,1024 → 1,512,1024"]
    PermuteSoftmax --> MatmulVW
  
    MatmulVW --> ReshapeOut["Reshape<br>1,512,1024 → 1,512,32,32"]
  
    ReshapeOut --> ProjOut["Proj_out Conv2d(1x1)<br>1,512,32,32"]
    ProjOut --> Add["Add (x + h_)<br>1,512,32,32"]
  
    X --> Add
    Add --> Output[("Final Output<br>1,512,32,32")]</pre>
<ul>
<li>下面附上 <code>Conditioning UNet block</code> 的实现代码，可以看出非常优雅：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, context_dim=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.to_q = nn.Linear(in_dim, in_dim, bias=<span class="literal">False</span>)</span><br><span class="line">        self.to_k = nn.Linear(</span><br><span class="line">            context_dim <span class="keyword">if</span> context_dim <span class="keyword">else</span> in_dim, in_dim, bias=<span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line">        self.to_v = nn.Linear(</span><br><span class="line">            context_dim <span class="keyword">if</span> context_dim <span class="keyword">else</span> in_dim, in_dim, bias=<span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line">        self.to_out = nn.Sequential(nn.Linear(in_dim, in_dim), nn.Dropout(<span class="number">0.0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, context=<span class="literal">None</span></span>):</span></span><br><span class="line">        q = self.to_q(x)</span><br><span class="line">        k = self.to_k(context <span class="keyword">if</span> context <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> x)</span><br><span class="line">        v = self.to_v(context <span class="keyword">if</span> context <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> x)</span><br><span class="line"></span><br><span class="line">        attn = torch.einsum(<span class="string">&quot;b i d, b j d -&gt; b i j&quot;</span>, q, k) * (x.shape[-<span class="number">1</span>] ** -<span class="number">0.5</span>)</span><br><span class="line">        attn = F.softmax(attn, dim=-<span class="number">1</span>)</span><br><span class="line">        out = torch.einsum(<span class="string">&quot;b i j, b j d -&gt; b i d&quot;</span>, attn, v)</span><br><span class="line">        <span class="keyword">return</span> self.to_out(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GEGLU</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, hidden_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.proj = nn.Linear(in_dim, hidden_dim * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x_proj = self.proj(x)</span><br><span class="line">        x1, x2 = x_proj.chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x1 * F.gelu(x2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, hidden_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            GEGLU(in_dim, hidden_dim), nn.Dropout(<span class="number">0.0</span>), nn.Linear(hidden_dim, in_dim)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicTransformerBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm1 = nn.LayerNorm(dim, eps=<span class="number">1e-5</span>)</span><br><span class="line">        self.attn1 = Attention(dim)</span><br><span class="line">        self.norm2 = nn.LayerNorm(dim, eps=<span class="number">1e-5</span>)</span><br><span class="line">        self.attn2 = Attention(dim, context_dim=<span class="number">768</span>)</span><br><span class="line">        self.norm3 = nn.LayerNorm(dim, eps=<span class="number">1e-5</span>)</span><br><span class="line">        self.ff = FeedForward(dim, <span class="number">1280</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, context=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># Self attention</span></span><br><span class="line">        x = self.attn1(self.norm1(x)) + x</span><br><span class="line">        <span class="comment"># Cross attention</span></span><br><span class="line">        x = self.attn2(self.norm2(x), context=context) + x</span><br><span class="line">        <span class="comment"># Feed forward</span></span><br><span class="line">        x = self.ff(self.norm3(x)) + x</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer2DModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm = nn.GroupNorm(<span class="number">32</span>, in_channels, eps=<span class="number">1e-6</span>, affine=<span class="literal">True</span>)</span><br><span class="line">        self.proj_in = nn.Conv2d(in_channels, in_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.transformer_blocks = nn.ModuleList([BasicTransformerBlock(in_channels)])</span><br><span class="line">        self.proj_out = nn.Conv2d(in_channels, in_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, context=<span class="literal">None</span></span>):</span></span><br><span class="line">        b, c, h, w = x.shape</span><br><span class="line">        x_in = x</span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        x = self.proj_in(x)</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(b, h * w, c)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self.transformer_blocks:</span><br><span class="line">            x = block(x, context)</span><br><span class="line"></span><br><span class="line">        x = x.reshape(b, h, w, c).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        x = self.proj_out(x)</span><br><span class="line">        <span class="keyword">return</span> x + x_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResnetBlock2D</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.norm1 = nn.GroupNorm(<span class="number">32</span>, in_channels, eps=<span class="number">1e-5</span>, affine=<span class="literal">True</span>)</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.time_emb_proj = nn.Linear(<span class="number">1280</span>, in_channels)</span><br><span class="line">        self.norm2 = nn.GroupNorm(<span class="number">32</span>, in_channels, eps=<span class="number">1e-5</span>, affine=<span class="literal">True</span>)</span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.0</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.nonlinearity = nn.SiLU()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, time_emb=<span class="literal">None</span></span>):</span></span><br><span class="line">        h = x</span><br><span class="line">        h = self.norm1(h)</span><br><span class="line">        h = self.nonlinearity(h)</span><br><span class="line">        h = self.conv1(h)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> time_emb <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            time_emb = self.nonlinearity(time_emb)</span><br><span class="line">            time_emb = self.time_emb_proj(time_emb)[:, :, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">            h = h + time_emb</span><br><span class="line"></span><br><span class="line">        h = self.norm2(h)</span><br><span class="line">        h = self.nonlinearity(h)</span><br><span class="line">        h = self.dropout(h)</span><br><span class="line">        h = self.conv2(h)</span><br><span class="line">        <span class="keyword">return</span> h + x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Downsample2D</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Conv2d(channels, channels, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrossAttnDownBlock2D</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels=<span class="number">320</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.attentions = nn.ModuleList(</span><br><span class="line">            [Transformer2DModel(in_channels) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]</span><br><span class="line">        )</span><br><span class="line">        self.resnets = nn.ModuleList([ResnetBlock2D(in_channels) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)])</span><br><span class="line">        self.downsamplers = nn.ModuleList([Downsample2D(in_channels)])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, context=<span class="literal">None</span>, time_emb=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">for</span> attn, resnet <span class="keyword">in</span> <span class="built_in">zip</span>(self.attentions, self.resnets):</span><br><span class="line">            x = attn(x, context)</span><br><span class="line">            x = resnet(x, time_emb)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> downsampler <span class="keyword">in</span> self.downsamplers:</span><br><span class="line">            x = downsampler(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试代码</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    block = CrossAttnDownBlock2D(in_channels=<span class="number">320</span>)</span><br><span class="line">    x = torch.randn(<span class="number">1</span>, <span class="number">320</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">    context = torch.randn(<span class="number">1</span>, <span class="number">77</span>, <span class="number">768</span>)  <span class="comment"># 文本条件，77 个 token 组成的文本序列经过 CLIP 编码成向量 </span></span><br><span class="line">    time_emb = torch.randn(<span class="number">1</span>, <span class="number">1280</span>)  <span class="comment"># 时间嵌入，一个时间步（例如：961）变成一个 enbedding</span></span><br><span class="line"></span><br><span class="line">    output = block(x, context, time_emb)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;输入形状: <span class="subst">&#123;x.shape&#125;</span> -&gt; 输出形状: <span class="subst">&#123;output.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 预期输出: torch.Size([1, 320, 32, 32])</span></span><br></pre></td></tr></table></figure>
<h2 id="thoughts"><a class="markdownIt-Anchor" href="#thoughts"></a> Thoughts</h2>
<ul>
<li>论文思路无比清晰，且说服力很强，把很多领域的知识结合起来，真正把图像生成在实用性方面推到了一个新的高度</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhangzhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">172</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">52</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">106</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhangzhe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js', () => {
    // 初始化 Mermaid 配置
    mermaid.initialize({
      theme    : 'dark',  // 设置主题
      logLevel : 3,  // 设置日志等级
      flowchart: { curve: 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 },
      themeVariables: {
        'fontFamily': 'Microsoft YaHei, Arial, sans-serif',  // 设置中文字体
      }
    });

    // 初始化 Mermaid 图表
    mermaid.init(undefined, document.querySelectorAll('pre.mermaid'));
  }, window.mermaid);
}
</script>


  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'eK3W25jybCO5jVUrYBBpAPqM-gzGzoHsz',
      appKey     : 'F4KVyUj9wHI5c80Bhz7O2uhq',
      placeholder: "说点什么再走吧...",
      avatar     : 'hide',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
