<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"real-zhangzhe.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Zhangzhe&#39;s Blog">
<meta property="og:url" content="https://real-zhangzhe.github.io/page/6/index.html">
<meta property="og:site_name" content="Zhangzhe&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhangzhe">
<meta property="article:tag" content="No mistakes in the tango, not like life.">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://real-zhangzhe.github.io/page/6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Zhangzhe's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhangzhe's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">The projection of my life.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/archives/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/11/06/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-1-%E2%80%94%E2%80%94%E7%94%A8REINFORCE%E7%AE%97%E6%B3%95%E8%AE%AD%E7%BB%83Agent%E7%8E%A9%E5%80%92%E7%AB%8B%E6%91%86%E6%B8%B8%E6%88%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/11/06/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-1-%E2%80%94%E2%80%94%E7%94%A8REINFORCE%E7%AE%97%E6%B3%95%E8%AE%AD%E7%BB%83Agent%E7%8E%A9%E5%80%92%E7%AB%8B%E6%91%86%E6%B8%B8%E6%88%8F/" class="post-title-link" itemprop="url">强化学习(1)——用REINFORCE算法训练Agent玩倒立摆游戏</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-11-06 18:50:40" itemprop="dateCreated datePublished" datetime="2024-11-06T18:50:40+08:00">2024-11-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reinforcement-Learning/" itemprop="url" rel="index"><span itemprop="name">Reinforcement Learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/11/06/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-1-%E2%80%94%E2%80%94%E7%94%A8REINFORCE%E7%AE%97%E6%B3%95%E8%AE%AD%E7%BB%83Agent%E7%8E%A9%E5%80%92%E7%AB%8B%E6%91%86%E6%B8%B8%E6%88%8F/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/11/06/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-1-%E2%80%94%E2%80%94%E7%94%A8REINFORCE%E7%AE%97%E6%B3%95%E8%AE%AD%E7%BB%83Agent%E7%8E%A9%E5%80%92%E7%AB%8B%E6%91%86%E6%B8%B8%E6%88%8F/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/BF00992696">https://link.springer.com/article/10.1007/BF00992696</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://gymnasium.farama.org/tutorials/training_agents/reinforce_invpend_gym_v26/">https://gymnasium.farama.org/tutorials/training_agents/reinforce_invpend_gym_v26/</a></li>
<li>doc: <a target="_blank" rel="noopener" href="https://gymnasium.farama.org/environments/mujoco/inverted_pendulum/">https://gymnasium.farama.org/environments/mujoco/inverted_pendulum/</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本博客是从零开始学习强化学习系列的第一篇，重点在于介绍强化学习的基础概念。主要介绍了 <code>REINFORCE</code> 算法的基本原理，并用 <code>REINFORCE</code> 算法训练 <code>Agent</code> 玩倒立摆游戏</li>
<li><code>REINFORCE</code> 算法是一种基于梯度的策略优化算法，提出时间是 <code>1992</code> 年，算是强化学习的基础算法之一</li>
<li>倒立摆游戏是一个非常简单的强化学习环境，但是可以很好地展示 <code>REINFORCE</code> 算法的效果</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="1-强化学习基础"><a class="markdownIt-Anchor" href="#1-强化学习基础"></a> 1. 强化学习基础</h3>
<p><img src="https://s2.loli.net/2024/11/07/ziDdBWXup71goAC.jpg" alt="AE_loop_dark.png" /></p>
<ul>
<li>强化学习的基本流程如上图所示，主要包括:
<ol>
<li><strong><code>Agent</code></strong>：智能体，即我们要训练的模型</li>
<li><strong><code>Environment</code></strong>：环境，即智能体需要与之交互的环境，比如倒立摆游戏</li>
<li><strong><code>State</code></strong>：状态，也被称为 <strong><code>Observation</code> (观测)</strong> 即环境的状态，比如倒立摆的角度</li>
<li><strong><code>Action</code></strong>：动作，即智能体在某个状态下可以采取的动作，比如向左或向右</li>
<li><strong><code>Reward</code></strong>：奖励，即智能体在某个状态下采取某个动作后得到的奖励，比如倒立摆保持平衡时给予正奖励</li>
<li><strong><code>Policy</code></strong>：策略，是智能体的核心部分，即智能体在某个状态下采取某个动作的概率分布，智能体需要根据策略来选择动作</li>
</ol>
</li>
</ul>
<h3 id="2-倒立摆游戏"><a class="markdownIt-Anchor" href="#2-倒立摆游戏"></a> 2. 倒立摆游戏</h3>
<p><img src="https://s2.loli.net/2024/11/13/6Li1lHQnFB49hA2.gif" alt="episode-episode-8000.gif" /></p>
<ul>
<li>上图是用强化学习实际学习得到的倒立摆游戏效果，目标推动小车让杆尽可能竖直，这个游戏在 <code>Gymnasium</code> 库中，被定义为：
<ol>
<li><strong>Observation Space</strong>：<code>Box(-inf, inf, (4,), float64)</code>，观测状态用一个长度为 <code>4</code> 的向量表示，每个元素的取值范围为任意实数，其中每个维度数值的含义如下：
<ol>
<li>小车的位置</li>
<li>小车上杆子的垂直角度</li>
<li>小车的速度</li>
<li>小车上杆子的角速度</li>
</ol>
</li>
<li><strong><code>Action Space</code></strong>：<code>Box(-3.0, 3.0, (1,), float32)</code>，动作空间为 <code>[-3, 3]</code> 之间的一个浮点数，表示智能体推小车的力（带方向）</li>
<li><strong><code>Reward</code></strong>：目标是使倒立摆尽可能长时间直立（在一定角度限制内），因此，当杆直立的每个时间步都会获得 <code>+1</code> 的奖励</li>
<li><strong><code>Starting State</code></strong>：起始状态为 <code>(0, 0, 0, 0)</code>，然后随机施加 <code>[-0.01, 0.01]</code> 的均匀随机噪声</li>
<li><strong><code>Episode End</code></strong>：一次游戏结束，判定条件为：
<ol>
<li><code>Truncation</code>：游戏累积 <code>1000</code> 个时间步</li>
<li><code>Termination</code>：状态空间中元素出现无穷 或 立杆的垂直角度大于 <code>0.2</code> 弧度（约 <code>11.5</code> 度）</li>
</ol>
</li>
</ol>
</li>
</ul>
<h3 id="3-reinforce算法"><a class="markdownIt-Anchor" href="#3-reinforce算法"></a> 3. REINFORCE算法</h3>
<ul>
<li><code>REINFORCE</code> 算法是一种基于策略梯度的强化学习算法，其核心思想是通过采样得到的轨迹来估计策略梯度，并通过梯度上升的方法来优化策略</li>
</ul>
<h4 id="31-从公式角度讲"><a class="markdownIt-Anchor" href="#31-从公式角度讲"></a> 3.1 从公式角度讲</h4>
<ul>
<li>具体步骤如下：
<ol>
<li><strong>初始化策略</strong>：随机初始化策略参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span></li>
<li><strong>采样轨迹</strong>：在当前策略 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">\pi_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 下采样一条轨迹（状态、动作、奖励在时间维度上组成的序列） <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>r</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>r</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>s</mi><mi>T</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tau = (s_0, a_0, r_1, s_1, a_1, r_2, \ldots, s_T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li><strong>计算累积回报</strong>：对于轨迹中的每个时间步 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>，计算从时间步 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> 开始的累积回报 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>t</mi></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi></mrow><mi>T</mi></msubsup><msup><mi>γ</mi><mrow><mi>k</mi><mo>−</mo><mi>t</mi></mrow></msup><msub><mi>r</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">G_t = \sum_{k=t}^T \gamma^{k-t} r_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span> 是折扣因子</li>
<li><strong>计算累积回报期望</strong>：计算轨迹中每个时间步的累积回报期望 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>τ</mi><mo>∼</mo><msub><mi>π</mi><mi>θ</mi></msub></mrow></msub><mrow><mo fence="true">[</mo><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mi>T</mi></msubsup><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><msub><mi>G</mi><mi>t</mi></msub><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} \left[ \sum_{t=0}^T \log \pi_\theta(a_t | s_t) G_t \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em;">τ</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.25586em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">[</span></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">]</span></span></span></span></span></span></li>
<li><strong>更新策略参数</strong>：根据轨迹中的状态、动作和回报，计算策略梯度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>τ</mi><mo>∼</mo><msub><mi>π</mi><mi>θ</mi></msub></mrow></msub><mrow><mo fence="true">[</mo><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mi>T</mi></msubsup><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><msub><mi>G</mi><mi>t</mi></msub><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\nabla_\theta J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} \left[ \sum_{t=0}^T \nabla_\theta \log \pi_\theta(a_t | s_t) G_t \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em;">τ</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.25586em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">[</span></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">]</span></span></span></span></span></span>，并使用梯度上升法更新策略参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>←</mo><mi>θ</mi><mo>+</mo><mi>α</mi><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\theta \leftarrow \theta + \alpha \nabla_\theta J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 是学习率</li>
</ol>
</li>
<li>通过不断重复上述步骤，策略会逐渐优化，使得智能体在环境中的表现越来越好</li>
<li><code>REINFORCE</code> 算法的优点是简单易实现，但缺点是方差较大，收敛速度较慢</li>
<li>代码实现可以参考 <a target="_blank" rel="noopener" href="https://gymnasium.farama.org/tutorials/training_agents/reinforce_invpend_gym_v26/">Gymnasium 教程</a></li>
</ul>
<h4 id="32-从实现代码角度讲"><a class="markdownIt-Anchor" href="#32-从实现代码角度讲"></a> 3.2 从实现代码角度讲</h4>
<ol>
<li>构建 <code>Policy</code>：
<ol>
<li>构成：<code>Policy</code> 是一个 <code>MLP</code> 网络</li>
<li>输入：<code>State</code>（一个长度为 <code>4</code> 的浮点数向量）</li>
<li>输出：两个标量，分别表示正态分布的均值和标准差</li>
</ol>
</li>
<li>构建 <code>Agent</code>：
<ol>
<li>构成：一个 <code>Agent</code> 包含一个 <code>Policy</code> 以及对此 <code>Policy</code> 的使用和更新方法</li>
<li>使用：即如何使用 <code>Agent</code> 根据当前状态选择动作</li>
<li>更新：即如何根据环境的反馈（奖励）更新 <code>Policy</code> 的参数</li>
</ol>
</li>
<li>训练 <code>Agent</code>（<code>Agent</code> 和 <code>Env</code> 交互）：
<ol>
<li>初始化 <code>Agent</code> 和环境</li>
<li>采样轨迹：在当前策略下采样动作，形成一条轨迹</li>
<li>计算回报：计算轨迹中每个时间步的回报</li>
<li>更新策略：根据策略梯度更新策略参数</li>
<li>重复上述步骤直到策略收敛<br />
代码实现：</li>
</ol>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.distributions.normal <span class="keyword">import</span> Normal</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> gymnasium <span class="keyword">as</span> gym</span><br><span class="line">plt.rcParams[<span class="string">&quot;figure.figsize&quot;</span>] = (<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Policy_Network</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Parametrized Policy Network.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, obs_space_dims: <span class="built_in">int</span>, action_space_dims: <span class="built_in">int</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Initializes a neural network that estimates the mean and standard deviation</span></span><br><span class="line"><span class="string">         of a normal distribution from which an action is sampled from.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            obs_space_dims: Dimension of the observation space</span></span><br><span class="line"><span class="string">            action_space_dims: Dimension of the action space</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        hidden_space1 = <span class="number">16</span>  <span class="comment"># Nothing special with 16, feel free to change</span></span><br><span class="line">        hidden_space2 = <span class="number">32</span>  <span class="comment"># Nothing special with 32, feel free to change</span></span><br><span class="line">        <span class="comment"># Shared Network</span></span><br><span class="line">        self.shared_net = nn.Sequential(</span><br><span class="line">            nn.Linear(obs_space_dims, hidden_space1),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(hidden_space1, hidden_space2),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># Policy Mean specific Linear Layer</span></span><br><span class="line">        self.policy_mean_net = nn.Sequential(</span><br><span class="line">            nn.Linear(hidden_space2, action_space_dims)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># Policy Std Dev specific Linear Layer</span></span><br><span class="line">        self.policy_stddev_net = nn.Sequential(</span><br><span class="line">            nn.Linear(hidden_space2, action_space_dims)</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, torch.Tensor]:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Conditioned on the observation, returns the mean and standard deviation</span></span><br><span class="line"><span class="string">         of a normal distribution from which an action is sampled from.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: Observation from the environment</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            action_means: predicted mean of the normal distribution</span></span><br><span class="line"><span class="string">            action_stddevs: predicted standard deviation of the normal distribution</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        shared_features = self.shared_net(x.<span class="built_in">float</span>())</span><br><span class="line">        action_means = self.policy_mean_net(shared_features)</span><br><span class="line">        action_stddevs = torch.log(</span><br><span class="line">            <span class="number">1</span> + torch.exp(self.policy_stddev_net(shared_features))</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> action_means, action_stddevs</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">REINFORCE</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;REINFORCE algorithm.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, obs_space_dims: <span class="built_in">int</span>, action_space_dims: <span class="built_in">int</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Initializes an agent that learns a policy via REINFORCE algorithm [1]</span></span><br><span class="line"><span class="string">        to solve the task at hand (Inverted Pendulum v4).</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            obs_space_dims: Dimension of the observation space</span></span><br><span class="line"><span class="string">            action_space_dims: Dimension of the action space</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Hyperparameters</span></span><br><span class="line">        self.learning_rate = <span class="number">1e-4</span>  <span class="comment"># Learning rate for policy optimization</span></span><br><span class="line">        self.gamma = <span class="number">0.99</span>  <span class="comment"># Discount factor</span></span><br><span class="line">        self.eps = <span class="number">1e-6</span>  <span class="comment"># small number for mathematical stability</span></span><br><span class="line">        self.probs = []  <span class="comment"># Stores probability values of the sampled action</span></span><br><span class="line">        self.rewards = []  <span class="comment"># Stores the corresponding rewards</span></span><br><span class="line">        self.net = Policy_Network(obs_space_dims, action_space_dims)</span><br><span class="line">        self.optimizer = torch.optim.AdamW(self.net.parameters(), lr=self.learning_rate)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample_action</span>(<span class="params">self, state: np.ndarray</span>) -&gt; <span class="built_in">float</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Returns an action, conditioned on the policy and observation.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            state: Observation from the environment</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            action: Action to be performed</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        state = torch.tensor(np.array([state]))</span><br><span class="line">        action_means, action_stddevs = self.net(state)</span><br><span class="line">        <span class="comment"># create a normal distribution from the predicted</span></span><br><span class="line">        <span class="comment">#   mean and standard deviation and sample an action</span></span><br><span class="line">        distrib = Normal(action_means[<span class="number">0</span>] + self.eps, action_stddevs[<span class="number">0</span>] + self.eps)</span><br><span class="line">        action = distrib.sample()</span><br><span class="line">        prob = distrib.log_prob(action)</span><br><span class="line">        action = action.numpy()</span><br><span class="line">        self.probs.append(prob)</span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Updates the policy network&#x27;s weights.&quot;&quot;&quot;</span></span><br><span class="line">        running_g = <span class="number">0</span></span><br><span class="line">        gs = []</span><br><span class="line">        <span class="comment"># Discounted return (backwards) - [::-1] will return an array in reverse</span></span><br><span class="line">        <span class="keyword">for</span> R <span class="keyword">in</span> self.rewards[::-<span class="number">1</span>]:</span><br><span class="line">            running_g = R + self.gamma * running_g</span><br><span class="line">            gs.insert(<span class="number">0</span>, running_g)</span><br><span class="line">        deltas = torch.tensor(gs)</span><br><span class="line">        log_probs = torch.stack(self.probs)</span><br><span class="line">        <span class="comment"># Update the loss with the mean log probability and deltas</span></span><br><span class="line">        <span class="comment"># Now, we compute the correct total loss by taking the sum of the element-wise products.</span></span><br><span class="line">        loss = -torch.<span class="built_in">sum</span>(log_probs * deltas)</span><br><span class="line">        <span class="comment"># Update the policy network</span></span><br><span class="line">        self.optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        <span class="comment"># Empty / zero out all episode-centric/related variables</span></span><br><span class="line">        self.probs = []</span><br><span class="line">        self.rewards = []</span><br><span class="line"><span class="comment"># Create and wrap the environment</span></span><br><span class="line">env = gym.make(<span class="string">&quot;InvertedPendulum-v4&quot;</span>)</span><br><span class="line">env = gym.make(<span class="string">&quot;InvertedPendulum-v4&quot;</span>, render_mode=<span class="string">&quot;rgb_array&quot;</span>)</span><br><span class="line">wrapped_env = gym.wrappers.RecordVideo(</span><br><span class="line">    env,</span><br><span class="line">    video_folder=<span class="string">&quot;./InvertedPendulum_video&quot;</span>,</span><br><span class="line">    episode_trigger=<span class="keyword">lambda</span> episode_id: episode_id % <span class="number">2000</span> == <span class="number">0</span>,</span><br><span class="line">    name_prefix=<span class="string">&quot;episode&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Observation-space of InvertedPendulum-v4 (4)</span></span><br><span class="line">obs_space_dims = env.observation_space.shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># Action-space of InvertedPendulum-v4 (1)</span></span><br><span class="line">action_space_dims = env.action_space.shape[<span class="number">0</span>]</span><br><span class="line">agent = REINFORCE(obs_space_dims, action_space_dims)</span><br><span class="line">reward_over_episodes = []</span><br><span class="line"><span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(total_num_episodes):</span><br><span class="line">    obs, info = wrapped_env.reset()</span><br><span class="line">    done = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">        action = agent.sample_action(obs)</span><br><span class="line">        obs, reward, terminated, truncated, info = wrapped_env.step(action)</span><br><span class="line">        agent.rewards.append(reward)</span><br><span class="line">        done = terminated <span class="keyword">or</span> truncated</span><br><span class="line">    reward_over_episodes.append(wrapped_env.return_queue[-<span class="number">1</span>])</span><br><span class="line">    agent.update()  <span class="comment"># 每完成一次轨迹才会更新一次策略</span></span><br></pre></td></tr></table></figure>
<p>重点代码分析：</p>
<ol>
<li><code>Policy</code> 预测采样动作的均值和标准差： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">shared_features = self.shared_net(x.<span class="built_in">float</span>())</span><br><span class="line">action_means = self.policy_mean_net(shared_features)    <span class="comment"># 直接预测采样动作的均值</span></span><br><span class="line">action_stddevs = torch.log(</span><br><span class="line">    <span class="number">1</span> + torch.exp(self.policy_stddev_net(shared_features))</span><br><span class="line">)   <span class="comment"># 预测采样动作的标准差，保证标准差为正</span></span><br></pre></td></tr></table></figure>
</li>
<li>采样动作： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">distrib = Normal(action_means[<span class="number">0</span>] + self.eps, action_stddevs[<span class="number">0</span>] + self.eps)  <span class="comment"># 根据 Policy 预测的均值和标准差构建正态分布</span></span><br><span class="line">action = distrib.sample()   <span class="comment"># 从正态分布中采样动作</span></span><br><span class="line">prob = distrib.log_prob(action) <span class="comment"># 同时计算采样动作的概率，用于后续计算策略梯度来更新策略</span></span><br></pre></td></tr></table></figure>
</li>
<li>更新策略： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">running_g = <span class="number">0</span></span><br><span class="line">gs = []</span><br><span class="line"><span class="keyword">for</span> R <span class="keyword">in</span> self.rewards[::-<span class="number">1</span>]:</span><br><span class="line">    running_g = R + self.gamma * running_g</span><br><span class="line">    gs.insert(<span class="number">0</span>, running_g)</span><br><span class="line">deltas = torch.tensor(gs)   <span class="comment"># 计算折扣累积回报</span></span><br><span class="line">log_probs = torch.stack(self.probs)</span><br><span class="line">loss = -torch.<span class="built_in">sum</span>(log_probs * deltas)   <span class="comment"># 根据策略累积折扣回报和策略概率计算期望策略累积折扣期望，目标是最大化期望</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>最终效果：<br />
<img src="https://s2.loli.net/2024/11/07/Yo76Ct3Oewcqs1f.png" alt="reinforce_learning_v2.png" /></p>
<blockquote>
<p>可以看出，<code>Agent</code> 在训练过程中逐渐学会了如何控制小车，使得倒立摆尽可能直立，训练 <code>5000</code> 步就可以将倒立摆稳定保持 <code>200</code> 时间步</p>
</blockquote>
<h3 id="4-思考和尝试"><a class="markdownIt-Anchor" href="#4-思考和尝试"></a> 4. 思考和尝试</h3>
<ul>
<li>由于长期做有监督深度学习项目，所以会思考：如果使用深度有监督学习模型来解决倒立摆问题，会有什么不同？</li>
<li>但直接使用深度有监督学习模型来解决倒立摆问题是不现实的，因为不管是用奖励计算损失还是用观测状态计算损失，都无法通过梯度反向传播来优化模型，<strong>因为环境并不可微</strong></li>
<li><strong>环境不可微</strong> 是强化学习和深度学习的根本区别之一，那么如何解决 “深度有监督学习无法解决倒立摆问题” 呢？</li>
<li>一个简单有效的方法是使用两个阶段的模型：
<ol>
<li><strong>第一阶段</strong>：训练一个深度有监督学习模型，作为环境仿真器
<ol>
<li>输入：状态（观测）+ 随机动作</li>
<li>输出：预测的下一个状态 + 预测的奖励</li>
<li>监督：真实环境下，输入随机动作后的新状态和奖励</li>
</ol>
</li>
<li><strong>第二阶段</strong>：训练一个深度有监督学习模型，作为智能体
<ol>
<li>输入：状态（观测）</li>
<li>输出：动作</li>
<li>监督：环境仿真器（冻结）预测的下一个状态和奖励（目标是奖励尽可能高 且 立杆尽可能竖直 且 小车速度尽可能小 且 立杆线速度尽可能小）</li>
</ol>
</li>
</ol>
</li>
<li>通过两个阶段的模型训练，可以将环境的不可微性质转化为可微性质，从而使用深度有监督学习模型来解决倒立摆问题</li>
<li>实现代码：</li>
</ul>
<ol>
<li>训练环境仿真器</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> gymnasium <span class="keyword">as</span> gym</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EnvPredNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, obs_space_dims: <span class="built_in">int</span>, action_space_dims: <span class="built_in">int</span>, reward_space_dims: <span class="built_in">int</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        hidden_space1 = <span class="number">128</span>  <span class="comment"># Nothing special with 16, feel free to change</span></span><br><span class="line">        hidden_space2 = <span class="number">256</span>  <span class="comment"># Nothing special with 32, feel free to change</span></span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(obs_space_dims + action_space_dims, hidden_space1),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_space1, hidden_space2),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_space2, obs_space_dims + reward_space_dims),</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x.<span class="built_in">float</span>())</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SupervisedAgent</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, obs_space_dims: <span class="built_in">int</span>, action_space_dims: <span class="built_in">int</span>, reward_space_dims: <span class="built_in">int</span></span>):</span></span><br><span class="line">        <span class="comment"># Hyperparameters</span></span><br><span class="line">        self.learning_rate = <span class="number">1e-4</span>  <span class="comment"># Learning rate for policy optimization</span></span><br><span class="line">        self.net = EnvPredNet(obs_space_dims, action_space_dims, reward_space_dims)</span><br><span class="line">        self.optimizer = torch.optim.AdamW(self.net.parameters(), lr=self.learning_rate)</span><br><span class="line">        self.loss_fn = nn.MSELoss(reduce=<span class="string">&quot;sum&quot;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample_action</span>(<span class="params">self</span>) -&gt; <span class="built_in">float</span>:</span></span><br><span class="line">        random_action = torch.clamp(torch.randn(<span class="number">1</span>), -<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="keyword">return</span> random_action</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pred_state</span>(<span class="params">self, state, action</span>):</span></span><br><span class="line">        state = torch.tensor(np.array([state]))</span><br><span class="line">        state_action = torch.cat((state, action.unsqueeze(<span class="number">0</span>)), dim=<span class="number">1</span>)</span><br><span class="line">        next_state = self.net(state_action)</span><br><span class="line">        <span class="keyword">return</span> next_state</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self, pred_state, gt_state, reward</span>):</span></span><br><span class="line">        loss = self.loss_fn(</span><br><span class="line">            pred_state, torch.tensor([[*gt_state, reward]], dtype=torch.float32)</span><br><span class="line">        )</span><br><span class="line">        self.optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        <span class="keyword">return</span> loss.item()</span><br><span class="line">env = gym.make(<span class="string">&quot;InvertedPendulum-v4&quot;</span>)</span><br><span class="line">wrapped_env = gym.wrappers.RecordEpisodeStatistics(env, <span class="number">50</span>)  <span class="comment"># Records episode-reward</span></span><br><span class="line">total_num_episodes = <span class="built_in">int</span>(<span class="number">5e4</span>)</span><br><span class="line">obs_space_dims = env.observation_space.shape[<span class="number">0</span>]</span><br><span class="line">action_space_dims = env.action_space.shape[<span class="number">0</span>]</span><br><span class="line">reward_space_dims = <span class="number">1</span></span><br><span class="line">agent = SupervisedAgent(obs_space_dims, action_space_dims, reward_space_dims)</span><br><span class="line">agent.net.train()</span><br><span class="line"><span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(total_num_episodes):</span><br><span class="line">    state, info = wrapped_env.reset()</span><br><span class="line">    done = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">        action = agent.sample_action()</span><br><span class="line">        gt_next_state, reward, terminated, truncated, info = wrapped_env.step(action)</span><br><span class="line">        pred_state = agent.pred_state(state, action)</span><br><span class="line">        loss = agent.update(pred_state, gt_next_state, reward)</span><br><span class="line">        state = gt_next_state</span><br><span class="line">        done = terminated <span class="keyword">or</span> truncated</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Episode: <span class="subst">&#123;episode&#125;</span>, Loss: <span class="subst">&#123;loss&#125;</span>&quot;</span>)</span><br><span class="line">torch.save(agent.net.state_dict(), <span class="string">&quot;env_predict_model.pth&quot;</span>)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>训练智能体</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> gymnasium <span class="keyword">as</span> gym</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EnvPredNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, obs_space_dims: <span class="built_in">int</span>, action_space_dims: <span class="built_in">int</span>, reward_space_dims: <span class="built_in">int</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        hidden_space1 = <span class="number">128</span>  <span class="comment"># Nothing special with 16, feel free to change</span></span><br><span class="line">        hidden_space2 = <span class="number">256</span>  <span class="comment"># Nothing special with 32, feel free to change</span></span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(obs_space_dims + action_space_dims, hidden_space1),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_space1, hidden_space2),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_space2, obs_space_dims + reward_space_dims),</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x.<span class="built_in">float</span>())</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ActionPredNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, obs_space_dims: <span class="built_in">int</span>, action_space_dims: <span class="built_in">int</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        hidden_space1 = <span class="number">128</span>  <span class="comment"># Nothing special with 16, feel free to change</span></span><br><span class="line">        hidden_space2 = <span class="number">256</span>  <span class="comment"># Nothing special with 32, feel free to change</span></span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(obs_space_dims, hidden_space1),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_space1, hidden_space2),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_space2, action_space_dims),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span></span><br><span class="line">        action = self.net(x.<span class="built_in">float</span>()) * <span class="number">3</span></span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SupervisedAgent</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, obs_space_dims: <span class="built_in">int</span>, action_space_dims: <span class="built_in">int</span>, reward_space_dims: <span class="built_in">int</span></span>):</span></span><br><span class="line">        self.env_pred_net = EnvPredNet(obs_space_dims, action_space_dims, reward_space_dims)</span><br><span class="line">        self.action_pred_net = ActionPredNet(obs_space_dims, action_space_dims)</span><br><span class="line">        self.env_pred_net.load_state_dict(torch.load(<span class="string">&quot;env_predict_model.pth&quot;</span>))</span><br><span class="line">        self.env_pred_net.<span class="built_in">eval</span>()</span><br><span class="line">        self.action_pred_net.train()</span><br><span class="line">        self.learning_rate = <span class="number">1e-4</span></span><br><span class="line">        self.optimizer = torch.optim.AdamW(</span><br><span class="line">            self.action_pred_net.parameters(), lr=self.learning_rate</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_action</span>(<span class="params">self, state</span>) -&gt; <span class="built_in">float</span>:</span></span><br><span class="line">        action = self.action_pred_net(state)</span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pred_state_reward</span>(<span class="params">self, state, action</span>):</span></span><br><span class="line">        state_action = torch.cat([torch.tensor([state]), action], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.env_pred_net(state_action)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self, pred_state_reward, state</span>):</span></span><br><span class="line">        loss = (</span><br><span class="line">            pred_state_reward[<span class="number">0</span>, <span class="number">1</span>].<span class="built_in">abs</span>() * <span class="number">10</span>  <span class="comment"># 立杆尽可能竖直</span></span><br><span class="line">            + pred_state_reward[<span class="number">0</span>, <span class="number">2</span>:<span class="number">4</span>].<span class="built_in">abs</span>().<span class="built_in">sum</span>() <span class="comment"># 小车速度和立杆角速度尽可能小</span></span><br><span class="line">            + (pred_state_reward[<span class="number">0</span>, <span class="number">0</span>] - state[<span class="number">0</span>]).<span class="built_in">abs</span>() * <span class="number">0.1</span>  <span class="comment"># 小车位置尽可能不变</span></span><br><span class="line">            - pred_state_reward[<span class="number">0</span>, <span class="number">4</span>].<span class="built_in">abs</span>() <span class="comment"># 奖励尽可能高</span></span><br><span class="line">        )</span><br><span class="line">        self.optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        <span class="keyword">return</span> loss.item()</span><br><span class="line"><span class="comment"># Create and wrap the environment</span></span><br><span class="line">env = gym.make(<span class="string">&quot;InvertedPendulum-v4&quot;</span>)</span><br><span class="line">wrapped_env = gym.wrappers.RecordEpisodeStatistics(env, <span class="number">50</span>)  <span class="comment"># Records episode-reward</span></span><br><span class="line">total_num_episodes = <span class="built_in">int</span>(<span class="number">5e4</span>)  <span class="comment"># Total number of episodes</span></span><br><span class="line">obs_space_dims = env.observation_space.shape[<span class="number">0</span>]</span><br><span class="line">action_space_dims = env.action_space.shape[<span class="number">0</span>]</span><br><span class="line">reward_space_dims = <span class="number">1</span></span><br><span class="line">agent = SupervisedAgent(obs_space_dims, action_space_dims, reward_space_dims)</span><br><span class="line"><span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(total_num_episodes):</span><br><span class="line">    state, info = wrapped_env.reset()</span><br><span class="line">    done = <span class="literal">False</span></span><br><span class="line">    reward_sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">        action = agent.get_action(torch.tensor([state]))</span><br><span class="line">        gt_next_state, reward, terminated, truncated, info = wrapped_env.step(</span><br><span class="line">            action.detach().numpy()[<span class="number">0</span>]</span><br><span class="line">        )</span><br><span class="line">        pred_state_reward = agent.pred_state_reward(state, action)</span><br><span class="line">        loss = agent.update(pred_state_reward, state)</span><br><span class="line">        state = gt_next_state</span><br><span class="line">        done = terminated <span class="keyword">or</span> truncated</span><br><span class="line">        reward_sum += reward</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Episode: <span class="subst">&#123;episode&#125;</span>, Reward: <span class="subst">&#123;reward_sum&#125;</span>, Loss: <span class="subst">&#123;loss&#125;</span>&quot;</span>)</span><br><span class="line">torch.save(agent.action_pred_net.state_dict(), <span class="string">&quot;action_predict_model.pth&quot;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>最终效果：可以正常训练，也可以正常收敛，但效果远不如 <code>REINFORCE</code> 算法</li>
</ul>
<h3 id="5-总结"><a class="markdownIt-Anchor" href="#5-总结"></a> 5. 总结</h3>
<ul>
<li>通过结合 REINFORCE 算法和倒立摆任务，本文展示了强化学习的基本原理和具体实现。</li>
<li>同时，提出了针对环境不可微问题的创新方法，即通过建立环境仿真器来将不可微问题转化为可微问题，从而使得深度学习能够在强化学习任务中发挥作用。</li>
<li>有监督学习和强化学习的对比：
<ul>
<li>二阶段有监督学习适合在已知环境模型的基础上，快速训练并优化策略，特别是离线学习和仿真场景。</li>
<li>强化学习则适用于更为复杂、不确定的环境，尤其是无法精确建模的动态场景，并且可以在实时交互中自我改进。</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/10/29/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96-%E9%83%A8%E7%BD%B2%E2%80%94%E2%80%94%E5%9C%A8AX650%E4%B8%8A%E9%83%A8%E7%BD%B2Qwen%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/10/29/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96-%E9%83%A8%E7%BD%B2%E2%80%94%E2%80%94%E5%9C%A8AX650%E4%B8%8A%E9%83%A8%E7%BD%B2Qwen%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">大模型量化/部署——在AX650上部署Qwen模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-10-29 14:21:46" itemprop="dateCreated datePublished" datetime="2024-10-29T14:21:46+08:00">2024-10-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Quantization/" itemprop="url" rel="index"><span itemprop="name">Quantization</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/10/29/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96-%E9%83%A8%E7%BD%B2%E2%80%94%E2%80%94%E5%9C%A8AX650%E4%B8%8A%E9%83%A8%E7%BD%B2Qwen%E6%A8%A1%E5%9E%8B/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/10/29/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96-%E9%83%A8%E7%BD%B2%E2%80%94%E2%80%94%E5%9C%A8AX650%E4%B8%8A%E9%83%A8%E7%BD%B2Qwen%E6%A8%A1%E5%9E%8B/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/AXERA-TECH/ax-llm">https://github.com/AXERA-TECH/ax-llm</a></li>
</ul>
<h2 id="关键问题列表以-qwen25-05b-prefill-为例"><a class="markdownIt-Anchor" href="#关键问题列表以-qwen25-05b-prefill-为例"></a> 关键问题列表（以 Qwen2.5-0.5B-prefill 为例）</h2>
<ol>
<li>pulsar2 llm_build 模式和标准编译模式的区别？共用了什么部分？
<ol>
<li>标准编译模式有前端，llm_build 模式没有前端</li>
<li>llm_build 量化不共用标准编译，weight 8 bit minmax / decoder layer 之间用 bf16 浮点 / 层内动态量化</li>
</ol>
</li>
<li>ax-llm-build / ax-llm 两个 repo 的关系？他们用来做什么？
<ol>
<li>ax-llm-build 给上板准备除了模型之外的文件，例如 embed / 数据类型转换等</li>
<li>ax-llm 输入编译后模型文件，输出是板上可运行的 chatbot</li>
</ol>
</li>
<li>模型输出文件的含义？l%d.axmodel 表示层，qwen_post.axmodel 表示 hidden size -&gt; vocab size 的 fc 吗？model.embed_tokens.weight.bfloat16.bin 是 token embedding 吗？
<ol>
<li>token embedding / post.axmodel 都用 fc / 查表去做</li>
</ol>
</li>
<li>为什么分层部署？动态量化发生在 decode layer 层之间吗？在 ppl 里用 cpu 动态量化 activation 吗？decoder layer 中有没有用到动态量化？
<ol>
<li>teng 可以做动态量化，不需要用 cpu</li>
</ol>
</li>
<li>decode layer 用 flash attention 了吗？v2 / v3 ？
<ol>
<li>没有，用了标准 attention，softmax 单独计算</li>
</ol>
</li>
<li>用 kv cache 了吗？如何用？DRAM 够用吗？
<ol>
<li>用了，squence length 限制到 2k 之后，DRAM 够用</li>
</ol>
</li>
<li>GQA 用了吗？如何用？repeat 再做 self-attention？
<ol>
<li>有实际节约效率</li>
</ol>
</li>
<li>有没有用到 llm 专用的量化算法？
<ol>
<li>没有</li>
</ol>
</li>
<li>decode method 在 ppl 中用 cpu 实现吗？可以放到 npu 上吗？
<ol>
<li>用 cpu 实现，目前直接用 argmax 了</li>
<li>用 npu 实现的话可以用 top-k</li>
</ol>
</li>
<li>continue batching 用到了吗？（单 batch 似乎不用考虑这个问题，假如 ax650 作为云端芯片就需要考虑了）
<ol>
<li>没有</li>
</ol>
</li>
<li>paged attention 用到了吗？（似乎用内存分页管理就够了？）
<ol>
<li>没有</li>
</ol>
</li>
<li>有哪部分是用浮点运行的？哪部分用定点运行的？
<ol>
<li>除了 conv 相关的都用浮点，例如 softmax</li>
</ol>
</li>
<li>对于长上下文如何处理？qwen2 似乎禁用了 sliding_window，那么如何处理长上下文？计算效率如何？
<ol>
<li>最长测试过 1024</li>
</ol>
</li>
<li>ssm 状态空间模型支持吗？例如 mamba
<ol>
<li>没有，后续可能从节省 kv cache 角度会考虑支持</li>
</ol>
</li>
<li>假如有一个 sparse attention 模型，会快吗？还是要补成 dense 再算？
<ol>
<li>没有专用加速算子，可能不会太快</li>
</ol>
</li>
<li>可能考虑投机解码这种相对更高端的加速技术吗？例如 SpecInfer 这种
<ol>
<li>没有</li>
</ol>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/10/22/%E7%94%A8-transformers-%E6%8E%A8%E7%90%86-Qwen2-0-5B-Instruct/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/10/22/%E7%94%A8-transformers-%E6%8E%A8%E7%90%86-Qwen2-0-5B-Instruct/" class="post-title-link" itemprop="url">用 transformers 推理 Qwen2-0.5B-Instruct</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-10-22 12:03:04" itemprop="dateCreated datePublished" datetime="2024-10-22T12:03:04+08:00">2024-10-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/10/22/%E7%94%A8-transformers-%E6%8E%A8%E7%90%86-Qwen2-0-5B-Instruct/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/10/22/%E7%94%A8-transformers-%E6%8E%A8%E7%90%86-Qwen2-0-5B-Instruct/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="0-背景"><a class="markdownIt-Anchor" href="#0-背景"></a> 0. 背景</h2>
<ul>
<li>本文主要介绍 <code>hugging face</code> 托管的 <code>LLM</code> 如何下载，并用 <code>transformers repo</code> 推理</li>
</ul>
<h2 id="1-相关工具介绍"><a class="markdownIt-Anchor" href="#1-相关工具介绍"></a> 1. 相关工具介绍</h2>
<ol>
<li><a target="_blank" rel="noopener" href="https://huggingface.co"><code>hugging face</code></a> 是一个托管 <code>LLM</code> 的网站，类似 <code>github / dockerhub</code>，可以上传下载大模型，也可以在线推理等</li>
<li><a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers"><code>transformers</code></a> 是一个 <code>hugging face</code> 维护的开源大模型代码库，包含约 <code>300</code> 个开源大模型的网络结构，可以配合 <code>hugging face</code> 下载的大模型，实现一键推理</li>
</ol>
<h2 id="2-模型文件下载"><a class="markdownIt-Anchor" href="#2-模型文件下载"></a> 2. 模型文件下载</h2>
<h3 id="21-下载工具"><a class="markdownIt-Anchor" href="#21-下载工具"></a> 2.1 下载工具</h3>
<ol>
<li><code>hugging face</code> 有专用工具 <code>huggingface-cli</code>，作用类似于低配版 <code>git</code>，可以实现远程 <code>hugging face repo</code> 的登录、登出、上传、下载等</li>
<li>对于 <code>Qwen2-0.5B-Instruct</code> 模型，<code>huggingface-cli</code> 可直接免登录下载，而例如 <code>Llama3.2-1B</code> 等模型需要向 <code>meta</code> 提交申请并获得同意后下载</li>
</ol>
<h3 id="22-下载文件内容"><a class="markdownIt-Anchor" href="#22-下载文件内容"></a> 2.2 下载文件内容</h3>
<ol>
<li><code>hugging face</code> 模型文件格式较为固定，一般为：
<ol>
<li><code>config.json</code>：
<ol>
<li>这个文件包含了模型的配置信息，比如模型的架构参数、词表大小、激活函数类型等</li>
<li>它通常用于在加载模型时，确保模型的配置与原始模型一致</li>
</ol>
</li>
<li><code>generation_config.json</code>：
<ol>
<li>这个文件包含了生成文本时的配置信息，比如最大长度、停止序列、解码相关配置（温度、<code>top-k</code>、<code>top-p</code>、惩罚系数）等，以及依赖的 <code>transformers</code> 版本</li>
<li>这些参数影响模型生成文本的行为</li>
</ol>
</li>
<li><code>LICENSE</code>：
<ol>
<li>这个文件包含了模型的许可证信息，说明了你可以如何使用这个模型，以及使用时需要遵守的法律条款</li>
</ol>
</li>
<li><code>merges.txt</code>：
<ol>
<li>这个文件通常用于字节对编码（<code>Byte Pair Encoding, BPE</code>）分词器，它包含了词汇的合并规则</li>
<li><code>BPE</code> 是一种用于创建词汇表和编码文本的算法</li>
</ol>
</li>
<li><code>model.safetensors</code>：
<ol>
<li>这是一个保存模型权重的文件，使用了 <code>SafeTensors</code> 格式</li>
<li>这是一种高效的文件格式，用于存储和加载深度学习模型的权重</li>
</ol>
</li>
<li><code>README.md</code>：
<ol>
<li>这个文件包含了模型的说明文档，通常包括模型的简介、如何使用模型、训练细节、性能指标等信息</li>
</ol>
</li>
<li><code>tokenizer_config.json</code>：
<ol>
<li>这个文件包含了分词器的配置信息，比如分词器的类型、是否使用 <code>BPE</code> 等</li>
</ol>
</li>
<li><code>tokenizer.json</code>：
<ol>
<li>这个文件包含了分词器的预训练信息，比如词汇表、特殊标记等</li>
<li>它用于将文本转换为模型可以理解的数值输入</li>
</ol>
</li>
<li><code>vocab.json</code>：
<ol>
<li>这个文件包含了模型的词汇表，即模型在训练时使用的所有单词或标记的列表</li>
<li>分词器使用这个词汇表将文本分割成模型可以理解的输入</li>
</ol>
</li>
</ol>
</li>
<li><code>Qwen2-0.5B-Instruct</code> 中的 <code>&quot;Instruct&quot;</code> 是指此模型是经过指令遵循微调后的模型</li>
</ol>
<h3 id="23-模型参数解析"><a class="markdownIt-Anchor" href="#23-模型参数解析"></a> 2.3 模型参数解析</h3>
<ol>
<li>下载的文件中 <code>model.safetensors</code> 就是模型参数</li>
<li><code>safetensors</code> 是由 <code>Hugging Face</code> 开发的一种新型文件格式，专门用于安全地存储和加载机器学习模型的权重，这种格式特别关注模型的安全性、隐私保护和快速加载
<ol>
<li>安全性：<code>safetensors</code> 格式的设计目标之一是提高模型存储的安全性，它不允许执行代码，从而减少了模型文件被恶意篡改的风险</li>
<li>快速加载：与传统的 <code>PyTorch</code> 序列化格式（如 <code>.pth</code> 或 <code>.bin</code>）相比，<code>safetensors</code> 可以更快地加载模型权重，尤其是在 <code>CPU</code> 和 <code>GPU</code> 上</li>
<li>跨语言和跨框架兼容性：<code>safetensors</code> 支持在不同的编程语言和机器学习框架之间共享模型权重，例如可以在 <code>Python</code> 中序列化并在 <code>C++ / Java / JavaScript</code> 中加载</li>
<li>懒加载：支持懒加载，即可以选择只读取文件中的一部分张量，这对于分布式设置中的多节点或 <code>GPU</code> 非常有用</li>
</ol>
</li>
<li>如何解析一个 <code>model.safetensors</code> 文件？</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> safetensors <span class="keyword">import</span> safe_open</span><br><span class="line">tensors = &#123;&#125;</span><br><span class="line"><span class="comment"># framework=&quot;pt&quot; means pytorch</span></span><br><span class="line"><span class="keyword">with</span> safe_open(<span class="string">&quot;model.safetensors&quot;</span>, framework=<span class="string">&quot;pt&quot;</span>, device=<span class="string">&quot;cpu&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> f.keys():</span><br><span class="line">        tensors[key] = f.get_tensor(key)</span><br></pre></td></tr></table></figure>
<h2 id="3-构建模型并加载预训练参数"><a class="markdownIt-Anchor" href="#3-构建模型并加载预训练参数"></a> 3. 构建模型并加载预训练参数</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    model_path, torch_dtype=<span class="string">&quot;auto&quot;</span>, device_map=<span class="string">&quot;auto&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>hugging face</code> 的 <code>transformers</code> 库提供了一个 <code>AutoModelForCausalLM</code> 类，可以根据模型路径，读取配置文件并自动加载模型</li>
</ul>
<h2 id="4-输入构建"><a class="markdownIt-Anchor" href="#4-输入构建"></a> 4. 输入构建</h2>
<p>输入构建分成三个部分：</p>
<ol>
<li>初始化 <code>tokenizer</code></li>
<li><code>prompt</code> 指令化</li>
<li><code>text to token id</code> （<code>tokenize</code>）</li>
</ol>
<h3 id="41-初始化-tokenizer"><a class="markdownIt-Anchor" href="#41-初始化-tokenizer"></a> 4.1 初始化 <code>tokenizer</code></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>transformers</code> 会自动读取 <code>tokenizer</code> 相关配置文件，创建对应的 <code>tokenizer</code> 对象</li>
</ul>
<h3 id="42-prompt-指令化"><a class="markdownIt-Anchor" href="#42-prompt-指令化"></a> 4.2 <code>prompt</code> 指令化</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">prompt = <span class="string">&quot;艾萨克牛顿是谁？&quot;</span></span><br><span class="line">messages = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are Qwen, created by Alibaba Cloud. You are a helpful assistant.&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;,</span><br><span class="line">]</span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tokenize=<span class="literal">False</span>,</span><br><span class="line">    add_generation_prompt=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>上面的 <code>message</code> 是 <code>Qwen2</code> 指令微调后模型的输入格式，包含了 <code>role</code> 和 <code>content</code> 两个字段</li>
<li>具体来说需要两个步骤：
<ol>
<li><strong><code>prompt to message</code></strong>：将 <code>prompt</code> 转换为 <code>message</code> 格式</li>
<li><strong><code>message to chat</code></strong>：在 <code>message</code> 中插入特殊字符，形成 <code>chat</code> 格式，特殊字符主要包括：
<ol>
<li><code>&lt;|im_start|&gt;</code>：表示对话开始</li>
<li><code>&lt;|im_end|&gt;</code>：表示对话结束</li>
<li><code>\n</code>：间隔 <code>role</code> 和 <code>content</code></li>
</ol>
</li>
</ol>
</li>
<li>最终生成的 <code>text</code> 实际内容为：</li>
</ul>
<figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;|<span class="type">im_start</span>|<span class="type">&gt;system</span>\nYou are Qwen, created <span class="built_in">by</span> Alibaba Cloud. You are a helpful assistant.&lt;|<span class="type">im_end</span>|<span class="type">&gt;\n</span>&lt;|<span class="type">im_start</span>|<span class="type">&gt;user</span>\n艾萨克牛顿是谁？&lt;|<span class="type">im_end</span>|<span class="type">&gt;\n</span>&lt;|<span class="type">im_start</span>|<span class="type">&gt;assistant</span></span><br></pre></td></tr></table></figure>
<ul>
<li>一些额外知识：
<ol>
<li><code>prompt</code> 输入模板信息在 <code>tokenizer_config.json</code> 中被定义过，<code>key</code> 为 <code>chat_template</code>： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% for message in messages %&#125;&#123;% if loop.first and messages[0][&#x27;role&#x27;] != &#x27;system&#x27; %&#125;&#123;&#123; &#x27;&lt;|im_start|&gt;system\nYou are a helpful assistant.&lt;|im_end|&gt;\n&#x27; &#125;&#125;&#123;% endif %&#125;&#123;&#123;&#x27;&lt;|im_start|&gt;&#x27; + message[&#x27;role&#x27;] + &#x27;\n&#x27; + message[&#x27;content&#x27;] + &#x27;&lt;|im_end|&gt;&#x27; + &#x27;\n&#x27;&#125;&#125;&#123;% endfor %&#125;&#123;% if add_generation_prompt %&#125;&#123;&#123; &#x27;&lt;|im_start|&gt;assistant\n&#x27; &#125;&#125;&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>模板用到的代码是 <code>Jinja2</code> 写的，<code>Jinja2</code> 是一种模板引擎，<code>tokenizer</code> 会根据这个模板生成 <code>chat</code> 格式的 <code>text</code></li>
<li>代码中的 <code>messages</code> 和 <code>add_generation_prompt</code> 是模板的输入参数</li>
</ol>
</li>
</ul>
<h3 id="43-tokenizetext-to-token-id"><a class="markdownIt-Anchor" href="#43-tokenizetext-to-token-id"></a> 4.3 <code>tokenize</code>(<code>text to token id</code>)</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_inputs = tokenizer([text], return_tensors=<span class="string">&quot;pt&quot;</span>).to(model.device)</span><br></pre></td></tr></table></figure>
<ul>
<li>这个过程就是 <code>tokenize</code>，将 <code>text</code> 转换为 <code>token id</code>
<ul>
<li>首先根据 <code>tokenizer.json</code> 中声明的 <code>token encode</code> 方法（例如 <code>BPE</code>），将 <code>text</code> 分词</li>
<li>然后根据 <code>vocab.json</code> 中的词汇表，将分词后的词转换为 <code>token id</code>（查表）</li>
<li>最后将 <code>token id</code> 转换为 <code>tensor</code> 格式（<code>tensor of uint64 dtype</code>）</li>
</ul>
</li>
</ul>
<h2 id="5-模型前向传播"><a class="markdownIt-Anchor" href="#5-模型前向传播"></a> 5. 模型前向传播</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">generated_ids = model.generate(</span><br><span class="line">    **model_inputs,</span><br><span class="line">    max_new_tokens=<span class="number">512</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>generate</code> 方法是 <code>transformers</code> 提供的一个高级封装方法，可以实现 <code>LLM</code> 的推理
<ul>
<li><code>max_new_tokens</code> 参数表示最大生成的 <code>token</code> 数量</li>
<li><code>generate</code> 方法会自动迭代调用模型的前向传播方法和解码方法，实现文本生成</li>
</ul>
</li>
<li>本章节的重点关注 <code>generate</code> 的模型推理过程，可以分成：
<ol>
<li><code>token id to token embedding</code></li>
<li><code>position emebedding</code> 构造</li>
<li><code>attention mask</code> 构造</li>
<li><code>decoder layer forward</code></li>
</ol>
</li>
</ul>
<h3 id="51-token-id-to-token-embedding"><a class="markdownIt-Anchor" href="#51-token-id-to-token-embedding"></a> 5.1 <code>token id to token embedding</code></h3>
<ul>
<li><code>nn.Embedding</code> 本质就是查表，将 <code>token id</code> 转换为 <code>token embedding</code></li>
</ul>
<h3 id="52-position-emebedding-构造"><a class="markdownIt-Anchor" href="#52-position-emebedding-构造"></a> 5.2 <code>position emebedding</code> 构造</h3>
<ul>
<li><code>Qwen2</code> 模型使用的 <code>position embedding</code> 方法是 <code>RoPE (rotary position embedding)</code></li>
</ul>
<h4 id="521-rope-介绍"><a class="markdownIt-Anchor" href="#521-rope-介绍"></a> 5.2.1 <code>RoPE</code> 介绍</h4>
<p><code>RoPE</code> 的核心思想是将 <code>query embedding</code> 和 <code>key embedding</code> 旋转一定角度，让模型感知到序列中的位置信息。</p>
<ul>
<li><code>RoPE</code> 的输入是：
<ol>
<li><code>position id</code>（例如：<code>[0, 1, 2, ..., seq_len - 1]</code>）</li>
<li><code>query embedding (shape = [seq_len, head_dim])</code></li>
<li><code>key embedding (shape = [seq_len, head_dim])</code></li>
</ol>
</li>
<li><code>RoPE</code> 的输出是：
<ol>
<li>经过 <code>RoPE</code> 处理后的 <code>query embedding</code></li>
<li>经过 <code>RoPE</code> 处理后的 <code>key embedding</code></li>
</ol>
</li>
<li><code>RoPE</code> 的计算过程是：
<ol>
<li>构造 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant="normal">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo>×</mo><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\cos\in\mathbb{R}^{seq\_len\times head\_dim}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mop">cos</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>sin</mi><mo>⁡</mo><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant="normal">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo>×</mo><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\sin\in\mathbb{R}^{seq\_len\times head\_dim}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.70696em;vertical-align:-0.0391em;"></span><span class="mop">sin</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span> 两个矩阵</li>
<li>用两个矩阵去旋转 <code>query embedding</code> 和 <code>key embedding</code></li>
</ol>
</li>
<li><code>RoPE</code> 的实现代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造 RoPE 旋转矩阵</span></span><br><span class="line">inv_freq = <span class="number">1.0</span> / (<span class="number">1000000</span> ** (torch.arange(<span class="number">0</span>, dim, <span class="number">2</span>, dtype=torch.int64).<span class="built_in">float</span>().to(device) / dim))    <span class="comment"># 1. 计算频率的倒数，shape = [dim // 2]</span></span><br><span class="line">freq = inv_freq_expanded.<span class="built_in">float</span>() @ position_ids_expanded.<span class="built_in">float</span>()    <span class="comment"># 2. 计算频率，shape = [seq_len, dim // 2]</span></span><br><span class="line">emb = torch.cat((freqs, freqs), dim=-<span class="number">1</span>)   <span class="comment"># 3. 构造 RoPE 矩阵，shape = [seq_len, dim]</span></span><br><span class="line">cos = emb.cos()[<span class="literal">None</span>, <span class="literal">None</span>, ...]    <span class="comment"># 4. 计算 RoPE 的 cos，扩展到多 batch 和多头，shape = [1, 1, seq_len, dim]</span></span><br><span class="line">sin = emb.sin()[<span class="literal">None</span>, <span class="literal">None</span>, ...]    <span class="comment"># 5. 计算 RoPE 的 sin，扩展到多 batch 和多头，shape = [1, 1, seq_len, dim]</span></span><br><span class="line"><span class="comment"># 旋转 query embedding 和 key embedding</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rotate_half</span>(<span class="params">x</span>):</span></span><br><span class="line">    x1 = x[..., : x.shape[-<span class="number">1</span>] // <span class="number">2</span>]</span><br><span class="line">    x2 = x[..., x.shape[-<span class="number">1</span>] // <span class="number">2</span> :]</span><br><span class="line">    <span class="keyword">return</span> torch.cat((-x2, x1), dim=-<span class="number">1</span>)</span><br><span class="line">q = (q * cos) + (rotate_half(q) * sin)  <span class="comment"># 6. 旋转 query embedding，shape = [batch_size, num_heads, seq_len, head_dim]</span></span><br><span class="line">k = (k * cos) + (rotate_half(k) * sin)  <span class="comment"># 7. 旋转 key embedding，shape = [batch_size, num_heads, seq_len, head_dim]</span></span><br></pre></td></tr></table></figure>
<ul>
<li>以上 <code>RoPE</code> 的公式解释：
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mi>i</mi></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><msub><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo>⋅</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><msub><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mi>i</mi><mo>+</mo><mi>d</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msub><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x&#x27;_{m,i}=x_{m,i}\cdot \cos (m\theta_i)-x_{m,i+d/2}\cdot \sin (m\theta_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.146664em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.730558em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.79965em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">d</span><span class="mord mtight">/</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mi>i</mi><mo>+</mo><mi>d</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><msub><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo>⋅</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mi>i</mi><mo>+</mo><mi>d</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msub><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x&#x27;_{m,i+d/2}=x_{m,i}\cdot \cos (m\theta_i)+x_{m,i+d/2}\cdot \sin (m\theta_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.248892em;vertical-align:-0.49699999999999994em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.378em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">d</span><span class="mord mtight">/</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.49699999999999994em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.730558em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.79965em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">d</span><span class="mord mtight">/</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li>其中：
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{m,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 是 <code>query embedding</code> 或 <code>key embedding</code> 的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> 个位置的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 个维度的值</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub><mo>=</mo><mn>100000</mn><msup><mn>0</mn><mrow><mo>−</mo><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mi>d</mi></mfrac></mrow></msup></mrow><annotation encoding="application/x-tex">\theta_i=1000000^{-\frac{2i}{d}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.96156em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.96156em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8550857142857142em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub><mo>=</mo><mi>m</mi><mo>⋅</mo><mn>100000</mn><msup><mn>0</mn><mrow><mo>−</mo><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mi>d</mi></mfrac></mrow></msup></mrow><annotation encoding="application/x-tex">m\theta_i=m\cdot 1000000^{-\frac{2i}{d}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.44445em;vertical-align:0em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.96156em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.96156em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8550857142857142em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> 是位置 <code>id</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> 是 <code>head_dim</code></li>
</ul>
</li>
</ul>
</li>
<li><code>Qwen</code> 模型中的 <code>RoPE</code> 实现代码是 <code>RoPE</code> 的一个简化版本，主要是为了提高计算效率，官方的 <code>RoPE</code> 计算公式如下：
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><msub><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi></mrow></msub><mo>⋅</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><msub><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x&#x27;_{m,2i}=x_{m,2i}\cdot \cos (m\theta_i)-x_{m,2i+1}\cdot \sin (m\theta_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.146664em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.730558em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.730558em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><msub><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi></mrow></msub><mo>⋅</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mi>x</mi><mrow><mi>m</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>⋅</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x&#x27;_{m,2i+1}=x_{m,2i}\cdot \cos (m\theta_i)+x_{m,2i+1}\cdot \sin (m\theta_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.146664em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.730558em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.730558em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">R</mi><mrow><mi>d</mi><mi mathvariant="normal">Θ</mi><mo separator="true">,</mo><mi>m</mi></mrow></msub><mi mathvariant="bold">x</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi mathvariant="bold">x</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi mathvariant="bold">x</mi><mn>2</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi mathvariant="bold">x</mi><mn>3</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi mathvariant="bold">x</mi><mn>4</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi><mi mathvariant="normal">⋮</mi><mpadded height="+0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mi></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi mathvariant="bold">x</mi><mrow><mi>d</mi><mo>−</mo><mn>1</mn></mrow></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi mathvariant="bold">x</mi><mi>d</mi></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>⊗</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">⋯</mo></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mrow><mi>d</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mrow><mi>d</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>+</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><msub><mi mathvariant="bold">x</mi><mn>2</mn></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi mathvariant="bold">x</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><msub><mi mathvariant="bold">x</mi><mn>4</mn></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi mathvariant="bold">x</mi><mn>3</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi><mi mathvariant="normal">⋮</mi><mpadded height="+0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mi></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><msub><mi mathvariant="bold">x</mi><mi>d</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi mathvariant="bold">x</mi><mrow><mi>d</mi><mo>−</mo><mn>1</mn></mrow></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>⊗</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">⋯</mo></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mrow><mi>d</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><msub><mi>θ</mi><mrow><mi>d</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{R}_{d\Theta,m}\mathbf{x} = \begin{bmatrix} \mathbf{x}_1 \\ \mathbf{x}_2 \\ \mathbf{x}_3 \\ \mathbf{x}_4 \\ \vdots \\ \mathbf{x}_{d-1} \\ \mathbf{x}_d \end{bmatrix} \otimes \begin{bmatrix} \cos(m\theta_1) \\ \cos(m\theta_1) \\ \cos(m\theta_2) \\ \cos(m\theta_2) \\ \cdots \\ \cos(m\theta_{d/2}) \\ \cos(m\theta_{d/2}) \end{bmatrix} + \begin{bmatrix} -\mathbf{x}_2 \\ \mathbf{x}_1 \\ -\mathbf{x}_4 \\ \mathbf{x}_3 \\ \vdots \\ -\mathbf{x}_d \\ \mathbf{x}_{d-1} \end{bmatrix} \otimes \begin{bmatrix} \sin(m\theta_1) \\ \sin(m\theta_1) \\ \sin(m\theta_2) \\ \sin(m\theta_2) \\ \cdots \\ \sin(m\theta_{d/2}) \\ \sin(m\theta_{d/2}) \end{bmatrix}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.972218em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">R</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mtight">Θ</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathbf">x</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:9.060000000000002em;vertical-align:-4.28em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.759965000000001em;"><span style="top:0.45004499999999903em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-0.699955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-1.295955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-1.8919550000000012em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-2.4879550000000012em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.0839550000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.679955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.2759550000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.871955000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.467955000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.518945000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-6.759965000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.250064999999999em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.780000000000001em;"><span style="top:-7.6275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-6.427500000000001em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-5.227500000000001em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.027500000000001em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.1675em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord">⋮</span><span class="mord rule" style="border-right-width:0em;border-top-width:1.5em;bottom:0em;"></span></span></span></span><span style="top:-0.9675em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span><span style="top:0.2325000000000002em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.28em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.759965000000001em;"><span style="top:0.45004499999999903em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-0.699955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-1.295955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-1.8919550000000012em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-2.4879550000000012em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.0839550000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.679955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.2759550000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.871955000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.467955000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.518945000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-6.759965000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.250064999999999em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:8.409030000000001em;vertical-align:-3.9500599999999997em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.458970000000001em;"><span style="top:0.1500399999999994em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-0.9999600000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-1.5959600000000007em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-2.191960000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-2.787960000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.3839600000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.9799600000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.57596em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.17196em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.217950000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-6.458970000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.9500599999999997em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.450000000000001em;"><span style="top:-6.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-5.410000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-4.210000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.0100000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-1.8100000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="minner">⋯</span></span></span><span style="top:-0.6100000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mtight">/</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:0.5900000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mtight">/</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.95em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.458970000000001em;"><span style="top:0.1500399999999994em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-0.9999600000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-1.5959600000000007em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-2.191960000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-2.787960000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.3839600000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.9799600000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.57596em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.17196em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.217950000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-6.458970000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.9500599999999997em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:9.060000000000002em;vertical-align:-4.28em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.759965000000001em;"><span style="top:0.45004499999999903em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-0.699955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-1.295955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-1.8919550000000012em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-2.4879550000000012em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.0839550000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.679955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.2759550000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.871955000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.467955000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.518945000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-6.759965000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.250064999999999em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.780000000000001em;"><span style="top:-7.6275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord">−</span><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-6.427500000000001em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-5.227500000000001em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord">−</span><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.027500000000001em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.1675em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord">⋮</span><span class="mord rule" style="border-right-width:0em;border-top-width:1.5em;bottom:0em;"></span></span></span></span><span style="top:-0.9675em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord">−</span><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:0.2325000000000002em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.28em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.759965000000001em;"><span style="top:0.45004499999999903em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-0.699955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-1.295955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-1.8919550000000012em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-2.4879550000000012em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.0839550000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.679955000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.2759550000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.871955000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.467955000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.518945000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-6.759965000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.250064999999999em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:8.409030000000001em;vertical-align:-3.9500599999999997em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.458970000000001em;"><span style="top:0.1500399999999994em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-0.9999600000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-1.5959600000000007em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-2.191960000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-2.787960000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.3839600000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.9799600000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.57596em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.17196em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.217950000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-6.458970000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.9500599999999997em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.450000000000001em;"><span style="top:-6.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-5.410000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-4.210000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.0100000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-1.8100000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="minner">⋯</span></span></span><span style="top:-0.6100000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mtight">/</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:0.5900000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mtight">/</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.95em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.458970000000001em;"><span style="top:0.1500399999999994em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-0.9999600000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-1.5959600000000007em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-2.191960000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-2.787960000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.3839600000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.9799600000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.57596em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.17196em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.217950000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-6.458970000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.9500599999999997em;"><span></span></span></span></span></span></span></span></span></span></span></li>
<li>区别在于：
<ul>
<li>官方的 <code>RoPE</code> 是同一个位置的相邻维度（<code>2i 和 2i+1</code>）之间旋转</li>
<li><code>Qwen</code> 的 <code>RoPE</code> 是同一个位置的跳跃维度（<code>i 和 i+d/2</code>）之间旋转</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="53-attention-mask-构造"><a class="markdownIt-Anchor" href="#53-attention-mask-构造"></a> 5.3 <code>attention mask</code> 构造</h3>
<ul>
<li>实现中，<code>attention mask</code> 实际上并不需要构造，因为 <code>torch.nn.functional.scaled_dot_product_attention</code> 的 <code>is_causal</code> 参数可以自动实现 <code>attention mask</code></li>
<li>具体来说：
<ol>
<li><code>torch.nn.functional.scaled_dot_product_attention</code> 的 <code>is_causal == True</code> 时，会自动构造一个 <code>attention bias</code>，<code>shape = [query_len, key_len]</code>，其中 <code>bias[i, j] = -inf if i &gt; j else 0</code></li>
<li>在 <code>query @ key.transpose(-2, -1)</code> 得到 <code>attention score</code> 后，会自动加上这个 <code>attention bias</code></li>
<li>然后再经过 <code>softmax</code>，这样就实现了 <code>causal attention</code></li>
</ol>
</li>
<li>而且 <code>causal attention</code> 在 <code>GPT-like LLM</code> 中，只在 <code>prefill</code> 阶段使用，<code>generate</code> 阶段不使用（或者说隐式使用）</li>
</ul>
<h3 id="54-decoder-layer-forward"><a class="markdownIt-Anchor" href="#54-decoder-layer-forward"></a> 5.4 <code>decoder layer forward</code></h3>
<ul>
<li><code>LLM</code> 的计算量几乎都体现在 <code>decoder layer forward</code> 上</li>
<li>从 <code>layer norm</code> 位置角度来看，<code>Qwen2</code> 模型属于 <code>pre-LM</code>，即：
<ol>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>x</mi><mo>+</mo><mi>M</mi><mi>H</mi><mi>A</mi><mo stretchy="false">(</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x=x+MHA(LayerNorm(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>x</mi><mo>+</mo><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy="false">(</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x=x+FFN(LayerNorm(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x = LayerNorm(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></li>
</ol>
</li>
<li>模型包含 <code>24</code> 层 <code>decoder layer</code>，每层包含 <code>2</code> 个子层：
<ol>
<li><code>multi-head self-attention</code>（<code>MHA</code>）</li>
<li><code>feed forward network</code>（<code>FFN</code>）</li>
</ol>
</li>
<li>为了减小计算量和参数量，<code>Qwen2</code> 模型使用了 <code>GQA (grouped query attention)</code> 方法：
<ol>
<li>对于 <code>query</code> 来讲，每层 <code>MHA</code> 包含 <code>14</code> 个头，每个头的 <code>head_dim = 64</code></li>
<li>对于 <code>key</code> 和 <code>value</code> 来讲，每层 <code>MHA</code> 包含 <code>2</code> 个头，每个头的 <code>head_dim = 64</code></li>
<li>计算时，需要将 <code>key</code> 和 <code>value</code> 的 <code>head</code> 通过 <code>repeat</code> 扩展到 <code>14</code> 个头</li>
</ol>
</li>
<li>同时，<code>Qwen2</code> 使用了 <code>KV cache</code> 算法，即：
<ol>
<li>在 <code>prefill</code> 阶段，<code>key</code> 和 <code>value</code> 会被缓存下来</li>
<li>在 <code>generate</code> 阶段，之前的 <code>key</code> 和 <code>value</code> 会被直接使用不再计算，只计算最后一个 <code>token</code> 的 <code>query / key / value</code></li>
</ol>
</li>
<li>在 <code>prefill</code> 阶段：
<ul>
<li>输入为 <code>hidden state</code>，<code>shape = [1, 36, 896]</code>，其中 <code>36</code> 是 <code>seq_len</code>，<code>896</code> 是 <code>hidden_dim</code></li>
<li>输入逐层经过 <code>decoder layer</code>，最后输出 <code>hidden state</code>，和输入 <code>shape</code> 一样（<code>shape = [1, 36, 896]</code>）</li>
<li>在这一阶段，每一层的每个头的每个位置（<code>token position</code>）的 <code>key</code> 和 <code>value</code> 都会被缓存下来，<code>shape = [2, 1, 24, 2, 36, 64]</code>，其中：
<ul>
<li><code>2</code> 是 <code>key / value</code></li>
<li><code>1</code> 是 <code>batch_size</code></li>
<li><code>24</code> 是 <code>layers</code></li>
<li><code>36</code> 是 <code>seq_len</code></li>
<li><code>2</code> 是 <code>key_value_head_num</code></li>
<li><code>64</code> 是 <code>head_dim</code></li>
</ul>
</li>
<li>每个 <code>decoder layer</code> 层的 <code>MHA</code> 都需要 <code>causal attention</code>，即 <code>is_causal = True</code></li>
<li>输出的 <code>hidden state</code> 的 <strong><font color='red'> 最后一个 </font> <code>token position</code> 的 <code>feature</code> (<code>shape = [1, 896]</code>)</strong> 会被输入到 <code>fc</code> 层，输出 <code>shape = [1, 151936]</code>，<code>151936</code> 是 <code>vocab_size</code></li>
<li>然后通过 <code>decode method</code> 得到最终的 <code>token id</code></li>
</ul>
</li>
<li>在 <code>generate</code> 阶段：
<ul>
<li>输入为 <strong>预填充阶段最终输出的 <code>token id</code> 对应的 <code>token embedding</code>，<code>shape = [1, 1, 896]</code></strong></li>
<li>输入逐层经过 <code>decoder layer</code>，最后输出 <code>hidden state</code>，和输入 <code>shape</code> 一样（<code>shape = [1, 1, 896]</code>）</li>
<li>在这一阶段，每一层的每个头的之前的位置（<code>token position</code>）的 <code>key</code> 和 <code>value</code> 都会被直接使用，不再计算；只计算最后一个 <code>token</code> 的 <code>query / key / value</code>，并将计算得到的 <code>key / value</code> 缓存下来，缓存的 <code>key / value</code> 会拼接到之前的 <code>key / value</code> 上，形成新的 <code>key / value</code>，<code>shape = [2, 1, 24, 14, 36 + 1, 64]</code></li>
<li>每个 <code>decoder layer</code> 层的 <code>MHA</code> 的输入 <code>shape</code> 如下：
<ul>
<li><code>query</code>: <code>shape = [1, 14, 1, 64]</code></li>
<li><code>key / value</code>: <code>shape = [1, 14, 37, 64]</code></li>
<li><strong>is_causal = False</strong>，因为 <code>query</code> 长度为 <code>1</code>，不需要 <code>causal attention</code></li>
</ul>
</li>
<li>最后一层 <code>decoder layer</code> 的输出经过 <code>fc</code> 和 <code>decode method</code> 得到最终的 <code>token id</code></li>
<li>重复直到生成的 <code>token id</code> 数量达到 <code>max_new_tokens</code> 或生成的 <code>token id</code> 为 <code>eos</code> 为止</li>
</ul>
</li>
</ul>
<h2 id="6-decode-method"><a class="markdownIt-Anchor" href="#6-decode-method"></a> 6. <code>decode method</code></h2>
<ul>
<li><code>decode method</code> 实际上属于模型 <code>forward</code> 过程中的一部分，但是为了方便理解，这里单独拎出来讲</li>
<li><code>decode method</code> 的作用是将 <code>vocab logits</code> 映射到 <code>token id</code></li>
<li>最简答的 <code>decode method</code> 是 <code>argmax</code> 方法，即取 <code>vocab logits</code> 中最大的值对应的 <code>token id</code>，但是这种方法会导致生成的文本过于单一</li>
<li>实际上 <code>Qwen2</code> 使用了五个串联的 <code>decode method</code>，分别是：
<ul>
<li><code>RepetitionPenaltyLogitsProcessor</code></li>
<li><code>TemperatureLogitsWarper</code></li>
<li><code>TopKLogitsWarper</code></li>
<li><code>TopPLogitsWarper</code></li>
<li><code>SoftmaxSampler</code></li>
</ul>
</li>
</ul>
<h3 id="61-repetitionpenaltylogitsprocessor"><a class="markdownIt-Anchor" href="#61-repetitionpenaltylogitsprocessor"></a> 6.1 <code>RepetitionPenaltyLogitsProcessor</code></h3>
<p><code>RepetitionPenaltyLogitsProcessor</code> 的作用是惩罚重复的 <code>token id</code>，即：</p>
<ol>
<li>在预测的 <code>vocab logits</code> 中，找到之前所有 <code>token id</code> 对应的 <code>logits</code></li>
<li>如果 <code>logits &gt; 0</code>，则将 <code>logits</code> 除以一个 <code>penalty</code>，<code>penalty</code> 的值取 <code>1.1</code></li>
<li>如果 <code>logits &lt; 0</code>，则将 <code>logits</code> 乘以一个 <code>penalty</code>，<code>penalty</code> 的值取 <code>1.1</code></li>
<li>目的是让模型更倾向于生成不重复的 <code>token id</code></li>
</ol>
<h3 id="62-temperaturelogitswarper"><a class="markdownIt-Anchor" href="#62-temperaturelogitswarper"></a> 6.2 <code>TemperatureLogitsWarper</code></h3>
<p><code>TemperatureLogitsWarper</code> 的作用是调整 <code>vocab logits</code> 的温度，即：</p>
<ol>
<li>将 <code>vocab logits</code> 除以一个 <code>temperature</code>，<code>temperature</code> 的值取 <code>0.7</code></li>
<li>目的是提高模型的生成多样性</li>
</ol>
<h3 id="63-topklogitswarper"><a class="markdownIt-Anchor" href="#63-topklogitswarper"></a> 6.3 <code>TopKLogitsWarper</code></h3>
<p><code>TopKLogitsWarper</code> 的作用是截断 <code>vocab logits</code>，即：</p>
<ol>
<li>保留 <code>vocab logits</code> 中最大的 <code>k</code> 个值，其他值置为 <code>-inf</code>，<code>k</code> 的值取 <code>20</code></li>
<li>目的是降低模型的生成多样性，提高生成的准确性</li>
</ol>
<h3 id="64-topplogitswarper"><a class="markdownIt-Anchor" href="#64-topplogitswarper"></a> 6.4 <code>TopPLogitsWarper</code></h3>
<p><code>TopPLogitsWarper</code> 的作用是截断 <code>vocab probs</code>，即：</p>
<ol>
<li>将 <code>vocab logit</code> 通过 <code>softmax</code> 变成 <code>vocab probs</code></li>
<li>将 <code>vocab probs</code> 从大到小排序，累加到 <code>p</code> 大于 <code>top-p</code> 为止，保留这些 <code>vocab logits</code>，其他值置为 <code>-inf</code></li>
<li><code>top-p</code> 的值取 <code>0.8</code>，最终至少需要保留一个 <code>token id</code></li>
<li>目的是降低模型的生成多样性，提高生成的准确性</li>
</ol>
<h3 id="65-softmaxsampler"><a class="markdownIt-Anchor" href="#65-softmaxsampler"></a> 6.5 <code>SoftmaxSampler</code></h3>
<ol>
<li>将 <code>vocab logits</code> (此时只有少量元素不是 <code>-inf</code>) 通过 <code>softmax</code> 变成 <code>vocab probs</code></li>
<li>根据 <code>vocab probs</code> 采样一个 <code>token id</code>，作为最终的输出</li>
</ol>
<h2 id="7-总结"><a class="markdownIt-Anchor" href="#7-总结"></a> 7. 总结</h2>
<ul>
<li>本文主要介绍了 <code>hugging face</code> 和 <code>transformers</code> 的使用方法，以及 <code>Qwen2-0.5B-Instruct</code> 模型的推理过程</li>
<li><code>GPT-like</code> 模型的推理过程主要包括 <code>tokenize</code>、<code>RoPE</code>、<code>attention mask</code>、<code>decoder layer forward</code>、<code>decode method</code> 等步骤</li>
<li><code>Qwen2</code> 模型使用了 <code>RoPE</code>、<code>GQA</code>、<code>KV cache</code> 等技术，提高了模型的计算效率和参数量</li>
<li><code>decode method</code> 使用了 <code>RepetitionPenaltyLogitsProcessor</code>、<code>TemperatureLogitsWarper</code>、<code>TopKLogitsWarper</code>、<code>TopPLogitsWarper</code>、<code>SoftmaxSampler</code> 等方法，提高了模型的生成多样性和准确性</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/10/21/%E7%94%A8%E6%A0%91%E8%8E%93%E6%B4%BE-5-%E6%90%AD%E5%BB%BA-NAS-%E7%9A%84-worklog/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/10/21/%E7%94%A8%E6%A0%91%E8%8E%93%E6%B4%BE-5-%E6%90%AD%E5%BB%BA-NAS-%E7%9A%84-worklog/" class="post-title-link" itemprop="url">用树莓派 5 搭建 NAS 的 worklog</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-10-21 12:22:45" itemprop="dateCreated datePublished" datetime="2024-10-21T12:22:45+08:00">2024-10-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/worklog/" itemprop="url" rel="index"><span itemprop="name">worklog</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/10/21/%E7%94%A8%E6%A0%91%E8%8E%93%E6%B4%BE-5-%E6%90%AD%E5%BB%BA-NAS-%E7%9A%84-worklog/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/10/21/%E7%94%A8%E6%A0%91%E8%8E%93%E6%B4%BE-5-%E6%90%AD%E5%BB%BA-NAS-%E7%9A%84-worklog/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="0-背景知识"><a class="markdownIt-Anchor" href="#0-背景知识"></a> 0. 背景知识</h2>
<ol>
<li><code>NAS</code> 是什么？
<ul>
<li><code>NAS</code> 的全称是 <code>Network Attached Storage</code>，网络附加存储，说白了就是一个低性能高容量的私有云服务器</li>
</ul>
</li>
<li><code>NAS</code> 能干什么用？
<ul>
<li><code>NAS</code> 可以作为家庭影院数据中心，<code>NAS</code> + 局域网文件传输协议 + 智能电视 + 家庭影院软件可以实现非常好的家庭观影体验</li>
<li><code>NAS</code> 可以作为私有云服务器，承担例如图床/视频床等功能，也可以建网站</li>
</ul>
</li>
<li>怎么做一个 <code>NAS</code>？
<ul>
<li>通常情况下，直接买一个成品 <code>NAS</code> 是一个省心的选择，外观看通常是一个可以插硬盘的盒子，本质是一个 <code>PC</code></li>
<li>我更喜欢自己手搓</li>
</ul>
</li>
</ol>
<h2 id="1-手搓-nas-方案"><a class="markdownIt-Anchor" href="#1-手搓-nas-方案"></a> 1. 手搓 <code>NAS</code> 方案</h2>
<ol>
<li><code>NAS</code> 手搓需要搞定 <code>NAS</code> 本体和网络两大块
<ol>
<li><code>NAS</code> 本体负责下载数据，保存数据和局域网内数据共享</li>
<li>网络部分负责让 <code>NAS</code> 本体成为一个公网可访问的设备</li>
</ol>
</li>
<li><code>NAS</code> 本体用树莓派 <code>5</code> 实现是一个不错的选择</li>
<li>网络部分用光猫桥接 + <code>DDNS</code> + 端口转发方案</li>
</ol>
<h2 id="2-nas-本体"><a class="markdownIt-Anchor" href="#2-nas-本体"></a> 2. <code>NAS</code> 本体</h2>
<h3 id="硬件"><a class="markdownIt-Anchor" href="#硬件"></a> 硬件</h3>
<ol>
<li><code>NAS</code> 本体是一个 <code>4GB</code> 版本树莓派 <code>5</code></li>
<li>一个 <code>32GB</code> 的 <code>SD</code> 卡作为系统盘</li>
<li>一块 <code>500GB</code> 的 <code>USB 3.0</code> 的移动机械硬盘（后续根据需求扩容）</li>
</ol>
<h3 id="软件"><a class="markdownIt-Anchor" href="#软件"></a> 软件</h3>
<ol>
<li>操作系统：<code>Ubuntu 24.04 Desktop arm64</code>，<a target="_blank" rel="noopener" href="https://mirror.tuna.tsinghua.edu.cn/ubuntu-cdimage/ubuntu/releases/24.04.1/release/ubuntu-24.04.1-preinstalled-desktop-arm64%2Braspi.img.xz">下载地址</a>
<ol>
<li>用 <code>Ubuntu</code> 的好处：社区活跃，遇到问题容易解决</li>
<li>坏处：预安装软件很多，比较大</li>
</ol>
</li>
<li>其他软件：根据需求安装，例如：
<ol>
<li><code>Samba</code> 局域网共享软件</li>
<li><code>RDP</code> 远程桌面软件</li>
<li><code>Transmission</code> 磁力链接下载器</li>
</ol>
</li>
</ol>
<h2 id="3-网络"><a class="markdownIt-Anchor" href="#3-网络"></a> 3. 网络</h2>
<p>和 <code>NAS</code> 本体比起来，网络才是手搓 <code>NAS</code> 最难的部分，主要包含如下几个部分</p>
<h3 id="公网-ip"><a class="markdownIt-Anchor" href="#公网-ip"></a> 公网 <code>IP</code></h3>
<ol>
<li>选择的宽带运营商是电信，电信的入户光纤是动态公网 <code>IPv4</code> 地址（这一点还是比较良心的）</li>
<li>光猫默认开启了路由模式，因此路由器的输入已经变成了局域网，为了简化网络拓扑，需要给电信客服打电话要求将光猫改成桥接模式，即光猫只承担光电转换功能，输出端口 <code>IP</code> 和输入端口 <code>IP</code> 一致</li>
<li>光猫开启桥接模式之后，路由器输入端口变成了公网 <code>IP</code>，通过 <code>PPPoE</code> 拨号上网，同时实测发现，光猫桥接模式下，下载速度更快</li>
</ol>
<h3 id="ddns"><a class="markdownIt-Anchor" href="#ddns"></a> <code>DDNS</code></h3>
<ol>
<li>虽然路由器的输入已经变成公网 <code>IP</code>，但是动态的，几乎每天都在发生变化</li>
<li>因此需要用到 <code>DDNS</code> 服务，让动态 <code>IP</code> 绑定到静态的域名上，域名之前已购买，只需要在顶级域名之前加上一个 <code>A</code> 记录的子域名</li>
<li>由于家里用的路由器是小米 <code>be6500 pro</code> 型号，这个路由器本身并不支持腾讯云（<code>dnspod</code>）的 <code>DDNS</code> 服务，所以有两条路可以选：
<ol>
<li>刷机到 <code>Openwrt</code> 路由器固件，这个开源固件功能十分强大，但坏处是路由器无法再绑定到米家 <code>APP</code> 实现远程控制的一些官方功能</li>
<li>另外一种方法是通过某种方法开启路由器的 <code>ssh</code> 权限，登录到路由器内部，在内部开启 <code>dnspod DDNS</code></li>
</ol>
</li>
<li>这里选择了第二种方法，<code>ssh</code> 开启教程在 <a target="_blank" rel="noopener" href="https://www.gaicas.com/xiaomi-be6500-pro.html">这里</a></li>
<li>开启 <code>ssh</code> 后，就可以登录到路由器 <code>terminal</code>，然而路由器使用的是小米自己魔改的 <code>XiaoQiang Linux</code> 操作系统，包管理工具以及软件源什么的完全搞不懂，也很难查到相关资料，所以常用的 <code>DDNS</code> 服务软件例如 <a target="_blank" rel="noopener" href="https://github.com/jeessy2/ddns-go"><code>ddns-go</code></a> 什么的也无法正常安装和配置</li>
<li>在仔细了解了 <code>DDNS</code> 服务的基本原理之后，决定用 <code>SHELL</code> 手写一个 <code>DDNS</code> 服务
<ol>
<li><code>DDNS</code> 的原理（仅在 <code>dnspod</code> 服务商上测试过）：客户端（路由器）定期检查输入端口 <code>IP</code>，当发现和 <code>dnspod</code> 服务商记录的这个域名绑定的 <code>IP</code> 不一致时，就给 <code>dnspod</code> 发一条修改绑定关系的请求，<code>dnspod</code> 更改后，新的 “域名——<code>IP</code>” 绑定关系就建立了</li>
<li>这里涉及到几个关键：
<ol>
<li><code>API Token</code>：上面这个修改过程显然不是任何人都可以改的，你只能修改自己名下的域名绑定的 <code>IP</code>，所以需要一个密钥来和 <code>dnspod</code> 服务器交互，这个密钥在 <code>https://console.dnspod.cn/account/token/token</code> 创建</li>
<li>查找域名和记录对应的 <code>ID</code>：由于 <code>dnspod</code> 的 <code>DDNS API</code> 要求域名和对应的记录是以 <code>ID</code> 的方式描述的，所以需要查到域名 <code>ID</code> 和记录 <code>ID</code>
<ol>
<li>域名 <code>ID</code>：
<ol>
<li><code>curl -s &quot;https://dnsapi.cn/Domain.List&quot;  -d &quot;login_token=&lt;your_token&gt;&amp;format=json&quot;</code> 得到输出查询结果</li>
<li>然后在查询结果中找到名下多个域名中想要查询域名的 <code>ID</code></li>
</ol>
</li>
<li>记录 <code>ID</code>：
<ol>
<li><code>curl -s &quot;https://dnsapi.cn/Record.List&quot;  -d &quot;login_token=&lt;your_token&gt;&amp;format=json&amp;domain_id=&lt;your_domain_id&gt;&amp;sub_domain=&lt;your_sub_domain&gt;&quot;</code> 得到查询结果</li>
<li>在查询到的此域名下多条记录中，找到关注的记录 <code>ID</code></li>
</ol>
</li>
</ol>
</li>
<li>查询当前 <code>IP</code>：<code>curl -s http://ipinfo.io/ip</code></li>
<li>更新 <code>DNS</code> 记录：<code>curl -s -X POST &quot;https://dnsapi.cn/Record.Modify&quot;  -d &quot;login_token=$&#123;API_TOKEN&#125;&quot; -d &quot;format=json&quot; -d &quot;domain_id=$&#123;DOMAIN_ID&#125;&quot; -d &quot;record_id=$&#123;RECORD_ID&#125;&quot; -d &quot;sub_domain=$&#123;SUB_DOMAIN&#125;&quot; -d &quot;record_line=$&#123;RECORD_LINE&#125;&quot; -d &quot;record_type=$&#123;RECORD_TYPE&#125;&quot; -d &quot;value=$&#123;CURRENT_IP&#125;&quot;</code></li>
</ol>
</li>
<li>然后将此 <code>DDNS_update.sh</code> 文件注册到 <code>crontab</code> 中，每 <code>5</code> 分钟更新一次</li>
</ol>
</li>
<li>确实可以正常更新 <code>DNS</code>，不过忙完之后才发现可以在树莓派上实现，不用自己写 <code>SHELL</code>…</li>
</ol>
<h3 id="端口转发"><a class="markdownIt-Anchor" href="#端口转发"></a> 端口转发</h3>
<ul>
<li>外网只能访问到路由器，如果想要通过 <code>ssh</code> 实现外网直连树莓派，那么需要在路由器上配置端口转发</li>
<li>由于目前只有 <code>SSH</code> 和 <code>VNC</code> 两个远程访问需求，所以只开了 <code>22</code> 的 <code>TCP</code> 端口转发</li>
<li><code>VNC</code> 可以通过 <code>ssh</code> + 端口转发实现，不用开 <code>5900</code> 端口，开的越少内网设备越安全</li>
<li><code>VNC</code> 具体使用方法
<ol>
<li>在树莓派上开启 <code>VNC</code> 服务，并打开 <code>5900</code> 监听端口</li>
<li>由于路由器只配置了 <code>22</code> 端口转发，所以这个 <code>5900</code> 端口在公网是无法访问的</li>
<li>这时候就需要用到 <code>ssh</code> 的端口转发功能，在本地电脑上执行如下命令： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在连接 ssh 的时候，开启端口转发，将本地的 `5900` 端口转发到树莓派的 `5900` 端口</span></span><br><span class="line"><span class="comment"># 实际上走的还是服务器的 `22` 端口</span></span><br><span class="line">ssh -L 5900:localhost:5900 &lt;your_username&gt;@&lt;your_domain&gt;</span><br></pre></td></tr></table></figure>
</li>
<li>建立好 <code>ssh</code> 连接后，就可以在本地电脑上通过 <code>localhost:5900</code> 访问树莓派的 <code>VNC</code> 服务了（一定要注意，是连接 <font color='red'><strong>本地 localhost 不是服务器</strong></font> <code>5900</code> 端口）</li>
</ol>
</li>
</ul>
<h2 id="4-使用体验和后续计划"><a class="markdownIt-Anchor" href="#4-使用体验和后续计划"></a> 4. 使用体验和后续计划</h2>
<h3 id="使用体验"><a class="markdownIt-Anchor" href="#使用体验"></a> 使用体验</h3>
<ol>
<li>用外网可以直连树莓派，可以用 <code>SSH</code> 远程给树莓派下发一些下载任务，也可以用 <code>VNC</code> 处理一些需要 <code>GUI</code> 的需求</li>
<li>设置了移动硬盘开机自动挂载，索尼电视安装 <code>KODI</code> 通过 <code>Samba</code> 协议看 <code>4K</code> 电影体验很震撼</li>
</ol>
<h3 id="后续计划"><a class="markdownIt-Anchor" href="#后续计划"></a> 后续计划</h3>
<ol>
<li>开放 <code>http</code> 协议端口，在树莓派上用 <code>Nginx</code> 等引擎让树莓派作为个人博客的图床和视频床</li>
<li>扩展硬盘架，树莓派外接 <a target="_blank" rel="noopener" href="https://wiki.geekworm.com/X1009"><code>16 pin PCIE</code> 转多口 <code>SATA</code> 扩展板</a> ，连接机械硬盘架</li>
</ol>
<h2 id="5-最终版效果"><a class="markdownIt-Anchor" href="#5-最终版效果"></a> 5. 最终版效果</h2>
<p><img src="https://s2.loli.net/2025/06/08/EI1Cr2WXAkvhKfU.jpg" alt="nas.jpg" /></p>
<ul>
<li>买了一个二手服务器电源 <code>12v</code> 供电，买了一个车载 <code>12v</code> 转 <code>5v</code> 的电源模块，这两个一起给所有设备供电</li>
<li>买了树莓派 <code>m2</code> 转 <code>SATA * 6</code> 的扩展板，用 <code>16pin PCIE</code> 连到主板上</li>
<li>硬盘架现在是两块 <code>16T</code> 服务器拆机机械硬盘 + 四块 <code>500G</code> 单片机械硬盘（凑数用的），后续会根据实际情况逐步把 <code>500G</code> 硬盘换成 <code>16T</code> 的服务器氦气盘</li>
<li>因为供电电流充足（服务器电源可最高提供 <code>50A</code> 稳定电流），在不同时和多个硬盘交互的情况下，<code>16T</code> 硬盘读写速度差不多 <code>260MB/s</code>，<code>500G</code> 硬盘读写速度差不多 <code>100MB/s</code></li>
<li>如果有小容量高速读写需求的话，主板上有一块 <code>512GB</code> 的 <code>Flash</code> 可以用</li>
<li>一堆风扇组成了一个小型的散热系统，电视柜当机箱用</li>
<li>非常耐操，已经稳定运行半年多了，几乎没有关过机，随时随地访问私有云 + 家庭影院确实爽</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/10/12/LoRA-Low-Rank-Adaptation-of-Large-Language-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/10/12/LoRA-Low-Rank-Adaptation-of-Large-Language-Models/" class="post-title-link" itemprop="url">LoRA: Low-Rank Adaptation of Large Language Models</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-10-12 09:59:20" itemprop="dateCreated datePublished" datetime="2024-10-12T09:59:20+08:00">2024-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tuning/" itemprop="url" rel="index"><span itemprop="name">Tuning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/10/12/LoRA-Low-Rank-Adaptation-of-Large-Language-Models/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/10/12/LoRA-Low-Rank-Adaptation-of-Large-Language-Models/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.09685">https://arxiv.org/pdf/2106.09685</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/microsoft/LoRA">https://github.com/microsoft/LoRA</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一种名为 <code>Low Rank Adaption (LoRA)</code> 的大模型微调技术，可有效降低大模型微调过程中的可微调参数（降低 <code>10000</code> 倍）和显存占用（降低 <code>3</code> 倍）</li>
<li>具体做法是在 <code>Linear</code> 算子和 <code>Embedding</code> 算子中插入可训练的参数量较少的低秩分解矩阵，冻结原始参数，只训练低秩分解矩阵</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="总体流程"><a class="markdownIt-Anchor" href="#总体流程"></a> 总体流程</h3>
<p><img src="https://s2.loli.net/2024/10/12/ITtG5jfKamDpVMF.png" alt="lora_1.png" /></p>
<ul>
<li>这张图几乎包含了 <code>LoRA</code> 全部的信息量：
<ol>
<li><code>LoRA</code> 在原始 <code>Linear</code> 参数的基础上，加入了低秩分解矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>r</mi></mrow></msup><mo separator="true">,</mo><mi>B</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>r</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A\in\mathbb{R}^{d\times r},B\in\mathbb{R}^{r\times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.043548em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></li>
<li><code>r &lt;&lt; d</code>，所以叫 <strong>低</strong> 秩</li>
<li>原始参数冻结，只训练 <code>A</code> 和 <code>B</code></li>
<li>矩阵 <code>A</code> 用均值为 <code>0</code> 的正态分布初始化</li>
<li>矩阵 <code>B</code> 用全 <code>0</code> 初始化</li>
</ol>
</li>
</ul>
<h3 id="对应代码"><a class="markdownIt-Anchor" href="#对应代码"></a> 对应代码</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoRALinear</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_features, out_features, r</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LoRALinear, self).__init__()</span><br><span class="line">        self.in_features = in_features</span><br><span class="line">        self.out_features = out_features</span><br><span class="line">        self.r = r</span><br><span class="line">        <span class="comment"># 线性层的权重矩阵</span></span><br><span class="line">        self.weight = nn.Parameter(torch.randn(out_features, in_features))</span><br><span class="line">        self.bias = nn.Parameter(torch.zeros(out_features))</span><br><span class="line">        <span class="comment"># LoRA的低秩分解矩阵</span></span><br><span class="line">        self.A = nn.Parameter(torch.randn(r, out_features))</span><br><span class="line">        self.B = nn.Parameter(torch.zeros(in_features, r))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 应用线性层</span></span><br><span class="line">        output = torch.matmul(x, self.weight) + self.bias</span><br><span class="line">        <span class="comment"># 应用LoRA的低秩分解矩阵</span></span><br><span class="line">        output = output + torch.matmul(x, torch.matmul(self.B, self.A))</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convert_to_standard_linear</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 将LoRA参数转换到标准线性层中</span></span><br><span class="line">        self.weight = nn.Parameter(self.weight + torch.matmul(self.B, self.A))</span><br><span class="line">        <span class="comment"># 删除LoRA的低秩分解矩阵</span></span><br><span class="line">        <span class="keyword">del</span> self.A</span><br><span class="line">        <span class="keyword">del</span> self.B</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoRATransformerLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, r</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LoRATransformerLayer, self).__init__()</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.r = r</span><br><span class="line">        <span class="comment"># 自注意力模块的权重矩阵</span></span><br><span class="line">        self.Wq = LoRALinear(d_model, d_model, r)</span><br><span class="line">        self.Wk = LoRALinear(d_model, d_model, r)</span><br><span class="line">        self.Wv = LoRALinear(d_model, d_model, r)</span><br><span class="line">        self.Wo = nn.Linear(d_model, d_model)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 计算查询、键和值的投影</span></span><br><span class="line">        q = self.Wq(x)</span><br><span class="line">        k = self.Wk(x)</span><br><span class="line">        v = self.Wv(x)</span><br><span class="line">        <span class="comment"># 计算自注意力得分和输出</span></span><br><span class="line">        attn_scores = torch.matmul(q, k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / (self.d_model**<span class="number">0.5</span>)</span><br><span class="line">        attn_weights = torch.softmax(attn_scores, dim=-<span class="number">1</span>)</span><br><span class="line">        attn_output = torch.matmul(attn_weights, v)</span><br><span class="line">        <span class="comment"># 计算最终的输出</span></span><br><span class="line">        output = self.Wo(attn_output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convert_to_standard_transformer</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 将LoRA参数转换到标准Transformer网络中</span></span><br><span class="line">        self.Wq = self.Wq.convert_to_standard_linear()</span><br><span class="line">        self.Wk = self.Wk.convert_to_standard_linear()</span><br><span class="line">        self.Wv = self.Wv.convert_to_standard_linear()</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line">d_model = <span class="number">512</span></span><br><span class="line">r = <span class="number">8</span></span><br><span class="line">layer = LoRATransformerLayer(d_model, r)</span><br><span class="line">input_tensor = torch.randn(<span class="number">10</span>, <span class="number">32</span>, d_model)</span><br><span class="line">output_tensor = layer(input_tensor)</span><br><span class="line"><span class="built_in">print</span>(output_tensor.shape)  <span class="comment"># 输出: torch.Size([10, 32, 512])</span></span><br><span class="line"><span class="comment"># 转换到标准Transformer网络</span></span><br><span class="line">standard_layer = layer.convert_to_standard_transformer()</span><br><span class="line"><span class="built_in">print</span>(standard_layer)</span><br></pre></td></tr></table></figure>
<h3 id="实际使用"><a class="markdownIt-Anchor" href="#实际使用"></a> 实际使用</h3>
<ol>
<li>实际使用时，可以用 <code>LoRA_Layer</code>替换大模型中所有 <code>Transformer</code> 层的 <code>Linear</code> 和 <code>Embedding</code>，对 <code>FFN</code> 中的 <code>MLP</code> <strong>不做替换</strong></li>
<li>可以不同的任务微调不同的 <code>LoRA</code> 模型</li>
<li>部署时可以用重参数化融合的方法，将 <code>LoRA</code> 训练参数融合到原始模型中，不会付出任何推理代价</li>
</ol>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>有道理，也挺好用，但据说真正做大模型预训练 / 微调的没人用</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/10/11/llava-Visual-Instruction-Tuning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/10/11/llava-Visual-Instruction-Tuning/" class="post-title-link" itemprop="url">LLaVA: Visual Instruction Tuning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-10-11 17:13:52" itemprop="dateCreated datePublished" datetime="2024-10-11T17:13:52+08:00">2024-10-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/10/11/llava-Visual-Instruction-Tuning/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/10/11/llava-Visual-Instruction-Tuning/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2304.08485">https://arxiv.org/pdf/2304.08485</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://llava-vl.github.io">https://llava-vl.github.io</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一种类似 <code>GPT-4</code> 的图文多模态模型 <code>Large Language and Vision Assistant (LLaVA)</code>，基于开源的 <code>CLIP</code> 和 <code>LLaMA</code> 分别作为图文编码器，因此 <code>LLaVA</code> 也完全开源</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="多模态指令遵循数据生成"><a class="markdownIt-Anchor" href="#多模态指令遵循数据生成"></a> 多模态指令遵循数据生成</h3>
<ul>
<li>已有：图形——文本对数据集</li>
<li>需要：图文指令遵循数据集，格式为：
<ul>
<li>图片：原始图片</li>
<li>问题：由 <code>GPT-4</code> 生成，输入原始 “图片-文本” 给 <code>GPT-4</code>，让 <code>GPT-4</code> 就这些信息提问</li>
<li>答案：同上，让 <code>GPT-4</code> 回答自己提出的问题</li>
</ul>
</li>
</ul>
<h3 id="模型结构"><a class="markdownIt-Anchor" href="#模型结构"></a> 模型结构</h3>
<ul>
<li>图像模型：<code>CLIP ViT-L/14</code> 已做过图像文本对齐的预训练图像编码器模型</li>
<li>大语言模型：<code>LLaMA</code> 预训练模型</li>
<li>连接层：简单的线性映射层</li>
</ul>
<h3 id="如何训练和微调"><a class="markdownIt-Anchor" href="#如何训练和微调"></a> 如何训练和微调</h3>
<h4 id="训练"><a class="markdownIt-Anchor" href="#训练"></a> 训练</h4>
<ul>
<li>冻结图像编码模型</li>
<li>冻结 <code>LLM</code> 模型</li>
<li>训练连接层</li>
</ul>
<h3 id="微调"><a class="markdownIt-Anchor" href="#微调"></a> 微调</h3>
<ul>
<li>冻结图像编码模型</li>
<li>训练 <code>LLM</code> 模型</li>
<li>训练连接层</li>
</ul>
<pre class="mermaid">graph TD;
    A([视觉编码器]) --> B([连接层])
    B --> C([LLaMA语言模型])
    D[语言指令（例如：“请根据这张图片生成一个详细的描述”）] --> C
    C --> E[文本响应]
    F[图像] --> A
    G[系统消息（例如：对话历史记录）] --> C</pre>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>简单直接，来自开源，也回馈开源，很棒！</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/10/11/Grounding-DINO-Marrying-DINO-with-Grounded-Pre-Training-for-Open-Set-Object-Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/10/11/Grounding-DINO-Marrying-DINO-with-Grounded-Pre-Training-for-Open-Set-Object-Detection/" class="post-title-link" itemprop="url">Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-10-11 15:44:25" itemprop="dateCreated datePublished" datetime="2024-10-11T15:44:25+08:00">2024-10-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MultiModal/" itemprop="url" rel="index"><span itemprop="name">MultiModal</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/10/11/Grounding-DINO-Marrying-DINO-with-Grounded-Pre-Training-for-Open-Set-Object-Detection/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/10/11/Grounding-DINO-Marrying-DINO-with-Grounded-Pre-Training-for-Open-Set-Object-Detection/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.05499">https://arxiv.org/pdf/2303.05499</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/IDEA-Research/GroundingDINO">https://github.com/IDEA-Research/GroundingDINO</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本文提出一种跨模态开放集目标检测算法，即：输入一张图片 和 需要检测内容的文本描述，给出框</li>
<li>其中文本描述可以是开放的（任意内容的文本）</li>
<li>本文最重要的部分是模型结构中图文多模态内容的融合</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2024/10/11/DNWilYg47RICbOT.png" alt="groundingdino.png" /></p>
<ul>
<li><strong>本质是通过多次 <code>Cross-Attention</code> 来做多模态信息融合</strong></li>
<li><code>text backbone</code> 实际是 <code>BERT</code></li>
<li><code>image backbone</code> 实际是 <code>SwinTransformer</code></li>
<li>其中的 <code>Language-guide Query Selection</code> 是根据文本特征，找到图像特征中最匹配的部分初始化跨模态解码器</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>这篇论文想要解决的任务时开放集目标检测，但其多模态信息融合方式让其出圈，成了多模态领域的经典</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/10/11/DINOv2-Learning-Robust-Visual-Features-without-Supervision/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/10/11/DINOv2-Learning-Robust-Visual-Features-without-Supervision/" class="post-title-link" itemprop="url">DINOv2: Learning Robust Visual Features without Supervision</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-10-11 14:56:59" itemprop="dateCreated datePublished" datetime="2024-10-11T14:56:59+08:00">2024-10-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Self-Supervised/" itemprop="url" rel="index"><span itemprop="name">Self-Supervised</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/10/11/DINOv2-Learning-Robust-Visual-Features-without-Supervision/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/10/11/DINOv2-Learning-Robust-Visual-Features-without-Supervision/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2304.07193">https://arxiv.org/pdf/2304.07193</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/dinov2">https://github.com/facebookresearch/dinov2</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>和 <code>DINO</code> 一样，都是做自监督视觉预训练的，对于 <code>DINO</code> 的主要升级是构建了一个大规模自动化数据处理管线，构建了 <code>LVD-142M</code> 高质量数据集</li>
<li>用这些数据集预训练了一个 <code>1B</code> 参数的 <code>ViT</code> 模型，通过无监督蒸馏的方式，得到用于不同任务的小模型</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="自动化数据处理管线"><a class="markdownIt-Anchor" href="#自动化数据处理管线"></a> 自动化数据处理管线</h3>
<p><img src="https://s2.loli.net/2024/10/11/qUjk2JMiucb8pQn.png" alt="dino_v2.png" /></p>
<ul>
<li>自动化处理流程包括如下几个步骤，不断重复迭代</li>
</ul>
<h4 id="1-数据收集"><a class="markdownIt-Anchor" href="#1-数据收集"></a> 1. 数据收集</h4>
<ul>
<li><code>DINOv2</code> 的数据源包括一个大型的未筛选图像数据集和一个较小的经过筛选的图像数据集</li>
<li>未筛选数据集来自网络爬取</li>
<li>筛选数据集来自 <code>ImageNet-22k</code> / <code>Google Landmarks</code> 等</li>
</ul>
<h4 id="2-图像嵌入"><a class="markdownIt-Anchor" href="#2-图像嵌入"></a> 2. 图像嵌入</h4>
<ul>
<li>对于未筛选数据集，用一个训练好的 <code>ViT-H/16</code> 计算得到图像 <code>embedding vector</code></li>
</ul>
<h4 id="3-图像去重"><a class="markdownIt-Anchor" href="#3-图像去重"></a> 3. 图像去重</h4>
<ul>
<li>用特征空间下去重算法，将未筛选的数据集去重</li>
</ul>
<h4 id="4-图像检索"><a class="markdownIt-Anchor" href="#4-图像检索"></a> 4. 图像检索</h4>
<ul>
<li>在特征空间下聚类，得到与筛选数据集类似的未筛选数据样本</li>
</ul>
<h4 id="5-数据增强"><a class="markdownIt-Anchor" href="#5-数据增强"></a> 5. 数据增强</h4>
<ul>
<li>让这些聚类得到的类似的未筛选样本作为筛选样本，不断扩大筛选样本的数量和场景丰富度</li>
</ul>
<h3 id="模型架构"><a class="markdownIt-Anchor" href="#模型架构"></a> 模型架构</h3>
<ul>
<li>和 <code>DINO v1</code> 中教师和学生使用动量更新的方式不同，<code>DINO v2</code> 使用了常见的 “大老师，小学生” 架构</li>
<li>先训练一个 <code>1B</code> 参数的 <code>ViT</code> 模型作为老师模型</li>
<li>然后再在各个不同任务数据上蒸馏得到小模型</li>
</ul>
<h3 id="训练策略优化"><a class="markdownIt-Anchor" href="#训练策略优化"></a> 训练策略优化</h3>
<ul>
<li>由于老师模型很大（<code>1B</code> 参数量），所以需要 <code>LM</code> 常用的训练加速方法，包括：
<ul>
<li><code>FlashAttention</code></li>
<li><code>Fully-shared Data Parallel (FSDP)</code> 等</li>
</ul>
</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>这套数据处理管线是本文重点，所有的自监督任务，自动化数据处理流程都是必不可少的</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/10/11/CLIP-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/10/11/CLIP-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision/" class="post-title-link" itemprop="url">CLIP: Learning Transferable Visual Models From Natural Language Supervision</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-10-11 14:33:00" itemprop="dateCreated datePublished" datetime="2024-10-11T14:33:00+08:00">2024-10-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MultiModal/" itemprop="url" rel="index"><span itemprop="name">MultiModal</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/10/11/CLIP-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/10/11/CLIP-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.00020">https://arxiv.org/pdf/2103.00020</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/OpenAI/CLIP">https://github.com/OpenAI/CLIP</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>CLIP</code> 是 <code>OpenAI</code> 提出的一种图文多模态对齐算法，在收集到的 <code>4</code> 亿对图片文本数据对上，将文本和图像编码在同一表达空间下，实现了图文模态的对齐</li>
<li>可以 <code>zero-shot</code> 迁移到其他计算机视觉任务上</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2024/10/11/pib2QxMDXOtNo19.png" alt="CLIP.png" /></p>
<h3 id="训练时"><a class="markdownIt-Anchor" href="#训练时"></a> 训练时</h3>
<ol>
<li><code>N</code> 对图片和文本各自编码</li>
<li>计算得到不同模态之间两两编码的 <strong>余弦相似度</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>N</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\in \mathbb{R}^{N\times N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span></span></span></span></span></span></span></span></li>
<li>使用对比学习的方式，提高 <code>N</code> 个正样本的相似度，降低剩余的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mn>2</mn></msup><mo>−</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">N^2-N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个样本的相似度</li>
</ol>
<h3 id="推理时以-imagenet-分类任务为例"><a class="markdownIt-Anchor" href="#推理时以-imagenet-分类任务为例"></a> 推理时（以 <code>ImageNet</code> 分类任务为例）</h3>
<ol>
<li>将 <code>ImageNet-1k</code> 的所有 <code>1000</code> 种类别标签，通过训练好的文本编码器，转换到特征空间中</li>
<li>将需要分类的图片，通过训练好的图片编码器，转换到特征空间中</li>
<li>图像编码找到余弦相似度最高的文本编码，对应的类别就是图片类别</li>
</ol>
<h3 id="模型选型"><a class="markdownIt-Anchor" href="#模型选型"></a> 模型选型</h3>
<ul>
<li>图像编码器：
<ul>
<li><code>Vision Transformer (ViT)</code></li>
<li><code>ResNet-50</code></li>
</ul>
</li>
<li>文本编码器：<code>Transformer</code>
<ul>
<li><code>63M</code> 参数</li>
<li><code>12</code> 层</li>
<li><code>512</code> 宽</li>
<li><code>49152</code> 词表大小</li>
<li><code>BPE</code> 文本编码方式</li>
</ul>
</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>简洁高效，像 <code>OpenAI</code> 固有的风格</li>
<li>有没有可能在 <code>GPT-4</code> 的多模态中用到呢？</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/10/11/DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/10/11/DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers/" class="post-title-link" itemprop="url">DINO: Emerging Properties in Self-Supervised Vision Transformers</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-10-11 13:56:46" itemprop="dateCreated datePublished" datetime="2024-10-11T13:56:46+08:00">2024-10-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Self-Supervised/" itemprop="url" rel="index"><span itemprop="name">Self-Supervised</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/10/11/DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/10/11/DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.14294">https://arxiv.org/pdf/2104.14294</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/dino">https://github.com/facebookresearch/dino</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>DINO（Distillation with No Labels）</code> 是一种自监督学习方法，主要用于 <code>Vision Transformer (ViT)</code> 的训练</li>
<li>在无标签的图片数据上训练模型，让模型学习图像的表示意义</li>
<li>利用 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1911.05722.pdf"><code>MoCo</code></a> 提出的 <code>Momentum Teacher</code> 算法做蒸馏</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2024/10/11/68LNGZCdlrh4y17.png" alt="dino_1.png" /></p>
<h3 id="训练流程"><a class="markdownIt-Anchor" href="#训练流程"></a> 训练流程</h3>
<ol>
<li>创建两个完全一样的网络，命名为教师 <code>teacher</code> 网络和学生 <code>student</code> 网络</li>
<li>对同一个输入 <code>x</code>，进行不同的数据增强，得到 <code>x1</code> 和 <code>x2</code></li>
<li>交叉计算对比损失，再求均值得到 <strong><code>loss for student</code></strong></li>
<li>只对 <code>student</code> 网络进行反向传播和梯度更新</li>
<li>基于 <code>student</code> 网络的参数更新 <code>teacher</code> 的参数，更新方式是 <code>EMA (exponential moving average)</code>，即：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>t</mi></msub><mo>=</mo><mi>λ</mi><msub><mi>θ</mi><mi>t</mi></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy="false">)</mo><msub><mi>θ</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">\theta_t=\lambda \theta_t+(1-\lambda)\theta_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">λ</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li>更新 <code>teacher</code> 网络输出的中心点：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>m</mi><mo>∗</mo><mi>C</mi><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>m</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo stretchy="false">(</mo><mi>t</mi><mn>1</mn><mo separator="true">,</mo><mi>t</mi><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C = m*C + (1 - m)*mean(t1, t2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">t</span><span class="mord">2</span><span class="mclose">)</span></span></span></span></li>
</ol>
<h3 id="中心化和锐化"><a class="markdownIt-Anchor" href="#中心化和锐化"></a> 中心化和锐化</h3>
<p><img src="https://s2.loli.net/2024/10/11/RgZf8HUTrwbYOND.png" alt="dino.png" /></p>
<ul>
<li>两种操作本质上是互补的，防止模型训练崩溃</li>
</ul>
<h4 id="中心化centering"><a class="markdownIt-Anchor" href="#中心化centering"></a> 中心化（<code>centering</code>）</h4>
<ul>
<li>中心化的目的是防止特征向量的某个维度占主导地位，从而导致模型输出分布过于集中</li>
<li>本质就是一种均值为 <code>0</code> 的归一化，可以提高模型训练的稳定性</li>
</ul>
<h4 id="锐化sharpening"><a class="markdownIt-Anchor" href="#锐化sharpening"></a> 锐化（<code>Sharpening</code>）</h4>
<ul>
<li>锐化操作的目的是增加教师网络输出的概率分布的锐度，使得输出的概率更加集中在少数几个维度上</li>
<li>实现上，锐化通过修改蒸馏温度系数实现</li>
</ul>
<h3 id="模型效果"><a class="markdownIt-Anchor" href="#模型效果"></a> 模型效果</h3>
<ul>
<li>比一众视觉自监督模型效果都好，比如：<code>MoCo v1/v2</code>，<code>SimCLR v1/v2</code> 等</li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>感觉是 <code>MoCo</code> 系列的升级，框架本身不变，加了数据，稳定了训练过程，增加了些许 <code>trick</code></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhangzhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">171</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">106</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhangzhe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js', () => {
    // 初始化 Mermaid 配置
    mermaid.initialize({
      theme    : 'dark',  // 设置主题
      logLevel : 3,  // 设置日志等级
      flowchart: { curve: 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 },
      themeVariables: {
        'fontFamily': 'Microsoft YaHei, Arial, sans-serif',  // 设置中文字体
      }
    });

    // 初始化 Mermaid 图表
    mermaid.init(undefined, document.querySelectorAll('pre.mermaid'));
  }, window.mermaid);
}
</script>


  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'eK3W25jybCO5jVUrYBBpAPqM-gzGzoHsz',
      appKey     : 'F4KVyUj9wHI5c80Bhz7O2uhq',
      placeholder: "说点什么再走吧...",
      avatar     : 'hide',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
