<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"real-zhangzhe.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Zhangzhe&#39;s Blog">
<meta property="og:url" content="https://real-zhangzhe.github.io/page/9/index.html">
<meta property="og:site_name" content="Zhangzhe&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhangzhe">
<meta property="article:tag" content="No mistakes in the tango, not like life.">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://real-zhangzhe.github.io/page/9/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Zhangzhe's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhangzhe's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">The projection of my life.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/archives/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/07/12/GQA-Grouped-Query-Attention/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/07/12/GQA-Grouped-Query-Attention/" class="post-title-link" itemprop="url">GQA: Grouped-Query Attention</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-07-12 12:55:14" itemprop="dateCreated datePublished" datetime="2024-07-12T12:55:14+08:00">2024-07-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Transformer/" itemprop="url" rel="index"><span itemprop="name">Transformer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/07/12/GQA-Grouped-Query-Attention/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/07/12/GQA-Grouped-Query-Attention/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.13245">https://arxiv.org/pdf/2305.13245</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本质是标准 <code>Multi-Head Attention</code> 和 <code>Multi-Query Attention</code> 的一个折衷。<br />
<img src="https://s2.loli.net/2024/07/12/zPEebjTWqMphBVt.png" alt="GQA.png" /></li>
<li>目的是 <strong>降低 <code>Attention</code> 过程内存带宽成本</strong>，并没有降低计算复杂度，计算复杂度依然是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">O</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiquery_attention_batched</span>(<span class="params">X, M, mask, P_q, P_k, P_v, P_o, num_groups</span>):</span></span><br><span class="line">    <span class="comment"># b: batch size</span></span><br><span class="line">    <span class="comment"># n: number of querys</span></span><br><span class="line">    <span class="comment"># m: number of keys / values</span></span><br><span class="line">    <span class="comment"># d: input dimension</span></span><br><span class="line">    <span class="comment"># H: number of heads</span></span><br><span class="line">    <span class="comment"># g: number of groups</span></span><br><span class="line">    <span class="comment"># h: number of heads per group</span></span><br><span class="line">    <span class="comment"># k: key / query dimention</span></span><br><span class="line">    <span class="comment"># v: value dimention</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="number">0</span> == P_q.size(<span class="number">0</span>) % num_groups</span><br><span class="line">    heads_per_group = P_q.size(<span class="number">0</span>) // num_groups</span><br><span class="line">    <span class="comment"># 应用线性变换获取查询Q（multi-head）</span></span><br><span class="line">    Q = torch.einsum(<span class="string">&quot;bnd,Hdk-&gt;bHkn&quot;</span>, X, P_q).view(</span><br><span class="line">        -<span class="number">1</span>, num_groups, heads_per_group, P_q.size(<span class="number">2</span>), X.size(<span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 应用线性变换获取键K和值V（single-head）</span></span><br><span class="line">    K = torch.einsum(<span class="string">&quot;bmd,gdk-&gt;bgmk&quot;</span>, M, P_k)</span><br><span class="line">    V = torch.einsum(<span class="string">&quot;bmd,gdv-&gt;bgmv&quot;</span>, M, P_v)</span><br><span class="line">    <span class="comment"># 计算注意力得分并应用掩码</span></span><br><span class="line">    logits = torch.einsum(<span class="string">&quot;bghkn,bgmk-&gt;bghnm&quot;</span>, Q, K)</span><br><span class="line">    <span class="comment"># mask 分组</span></span><br><span class="line">    mask = mask.view(-<span class="number">1</span>, num_groups, heads_per_group, mask.size(-<span class="number">2</span>), mask.size(-<span class="number">1</span>))</span><br><span class="line">    weights = F.softmax(logits + mask, dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 计算加权的值</span></span><br><span class="line">    O = torch.einsum(<span class="string">&quot;bghnm,bgmv-&gt;bghnv&quot;</span>, weights, V)</span><br><span class="line">    <span class="comment"># P_o 分组</span></span><br><span class="line">    P_o = P_o.view(num_groups, heads_per_group, P_o.size(-<span class="number">2</span>), P_o.size(-<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 应用输出变换</span></span><br><span class="line">    Y = torch.einsum(<span class="string">&quot;bghnv,ghvd-&gt;bnd&quot;</span>, O, P_o)</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"><span class="comment"># 假设参数和维度</span></span><br><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">num_queries = <span class="number">5</span></span><br><span class="line">num_keys = <span class="number">7</span>  <span class="comment"># 同时也是 num_values</span></span><br><span class="line">dim = <span class="number">64</span></span><br><span class="line">key_dim = <span class="number">32</span>  <span class="comment"># 同时也是 query_dim</span></span><br><span class="line">value_dim = <span class="number">48</span></span><br><span class="line">num_heads = <span class="number">8</span></span><br><span class="line">num_groups = <span class="number">4</span>  <span class="comment"># head 分成多少组，必须整除 num_heads</span></span><br><span class="line"><span class="comment"># 随机初始化输入数据和参数</span></span><br><span class="line">X = torch.randn(batch_size, num_queries, dim)</span><br><span class="line">M = torch.randn(batch_size, num_keys, dim)</span><br><span class="line">mask = torch.randn(batch_size, num_heads, num_queries, num_keys)</span><br><span class="line">P_q = torch.randn(num_heads, dim, key_dim)</span><br><span class="line">P_k = torch.randn(num_groups, dim, key_dim)     <span class="comment"># 组件 key / value 不共享</span></span><br><span class="line">P_v = torch.randn(num_groups, dim, value_dim)</span><br><span class="line">P_o = torch.randn(num_heads, value_dim, dim)</span><br><span class="line"><span class="comment"># 运行多查询注意力机制</span></span><br><span class="line">output = multiquery_attention_batched(X, M, mask, P_q, P_k, P_v, P_o, num_groups)</span><br><span class="line"><span class="built_in">print</span>(output.shape)  <span class="comment"># 应该输出: torch.Size([2, 5, 64])</span></span><br></pre></td></tr></table></figure>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li><code>GQA</code> 介于 <code>MHA</code> 和 <code>MQA</code> 之间，每个 <code>group</code> 内部实际上是 <code>MQA</code></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/07/11/MQA-Multi-Query-Attention/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/07/11/MQA-Multi-Query-Attention/" class="post-title-link" itemprop="url">MQA: Multi-Query Attention</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-07-11 13:24:35" itemprop="dateCreated datePublished" datetime="2024-07-11T13:24:35+08:00">2024-07-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Transformer/" itemprop="url" rel="index"><span itemprop="name">Transformer</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/07/11/MQA-Multi-Query-Attention/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/07/11/MQA-Multi-Query-Attention/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1911.02150">https://arxiv.org/pdf/1911.02150</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>本质很简单，就是把标准的 <code>Multi-Head Attention</code> 中的 <code>Key</code> 和 <code>Value</code> 退化为 <code>Single-Head</code>，<code>Query</code> 保留 <code>Multi-Head</code></li>
<li>目的是 <strong>降低 <code>Attention</code> 过程内存带宽成本</strong>，并没有降低计算复杂度，计算复杂度依然是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">O</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiquery_attention_batched</span>(<span class="params">X, M, mask, P_q, P_k, P_v, P_o</span>):</span></span><br><span class="line">    <span class="comment"># b: batch size</span></span><br><span class="line">    <span class="comment"># n: number of querys</span></span><br><span class="line">    <span class="comment"># m: number of keys / values</span></span><br><span class="line">    <span class="comment"># d: input dimension</span></span><br><span class="line">    <span class="comment"># h: number of heads</span></span><br><span class="line">    <span class="comment"># k: key / query dimention</span></span><br><span class="line">    <span class="comment"># v: value dimention</span></span><br><span class="line">    <span class="comment"># 应用线性变换获取查询Q（multi-head）</span></span><br><span class="line">    Q = torch.einsum(<span class="string">&quot;bnd,hdk-&gt;bhkn&quot;</span>, X, P_q)</span><br><span class="line">    <span class="comment"># 应用线性变换获取键K和值V（single-head）</span></span><br><span class="line">    K = torch.einsum(<span class="string">&quot;bmd,dk-&gt;bmk&quot;</span>, M, P_k)</span><br><span class="line">    V = torch.einsum(<span class="string">&quot;bmd,dv-&gt;bmv&quot;</span>, M, P_v)</span><br><span class="line">    <span class="comment"># 计算注意力得分并应用掩码</span></span><br><span class="line">    logits = torch.einsum(<span class="string">&quot;bhkn,bmk-&gt;bhnm&quot;</span>, Q, K)</span><br><span class="line">    weights = F.softmax(logits + mask, dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 计算加权的值</span></span><br><span class="line">    O = torch.einsum(<span class="string">&quot;bhnm,bmv-&gt;bhnv&quot;</span>, weights, V)</span><br><span class="line">    <span class="comment"># 应用输出变换</span></span><br><span class="line">    Y = torch.einsum(<span class="string">&quot;bhnv,hvd-&gt;bnd&quot;</span>, O, P_o)</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"><span class="comment"># 假设参数和维度</span></span><br><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">num_queries = <span class="number">5</span></span><br><span class="line">num_keys = <span class="number">7</span>    <span class="comment"># 同时也是 num_values</span></span><br><span class="line">dim = <span class="number">64</span></span><br><span class="line">key_dim = <span class="number">32</span>    <span class="comment"># 同时也是 query_dim</span></span><br><span class="line">value_dim = <span class="number">48</span></span><br><span class="line">num_heads = <span class="number">8</span></span><br><span class="line"><span class="comment"># 随机初始化输入数据和参数</span></span><br><span class="line">X = torch.randn(batch_size, num_queries, dim)</span><br><span class="line">M = torch.randn(batch_size, num_keys, dim)</span><br><span class="line">mask = torch.randn(batch_size, num_heads, num_queries, num_keys)</span><br><span class="line">P_q = torch.randn(num_heads, dim, key_dim)</span><br><span class="line">P_k = torch.randn(dim, key_dim)</span><br><span class="line">P_v = torch.randn(dim, value_dim)</span><br><span class="line">P_o = torch.randn(num_heads, value_dim, dim)</span><br><span class="line"><span class="comment"># 运行多查询注意力机制</span></span><br><span class="line">output = multiquery_attention_batched(X, M, mask, P_q, P_k, P_v, P_o)</span><br><span class="line"><span class="built_in">print</span>(output.shape)  <span class="comment"># 输出: torch.Size([2, 5, 64])</span></span><br></pre></td></tr></table></figure>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>本质是标准 <code>Attention</code> 的部分 <code>multi-head</code> 化</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/07/01/LLM-%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/07/01/LLM-%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">LLM 面试题汇总</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-07-01 13:35:13" itemprop="dateCreated datePublished" datetime="2024-07-01T13:35:13+08:00">2024-07-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/07/01/LLM-%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/07/01/LLM-%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="llm-自动驾驶相关"><a class="markdownIt-Anchor" href="#llm-自动驾驶相关"></a> LLM / 自动驾驶相关</h2>
<ol>
<li>LN和BN</li>
<li>介绍RLHF</li>
<li>介绍MoE和变体</li>
<li>介绍LoRA和变体</li>
<li>LoRA 参数更新机制</li>
<li>如何减轻LLM中的幻觉现象？</li>
<li>MLM和MIM的关系和区别?</li>
<li>Stable Diffusion的技术原理</li>
<li>解決LLM Hallucination的方法</li>
<li>Occupancy预测的出发点是什么?</li>
<li>介绍RWKV、Mamba和Mamba-2</li>
<li>2D图像预训练怎么迁移到3D点云任务</li>
<li>为什么现在的LLM都是Decoder only的架构?</li>
<li>把Transformer模型训深的问题有哪些?怎么解决</li>
<li>现在车道线检测的主流的loss是什么?你有哪些想法?</li>
<li>为什么GAN中经常遇到mode collapse，而Diffusion比较少?</li>
</ol>
<h2 id="transformer-相关"><a class="markdownIt-Anchor" href="#transformer-相关"></a> Transformer 相关</h2>
<ol>
<li>介绍Transformer和ViT</li>
<li>介绍Transformer的QKV</li>
<li>介绍Layer Normalization</li>
<li>Transformer训练和部署技巧</li>
<li>介绍Transformer的位置编码</li>
<li>介绍自注意力机制和数学公式</li>
<li>介绍Transformer的Encoder模块</li>
<li>介绍Transformer的Decoder模块</li>
<li>Transformer和Mamba（SSM）的区别</li>
<li>Transformer中的残差结构以及意义</li>
<li>为什么Transformer适合多模态任务？</li>
<li>Transformer的并行化体现在哪个地方？</li>
<li>为什么Transformer一般使用LayerNorm？</li>
<li>Transformer为什么使用多头注意力机制？</li>
<li>Transformer训练的Dropout是如何设定的？</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/06/17/HiPPO-Recurrent-Memory-with-Optimal-Polynomial-Projections/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/06/17/HiPPO-Recurrent-Memory-with-Optimal-Polynomial-Projections/" class="post-title-link" itemprop="url">HiPPO: Recurrent Memory with Optimal Polynomial Projections</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-06-17 13:29:21" itemprop="dateCreated datePublished" datetime="2024-06-17T13:29:21+08:00">2024-06-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/SSM/" itemprop="url" rel="index"><span itemprop="name">SSM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/06/17/HiPPO-Recurrent-Memory-with-Optimal-Polynomial-Projections/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/06/17/HiPPO-Recurrent-Memory-with-Optimal-Polynomial-Projections/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2008.07669">https://arxiv.org/pdf/2008.07669</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/HazyResearch/hippo-code">https://github.com/HazyResearch/hippo-code</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>HiPPO</code> 全称是 <code>High-order Polynomial Projection Operators</code>，是 <code>SSM (State Space Model)</code> 的开山之作，之后作者延续 <code>SSM</code> 思路，做出了可以和 <code>Transformer</code> 结构掰手腕的 <code>Mamba</code></li>
<li><code>HiPPO</code> 的目标是用一个有限维的向量来储存这一段 <code>u(t)</code> 的信息，实现方式是将 <code>u(t)</code> 通过 <code>Legendre</code> (勒让德)多项式展开，用有限维的向量存储勒让德多项式系数，且这些 <strong>向量的值通过求解勒让德多项式得出，不在训练过程中通过梯度下降更新</strong></li>
<li><code>HiPPO</code> 可以给 <code>RNN</code> 提供一种记忆表示方法，因此一个实际的用处是使用 <code>HiPPO</code> 作为 <code>RNN</code> 的记忆存储算子</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<ul>
<li>勒让德多项式本身是定义在连续函数上的，但实际使用中需要记忆的内容是离散的，因此需要离散化过程</li>
<li><code>HiPPO</code> 的记忆更新公式是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo stretchy="false">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mi>A</mi><mi>m</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mi>B</mi><mi>u</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">m(t+1) = Am(t)+Bu(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">u</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span>，其中 <code>A</code> 和 <code>B</code> 是 <code>HiPPO</code> 参数，<code>m(t)</code> 表示记忆向量，<code>u(t)</code> 表示更新向量，<code>m(t+1)</code> 表示更新后的记忆向量
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>N</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A\in\mathbb R^{N\times N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span></span></span></span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">B\in\mathbb R^{N\times 1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></li>
<li><code>N</code> 表示记忆单元的参数尺度，类似于 <code>Transformer</code> 的 <code>hidden size</code>，越大记忆能力越强</li>
</ul>
</li>
<li><code>HiPPO</code> 有 <code>LegT (Translated Legendre Measure)</code> 和 <code>LegS (Scaled Legendre Measure)</code> 两种度量方法，二者都使用上述记忆更新公式，只是 <code>A</code> 和 <code>B</code> 参数不同
<ul>
<li><code>LegT</code> 使用 <strong>翻译</strong> 任务的勒让德多项式，本质是一个滑动窗口，只记忆当前时刻前 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 窗口内容，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 为超参数
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>n</mi><mi>k</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mi>θ</mi></mfrac><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mrow><mi>n</mi><mo>−</mo><mi>k</mi></mrow></msup><mo stretchy="false">(</mo><mn>2</mn><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>i</mi><mi>f</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>n</mi><mo>≥</mo><mi>k</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>2</mn><mi>n</mi><mo>+</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>i</mi><mi>f</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>n</mi><mo>&lt;</mo><mi>k</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">A_{nk}=\frac{1}{\theta}
\begin{cases}
(-1)^{n-k}(2n+1) &amp; if &amp; n\ge k\\
2n+1 &amp; if &amp; n &lt; k
\end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord">2</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>n</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>θ</mi></mfrac><mo stretchy="false">(</mo><mn>2</mn><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">B_n=\frac{1}{\theta}(2n+1)(-1)^n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
<li><code>LegS</code> 使用 <strong>缩放</strong> 的勒让德多项式，记忆全部时刻的序列内容
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>n</mi><mi>k</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mi>θ</mi></mfrac><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">(</mo><mn>2</mn><mi>n</mi><mo>+</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mo stretchy="false">(</mo><mn>2</mn><mi>k</mi><mo>+</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>i</mi><mi>f</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>n</mi><mo>&gt;</mo><mi>k</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>i</mi><mi>f</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>n</mi><mo>=</mo><mi>k</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>i</mi><mi>f</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>n</mi><mo>&lt;</mo><mi>k</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">A_{nk}=\frac{1}{\theta}
\begin{cases}
(2n+1)^{\frac{1}{2}}(2k+1)^{\frac{1}{2}} &amp; if &amp; n\gt k\\
n+1 &amp; if &amp; n = k\\
0 &amp; if &amp; n &lt; k
\end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:4.32em;vertical-align:-1.9099999999999997em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.35002em;"><span style="top:-2.19999em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-2.19499em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-2.20499em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-3.15001em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-4.2950099999999996em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-4.30501em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-4.60002em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.8500199999999998em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.41em;"><span style="top:-4.41em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9540200000000001em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9540200000000001em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.97em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span><span style="top:-1.5300000000000002em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9099999999999997em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.41em;"><span style="top:-4.41em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span><span style="top:-2.97em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span><span style="top:-1.5300000000000002em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9099999999999997em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.41em;"><span style="top:-4.41em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span><span style="top:-2.97em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span><span style="top:-1.5300000000000002em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9099999999999997em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>n</mi></msub><mo>=</mo><mo stretchy="false">(</mo><mn>2</mn><mi>n</mi><mo>+</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup></mrow><annotation encoding="application/x-tex">B_n=(2n+1)^{\frac{1}{2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.20402em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9540200000000001em;"><span style="top:-3.363em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
</ul>
</li>
<li>以 <code>Permute Mnist</code> 分类任务的例子讲解 <code>HiPPO</code> 如何作为 <code>RNN</code> 的单元参与计算，以及<code>HiPPO</code> 的记忆单元如何更新</li>
<li><code>Permute Mnist</code> 任务是将 <code>28x28</code> 的 <code>Mnist</code> 图像的每一类按照同一种 <code>pattern</code> 进行 <code>shuffle</code>，训练并分类</li>
<li>下图为使用 <code>HiPPO</code> 作为记忆单元的 <code>RNN</code> 网络解决 <code>Permute Mnist</code> 任务的计算过程，<code>input_t</code> 是每次顺序输入图片的一个像素值，是一个时间步总长为 <code>28 * 28 = 784</code> 的 <code>RNN</code> 网络，最后一个 <code>hidden state</code> 输出映射到 <code>class dim</code> 上进行分类</li>
</ul>
<pre class="mermaid">graph TD
    subgraph input;
    input_t([input_t]);
    h_t;
    end;
    subgraph fully_connect;
    W_hxm;
    W_gxm;
    W_uxh;
    end;
    h_t([h_t])-->|512|Concat_1-->|513|W_uxh-->|1|u_t([u_t]);
    input_t([input_t])-->|1|Concat_1[Concat];
    subgraph update_memory;
    A([A])-->|max_length, 512, 512|get_index_A[get_index]-->|512, 512|A_t;
    timestep([timestep])-->get_index_A;
    A_t([A_t])-->|512, 512|MatMul_A[MatMul];
    m_t([m_t])-->|1, 512|MatMul_A-->|1, 512|Add;
    m_t([m_t])-->|1, 512|Add;
    timestep([timestep])-->get_index_B;
    B([B])-->|max_length, 512|get_index_B[get_index]-->|512, 1|B_t;
    B_t([B_t])-->|512, 1|MatMul_B[MatMul];
    u_t([u_t])-->|1|MatMul_B-->|1, 512|Add-->|1, 512|m_t+1([m_t+1]);
    end;
    m_t+1-->|512|Concat_2;
    input_t-->|1|Concat_2[Concat]-->|513|W_hxm-->|512|Tanh-->|512|hidden([hidden]);
    Concat_2-->|513|W_gxm-->|512|gate([gate]);
    h_t-->|512|Alpha_Blending-->|512|h_t+1([h_t+1])-->|512|until_last_h{until_last_h};
    hidden-->|512|Alpha_Blending;
    gate-->|512|Alpha_Blending;
    subgraph output;
    until_last_h-->|512|map_to_class_dim-->|10|classification_result([classification_result]);
    end;</pre>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li><code>LegT</code> 和 <code>LegS</code> 的参数计算过程需要较强的数学功底才能完全理解</li>
<li>如果只把 <code>A</code> 和 <code>B</code> 当做 <strong>万能的不需要梯度下降更新的神经网络记忆力更新参数</strong>，那么实际上并不复杂</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/06/03/T5-Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/06/03/T5-Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/" class="post-title-link" itemprop="url">T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-06-03 13:24:49" itemprop="dateCreated datePublished" datetime="2024-06-03T13:24:49+08:00">2024-06-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/06/03/T5-Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/06/03/T5-Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1910.10683">https://arxiv.org/pdf/1910.10683</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/t5">https://github.com/huggingface/transformers/tree/main/src/transformers/models/t5</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li><code>T5</code> 名字的由来是：<code>Text-to-Text Transfer Transformer</code>（<strong>文本到文本转换的 Transformer</strong>）</li>
<li><code>T5</code> 使用了 <code>《Attention is all you need》</code> 中提出的标准 <code>Transformer</code> 网络，没有任何改变</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="example"><a class="markdownIt-Anchor" href="#example"></a> example</h3>
<ul>
<li><code>T5</code> 是一个 <code>encoder-decoder</code> 架构的模型，可以用来做文本翻译，本例子使用 <code>Hello, world!</code> 英语翻译法语为例</li>
</ul>
<h4 id="0-prompt"><a class="markdownIt-Anchor" href="#0-prompt"></a> 0. prompt</h4>
<ul>
<li><code>prompt</code> 的作用是在输入之前加上对任务的描述</li>
<li>比如 <code>english_to_franch(&quot;Hello, world!&quot;) API</code> 会被 <code>prompt</code> 为 <code>&quot;translate English to French: Hello, world!&quot;</code> 纯文本输入到模型</li>
</ul>
<h4 id="1-encoder-input-tokenize"><a class="markdownIt-Anchor" href="#1-encoder-input-tokenize"></a> 1. encoder input tokenize</h4>
<ul>
<li><code>T5</code> 使用的分词算法是 <code>unigram</code>，词表可以在 <a target="_blank" rel="noopener" href="https://huggingface.co/google-t5/t5-base/blob/main/tokenizer.json">https://huggingface.co/google-t5/t5-base/blob/main/tokenizer.json</a> 这里找到</li>
<li><code>&quot;translate English to French: Hello, world!&quot;</code> 会被 <code>tokenize</code> 为：<code>[13959, 1566, 12, 2379, 10, 8774, 6, 296, 55, 1]</code></li>
</ul>
<h4 id="2-encoder-input-token-embedding"><a class="markdownIt-Anchor" href="#2-encoder-input-token-embedding"></a> 2. encoder input token embedding</h4>
<ul>
<li>和 <code>GPT</code> 系列没有区别，需要把 <code>encoder input token id</code> 查表变成 <code>token embedding</code></li>
</ul>
<h4 id="3-encoder-input-position-encoding"><a class="markdownIt-Anchor" href="#3-encoder-input-position-encoding"></a> 3. encoder input position encoding</h4>
<ul>
<li>与 <code>GPT</code> 系列使用可学习的 <code>position embedding</code> 不同，<code>T5</code> 使用的是 <code>position encoding</code></li>
<li>且使用的是相对位置编码，而不是绝对位置编码</li>
<li>与 <code>GPT</code> 系列只在模型 <code>casual decoder</code> 第一层输入加入 <code>position embedding</code> 不同，<code>T5</code> 的 <code>position encoding</code> 是在 <code>encoder</code> 以及 <code>decoder</code> 的每一层都是使用了</li>
</ul>
<h4 id="4-encoder"><a class="markdownIt-Anchor" href="#4-encoder"></a> 4. encoder</h4>
<ul>
<li>与 <code>GPT</code> 系列直接使用 <code>token embedding</code> + <code>position embedding</code> 直接得到 <code>hidden state</code> 来输入 <code>decoder</code> 不同，<code>T5</code> 有 <code>encoder</code> 结构</li>
<li><code>T5</code> 的 <code>encoder</code> 结构采用标准 <code>transformer encoder</code> 结构，<strong>每个 <code>token</code> 可以看到所有 <code>token</code>（双向注意力机制）</strong></li>
<li><code>encoder</code> 一共 <code>12</code> 层，每一层包括如下顺序结构为：
<ul>
<li><code>self attention block</code>
<ul>
<li><code>layer norm</code></li>
<li><code>self attention</code></li>
<li><code>dropout</code></li>
</ul>
</li>
<li><code>FFN</code>
<ul>
<li><code>layer norm</code></li>
<li><code>MLP</code></li>
<li><code>dropout</code></li>
</ul>
</li>
</ul>
</li>
<li><strong><code>encoder</code> 最终输出一个 <code>shape = (batch, input_token_len, encoder_dim)</code> 的 <code>encoder hidden state</code></strong></li>
</ul>
<h4 id="5-decoder-input-token-embedding-and-position-encoding"><a class="markdownIt-Anchor" href="#5-decoder-input-token-embedding-and-position-encoding"></a> 5. decoder input token embedding and position encoding</h4>
<ul>
<li>与 <code>GPT</code> 系列不同之处在于 <code>T5</code> 在 <code>decoder</code> 阶段需要 <code>decoder input</code></li>
<li>通常情况下 <code>decoder input</code> 是 <code>&lt;BOS&gt;</code> 或 <code>&lt;S&gt;</code> 等特殊标记，<code>token</code> 长度仅仅为 <code>1</code>，用于表示序列开始</li>
<li><code>decoder input token embedding</code> 和 <code>position encoding</code> 过程和 <code>encoder input token embedding</code> 和 <code>position encoding</code> 并无区别</li>
<li><strong><code>token embedding</code> + <code>position encoding</code> 得到 <code>decoder hidden state</code>，其 <code>shape = (batch, 1, decoder_dim)</code></strong></li>
</ul>
<h4 id="6-decoder"><a class="markdownIt-Anchor" href="#6-decoder"></a> 6. decoder</h4>
<ul>
<li><code>decoder</code> 一共 <code>12</code> 层，每一层包括如下顺序结构为：
<ul>
<li><code>self attention block</code>
<ul>
<li><code>layer norm</code></li>
<li><code>self attention</code></li>
<li><code>dropout</code></li>
</ul>
</li>
<li><code>cross attention block</code>
<ul>
<li><code>layer norm</code></li>
<li><code>self attention</code></li>
<li><code>dropout</code></li>
</ul>
</li>
<li><code>FFN</code>
<ul>
<li><code>layer norm</code></li>
<li><code>MLP</code></li>
<li><code>dropout</code></li>
</ul>
</li>
</ul>
</li>
<li>其中 <code>self attention</code> 的输入是 <code>decoder hidden state</code>（<strong>注意不是 <code>encoder hidden state</code></strong>），在 <code>self attention</code> 中，和 <code>GPT</code> 类似，采用 <strong>单向注意力</strong></li>
<li><code>decoder hidden state</code> 和 <code>encoder hidden state</code> 输入到 <code>cross attention</code>中，<code>Cross attention</code> 和 <code>Self attention</code> 实际上只有一个区别：
<ul>
<li><strong><code>self attention</code> 的 <code>query / key / value</code> 都由同一个 <code>hidden state</code> 得到，因此称为 <code>self</code></strong></li>
<li><strong><code>cross attention</code> 的 <code>key / value</code> 由同一个 <code>hidden state</code> 得到，<code>query</code> 由另一个 <code>hidden state</code> 得到，因此称为 <code>cross</code></strong></li>
<li><strong>在 <code>encoder-decoder</code> 架构的 <code>transformer</code> 中，<code>decoder</code> 中的 <code>cross attention</code> 的 <code>key / value</code> 通常由 <code>encoder output hidden state</code> 得到，<code>query</code> 通常由 <code>decoder hidden state</code> 得到</strong></li>
<li><code>Cross attention</code> 中每个 <code>decoder hidden state</code> 可以查询到所有的 <code>encoder hidden state</code></li>
</ul>
</li>
<li>重复跑完 <code>12</code> 层，最终输出 <code>shape = (batch, 1, decoder_dim)</code> 的 <code>decoder output hidden state</code></li>
</ul>
<h4 id="7-decoder-output-hidden-state-to-token"><a class="markdownIt-Anchor" href="#7-decoder-output-hidden-state-to-token"></a> 7. decoder output hidden state to token</h4>
<ul>
<li>需要将 <code>docoder output hidden state</code> 用一层 <code>MLP</code> 转化到 <code>vocabulary</code> 空间，找到最可能的一个 <code>token</code></li>
<li>此 <code>token</code> 对应的单词即为模型最终输出的第一个词。</li>
<li>如果这个词是词表中的结束符，则停止输出。如果不是，则用此词替代前一个词，重复上述的 <strong>5. decoder input token embedding and position encoding</strong> 和 <strong>6. decoder</strong> 和 <strong>7. decoder output hidden state to token</strong> 过程，直到达到最长输出长度限制或出现停止符。</li>
</ul>
<h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3>
<p>标准 <code>transformer</code> 的行为</p>
<ol>
<li><code>encoder</code> 输入所有文本，<strong>双向注意力</strong>，得到 <code>encoder hidden state</code></li>
<li><code>decoder</code> 输入初始化为 <code>&lt;BOS&gt;</code>，长度为 <code>1</code></li>
<li><code>decoder</code> 每一层包含：
<ol>
<li><code>self attention</code>，<strong>单向注意力</strong></li>
<li><code>cross attention</code>，<strong>双向注意力</strong>，<code>decoder hidden state</code> 做 <code>query</code>，<code>encoder hidden states</code> 做 <code>key and value</code></li>
<li><code>FFN</code></li>
</ol>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/04/24/[WIP]A-Survey-of-Large-Language-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/04/24/%5BWIP%5DA-Survey-of-Large-Language-Models/" class="post-title-link" itemprop="url">A Survey of Large Language Models</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-04-24 13:24:21" itemprop="dateCreated datePublished" datetime="2024-04-24T13:24:21+08:00">2024-04-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Survey/" itemprop="url" rel="index"><span itemprop="name">Survey</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/04/24/%5BWIP%5DA-Survey-of-Large-Language-Models/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/04/24/%5BWIP%5DA-Survey-of-Large-Language-Models/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h1>
<ul>
<li>paper(en): <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.18223">https://arxiv.org/abs/2303.18223</a></li>
<li>paper(cn)：<a target="_blank" rel="noopener" href="https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese.pdf">https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese.pdf</a></li>
</ul>
<h1 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h1>
<ul>
<li>一篇关于大模型的综述，截止到 2023 年 9 月 ，对现有的大模型做了较为详细的梳理。</li>
</ul>
<h1 id="survey"><a class="markdownIt-Anchor" href="#survey"></a> Survey</h1>
<h2 id="1-introduction"><a class="markdownIt-Anchor" href="#1-introduction"></a> 1. Introduction</h2>
<ul>
<li><code>LLM (large language model)</code> 和 <code>PLM (pretrain language model)</code> 主要有三个区别：
<ol>
<li><code>LLM</code> 表现出一些令人惊讶的涌现能力，这些能力可能在以前较小的 <code>PLM</code> 中没有观察到。</li>
<li><code>LLM</code> 将彻底改变人类开发和使用人工智能算法的方式，与小型 <code>PLM</code> 不同，访问 <code>LLM</code> 的主要方法是通过提示接口（例如 <code>GPT-4 API</code>）。</li>
<li><code>LLM</code> 的发展不再明确区分研究和工程。训练 <code>LLM</code> 需要在大规模数据处理和分布式并行训练方面具有丰富的实践经验。</li>
</ol>
</li>
<li>本文主要从四个方面介绍 <code>LLM</code> 的进展：
<ol>
<li><strong>预训练</strong>：如何训练出一个有能力的 <code>LLM</code></li>
<li><strong>适配微调</strong>：如何从有效性和安全性两个角度有效地微调预训练的 <code>LLM</code></li>
<li><strong>使用</strong>：如何利用 <code>LLM</code> 解决各种下游任务</li>
<li><strong>能力评估</strong>：如何评估 LLM 的能力和现有的经验性发现</li>
</ol>
</li>
</ul>
<h2 id="2-overview"><a class="markdownIt-Anchor" href="#2-overview"></a> 2. Overview</h2>
<h3 id="21-大语言模型的涌现能力"><a class="markdownIt-Anchor" href="#21-大语言模型的涌现能力"></a> 2.1 大语言模型的涌现能力</h3>
<p><code>LLM</code> 的涌现能力（<code>Emergent Abilities</code>）被正式定义为：<strong>在小型模型中不存在但在大型模型中产生的能力</strong>，这里介绍三种典型涌现能力：</p>
<h4 id="1-in-context-learning上下文学习"><a class="markdownIt-Anchor" href="#1-in-context-learning上下文学习"></a> 1. <strong><code>In-context learning</code></strong>（上下文学习）</h4>
<ul>
<li><code>ICL</code> 能力是由 <code>GPT-3</code> 正式引入的：假设已经为语言模型提供了一个自然语言指令和/或几个任务演示，它可以通过完成输入文本的单词序列的方式来为测试实例生成预期的输出，而无需额外的训练或梯度更新。</li>
</ul>
<h4 id="2-instruction-following指令遵循"><a class="markdownIt-Anchor" href="#2-instruction-following指令遵循"></a> 2. <strong><code>Instruction following</code></strong>（指令遵循）</h4>
<ul>
<li>通过使用自然语言描述的混合多任务数据集进行微调（称为指令微调），<code>LLM</code> 在未见过的以指令形式描述的任务上表现出色。</li>
</ul>
<h4 id="3-step-by-step-reasoning逐步推理"><a class="markdownIt-Anchor" href="#3-step-by-step-reasoning逐步推理"></a> 3. <strong><code>Step-by-step reasoning</code></strong>：（逐步推理）</h4>
<ul>
<li>通过使用思维链（<code>Chain-of-Thought, CoT</code>）提示策略，<code>LLM</code> 可以通过利用包含中间推理步骤的提示机制来解决这类任务，从而得出最终答案。<br />
<img src="https://s2.loli.net/2024/05/06/59Wjo8XOhNeETSi.png" alt="LLM_survey_1.png" /></li>
</ul>
<h3 id="22-大语言模型的关键技术"><a class="markdownIt-Anchor" href="#22-大语言模型的关键技术"></a> 2.2 大语言模型的关键技术</h3>
<p><code>LLM</code> 的关键技术主要分为以下五个方面：</p>
<h4 id="1-scaling扩展"><a class="markdownIt-Anchor" href="#1-scaling扩展"></a> 1. <strong><code>Scaling</code>（扩展）</strong></h4>
<ul>
<li><code>Transformer</code> 语言模型存在明显的扩展效应，更大的模型/更大的数据规模/更多的训练计算通常会导致模型能力的提升。</li>
</ul>
<h4 id="2-training训练"><a class="markdownIt-Anchor" href="#2-training训练"></a> 2. <strong><code>Training</code>（训练）</strong></h4>
<ul>
<li>分布式训练算法是学习 <code>LLM</code> 网络参数所必需的，其中通常联合使用各种并行策略。</li>
<li>为了支持分布式训练，已经发布了一些优化框架来促进并行算法的实现和部署，例如 <code>DeepSpeed</code> 和 <code>Megatron-LM</code>。</li>
<li>此外，优化技巧对于训练稳定性和模型性能也很重要，例如预训练以克服训练损失激增和混合精度训练等。</li>
</ul>
<h4 id="3-ability-eliciting能力引导"><a class="markdownIt-Anchor" href="#3-ability-eliciting能力引导"></a> 3. <strong><code>Ability eliciting</code>（能力引导）</strong></h4>
<ul>
<li>在大规模语料库上预训练之后，<code>LLM</code> 具备了作为通用任务求解器的潜在能力。</li>
<li>然而，当 <code>LLM</code> 执行一些特定任务时，这些能力可能不会显式地展示出来。</li>
<li>作为技术手段，设计合适的任务指令或具体的 <code>ICL</code> 策略可以激发这些能力。</li>
</ul>
<h4 id="4-alignment-tuning对齐微调"><a class="markdownIt-Anchor" href="#4-alignment-tuning对齐微调"></a> 4. <strong><code>Alignment tuning</code>（对齐微调）</strong></h4>
<ul>
<li><code>InstructGPT</code> 设计了一种有效的微调方法，使 <code>LLM</code> 能够按照期望的指令进行操作，其中利用了 <strong>基于人类反馈的强化学习技术（RLHF）</strong>，采用精心设计的标注策略，它将人类反馈纳入训练循环中。</li>
</ul>
<h4 id="5-tools-manipulation操作工具"><a class="markdownIt-Anchor" href="#5-tools-manipulation操作工具"></a> 5. <strong><code>Tools manipulation</code>（操作工具）</strong></h4>
<ul>
<li>利用外部工具可以进一步扩展 <code>LLM</code> 的能力。例如，<code>LLM</code> 可以利用计算器进行准确计算，利用搜索引擎检索未知信息，这种机制可以广泛扩展 <code>LLM</code> 的能力范围。</li>
</ul>
<h3 id="23-gpt-系列模型的演进"><a class="markdownIt-Anchor" href="#23-gpt-系列模型的演进"></a> 2.3 GPT 系列模型的演进</h3>
<p><img src="https://s2.loli.net/2024/05/07/awqKH82WlQrif3V.png" alt="LLM_survey_2.png" /></p>
<h4 id="1-gpt-1-2018-年"><a class="markdownIt-Anchor" href="#1-gpt-1-2018-年"></a> 1. <strong><code>GPT-1</code>: 2018 年</strong></h4>
<ul>
<li><code>2018</code> 年，<code>OpenAI</code> 发布了 <code>GPT-1</code>，代表生成式预训练（<code>Generative Pre-Training</code>）。</li>
<li><code>GPT-1</code> 是基于<strong>生成型的、仅含有解码器</strong>的 <code>Transformer</code> 架构开发的，并采用了<strong>无监督预训练和有监督微调</strong>的混合方法。</li>
<li><code>GPT-1</code> 为 <code>GPT</code> 系列模型建立了核心架构，并确立了对自然语言文本进行建模的基本原则，即<strong>预测下一个单词</strong>。</li>
</ul>
<h4 id="2-gpt-2-2019-年"><a class="markdownIt-Anchor" href="#2-gpt-2-2019-年"></a> 2. <strong><code>GPT-2</code>: 2019 年</strong></h4>
<ul>
<li>将参数规模增加到了 <code>15</code> 亿，并使用大规模的网页数据集 <code>WebText</code> 进行训练。</li>
<li>它旨在通过<strong>无监督语言建模来执行任务，而无需使用标记数据进行显式微调</strong>。</li>
<li>尽管 <code>GPT-2</code> 旨在成为一个<strong>无监督的多任务学习器</strong>，但与监督微调的 <code>SOTA</code> 方法相比，其整体性能仍然较差。</li>
</ul>
<h4 id="3-gpt-3-2020-年"><a class="markdownIt-Anchor" href="#3-gpt-3-2020-年"></a> 3. <strong><code>GPT-3</code>: 2020 年</strong></h4>
<ul>
<li>参数规模增加到了 <code>175</code> 亿，引入了 <code>ICL</code> 的概念，它是以小样本或零样本的方式使用 <code>LLM</code>。<code>ICL</code> 可以指导 <code>LLM</code> 理解以自然语言文本的形式给出的任务。</li>
<li><code>GPT-3</code> 不仅在各种 <code>NLP</code> 任务中表现出色，而且在一些需要推理或领域适配能力的特殊设计的任务中也表现出色。</li>
<li><code>GPT-3</code> 可以被视 为从 <code>PLM</code> 到 <code>LLM</code> 进化过程中的一个重要里程碑。它通过实证证明，将神经网络扩展到大的规模可以大幅增加模型的能力。</li>
<li><code>OpenAI</code> 为了提高 <code>GPT-3</code> 的性能，使用了两种策略：
<ol>
<li><strong>使用代码数据进行训练</strong>：
<ul>
<li>原始的 <code>GPT-3</code> 模型（在纯文本上进行预训练）的一个主要限制在于缺乏复杂任务的推理能力，例如完成代码和解决数学问题。</li>
<li><code>OpenAI</code> 在 <code>2021.07</code> 推出了 <code>Codex</code>，这是一个在大量 <code>GitHub</code> 代码上微调的 <code>GPT</code> 模型，<code>Codex</code> 可以解决非常困难的编程问题，并且在数学问题上有显著的性能提升。</li>
<li>实际上，<code>GPT-3.5</code> 模型是在基于代码的 <code>GPT</code> 模型（<code>code-davinci-002</code>）的基础上开发的。</li>
</ul>
</li>
<li><strong>与人类对齐</strong>：
<ul>
<li><code>InstructGPT</code> 在 <code>2022.01</code> 提出，以改进 <code>GPT-3</code> 模型与人类对齐能力，正式建立了一个三阶段的基于人类反馈的强化学习（<code>RLHF</code>）算法。</li>
<li>除了提高指令遵循能力之外，<code>RLHF</code> 算法对于缓解有害或有毒内容的生成问题十分有效，这对于 <code>LLM</code> 在实践中的安全部署至关重要。</li>
<li><code>OpenAI</code> 在对齐研究中的方法，总结了三个有前途的方向：
<ol>
<li>使用人类反馈训练 <code>AI</code> 系统</li>
<li>协助人类评估</li>
<li>做对齐研究</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h4 id="4-chatgpt-2022-年"><a class="markdownIt-Anchor" href="#4-chatgpt-2022-年"></a> 4. <strong><code>ChatGPT</code>: 2022 年</strong></h4>
<ul>
<li>它是以类似 <code>InstructGPT</code> 的方式进行训练的（在原始文章中称为“InstructGPT 的姊妹模型”），但专门针对对话能力进行了优化。</li>
<li><code>ChatGPT</code> 训练数据是通过将人类生成的对话（扮演用户和 <code>AI</code> 两个角色）与 <code>InstructGPT</code> 数据集结合起来以对话形式生成。</li>
<li><code>ChatGPT</code> 在与人类的交流中表现出卓越的能力：
<ol>
<li>拥有丰富的知识库</li>
<li>擅长解决数学问题</li>
<li>准确追踪多轮对话中的上下文</li>
<li>与人类的价值观保持一致以确保被安全使用</li>
</ol>
</li>
<li><code>ChatGPT</code> 支持了插件机制，进一步通过已有工具或应用扩展了 <code>ChatGPT</code> 的功能。</li>
</ul>
<h4 id="5-gpt-4-2023-年"><a class="markdownIt-Anchor" href="#5-gpt-4-2023-年"></a> 5. <strong><code>GPT-4</code>: 2023 年</strong></h4>
<ul>
<li>将文本输入扩展到多模态信号，性能有大幅提升。</li>
<li><code>GPT-4</code> 对于具有恶意或挑衅的提问的响应更加安全，并采用了多种干预策略来减轻语言模型的可能问题，如幻觉、隐私和过度依赖。</li>
</ul>
<h2 id="3-大语言模型公开可用资源"><a class="markdownIt-Anchor" href="#3-大语言模型公开可用资源"></a> 3. 大语言模型公开可用资源</h2>
<h3 id="31-公开可用的模型检查点或-api"><a class="markdownIt-Anchor" href="#31-公开可用的模型检查点或-api"></a> 3.1 公开可用的模型检查点或 <code>API</code></h3>
<p><img src="https://s2.loli.net/2024/05/07/1E2x79ysCUiYGea.png" alt="LLM_survey_3.png" /><br />
<img src="https://s2.loli.net/2024/05/07/G8oTZV6sxrq4p2f.png" alt="LLM_survey_4.png" /><br />
<img src="https://s2.loli.net/2024/05/07/r386TGoA2cNUdh9.png" alt="LLM_survey_5.png" /></p>
<h3 id="32-常用预训练语料库"><a class="markdownIt-Anchor" href="#32-常用预训练语料库"></a> 3.2 常用预训练语料库</h3>
<p>常用的<strong>用于预训练</strong>的语料库有：</p>
<h4 id="1-books"><a class="markdownIt-Anchor" href="#1-books"></a> 1. <strong><code>Books</code></strong></h4>
<ol>
<li><code>BookCorpus</code> 是之前小规模模型（如 <code>GPT</code> 和 <code>GPT-2</code>）中常用的预训练数据集，包含<strong>超过 <code>11,000</code> 本电子书</strong>，涵盖广泛的主题和类型（如小说和传记）。</li>
<li><code>Gutenberg</code> 是更大的数据语料库，包含<strong>超过 <code>70,000</code> 本文学作品</strong>，包括小说、散文、诗歌、戏剧、历史、科学、哲学和其他公共领域的作品。</li>
<li>在 <code>GPT-3</code> 中使用到的 <code>Books1</code> 和 <code>Books2</code> 是比 <code>Gutenberg</code> 大的多的语料库，但并未开源。</li>
</ol>
<h4 id="2-commoncrawl"><a class="markdownIt-Anchor" href="#2-commoncrawl"></a> 2. <strong><code>CommonCrawl</code></strong></h4>
<ol>
<li><code>CommonCrawl</code> 是最大的开源网络爬虫数据库之一，能力达到了百万亿字节级别，已经被广泛运用于训练 <code>LLM</code>。</li>
<li>由于网络数据中存在大量的噪音和低质量信息，因此使用前需要进行数据预处理。目前有四个较为常用的基于 <code>CommonCrawl</code> 的过滤数据集：
<ol>
<li>C4</li>
<li>CC-Stories</li>
<li>CC-News</li>
<li>RealNews</li>
</ol>
</li>
</ol>
<h4 id="3-reddit-link"><a class="markdownIt-Anchor" href="#3-reddit-link"></a> 3. <strong><code>Reddit Link</code></strong></h4>
<ol>
<li><code>Reddit</code> 是一个社交媒体平台，用户可以在上 面提交链接和帖子，其他人可以通过“赞同”或“反对”投票。高赞的帖子通常被认为对多数用户是有帮助的，可以用来创建高质量的数据集。</li>
<li><code>WebText</code> 就是一个著名的基于 <code>Reddit</code> 的 语料库，它由 <code>Reddit</code> 上高赞的链接组成，但<strong>尚未公开</strong>。</li>
<li>作为替代，有一个易于获取的开源替代品叫做 <code>OpenWebText</code>。</li>
<li>另一个从 <code>Reddit</code> 中提取的语料库是 <code>PushShift.io</code>.</li>
</ol>
<h4 id="4-wikipedia"><a class="markdownIt-Anchor" href="#4-wikipedia"></a> 4. <strong><code>Wikipedia</code></strong></h4>
<ol>
<li><code>Wikipedia</code> 是一个在线百科全书，包含大量高质量的文章，涵盖各种主题。其中大部分文章都采用解释性写作风格（并支持引用），覆盖了多种不同语言和广泛的知识领域。</li>
</ol>
<h4 id="5-code"><a class="markdownIt-Anchor" href="#5-code"></a> 5. <strong><code>Code</code></strong></h4>
<ol>
<li>为了收集代码数据，现有工作主要是从互联网上爬取有开源许可证的代码。代码数据有两个主要来源：
<ol>
<li>包括开源许可证的公共代码库（例如 <code>GitHub</code>）</li>
<li>与代码相关的问答平台（例如 <code>StackOverflow</code>）</li>
</ol>
</li>
<li><code>Google</code> 公开发布了 <code>BigQuery</code> 数据集，其中包括各种编程语言的大量开源许可证代码片段， 是一个典型的代码数据集。</li>
</ol>
<h4 id="6-other"><a class="markdownIt-Anchor" href="#6-other"></a> 6. <strong><code>Other</code></strong></h4>
<ol>
<li><code>The Pile</code> 是一个大规模、多样化、开源的文本数据集，有超过 <code>800GB</code> 数据，内容包括书籍、网站、代码、科学论文和社交媒体平台等。它由 <code>22</code> 个多样化的高质量子集构成。</li>
<li><code>ROOTS</code> 由各种较小的数据集（完全为 <code>1.61 TB</code> 的文本）组成，涵盖了 <code>59</code> 种不同的语言（包含自然语言和传统语言）。</li>
</ol>
<h4 id="7-一些经典模型使用的预训练语料库"><a class="markdownIt-Anchor" href="#7-一些经典模型使用的预训练语料库"></a> 7. 一些经典模型使用的预训练语料库</h4>
<ol>
<li><strong><code>GPT-3（175B）</code></strong> 是在混合数据集（共 <code>3000</code> 亿 <code>token</code>）上进行训练的，包括：
<ol>
<li><code>CommonCrawl</code></li>
<li><code>WebText2</code></li>
<li><code>Books1</code></li>
<li><code>Books2</code></li>
<li><code>Wikipedia</code></li>
</ol>
</li>
<li><strong><code>PaLM（540B）</code></strong> 使用了共包含 <code>7800</code> 亿 <code>token</code> 的数据集，包括：
<ol>
<li>社交媒体对话</li>
<li>过滤后的网页</li>
<li>书籍</li>
<li><code>Github</code></li>
<li>多语言维基百科</li>
<li>新闻</li>
</ol>
</li>
<li><strong><code>LLaMA</code></strong> 使用了更多的数据预训练，其中 <code>LLaMA（6B）</code> 和 <code>LLaMA（13B）</code> 的训练数据大小为 <code>1.0</code> 万亿 <code>token</code>，而 <code>LLaMA（32B）</code> 和  <code>LLaMA（65B）</code> 使用了 <code>1.4</code> 万亿 <code>token</code>，包括：
<ol>
<li><code>CommonCrawl</code></li>
<li><code>C4</code></li>
<li><code>Github</code></li>
<li><code>Wikipedia</code></li>
<li>书籍</li>
<li><code>ArXiv</code></li>
<li><code>StackExchange</code></li>
</ol>
</li>
</ol>
<h3 id="33-常用-fine-tuning-语料库"><a class="markdownIt-Anchor" href="#33-常用-fine-tuning-语料库"></a> 3.3 常用 <code>Fine-tuning</code> 语料库</h3>
<h4 id="1-instrction-tuning-指令微调-常用数据集"><a class="markdownIt-Anchor" href="#1-instrction-tuning-指令微调-常用数据集"></a> 1. <strong><code>instrction tuning</code> (指令微调)</strong> 常用数据集</h4>
<p><code>instrction tuning</code> (指令微调) 过程可将预训练好的多任务模型在 <code>Zero-shot</code> 任务上表现更好。</p>
<ol>
<li><strong><code>NLP task dataset</code></strong>
<ol>
<li><code>P3 (Public Pool of Prompts)</code>
<ol>
<li>一个涵盖各种自然语言处理任务的 <code>Prompted</code> 英文数据集集合，<code>Prompt</code> 是输入模板和目标模板的组合。</li>
<li>模板是将数据示例映射到自然语言输入和目标序列的函数。例如，在自然语言推理（<code>NLI</code>）数据集的情况下，数据示例将包括 <strong><code>Premise</code>（前提）、<code>Hypothesis</code>（假设）和 <code>Label</code>（标签）</strong> 字段。</li>
<li>输入模板可以定义为：“如果 <code>&#123;Premise&#125;</code> 为真，则 <code>&#123;Hypothesis&#125;</code> 也为真吗？”，而目标模板可以定义为：选择的选项为 <code>Choices[label]</code>。这里的 <code>Choices</code> 是特定于 <code>Prompt</code> 的元数据，包含对应于标签为包含（0）、中性（1）或矛盾（2）的选项 <code>yes</code>、<code>maybe</code>、<code>no</code>。</li>
</ol>
</li>
<li><code>FLAN</code> 使用的 <code>instrction tunning</code> 数据集
<ol>
<li><code>FLAN</code> 实际上是 <code>google</code> 的 《Finetuned Language Models Are Zero-Shot Learners》提出的模型，该模型用了大量的自然语言理解（<code>NLU</code>）和自然语言生成（<code>NLG</code>）任务数据集做指令微调。<br />
<img src="https://s2.loli.net/2024/05/08/gGScu4r6nFqaseZ.png" alt="LLM_survey_6.png" /></li>
<li>指令微调后的模型在 <code>Zero-shot</code> 任务上表现更好。</li>
</ol>
</li>
</ol>
</li>
<li><strong><code>Daily chat dataset</code></strong>
<ol>
<li><strong><code>ShareGPT</code></strong>：由用户资源上传的和 <code>ChatGPT</code> 或 <code>GPT4</code> 的对话，总量大约 <code>90,000</code> 组对话。</li>
<li><strong><code>OpenAssistant</code></strong>：多语言的人类和 <code>AI</code> 助手的对话，包含 <code>35</code> 种语言，<code>66,497</code> 组对话和 <code>461,292</code> 个人类标注。</li>
<li><strong><code>Dolly</code></strong>：由 <code>Databricks</code> 公司制作的 <code>15,000</code> 条英文人类对话，包含 <code>7</code> 大子类：
<ol>
<li>头脑风暴</li>
<li>内容生成</li>
<li>信息提取</li>
<li>摘要</li>
<li>分类</li>
<li>开卷考试的质量保证 (<code>closed-book quality assurance</code>)</li>
<li>闭卷考试的质量保证 (<code>open-book quality assurance</code>)</li>
</ol>
</li>
</ol>
</li>
<li><strong>合成数据</strong>
<ol>
<li><code>Self-Instruct-52K</code>：一个由 <code>Self-Instruct</code> 框架生成的指令遵循数据集，共 <code>82,000</code> 个实例包含约 <code>52,000</code> 条指令。</li>
<li><code>Alpaca</code>：一个用于训练和评估指令遵循型语言模型的集合，它包含了 <code>52,000</code> 条独特的指令和相应的输出，这些数据是基于 <code>OpenAI</code> 的 <code>text-davinci-003</code> 模型自动生成的。</li>
<li><code>Baize</code>：是一个开源的多轮对话数据集，它通过让 <code>ChatGPT</code> 自我对话生成，旨在为训练和评估对话模型提供高质量的语料资源。对话全部为英文，共包含 <code>111.5K</code> 个实例。</li>
</ol>
</li>
</ol>
<h4 id="2-alignment对齐-常用数据集"><a class="markdownIt-Anchor" href="#2-alignment对齐-常用数据集"></a> 2. <strong><code>Alignment</code>（对齐）</strong> 常用数据集</h4>
<p><code>Alignment</code>（对齐）过程的目的是让 <code>LLM</code> 对齐人类的价值观和偏好。<code>Alignment</code> 数据集需要是高质量的、有帮助的、诚实的、无害的。</p>
<ol>
<li><code>HH-RLHF</code> ：是由 Anthropic 公司收集的，用于训练和评估强化学习中的偏好（或奖励）模型的数据集，包含约 <code>169K</code> 实例。这个数据集包含两部分：
<ol>
<li>有益和无害性的人类偏好数据</li>
<li>红队对抗数据</li>
</ol>
</li>
<li><code>SHP</code>：包含 <code>385,000</code> 条人类偏好的数据集，这些偏好是对 <code>18</code> 个不同主题领域中问题/指令的回答进行的。</li>
<li><code>PKU-SafeRLHF</code>：由北京大学团队开发的，用于支持和推动安全强化学习（<code>RLHF</code>）技术的研究和发展的数据集。这个数据集是目前为止最大的多轮 <code>RLHF</code> 数据集之一，规模达到 <code>100</code> 万条，包含了一系列安全偏好的标注，这些标注覆盖了侮辱、歧视、犯罪、心理伤害、悲观情绪、色情、隐私等多种维度，用于对 <code>RLHF</code> 技术进行细粒度的约束价值对齐。</li>
<li><code>Stack Exchange Preferences</code>：是一个从 <code>Stack Overflow</code> 数据转储中提取的问答对数据集，它被设计用于偏好学习（<code>preference learning</code>）。这个数据集包含了大量的问题和答案，其中答案基于得票数进行了评分。数据集的大小超过了 <code>20GB</code>，并且包含了数百万条问题和答案对。</li>
<li><code>Sandbox Alignment Data</code> 是一个由大型语言模型（<code>LLM</code>）生成的对齐数据集，包含约 <code>169K</code> 个实例，它包含了来自模拟社交互动环境 <code>SANDBOX</code> 的反馈。在 <code>SANDBOX</code> 中，模型模拟了人类社会中的交互，通过这种方式生成的对话数据被用来训练和评估语言模型，使其更好地符合人类的价值观和社交规范。</li>
</ol>
<h3 id="34-常用代码库资源"><a class="markdownIt-Anchor" href="#34-常用代码库资源"></a> 3.4 常用代码库资源</h3>
<h4 id="1-transformers"><a class="markdownIt-Anchor" href="#1-transformers"></a> 1. <code>Transformers</code></h4>
<ul>
<li>一个使用 <code>Transformer</code> 架构构建模型的开源 <code>Python</code> 库，由 <code>Hugging Face</code> 开发和维护。它具有简单和用户友好的 <code>API</code>，方便使用和定制各种预训练模型。</li>
</ul>
<h4 id="2-deepspeed"><a class="markdownIt-Anchor" href="#2-deepspeed"></a> 2. <code>DeepSpeed</code></h4>
<ul>
<li>由 <code>Microsoft</code> 开发的深度学习优化库（与 <code>PyTorch</code> 兼容），已用于训练多个 <code>LLM</code>，例如 <code>MTNLG</code> 和 <code>BLOOM</code>。它提供了各种分布式训练优化技术的支持，例如内存优化（<code>ZeRO</code> 技术、梯度检查点）和管道并行。</li>
</ul>
<h4 id="3-megatron-lm"><a class="markdownIt-Anchor" href="#3-megatron-lm"></a> 3. <code>Megatron-LM</code></h4>
<ul>
<li>由 <code>NVIDIA</code> 开发的深度学习库，用于训练 <code>LLM</code>。它提供了丰富的分布式训练优化技术，包括模型和数据并行、混合精度训练和 <code>FlashAttention</code>。这些优化技术可以大大提高训练效率和速度，并实现 <code>GPU</code> 间的高效分布式训练。</li>
</ul>
<h4 id="4-jax"><a class="markdownIt-Anchor" href="#4-jax"></a> 4. <code>JAX</code></h4>
<ul>
<li>由 <code>Google</code> 开发的用于高性能机器学习算法的 <code>Python</code> 库，允许用户在带有硬件加速（例如 <code>GPU</code> 或 <code>TPU</code>）的情况下进行数组的高效运算。它可以在各种设备上进行高效计算，还支持自动微分和即时编译等特色功能。</li>
</ul>
<h4 id="5-colossal-ai"><a class="markdownIt-Anchor" href="#5-colossal-ai"></a> 5. <code>Colossal-AI</code></h4>
<ul>
<li>由 <code>HPC-AI Tech</code> 开发的用于训练大规模人工智能模型的深度学习库。它基于 <code>PyTorch</code> 实现，并支持丰富的并行训练策略。</li>
</ul>
<h4 id="6-bmtrain"><a class="markdownIt-Anchor" href="#6-bmtrain"></a> 6. <code>BMTrain</code></h4>
<ul>
<li>由 <code>OpenBMB</code> 开发的用于以分布式方式训练大规模参数模型的高效库，强调代码简洁、低资源占用和高可用性。</li>
</ul>
<h4 id="7-fastmoe"><a class="markdownIt-Anchor" href="#7-fastmoe"></a> 7. <code>FastMoE</code></h4>
<ul>
<li>一种专门用于 <code>MoE</code>（即混合专家）模型的训练库。</li>
</ul>
<h4 id="8-vllm"><a class="markdownIt-Anchor" href="#8-vllm"></a> 8. <code>vLLM</code></h4>
<ul>
<li>一个快速、内存高效、易用的 <code>LLM</code> 代码库，用于 <code>LLM</code> 的推理和服务。</li>
</ul>
<h4 id="9-deepspeed-mii"><a class="markdownIt-Anchor" href="#9-deepspeed-mii"></a> 9. <code>DeepSpeed-MII</code></h4>
<ul>
<li><code>DeepSpeed Model Implementations for Inference</code>，一个比 <code>vLLM</code> 更快的模型推理服务框架。</li>
</ul>
<h4 id="10-deepspeed-chat"><a class="markdownIt-Anchor" href="#10-deepspeed-chat"></a> 10. <code>DeepSpeed-Chat</code></h4>
<ul>
<li>基于 <code>DeepSpeed</code> 的一键式训练 <code>RLHF</code>，提速 <code>15</code> 倍。</li>
</ul>
<h2 id="4-预训练"><a class="markdownIt-Anchor" href="#4-预训练"></a> 4. 预训练</h2>
<p>预训练为 <code>LLM</code> 的语言理解和生成能力奠定了基础。</p>
<h3 id="41-数据收集和处理"><a class="markdownIt-Anchor" href="#41-数据收集和处理"></a> 4.1 数据收集和处理</h3>
<h4 id="1-数据来源"><a class="markdownIt-Anchor" href="#1-数据来源"></a> 1. <strong>数据来源</strong></h4>
<ol>
<li>通用文本数据
<ol>
<li><code>Webpages</code></li>
<li><code>Conversation text</code></li>
<li><code>Books</code></li>
</ol>
</li>
<li>专用文本数据
<ol>
<li>多语言文本</li>
<li>科学文本</li>
<li>代码</li>
</ol>
</li>
</ol>
<h4 id="2-数据处理"><a class="markdownIt-Anchor" href="#2-数据处理"></a> 2. <strong>数据处理</strong></h4>
<p>一个好用的数据处理代码库是 <code>Data-Juicer</code></p>
<ol>
<li>质量过滤<br />
为删除语料库中的低质量数据，通过有两种方式：<strong>基于分类器的方法</strong> 和 <strong>基于启发式的方法</strong>
<ol>
<li>基于分类器的方法
<ol>
<li>通常采用高质量文本（例如 <code>wikipedia</code>）作为正样本，候选文本作为负样本，训练二分类器，用于给出一个文本的质量分数。</li>
<li>预计分类器的质量过滤方法可能会 <strong>无意识的删除口语化、方言、社会语言的文本</strong>。</li>
</ol>
</li>
<li>基于启发式的方法<br />
启发式方法通常采用一系列预设的规则来过滤低质量文本，具体的方法有：
<ol>
<li>基于语言的过滤：例如删除小语种文本等。</li>
<li>基于度量的过滤：例如基于困惑度（<code>perplexity</code>）来检测和删除不自然的文本。</li>
<li>基于统计的过滤：例如根据标点符号的分布、符号和单词的比例等删除。</li>
<li>基于关键词的过滤：例如删除 <code>HTML</code> 标签、超链接、模板等。</li>
</ol>
</li>
</ol>
</li>
<li>数据去重
<ol>
<li>现有研究表明，重复数据会降低语料库的多样性，可能导致训练过程不稳定，从而影响模型性能。</li>
<li>三种粒度的数据去重：
<ol>
<li>句子级</li>
<li>文档级</li>
<li>数据集级</li>
</ol>
</li>
</ol>
</li>
<li>隐私去除
<ol>
<li>预训练数据大多来自网络，可能包含敏感隐私信息，存在隐私泄露风险。因此需要从数据集中删除 <code>personally identifiable information</code>（可识别个人信息，<code>PII</code>）。</li>
<li>一种有效的删除方法是通过规则（例如：关键字识别）来检测和删除可识别各人信息（例如：姓名、电话、地址等）。</li>
<li>现有研究表明，<code>LLM</code> 在隐私攻击下的脆弱性可能归因于预训练数据中存在重复的可识别个人信息。</li>
</ol>
</li>
<li>分词（<code>Tokenization</code>）<br />
分词也是数据预处理的关键步骤，它的目的是将原始文本分割成词序列，随后用作 <code>LLM</code> 的输入。常用的分词方式有以下三种：
<ol>
<li><code>BPE (Byte-Pair Encoding tokenization)</code> 字节对编码，计算过程如下：
<ol>
<li>首先将文本拆分成字母和分隔符，并统计每个字母或分隔符出现的频率。</li>
<li>计算任意两个字母/分隔符合并后出现的频率，找到最高频的字母/分隔符对合并，重新统计词频并更新词表。</li>
<li>重复第二步，直到词表大小满足要求。</li>
<li>特点：
<ol>
<li>简单高效</li>
<li>贪心算法，每一步都选择频数最大的相邻字符进行合并，这种做法可能不一定是全局最优、频数也不一定是最好的合并指标。</li>
<li>适合拉丁字母组成的语言，不适合汉字、日韩文字等。</li>
</ol>
</li>
</ol>
</li>
<li><code>WordPiece tokenization</code>，计算过程如下：
<ol>
<li>首先将文本拆分成字母和分隔符。</li>
<li>不同于 <code>BPE</code> 选择合并后词频最大的词作为 <code>Subword</code>，<code>WordPiece</code> 基于语言模型似然概率的最大值生成新的 <code>Subword</code>，具体的<strong>基于语言模型似然概率</strong>的定义如下：
<ol>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>t</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>t</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>t</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S=(t_1,t_2,...,t_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，句子 <code>S</code> 由 <code>n</code> 个子词组成。</li>
<li>则句子 <code>S</code> 的似然概率定义为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi><mo stretchy="false">(</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">log P(S)=\sum_{i=1}^n logP(t_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.104002em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li>其中 <code>P()</code> 表示一个训练好的语言概率模型。</li>
</ol>
</li>
<li>找到合并后可以使得句子的似然概率最大的子词合并，更新词表，重复这个过程。</li>
</ol>
</li>
<li><code>Unigram LM</code>，计算过程如下：
<ol>
<li><code>Unigram</code> 和 <code>BPE</code> 以及 <code>WordPiece</code> 有个很大的不同是：
<ol>
<li><code>BPE</code> 和 <code>WordPiece</code> 都是初始化小词表逐步变大直到满足词表大小要求。</li>
<li><code>Unigram LM</code> 是初始化大词表逐步删词直到满足词表大小要求。</li>
</ol>
</li>
<li><code>Unigram LM</code> 删词的根据和 <code>WordPiece</code> 一致，都是<strong>基于语言模型似然概率</strong></li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="3-预训练数据对大语言模型的影响"><a class="markdownIt-Anchor" href="#3-预训练数据对大语言模型的影响"></a> 3. <strong>预训练数据对大语言模型的影响</strong></h4>
<p>与小规模的 <code>PLM</code> 不同，由于对计算资源的巨大需求，通常不可能对 <code>LLM</code> 进行多次预训练迭代。因此，在训练 <code>LLM</code> 之前构建一个准备充分的预训练语料库尤为重要。<br />
目前，不同的 <code>LLM</code> 模型预训练采用不同的预训练策略，下图是一些模型的预训练数据分布图：<br />
<img src="https://s2.loli.net/2024/05/16/pbe61vwcSjx9COH.png" alt="LLM_survey_7.png" /><br />
不过，存在几个有效的混合策略：</p>
<ol>
<li>增加数据的多样性（<code>diversity</code>）<br />
预训练阶段，数据的多样性比数据的质量更重要，有实验表明，删除语料库中的多样性数据（例如：<code>Webpages</code>）比删除语料库中的高质量数据（例如：学术语料库）对模型的影响更大。</li>
<li>可以通过数据混合实验优化数据混合策略
<ol>
<li>在大模型上做数据混合实验是非常昂贵且耗时的，通过会在小模型上测试不同的数据混合策略的优劣，再将小模型测试得到的结果用在大模型上。</li>
<li>但小模型得到的数据混合策略结论在大模型上可能是不成立的，越大的小模型得出来结论越可信。</li>
</ol>
</li>
<li>先用 <code>general</code> 数据训练模型通用能力，再用 <code>skill-spcific</code> 数据训练模型专业能力
<ol>
<li>不同的数据训练的模型有不同的能力，比如：
<ol>
<li>用代码训练的模型对数学和编程更擅长。</li>
<li>用书籍训练的模型更擅长从文本中捕捉长期依赖。</li>
</ol>
</li>
<li>先训练 <code>basic skill</code> 再训练 <code>target skill</code> 比直接训练 <code>target skill</code> 模型表现更好</li>
</ol>
</li>
</ol>
<h3 id="42-架构设计"><a class="markdownIt-Anchor" href="#42-架构设计"></a> 4.2 架构设计</h3>
<p><img src="https://s2.loli.net/2024/05/21/QviOjpeFBkPyEg8.png" alt="LLM_survey_8.png" /></p>
<h4 id="1-典型结构"><a class="markdownIt-Anchor" href="#1-典型结构"></a> 1. <strong>典型结构</strong></h4>
<ol>
<li><strong><code>Casual Decoder</code> 结构</strong>
<ol>
<li>参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2022/07/04/GPT-Improving-Language-Understanding-by-Generative-Pre-Training/"><code>GPT</code> 博客</a> 中的 <code>Hello, world!</code> 续写例子</li>
</ol>
</li>
<li><strong><code>Encoder-Decoder</code> 结构</strong>
<ol>
<li>参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/06/03/T5-Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/"><code>T5</code> 博客</a> 中的 <code>Hello, world!</code> 英语翻译法语的例子</li>
</ol>
</li>
<li><strong><code>Prefix Decoder</code> 结构</strong>
<ol>
<li>是对 <code>Encoder-Decoder</code> 和 <code>Casual Decoder</code> 的折中，在 <code>prefix</code> 前缀文本中使用双向注意力，在生成后续序列时使用单向注意力</li>
<li>用到 <code>Prefix Decoder</code> 的模型有：
<ul>
<li><code>U-PaLM</code></li>
<li><code>GLM</code> 等</li>
</ul>
</li>
</ol>
</li>
<li><strong><code>Mixture-of-Experts</code> （混合专家）结构</strong>
<ol>
<li>优势：是一种灵活的模型参数扩展方法；性能提高明显；</li>
<li>劣势：由于路由操作复杂等原因，训练容易不稳定；</li>
<li>传言 <code>GPT-4</code> 使用了 <code>MOE</code> 结构</li>
</ol>
</li>
<li><strong><code>Emergent Architectures</code>（新兴结构）</strong><br />
<img src="https://s2.loli.net/2024/06/28/yGowfrAOPvWI7u6.png" alt="LLM_survey_9.png" />
<ol>
<li>现有架构存在的问题：
<ol>
<li><code>Transformer</code> 架构一个很大的问题是推理时复杂度较高，每一个 <code>token</code> 需要计算和之前的每一个 <code>token</code> 计算相关性</li>
<li>相比之下，<code>RNN</code> 架构推理的复杂度就很低，每一个 <code>token</code> 只需要和上一个 <code>token</code> 以及一个不断更新的 <code>hidden state</code> 计算相关性（本质是 <code>hidden state</code> 在某种程度上存储了之前所有 <code>token</code> 的信息）</li>
<li>但 <code>RNN</code> 数据依赖问题非常强，导致训练难以并行化，且通常效果较差</li>
</ol>
</li>
<li>一些新兴架构包括：
<ol>
<li><code>H3/S4</code></li>
<li><code>RWKV</code></li>
<li><code>Hyena</code></li>
<li><code>Mamba</code></li>
<li><code>RetNet</code></li>
</ol>
</li>
<li>这些新兴架构几乎无一例外的想做同一件事：<strong>像 <code>Transformer</code> 一样可以并行训练 + 像 <code>RNN</code> 一样高效推理，且效果可以和 <code>Transformer</code> 媲美</strong></li>
<li>状态空间模型 <code>SSM</code> 论文 <code>HiPPO</code> 可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/06/17/HiPPO-Recurrent-Memory-with-Optimal-Polynomial-Projections/">这篇论文</a></li>
</ol>
</li>
</ol>
<h4 id="2-配置细节"><a class="markdownIt-Anchor" href="#2-配置细节"></a> 2. <strong>配置细节</strong></h4>
<p><img src="https://s2.loli.net/2024/07/02/pWcYQraIxdyeZDF.png" alt="LLM_survey_11.png" /></p>
<ol>
<li><strong>归一化方法</strong>
<ol>
<li><strong>LayerNorm</strong>
<ul>
<li><code>LayerNorm</code> 和 <code>BatchNorm</code> 只有两个差别，为了简化，假设 <code>Channel = 1</code> 即 <code>feature shape = N, 1, H, W</code>：
<ul>
<li>训练时差别：
<ul>
<li><code>BatchNorm</code> 统计整个 <code>feature map</code> 的均值和标准差（<code>scalar</code>），然后在整个 <code>feature map</code> 做标准正态化；同时记录（滑动平均算法）到 <code>running_mean / running_var</code> 参数中</li>
<li><code>LayerNorm</code> 统计每一个样本的均值和标准差（均值和标准差都是长度为 <code>N</code> 的 <code>vector</code>），然后每个样本逐个做标准正态化；均值标准差用完即扔，无需记录</li>
</ul>
</li>
<li>推理时差别：
<ul>
<li><code>BatchNorm</code> 推理时不需要计算 <code>feature</code> 的均值和标准差，而是使用训练统计得到的 <code>running_mean / running_var</code>，因此是个静态行为，可以被前面的 <code>Conv2d</code> 运算吸收</li>
<li><code>LayerNorm</code> 推理阶段和训练阶段运算方式基本一致</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>RMSNorm</strong>
<ul>
<li>假设输入 <code>shape</code> 为 <code>N, C, L</code> 分别表示 <code>batch / feature_dim / seq_length</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>M</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>c</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>C</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msubsup><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></msubsup><msubsup><mi>x</mi><mrow><mi>n</mi><mi>l</mi></mrow><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding="application/x-tex">RMS(x_c)=\sqrt{\frac{1}{C}\sum_{n=1}^N\sum_{l=1}^Lx_{nl}^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.5368845em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3031155em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959079999999998em;"><span style="top:-2.398692em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.30130799999999996em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.2631154999999996em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5368845em;"><span></span></span></span></span></span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>M</mi><mi>S</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>c</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><msub><mi>x</mi><mi>c</mi></msub><mrow><mi>R</mi><mi>M</mi><mi>S</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>c</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>∗</mo><mi>k</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">RMSNorm(x_c)=\frac{x_c}{RMS(x_c)}*k+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2314919999999998em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7114919999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span></li>
<li>其中，<code>k / b</code> 都是可学习的 <code>per channel</code> 向量</li>
<li>和 <code>LayerNorm</code> 相比 <code>RMSNorm</code> 有如下优势：
<ol>
<li>更小的计算开销：<code>RMSNorm</code> 不需要计算输入数据的均值，因此减少了计算量，使得模型训练更加高效。</li>
<li>训练速度更快：由于减少了计算量，<code>RMSNorm</code> 在训练过程中的速度通常比 <code>LayerNorm</code> 更快。</li>
<li>性能相当或更好：尽管 <code>RMSNorm</code> 的计算更简单，但它在保持与 <code>LayerNorm</code> 相当性能的同时，甚至可能在某些情况下提供更好的性能。</li>
<li>保留重要的不变性：<code>RMSNorm</code> 保留了输入数据的均方根比例不变性，这有助于模型在面对不同尺度的输入数据时保持一致的性能。</li>
<li>隐式学习率适应：<code>RMSNorm</code> 通过归一化输入数据的 <code>RMS</code>，为模型提供了一种隐式的学习率适应能力，有助于模型在训练过程中更好地调整参数。</li>
</ol>
</li>
</ul>
</li>
<li><strong>DeepNorm</strong>
<ul>
<li><code>DeepNorm</code> 可以看做是一种增强型 <code>LayerNorm</code>，对 <code>LayerNorm</code> 改动较小，但效果惊人，<code>DeepNorm</code> 用在 <code>Post-LN</code> 架构上替代传统 <code>LayerNorm</code> 运算，可稳定训练，可训练深度超过 1,000 层的 <code>Transformer</code></li>
<li><code>DeepNorm</code> 对 <code>LayerNorm</code> 的改动如下：<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>→</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo>∗</mo><mi>α</mi><mo>+</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">LayerNorm (x + f(x)) \rightarrow LayerNorm(x*\alpha + f(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><br />
<img src="https://s2.loli.net/2024/07/02/kc8Q19t3amuS42z.png" alt="LLM_survey_10.png" /></li>
</ul>
</li>
</ol>
</li>
<li><strong>归一化位置</strong>
<ol>
<li><strong>Pre-LN</strong>
<ul>
<li><code>Pre-LN</code> 是一种 <code>Transformer</code> 架构，计算公式是:<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>x</mi><mo>+</mo><mi>M</mi><mi>H</mi><mi>A</mi><mo stretchy="false">(</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x=x+MHA(LayerNorm(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>x</mi><mo>+</mo><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy="false">(</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x=x+FFN(LayerNorm(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x = LayerNorm(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></li>
</ul>
</li>
<li><strong>Post-LN</strong>
<ul>
<li><code>Post-LN</code> 是另外一种 <code>Transformer</code> 架构，计算公式是：<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>M</mi><mi>H</mi><mi>A</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x=LayerNorm(x+MHA(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x=LayerNorm(x+FFN(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></li>
</ul>
</li>
<li><strong>Sandwich-LN</strong>
<ul>
<li><code>Sandwich-LN</code> 是 <code>Pre-LN</code> 的改进，公式为：<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>x</mi><mo>+</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>M</mi><mi>H</mi><mi>A</mi><mo stretchy="false">(</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x=x+LayerNorm(MHA(LayerNorm(x)))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>x</mi><mo>+</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy="false">(</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x=x+LayerNorm(FFN(LayerNorm(x)))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x = LayerNorm(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></li>
</ul>
</li>
</ol>
</li>
<li><strong>激活函数</strong>
<ol>
<li><strong>GeLU</strong><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.5</mn><mi>x</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mfrac><mi>x</mi><msqrt><mn>2</mn></msqrt></mfrac><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">GeLU(x)=0.5x*(1+erf(\frac{x}{\sqrt 2}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2879999999999998em;vertical-align:-0.5379999999999999em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.5510085em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.912845em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;">2</span></span><span style="top:-2.872845em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.12715500000000002em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5379999999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mi>r</mi><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>2</mn><msqrt><mi>π</mi></msqrt></mfrac><msubsup><mo>∫</mo><mn>0</mn><mi>x</mi></msubsup><msup><mi>e</mi><mrow><mo>−</mo><msup><mi>t</mi><mn>2</mn></msup></mrow></msup><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">erf(x)=\frac{2}{\sqrt \pi}\int_0^xe^{-t^2}dt</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.5249199999999998em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6258665em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8059050000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;padding-left:0.833em;">π</span></span><span style="top:-2.765905em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.234095em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8592920000000001em;"><span style="top:-2.34418em;margin-left:-0.19445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.2579000000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35582em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9869199999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span></span></span></span>
<ul>
<li>其中 <code>erf</code> 表示高斯误差函数，值域是 <code>[-1, 1]</code></li>
<li><code>GeLU</code> 是 <code>LLM</code> 中使用最广泛的激活函数</li>
</ul>
</li>
<li><strong>Swish</strong><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mo>∗</mo><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Swish(x) = x*sigmoid(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></li>
<li><strong>SwiGLU</strong><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>w</mi><mi>i</mi><mi>G</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>h</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>∗</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">SwiGLU(x_1, x_2) = Swish(x_1) * x_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">G</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li><strong>GeGLU</strong><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>e</mi><mi>G</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>∗</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">GeGLU(x_1, x_2)=GeLU(x_1) * x_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal">G</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">e</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
</ol>
</li>
<li><strong>位置编码</strong>
<ol>
<li><strong>绝对位置编码</strong>
<ol>
<li>用在传统 <code>Transformer</code> 上，有两种：
<ol>
<li>位置编码（<code>position encoding</code>）：使用正弦得到位置编码<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mfrac><msub><mi>p</mi><mi>j</mi></msub><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mfrac></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE(j, 2i)=sin(\frac{p_j}{10000^{\frac{2i}{d_{model}}}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.658217em;vertical-align:-0.8495050000000002em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.808712em;"><span style="top:-2.19em;"><span class="pstrut" style="height:3.039505em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.485007142857143em;"><span style="top:-3.7374928571428576em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size1 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0465200000000001em;"><span style="top:-2.468em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.69444em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34963999999999995em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.387em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.88164em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size1 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.269505em;"><span class="pstrut" style="height:3.039505em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.546825em;"><span class="pstrut" style="height:3.039505em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8495050000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy="false">(</mo><mfrac><msub><mi>p</mi><mi>j</mi></msub><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mfrac></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE(j, 2i+1)=cos(\frac{p_j}{10000^{\frac{2i}{d_{model}}}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.658217em;vertical-align:-0.8495050000000002em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.808712em;"><span style="top:-2.19em;"><span class="pstrut" style="height:3.039505em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.485007142857143em;"><span style="top:-3.7374928571428576em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size1 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0465200000000001em;"><span style="top:-2.468em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.69444em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34963999999999995em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.387em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.88164em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size1 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.269505em;"><span class="pstrut" style="height:3.039505em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.546825em;"><span class="pstrut" style="height:3.039505em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8495050000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span>
<ul>
<li>其中
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE(j,2i)/PE(j,2i+1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span> 分别表示位置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 对应的位置编码向量的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>i</mi><mi mathvariant="normal">/</mi><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2i/2i+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mord">/</span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 位置的值</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 个位置</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示向量维度</li>
</ul>
</li>
</ul>
</li>
<li>可学习位置编码（<code>position embedding</code>）：使用可学习的 <code>embedding</code> 编码：<code>position_embedding = nn.Embedding(max_seq_length, d_model)</code></li>
</ol>
</li>
<li>绝对位置编码 <code>position embedding</code> 通常会 <code>element-wise</code> 加到输出 <code>token embedding</code> 作为 <code>Transformer</code> 输入，即：<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i=x_i + p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示 <code>token embedding</code>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示 <code>position embedding</code></li>
</ol>
</li>
<li><strong>相对位置编码</strong>
<ol>
<li>从计算方法来说，相对位置编码需要：
<ol>
<li>先构造相对位置矩阵：<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>2</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><annotation encoding="application/x-tex">\begin{bmatrix}0&amp;-1&amp;-2\\1&amp;0&amp;-1\\2&amp;1&amp;0\end{bmatrix}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6010299999999997em;vertical-align:-1.55002em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.0510099999999998em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-2.8099900000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.05101em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">2</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.0510099999999998em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-2.8099900000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.05101em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span></span></span></span></span></li>
<li><strong>可学习</strong> 的相对位置偏置表：
<ol>
<li><code>shape = [2 * n - 1, 2 * n - 1, num_head] = [5, 5, num_head]</code></li>
<li>其中，坐标 <code>[i, j, k]</code> 表示第 <code>k</code> 的 <code>self-attention</code> 头上 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">K_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 的相对位置</li>
</ol>
</li>
</ol>
</li>
<li>从使用方法来说：
<ol>
<li>相对位置编码不再需要显式的将 <code>position embedding</code> 加上 <code>token embedding</code> 作为 <code>Transformer</code> 输入</li>
<li>而是将相对位置编码加到 <code>self-attention</code> 上，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>W</mi><mi>q</mi></msub><msub><mi>x</mi><mi>i</mi></msub><msubsup><mi>x</mi><mi>j</mi><mi>T</mi></msubsup><msubsup><mi>W</mi><mi>k</mi><mi>T</mi></msubsup><mo>+</mo><msub><mi>r</mi><mrow><mi>i</mi><mo>−</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{ij}=W_qx_ix_j^TW_k^T+r_{i-j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>
<ol>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">K_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 的 <code>self-attention score</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>−</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">r_{i-j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">K_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 的相对位置</li>
</ol>
</li>
<li>因此也被称为 <code>RelativePositionBias</code> （相当于 <code>self-attention</code> 的 <code>bias</code>）</li>
</ol>
</li>
<li>可以参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/05/ALiBi-Train-short-test-long-Attention-with-linear-biases-enables-input-length-extrapolation/"><code>ALiBi</code> 博客</a></li>
</ol>
</li>
<li><strong>旋转位置编码 <code>RoPE</code></strong>
<ol>
<li>是一种不可学习的 <code>position encoding</code> 位置编码方式，编码本身是绝对位置编码，但通过 <code>self-attention</code> 之后，<code>key</code> 和 <code>query</code> 会产生相对位置关系</li>
<li>计算过程：
<ol>
<li>首先以固定间隔角度计算旋转矩阵，矩阵中每个元素是复数形式，<code>shape = [max_seq_len, d_model]</code></li>
<li>对计算 <code>self-attention</code> 之前的 <code>key / query</code> 分别进行 <strong>旋转</strong>（本质是和旋转矩阵做复数乘法，然后再转换到实数空间），此步骤不改变 <code>key / query</code> 的 <code>shape</code></li>
<li>然后做标准的 <code>self-attention</code></li>
</ol>
</li>
</ol>
</li>
<li>总结
<ol>
<li><strong>绝对位置编码</strong>：<code>position embedding</code> 和 <code>token embedding</code> 的 <code>shape</code> 相同，作用在 <code>query / key / value</code> 生成之前</li>
<li><strong>旋转位置编码</strong>：<code>position embedding</code> 和 <code>token embedding</code> 的 <code>shape</code> 相同，作用在 <code>self-attention</code> 之前，只作用在 <code>key / query</code> 上，不对 <code>value</code> 生效</li>
<li><strong>相对位置编码</strong>：<code>position embedding</code> 和 <code>token embedding</code> 的 <code>shape</code> 不同，和 <code>attention map</code> 的 <code>shape</code> 相同，作用在 <code>self-attention</code> 生成的注意力矩阵上</li>
</ol>
</li>
</ol>
</li>
<li><strong>Attention 方式</strong>
<ol>
<li><strong>full attention</strong>
<ol>
<li>就是标准的 <code>self-attention</code>，即<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt {d_k}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.627473em;vertical-align:-0.538em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.089473em;"><span style="top:-2.5864385em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622307142857143em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222307142857144em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17776928571428574em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9190928571428572em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span><br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mi mathvariant="normal">/</mi><mi>K</mi><mi mathvariant="normal">/</mi><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">Q/K/V\in\mathbb{R}^{n\times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></li>
<li>在 <code>LLM</code> 语境下通常 <code>n &gt;&gt; d</code>，<code>softmax</code> 是非线性运算，所以需要先计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>∗</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">QK^T\in\mathbb{R}^{n*n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>，这决定了 <code>full attention</code> 的计算复杂度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">O</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，因此 <code>full attention</code> 复杂度也被称为 <code>softmax</code> 计算复杂度</li>
<li>假如没有 <code>softmax</code>，那么 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mi>V</mi></mrow><annotation encoding="application/x-tex">QK^TV</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 可以通过结合律先计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>K</mi><mi>T</mi></msup><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">K^TV\in\mathbb{R}^{d\times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.880431em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>，然后再计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">QK^TV\in\mathbb{R}^{n\times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>，计算复杂度退化为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">O</span></span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>，变成了线性复杂度</li>
</ol>
</li>
<li><strong>sparse attention</strong>
<ol>
<li>在标准 <code>self-attention</code> 的基础上，提前生成一个固定的二值的 <code>sparse attention mask</code>，将 <code>self-attention</code> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>O</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal(O)(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 的计算复杂度变成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>O</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>n</mi><msqrt><mi>n</mi></msqrt><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal(O)(n\sqrt n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.05028em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8002800000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="padding-left:0.833em;">n</span></span><span style="top:-2.76028em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.23972em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li>固定的二值的 <code>sparse attention mask</code> 可以有多种形式，比如：</li>
</ol>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1, 0, 0, 0, 0, 0, 0, 0, 0, 0    |   1, 0, 0, 0, 0, 0, 0, 0, 0, 0</span><br><span class="line">0, 1, 0, 0, 0, 0, 0, 0, 0, 0    |   1, 1, 0, 0, 0, 0, 0, 0, 0, 0</span><br><span class="line">0, 0, 1, 0, 0, 0, 0, 0, 0, 0    |   1, 1, 1, 0, 0, 0, 0, 0, 0, 0</span><br><span class="line">1, 0, 0, 1, 0, 0, 0, 0, 0, 0    |   0, 1, 1, 1, 0, 0, 0, 0, 0, 0</span><br><span class="line">0, 1, 0, 0, 1, 0, 0, 0, 0, 0    |   0, 0, 1, 1, 1, 0, 0, 0, 0, 0</span><br><span class="line">0, 0, 1, 0, 0, 1, 0, 0, 0, 0    |   0, 0, 0, 1, 1, 1, 0, 0, 0, 0</span><br><span class="line">1, 0, 0, 1, 0, 0, 1, 0, 0, 0    |   0, 0, 0, 0, 1, 1, 1, 0, 0, 0</span><br><span class="line">0, 1, 0, 0, 1, 0, 0, 1, 0, 0    |   0, 0, 0, 0, 0, 1, 1, 1, 0, 0</span><br><span class="line">0, 0, 1, 0, 0, 1, 0, 0, 1, 0    |   0, 0, 0, 0, 0, 0, 1, 1, 1, 0</span><br><span class="line">1, 0, 0, 1, 0, 0, 1, 0, 0, 1    |   0, 0, 0, 0, 0, 0, 0, 1, 1, 1</span><br></pre></td></tr></table></figure>
</li>
<li><strong>Multi-query/grouped-query attention</strong>
<ol>
<li>简单来说，<code>MQA</code> 是将标准 <code>MHA</code> 中的 <code>key / value</code> 的 <code>Multi-Head Attention</code> 退化成 <code>Single-Head</code>，<code>query</code> 保持不变</li>
<li><code>GQA</code> 是将 <code>Multi-Head</code> 分组，每个组内是 <code>MQA</code></li>
<li>具体可以参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/07/11/MQA-Multi-Query-Attention/">Multi-query attention</a> 和 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/07/12/GQA-Grouped-Query-Attention/">Grouped-query attention</a> 两篇博客</li>
</ol>
</li>
<li><strong>Flash attention</strong>
<ol>
<li>简单来说 <code>Flash attention</code> 和 <code>Flash attention v2</code> 是标准 <code>self-attention</code> 的完全等价的高效实现，通过更合理的实现大幅降低了 <code>SRAM</code> 和 <code>HBW</code> 之间的 <code>IO</code> 量，从而大幅加速训练 / 推理速度</li>
<li>详细分析可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/07/17/FlashAttention-Fast-and-Memory-Efficient-Exact-Attention-with-IO-Awareness/">flash attention</a>  和 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/07/18/FlashAttention-2-Faster-Attention-with-Better-Parallelism-and-Work-Partitioning/">flash attention v2</a> 两篇博客</li>
</ol>
</li>
<li><strong>Paged attention</strong>
<ol>
<li><code>Paged attention</code> 的目的是解决生成式模型 <code>kv cache</code> 占用太多显存导致显存利用率低的问题，<code>kv cache</code> 详细分析可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/07/30/KV-Cache-Transformer/">这篇博客</a></li>
<li><code>Paged attention</code> 通过类似分页内存管理的方法管理 <code>kv cache</code> 显存，随着序列变长，动态分配显存，显存物理空间不连续，最多只浪费一页，极大提高了显存利用率，使得可以运行更大的 <code>batch size</code></li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="3-预训练任务"><a class="markdownIt-Anchor" href="#3-预训练任务"></a> 3. <strong>预训练任务</strong></h4>
<ol>
<li><strong>Language modeling（语言建模）</strong>
<ol>
<li>语言建模任务是给定一个序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">X = \{x_1, x_2, ..., x_n\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>，使得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>L</mi><mi>M</mi></mrow></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>X</mi><mo>&lt;</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{LM}=\sum_{i=1}^n log P(x_i|X&lt;i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.104002em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span> 此极大似然估计最大，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>&lt;</mo><mi>i</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">X&lt;i=\{x_1,...,x_i\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></li>
<li>语言建模预训练任务是 <code>LLM</code> 最常用的预训练任务，在很多下游任务上甚至无需 <code>fine-tuning</code></li>
</ol>
</li>
<li><strong>Denoising Autoencoding（去噪自编码）</strong>
<ol>
<li>去噪自编码是在一个句子中随机替换 <code>token</code> 为噪声，然后训练模型去恢复原始信息</li>
</ol>
</li>
<li><strong>Mixture-of-Denoisers（混合降噪器）</strong>
<ol>
<li><code>MoD</code> 是出自 <code>Google UL2</code> 大模型，此大模型使用了 <code>MoD</code> 作为预训练任务，是前面提到的两种预训练任务的组合<br />
<img src="https://s2.loli.net/2024/07/31/eJvRXQnEjrLfN3M.png" alt="UL2.png" /></li>
</ol>
</li>
</ol>
<h4 id="4-长文本建模"><a class="markdownIt-Anchor" href="#4-长文本建模"></a> 4. <strong>长文本建模</strong></h4>
<p>长文本建模是指模型在推理阶段实际输入的序列长度比训练阶段更长，即 <code>train short, test long</code>，主要有两种范式：</p>
<ol>
<li><strong>扩展位置嵌入（<code>Scaling Position Embeddings</code>）</strong>
<ol>
<li>直接模型微调：通过多阶段逐步增加上下文长度来适应长文本。</li>
<li>位置插值：通过调整位置索引来扩展上下文窗口，相比直接模型微调更有效。</li>
<li>位置截断：截断超出预定义窗口长度的位置索引，保留局部位置关系。</li>
<li>基础修改：通过调整基础值来改变波长，以适应更长的文本。例如修改 <code>RoPE</code> 的旋转角度间隔等。</li>
<li>基础截断：截断超出特定范围的基础值，避免在更大位置索引处出现分布外的旋转角度。</li>
</ol>
</li>
<li><strong>适应上下文窗口（Adapting Context Window）</strong>
<ol>
<li>并行上下文窗口：将输入文本分割成多个段，独立编码并修改注意力掩码以访问先前段的令牌。</li>
<li>Λ 形上下文窗口：基于 <code>LLMs</code> 倾向于更多关注起始和最近的令牌，采用选择性保留初始和最近令牌的注意力掩码。</li>
<li>外部记忆：存储过去的键（<code>keys</code>）在外部记忆，并使用 <code>k</code>-最近邻搜索方法检索最相关的令牌。</li>
</ol>
</li>
</ol>
<h4 id="5-解码策略"><a class="markdownIt-Anchor" href="#5-解码策略"></a> 5. <strong>解码策略</strong></h4>
<ol>
<li>背景
<ol>
<li>对于绝大多数的文本生成任务，<code>language modeling</code> 解码策略就足够了，即预测下一个概率最大的词，这种解码策略也被称为 <code>Greedy search</code></li>
<li><code>language modeling</code> 解码策略对于比如机器翻译、文本总结等任务是够用的，但是对于比如故事生成、对话等任务就有问题，会输出大量重复的、无意义的文本</li>
<li>因此，一种简单有效的策略是根据输出的词表中每一个词的概率随机选择一个词（即从 <code>argmax</code> 变成 <code>softmax</code>），这种策略被称为 <code>Random sampling</code></li>
</ol>
</li>
<li><strong><code>Greedy search</code> 的改进</strong>
<ol>
<li><code>Beam search</code>：集束搜索可以缓解模型预测陷入局部最优解，<code>beam size</code> 通常设置在 <code>3 ~ 6</code> 之间，太大会降低模型效果</li>
<li><code>Length penalty</code>：对于集束搜索的搜索空间进行长度惩罚，最终加权选择最优生成序列</li>
</ol>
</li>
<li><strong><code>Random sampling</code> 的改进</strong><br />
<code>Random sampling</code> 是根据预测概率随机选，因此每个词都有可能被选中（即使概率很低），这可能会导致输出完全不合逻辑的文本序列，因此需要改进
<ol>
<li><code>Temperature sampling</code>
<ol>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><mi>x</mi><mo>&lt;</mo><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>l</mi><mi>j</mi></msub><mi mathvariant="normal">/</mi><mi>t</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mo>∑</mo><msup><mi>j</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>l</mi><msup><mi>j</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mi mathvariant="normal">/</mi><mi>t</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(x_j|x&lt;i)=\frac{exp(l_j/t)}{\sum_{j&#x27;}exp(l_{j&#x27;}/t)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.699547em;vertical-align:-0.667227em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.03232em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.28539000000000003em;"><span style="top:-2.2853899999999996em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.6068285714285713em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8495600000000001em;"><span style="top:-2.84956em;margin-right:0.1em;"><span class="pstrut" style="height:2.55556em;"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46032428571428574em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3447999999999998em;margin-left:-0.01968em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.6068285714285713em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8495600000000001em;"><span style="top:-2.84956em;margin-right:0.1em;"><span class="pstrut" style="height:2.55556em;"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4009142857142858em;"><span></span></span></span></span></span></span><span class="mord mtight">/</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.50732em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.01968em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mord mtight">/</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.667227em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，其中 <code>t</code> 代表温度</li>
<li>是对 <code>softmax</code> 得到概率分布的优化，加入了温度系数，可有效缓解随机采样导致的采样到不合理值的问题</li>
<li>当 <code>t = 1</code> 时，退化为 <code>random sampling</code></li>
<li>当 <code>t</code> 趋近于 <code>0</code> 时，退化为 <code>greedy search</code></li>
</ol>
</li>
<li><code>top-k sampling</code>
<ol>
<li>只保留可能性最高的 <code>k</code> 种取值</li>
<li>概率重新归一化后根据概率随机选</li>
</ol>
</li>
<li><code>top-p sampling</code>(<code>nucleus sampling</code>)
<ol>
<li>只保留累计概率不超过 <code>p</code> 的最小集；也就是按照预测概率降序，保留累计概率小于 <code>p</code> 的样本</li>
<li>概率重新归一化后根据概率随机选</li>
</ol>
</li>
<li><code>contrastive search</code>
<ol>
<li>参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/08/A-Contrastive-Framework-for-Neural-Text-Generation/">这篇博客</a></li>
<li>道理上讲得通，但模型推理阶段计算量翻了一倍</li>
</ol>
</li>
<li><code>typical sampling</code>
<ol>
<li>参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/09/Locally-Typical-Sampling/">这篇博客</a></li>
<li><code>top-p</code> 算法的升级版本</li>
</ol>
</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>−</mo><mi>s</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">\eta-sampling</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>
<ol>
<li>参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/09/Truncation-Sampling-as-Language-Model-Desmoothing/">这篇博客</a></li>
<li>算是一种动态自适应 <code>top-p</code> 算法，参考了 <code>typical sampling</code></li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="6-解码效率"><a class="markdownIt-Anchor" href="#6-解码效率"></a> 6. <strong>解码效率</strong></h4>
<p>作为主流的 <code>GPT-like LLM</code>，解码（推理）可以分为两个阶段：</p>
<ol>
<li><code>prefill stage</code>
<ol>
<li>预装填阶段，即将 <code>input / prompt</code> 输入到模型中计算 <code>hidden state</code> 的阶段</li>
<li>此阶段的计算访存比比较高，以 <code>A100 80GB GPU + LLaMA-13B</code> 为例，计算访存比为 <code>113.78</code>（硬件理论最高效计算访存比为 <code>156</code>）</li>
</ol>
</li>
<li><code>incremental decoding stage</code>
<ol>
<li>增量解码阶段，即累加上一轮输出持续解码直到 <code>&lt;EOS&gt;</code> 或 <code>max_length</code></li>
<li>此阶段计算访存比比较低，以 <code>A100 80GB GPU + LLaMA-13B</code> 为例，计算访存比为 <code>1.97</code><br />
因此，通过优化解码效率主要是针对 <code>incremental decoding stage</code>，对于增量解码阶段的优化主要有两个方向：</li>
</ol>
</li>
<li>减少数据 <code>IO</code>
<ol>
<li>这里的数据 <code>IO</code> 是指 <code>HBM</code> 和 <code>SRAM</code> 之间</li>
<li><code>Flash Attention</code> 通过分块计算 <code>Attention</code>，可大幅降低数据 <code>IO</code> 量</li>
<li><code>Multi-Query Attention</code> 和 <code>Grouped-Query Attention</code> 通过共享/分组共享 <code>KV</code> 来减小 <code>IO</code></li>
</ol>
</li>
<li>解码策略优化
<ol>
<li>投机解码：用小模型预测序列，让大模型评判是接受还是拒绝，可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/14/Fast-Inference-from-Transformers-via-Speculative-Decoding/">这篇博客</a></li>
<li>树式投机解码 <code>SpecInfer</code>：在投机解码基础上升级，用树结构来存储候选 <code>token</code>，可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/15/SpecInfer-Accelerating-Large-Language-Model-Serving-with-Tree-based-Speculative-Inference-and-Verification/">这篇博客</a></li>
<li>跳跃解码 <code>SkipDecode</code>：在模型中跳过一些层的计算以减小计算量，和投机解码的无损加速（和原解码方式输出完全一致）不同，<code>SkipDecode</code> 是有损加速</li>
</ol>
</li>
</ol>
<h4 id="7-实际设置"><a class="markdownIt-Anchor" href="#7-实际设置"></a> 7. <strong>实际设置</strong></h4>
<ol>
<li><strong><code>T5</code></strong>
<ol>
<li>默认使用贪心解码算法</li>
<li>对于翻译和总结任务，使用 <code>beam size = 4</code> 的 <code>beam search</code>，长度惩罚系数 <code>0.6</code></li>
</ol>
</li>
<li><strong><code>GPT-3</code></strong>
<ol>
<li>对于所有任务，使用 <code>beam size = 4</code> 的 <code>beam search</code>，长度惩罚系数 <code>0.6</code></li>
</ol>
</li>
<li><strong><code>Alpaca</code></strong>
<ol>
<li>对于开放式生成任务，使用随机解码，<code>top-k (k = 50)</code> 和 <code>top-p (p = 0.9)</code> 以及 <code>0.7</code> 的温度</li>
</ol>
</li>
<li><strong><code>LLaMA</code></strong>
<ol>
<li>对于问答任务，使用贪心解码算法</li>
<li>对于代码生成任务，使用随机解码，温度设置为 <code>0.1</code> 和 <code>0.8</code>（分别为 <code>Pass@1</code> 和 <code>Pass@100</code>）</li>
</ol>
</li>
<li><strong><code>Open-AI API</code></strong>
<ol>
<li>支持多种解码方式：
<ol>
<li><code>greedy search</code>：通过设置温度为 <code>0</code></li>
<li><code>beam search</code>：设置 <code>best_of</code></li>
<li><code>temperature sampling</code>：设置 <code>temperature</code></li>
<li><code>nucleus sampling</code>：设置 <code>top-p</code></li>
</ol>
</li>
<li>支持多种控制重复度的方法：
<ol>
<li>设置 <code>presence_penalty</code></li>
<li>设置 <code>frequency_penalty</code></li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="8-架构选择"><a class="markdownIt-Anchor" href="#8-架构选择"></a> 8. <strong>架构选择</strong></h4>
<ol>
<li>目前 <code>causal decoder</code> 是主流的大模型架构，主要原因有两点：
<ol>
<li>有证据表明，对于没有 <code>fine-tuning</code> 的情况下，<code>causal decoder</code> 表现比 <code>encoder decoder</code> 架构更好，即对于 <code>zero-shot / few-shot</code> 任务，<code>causal decoder</code> 效果更好</li>
<li><code>scaling law</code> 在 <code>causal decoder</code> 中表现明显，对于 <code>encoder decoder</code> 的研究缺乏</li>
</ol>
</li>
</ol>
<h3 id="43-模型训练"><a class="markdownIt-Anchor" href="#43-模型训练"></a> 4.3 模型训练</h3>
<h4 id="1-训练配置"><a class="markdownIt-Anchor" href="#1-训练配置"></a> 1. <strong>训练配置</strong></h4>
<ol>
<li><code>Batch Training</code>
<ol>
<li>对于 <code>Language model pre-training</code> 任务（例如 <code>bert</code> 等），通常用较大的 <code>batch size</code>，例如 <code>2048 examples</code> 或者 <code>4M tokens</code>，这样通常可以提高训练稳定性和吞吐量。</li>
<li>对于 <code>LLM</code> 任务（例如 <code>GPT-3 / PaLM</code>），引入了动态 <code>batch size</code> 的做法，<code>GPT-3</code> 在训练过程中会将 <code>batch size</code> 从 <code>32K tokens</code> 逐步增加到 <code>3.2M tokens</code>，动态 <code>batch size</code> 可提高 <code>LLM</code> 训练稳定性</li>
</ol>
</li>
<li><code>Learning Rate</code>
<ol>
<li><code>LLM</code> 的训练通常采用 <code>warmup</code> + <code>decay</code> 的训练策略</li>
<li><code>warmup</code> 过程通常占总训练 <code>step</code> 数量的 <code>0.1% - 0.5%</code>，学习率逐步从 <code>0</code> 提高到最大值，最大值通常在 <code>5e-5 ~ 1e-4</code> 之间（<code>GPT-3</code> 是 <code>6e-5</code>）。</li>
<li><code>decay</code> 过程通常使用 <code>cosine decay</code> 策略，在剩余的 <code>training step</code> 中逐步将 <code>learning rate</code> 降低到最大值的 <code>10%</code></li>
</ol>
</li>
<li><code>Optimizer</code>
<ol>
<li>通常使用 <code>Adam / AdamW / Adafactor</code> 优化器中的一种</li>
<li>对于 <code>Adam / AdamW</code>，超参数配置为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn><mo separator="true">,</mo><mtext> </mtext><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.95</mn><mo separator="true">,</mo><mtext> </mtext><mi>ϵ</mi><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\beta_1=0.9,\ \beta_2=0.95,\ \epsilon =10^{-8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span>，<code>GPT-3</code> 就使用了这组配置。</li>
<li><code>Adafactor</code> 优化器相比 <code>Adam / AdamW</code>，优点是训练过程更省显存，超参数配置为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn><mo separator="true">,</mo><mtext> </mtext><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>1.0</mn><mo>−</mo><msup><mi>k</mi><mrow><mo>−</mo><mn>0.8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\beta_1=0.9,\ \beta_2=1.0-k^{-0.8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span>，<code>k</code> 表示训练步数，<code>PaLM / T5</code> 就使用了 <code>Adafactor</code> 优化器。</li>
</ol>
</li>
<li>训练稳定化
<ol>
<li><code>LLM</code> 训练不稳定是常见情况，可以会导致训练崩溃</li>
<li>通常做法有：
<ol>
<li><code>weight decay 0.1</code></li>
<li><code>gradient clipping to 1.0</code></li>
</ol>
</li>
<li>损失函数尖峰（<code>loss spike</code>）也会导致训练不稳定，通常做法有：
<ol>
<li>模型回退到 <code>loss spike</code> 出现之前最近一次 <code>checkpoint</code>，且弃用导致 <code>loss spike</code> 的数据，<code>PaLM / OPT</code> 使用了这种方法</li>
<li><code>GLM</code> 模型发现 <code>Embedding layer</code> 不正常梯度容易导致 <code>loss spike</code>，因此缩小了 <code>embedding layer gradient</code></li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="2-可拓展性训练技术"><a class="markdownIt-Anchor" href="#2-可拓展性训练技术"></a> 2. <strong>可拓展性训练技术</strong></h4>
<ul>
<li><code>LLM</code> 训练会有两个技术难题：<em>训练吞吐量的增加</em> 和 <em>加载大模型到显存</em>，解决方法包含以下几种（以下几种并不冲突，可以同时使用）：
<ol>
<li><code>3D Parallelism</code>
<ol>
<li><code>Data parallelism</code>
<ol>
<li>主流框架都已有实现（例如 <code>pytorch</code> 的 <code>ddp</code>）</li>
<li>划分数据到不同 <code>GPU</code>，每个 <code>GPU</code> 独立前向反向</li>
<li>每个 <code>step</code> 中 <code>gradient</code> 都需要聚合一次，以确保每个 <code>GPU</code> 上参数更新保持一致</li>
</ol>
</li>
<li><code>Pipeline parallelism</code>
<ol>
<li>模型不同的层放到不同的 <code>GPU</code> 上训练，由于 <code>LLM</code> 基本都是 <code>Transformer</code> 架构，所以一个 <code>GPU</code> 通常会加载连续的几层，这样可以有效降低 <code>hiddent state</code> 和 <code>gradient</code> 通信量</li>
<li><code>GPU one-by-one</code> 计算会导致 <code>GPU</code> 利用率很低（流水存在大量气泡），需要有效的排计算流水</li>
<li><code>Gpipe</code> 和 <code>PipeDream</code> 可以通过重整数据 <code>batch</code> 和异步梯度更新提高 <code>GPU</code> 利用率
<ul>
<li><code>Gpipe</code> 可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/20/GPipe-Easy-Scaling-with-Micro-Batch-Pipeline-Parallelism/">这篇博客</a></li>
<li><code>PipeDream</code> 可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/20/PipeDream-Fast-and-Efficient-Pipeline-Parallel-DNN-Training/">这篇博客</a></li>
</ul>
</li>
</ol>
</li>
<li><code>Tensor parallelism</code>
<ol>
<li><code>Tensor parallelism</code> 是把模型一层的参数切成多份，每份独立计算，因此也叫做 <code>Model parallelism</code>。</li>
<li>即 <code>Pipeline parallelism</code> 是横向把模型切成几段，而 <code>Tensor parallelism</code> 是纵向把模型切成几段。</li>
<li>以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>X</mi><mi mathvariant="normal">@</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">Y=X @ A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord">@</span><span class="mord mathnormal">A</span></span></span></span> 矩阵乘运算为例，<code>Tensor parallelism</code> 是将 <code>A</code> 纵向切分为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>A</mi><mn>2</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[A_1,A_2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span> 放到不同的 <code>GPU</code> 上独立运算，则 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mo stretchy="false">[</mo><mi>X</mi><mi mathvariant="normal">@</mi><msub><mi>A</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>X</mi><mi mathvariant="normal">@</mi><msub><mi>A</mi><mn>2</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Y=[X@A_1,X@A_2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord">@</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord">@</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></li>
<li><code>Tensor parallelism</code> 需要分析每个算子的数据依赖情况，比如矩阵乘的右矩阵可以按列划分，但不可以按行划分。</li>
<li>目前一些开源框架都支持了 <code>Tensor parallelism</code>，例如 <code>Megatron-LM</code> (可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/21/Megatron-LM-Training-Multi-Billion-Parameter-Language-Models-Using-Model-Parallelism/">这篇博客</a>) 和 <code>Colossal-AI</code></li>
</ol>
</li>
</ol>
</li>
<li><code>ZeRO</code>
<ol>
<li>通过分片存储等方法降低冗余，<code>ZeRO-DP</code> 和 <code>ZeRO-R</code> 可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/08/21/ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/">这篇博客</a></li>
<li><code>FSDP</code> 是 <code>PyTorch</code> 官方提出和实现的类似于 <code>ZeRO</code> 的算法，全称是 <code>Fully Sharded Data Parallel</code>。
<ol>
<li>代码：<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/fairscale">https://github.com/facebookresearch/fairscale</a></li>
<li>文章：<a target="_blank" rel="noopener" href="https://engineering.fb.com/2021/07/15/open-source/fsdp/">https://engineering.fb.com/2021/07/15/open-source/fsdp/</a></li>
</ol>
</li>
</ol>
</li>
<li>混合精度训练
<table>
<thead>
<tr>
<th style="text-align:center">Format</th>
<th style="text-align:center">Bits</th>
<th style="text-align:center">Exponent</th>
<th style="text-align:center">Fraction</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">FP32</td>
<td style="text-align:center">32</td>
<td style="text-align:center">8</td>
<td style="text-align:center">23</td>
</tr>
<tr>
<td style="text-align:center">FP16</td>
<td style="text-align:center">16</td>
<td style="text-align:center">5</td>
<td style="text-align:center">10</td>
</tr>
<tr>
<td style="text-align:center">BF16</td>
<td style="text-align:center">16</td>
<td style="text-align:center">8</td>
<td style="text-align:center">7</td>
</tr>
</tbody>
</table>
<ol>
<li><code>FP16</code> 和 <code>FP32</code> 混合训练是比较常见的操作，但最近有研究发现 <code>FP16</code> 会造成模型精度降低。</li>
<li><code>BF16</code> 是为了解决 <code>FP16</code> 造成精度降低而提出的数据类型，全称是 <code>Brain Floating Point</code>，这种数据类型牺牲了表达精度，提高了表达范围。</li>
</ol>
</li>
<li>总体训练建议
<ol>
<li><code>3D Parallelism</code>
<ol>
<li>在实际应用中，<code>3D Parallelism</code> 通常是联合使用的，例如 <code>BLOOM</code> 模型，是用了：
<ul>
<li><code>4</code> 路 <code>Tensor Parallelism</code></li>
<li><code>8</code> 路 <code>Data Parallelism</code></li>
<li><code>12</code> 路 <code>Pipeline Parallelism</code><br />
共 <code>384 (384=4 x 8 x 12)</code> 块 <code>A100 GPU</code> 训练得到的。</li>
</ul>
</li>
<li><code>DeepSpeed</code>、<code>Colossal-AI</code>、<code>Alpa</code> 等开源库都对三种并行支持较好</li>
</ol>
</li>
<li>减小显存占用
<ol>
<li><code>ZeRO</code> 和 <code>FSDP</code> 等算法可有效降低大模型训练过程中的显存占用，从而可以训练参数量非常大的模型。</li>
<li><code>DeepSpeed</code>、<code>PyTroch</code>、<code>Megatron-LM</code> 等开源库都已集成此功能。</li>
</ol>
</li>
<li><code>predictable scaling</code>
<ol>
<li><code>GPT-4</code> 提出的，在小模型上等效预测放大后模型的效果，对超大规模网络训练来说必不可少。</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ul>
<h2 id="5-llm-的适配微调"><a class="markdownIt-Anchor" href="#5-llm-的适配微调"></a> 5. <code>LLM</code> 的适配微调</h2>
<ul>
<li>大模型在预训练结束之后，需要适配微调来使得大模型释放全部能力以及对齐人类的三观，主要的微调方式有两种：
<ul>
<li><code>Instruction Tuning</code>（指令微调）：用来提高或解锁大模型在某些方面的能力。</li>
<li><code>Alignment Tuning</code>（对齐微调）：对齐人类三观。</li>
</ul>
</li>
</ul>
<h3 id="51-instruction-tuning-指令微调"><a class="markdownIt-Anchor" href="#51-instruction-tuning-指令微调"></a> 5.1 <code>Instruction Tuning</code> 指令微调</h3>
<ol>
<li><code>Instruction Tuning</code> 可以大幅提高 <code>LLM</code> 的指令遵循能力，即让 <code>LLM</code> 可以解决具体的任务（指令）</li>
<li><code>Instruction Tuning</code> 通常需要两步：
<ol>
<li>收集指令数据：通常是构造结构化数据</li>
<li>使用收集到的指令数据用监督学习的方法微调 <code>LLM</code></li>
</ol>
</li>
</ol>
<h4 id="1-格式化实例的构造"><a class="markdownIt-Anchor" href="#1-格式化实例的构造"></a> 1. 格式化实例的构造</h4>
<p><img src="https://s2.loli.net/2024/09/05/aiP1VtZQzDSIpHT.png" alt="LLM_survey_12.png" /></p>
<ul>
<li>本文用三种（主要的）数据上格式化实例的构造举例：
<ol>
<li>格式化 <code>NLP</code> 任务数据（如图 <code>11.a</code>）</li>
<li>格式化日常对话数据（如图 <code>11.b</code>）</li>
<li>格式化人工合成数据（如图 <code>11.c</code>）</li>
</ol>
</li>
</ul>
<ol>
<li><strong>格式化 <code>NLP</code> 任务数据</strong>
<ol>
<li>这里的 <code>NLP</code> 任务是指常见的自然语言任务，例如：
<ol>
<li>文本总结（<code>text summarization</code>）</li>
<li>文本分类（<code>text classification</code>）</li>
<li>翻译（<code>translation</code>）</li>
</ol>
</li>
<li>格式化的 <code>NLP</code> 任务数据通常由四部分组成：
<ol>
<li>任务描述（<code>Task description</code>）</li>
<li>示例（<code>Demonstrations</code>）</li>
<li>输入</li>
<li>输出</li>
</ol>
</li>
<li>任务描述部分很重要，去掉之后微调效果下降明显</li>
<li><code>PromptSource</code> 是个很好用的格式化 <code>NLP</code> 任务数据的开源工具，提供了很多任务模板，同时提供了一个开源 <code>Prompt</code> 集合数据集称为 <code>Public Pool of Prompts (P3)</code></li>
</ol>
</li>
<li><strong>格式化日常对话数据集</strong>
<ol>
<li><code>NLP</code> 数据集上的格式化实例缺乏 <code>Prompt</code> 的多样性，且和人类实际需求不匹配</li>
<li>日常对话数据集主要包含两部分：
<ol>
<li>任务描述（<code>Task description</code>）</li>
<li>输出</li>
</ol>
</li>
<li>这两部分都由人类完成，其中：
<ol>
<li>任务描述来自于 <code>ChatGPT API</code> 收集到的问题以及人类标注员，内容包含：
<ol>
<li>开放内容生成（<code>opened generation</code>）</li>
<li>开放问答（<code>open question answering</code>）</li>
<li>头脑风暴（<code>brainstorm</code>）</li>
<li>聊天（<code>chatting</code>）</li>
</ol>
</li>
<li>输出全部由人类标注员完成</li>
</ol>
</li>
</ol>
</li>
<li><strong>格式化人工合成数据</strong>
<ol>
<li>以上两种数据集的格式化实例的方法要么需要大量的标注员，要么需要大量的手动收集，格式化人工合成数据是个半自动方法。</li>
<li>原理是通过将已收集的格式化数据输入到大模型中，让大模型给出相似的实例。</li>
<li>步骤：
<ol>
<li>首先用少量人工标注的格式化数据作为样本放入样本库</li>
<li>大模型从样本库中随机采样，仿照样本格式输出另外一个相似的实例</li>
<li>过滤生成实例的质量，如果没问题则加入样本库中，重复第一步</li>
</ol>
</li>
</ol>
</li>
<li><strong>格式化数据过程中的关键因素</strong>
<ol>
<li>指令的缩放法则（<code>Scaling the instructions</code>）
<ol>
<li>指令微调数据集中涉及到的任务种类越多，多样性越丰富，效果就越好</li>
<li>一种任务中的实例数量不需要很多，大模型容易饱和</li>
</ol>
</li>
<li>格式设计（<code>Formatting design</code>）
<ol>
<li>必须包含任务描述，任务描述对 <code>LLM</code> 理解任务至关重要</li>
<li>适当数量的演示示例可以降低模型对指令工程的敏感性</li>
<li>引入 <code>CoT (Chain-of-Thought)</code> 和非 <code>CoT</code> 数据会让 <code>LLM</code> 在需要多跳推理能力的任务和不需要多跳推理的任务上表现好</li>
<li>引入其他信息（例如： 避免的事项、原因和建议等）对 <code>LLM</code> 性能影响较小或会产生负面影响</li>
</ol>
</li>
<li>总结
<ol>
<li>指令数据集的多样性和质量比数量更重要</li>
<li>标注员编写人类需求实例比特定于数据集的任务更有用，但人力成本较高</li>
<li>为减少人力成本，<code>LLM</code> 自动构建指令数据集是一种有效的方法</li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="2-指令微调策略"><a class="markdownIt-Anchor" href="#2-指令微调策略"></a> 2. 指令微调策略</h4>
<ol>
<li><strong>平衡数据分布</strong>
<ol>
<li>最简单的也是应用最广泛的方法是：混合所有数据，然后平等的采样每一个样本</li>
<li>有研究表明，对于高质量的数据集，应该适当提高其采样概率</li>
<li>需要设置采样上限，防止较大数据集主导整个指令微调过程</li>
<li>每个数据集所侧重的能力不同，用单一数据集微调无法全面增强模型容量，通常需要多种类型的数据混合微调，例如：
<ol>
<li><code>NLP</code> 任务数据集（<code>FLAN v2</code>）</li>
<li>聊天数据集（<code>ShareGPT</code>）</li>
<li>合成数据（<code>GPT4-Alpaca</code>）</li>
</ol>
</li>
</ol>
</li>
<li><strong>预训练与指令微调联合训练</strong>
<ol>
<li>有些模型预训练阶段是个多任务模型，一个任务是常规预训练，另一个任务是指令对齐任务，例如 <code>OPT-IML</code> 模型</li>
<li>有些模型预训练阶段的数据中混入了一小部分格式化后的指令对齐数据，在预训练过程中就完成了指令对齐，例如 <code>GLM-130B</code> 和 <code>Galactica</code> 等</li>
</ol>
</li>
<li><strong>多阶段指令微调</strong>
<ol>
<li>指令微调数据集大体上分为两种：任务格式化指令对齐数据和日常对话指令微调数据</li>
<li>其中任务格式化指令数据通常数据量更大，数据集的平衡是非常重要的，因此通常需要非常小心的平衡两种数据</li>
<li>另外一种更简单的方法是将两种数据分成两个阶段分别训练，例如：先用任务格式化指令数据微调，然后再用日常对话指令数据微调</li>
<li>实际应用中为了防止能力遗忘问题（<code>Capacity forgetting issue</code>），通常在日常对话指令数据微调过程中加入少量任务格式化指令数据</li>
</ol>
</li>
<li><strong>一些其他微调技巧</strong>
<ol>
<li>多轮对话数据的高效微调方法
<ol>
<li>对于人机多轮对话数据，通常的做法是将其拆分成多组问答对，然后每对对话数据单独训练，这种训练方式会有对话内容重叠的问题</li>
<li>一种高效的多轮对话数据微调方法是将整个对话一次送入 <code>LLM</code> 微调，且只对 <strong>机器输出的对话部分计算损失</strong></li>
</ol>
</li>
<li>建立 <code>LLM</code> 的自我认知
<ol>
<li>为 <code>LLM</code> 建立自我认知对于部署应用 <code>LLM</code> 很有必要，例如：名称、开发者和隶属关系</li>
<li>一种实用的方法是 <strong>构建自我认知相关的微调指令</strong>，也可以加入带有自我认知相关的提示前缀，例如：”以下是人类和 <code>AI</code> 助手之间的对话“</li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="3-指令微调的作用"><a class="markdownIt-Anchor" href="#3-指令微调的作用"></a> 3. 指令微调的作用</h4>
<ol>
<li><strong>提升模型表现</strong>
<ol>
<li>指令微调已经成为提升模型能力和解锁模型部分能力的重要方法</li>
<li>大模型和小模型都可以在指令微调过程中获得收益，模型越大收益越大</li>
<li>经过指令微调过的小模型比没有经过指令微调的大模型效果更好</li>
<li>指令微调不止可以用于 <code>LLM</code>，预训练 <code>NLP</code> 模型也可以用</li>
<li>此外指令微调的计算代价和数据量和预训练过程相比很小</li>
</ol>
</li>
<li><strong>任务泛化</strong>
<ol>
<li>大量研究表明，指令微调可以使大模型在见过和没有见过的任务上都表现良好（也可以认为指令微调可以使大模型获得任务泛化的能力）</li>
<li>指令微调甚至可以缓解大模型的部分缺点，例如重复生成</li>
<li>指令微调可以让大模型泛化到跨语言种类的相似任务上，例如 <code>BLOOMZ-P3</code> 是在 <code>BLOOM</code> 上仅用纯英文数据 <code>P3</code> 微调得到的，经测试发现在多语种语句补全任务上，<code>BLOOMZ-P3</code> 比 <code>BLOOM</code> 提升超过 <code>50%</code>，表明即使用纯英文数据做指令微调，可以提高大模型在其他语言上的表现</li>
<li>研究表明，仅用纯英文数据做指令微调，即可解决多语种任务的性能</li>
</ol>
</li>
<li><strong>任务专业化</strong>
<ol>
<li>在专业领域指令数据上上做指令微调，大模型可以变成专业模型，例如：在医疗、法律、金融等指令微调数据集上做微调</li>
</ol>
</li>
</ol>
<h4 id="4-指令微调经验性的分析"><a class="markdownIt-Anchor" href="#4-指令微调经验性的分析"></a> 4. 指令微调经验性的分析</h4>
<ol>
<li><strong>指令微调数据集</strong>
<ol>
<li>任务相关的指令数据
<ul>
<li>常用的数据集是 <code>FLAN-T5</code> 包含 <code>1836</code> 个任务的超过 <code>15M</code> 条指令数据</li>
</ul>
</li>
<li>日常对话指令数据
<ul>
<li>常用的数据集是 <code>ShareGPT</code>，包含 <code>63K</code> 条真实用户指令</li>
</ul>
</li>
<li>合成指令数据
<ul>
<li>常用的数据集是 <code>Self-Instruct-52K</code> 包含 <code>52K</code> 条指令对共计 <code>82K</code> 个实例的输入输出</li>
</ul>
</li>
</ol>
</li>
<li><strong>微调效果提升策略</strong>
<ol>
<li>提升指令的复杂性
<ul>
<li>可以参考 <code>WizardLM</code> 设计，通过增加约束、提高推理步骤、提高输入复杂度的方式，逐步提高指令的复杂性</li>
</ul>
</li>
<li>提升指令数据集话题的多样性
<ul>
<li>合成数据通常会有话题多样性差的问题，可以通过更强的 <code>LLM</code> 对其进行话题多样性扩写，例如用 <code>ChatGPT</code> 扩写 <code>Self-Instruct-52K</code> 数据</li>
</ul>
</li>
<li>提升指令数据量
<ul>
<li>在指令质量不下降的情况下，尽可能提高指令数据量</li>
</ul>
</li>
<li>平衡指令的困难程度
<ol>
<li>指令太简单或太复杂都会影响模型微调，容易出现训练不稳定或过拟合的问题</li>
<li>需要去除数据集中太简单或太复杂的指令</li>
<li>可以通过用 <code>LLaMa</code> 推理指令输出的困惑度来对指令的困难程度排序，删除过难过易的样本</li>
</ol>
</li>
</ol>
</li>
<li><strong>实验设置和结果分析</strong>
<ol>
<li>本节是 <code>Survey</code> 的作者亲自做的指令微调实验的设置和结果分析</li>
<li>实验设置
<ol>
<li>模型：对 <code>LLaMa</code> 做指令微调，包括 <code>LLaMa-7B</code> 和 <code>LLaMa-13B</code> 两个模型</li>
<li><code>code base</code>: <code>[YuLan-Chat](https://github.com/RUC-GSAI/YuLan-Chat)</code> 一个作者实验室开源的代码</li>
<li>硬件环境：一台 <code>8</code> 卡 <code>A800-80G GPU</code> 服务器</li>
<li>超参数：和 <code>[Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)</code> 指令微调超参数相同（<code>Stanford Alpaca</code> 是一个基于 <code>LLaMa</code> 的指令跟随模型）</li>
<li>微调配置：分成 <code>Chat setting</code> 和 <code>QA setting</code> 两个微调配置
<ol>
<li><code>Chat setting</code>:
<ol>
<li>利用来自日常对话的用户指令和请求做微调</li>
<li>微调实验：
<ol>
<li><code>baseline</code>（对照组）：在 <code>Self-Instruct-52K</code> 上微调的 <code>LLaMa-7B</code> 和 <code>LLaMa-13B</code> 模型</li>
<li>实验组：用上面提到的更科学的数据集和数据集混合方法得到的指令微调数据</li>
</ol>
</li>
<li><code>benchmark</code>：<code>[AlpacaFarm evaluation set](https://github.com/tatsu-lab/alpaca_farm)</code></li>
<li>对比方法：对于 <code>benchmark</code> 的每一条数据，用实验组和对照组的两个模型分别推理给出结果，让 <code>ChatGPT</code> 评判哪个更好，最后比较胜率</li>
</ol>
</li>
<li><code>QA setting</code>:
<ol>
<li>利用来自已有的 <code>NLP</code> 任务的问答数据集做微调</li>
<li><code>benchmark</code>：<code>[MMLU (Massive Multitask Language Understanding)](https://arxiv.org/abs/2009.03300)</code> 和 <code>[BBH (BIG-Bench Hard)](https://arxiv.org/abs/2210.09261)</code> 数据集</li>
</ol>
</li>
</ol>
</li>
<li><code>Prompt</code>：
<ol>
<li>“The following is a conversation between a human and an AI assistant. The AI assistant giveshelpful, detailed, and polite answers to the user’s questions.\n[|Human|]:{input}\n[|AI|]:”.</li>
<li>在微调训练和 <code>benchmark</code> 推理时都加</li>
</ol>
</li>
</ol>
</li>
<li>结果分析
<ol>
<li><code>NLP</code> 任务格式化指令数据对 <code>QA setting</code> 任务有效，对 <code>Chat setting</code> 任务无效</li>
<li>混合多种不同的指令数据对提高模型理解能力有帮助</li>
<li>提高指令的复杂性和多样性主导了指令微调效果的提升</li>
<li>简单提高指令的数量可能没有收益，平衡指令的困难程度也不总是有效的</li>
<li>模型越大，指令微调效果越好</li>
</ol>
</li>
<li>指令微调建议
<ol>
<li>提前准备计算资源（<code>GPU</code>）</li>
<li>用 <code>Alpha</code> 开源库做微调</li>
<li>选择合适的开源预训练 <code>LLM</code> 模型和指令微调数据集，开始微调</li>
<li>如果计算资源有限，可以考虑 <code>LoRA</code> 等微调方式</li>
<li>对于部署，可考虑使用低比特量化等方法减小计算量</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="52-alignment-tuning-对齐微调"><a class="markdownIt-Anchor" href="#52-alignment-tuning-对齐微调"></a> 5.2 <code>Alignment Tuning</code> 对齐微调</h3>
<h4 id="1-背景和对齐标准"><a class="markdownIt-Anchor" href="#1-背景和对齐标准"></a> 1. 背景和对齐标准</h4>
<ol>
<li><strong>背景</strong>
<ol>
<li>大模型在很多 <code>NLP</code> 任务中表现出非凡的能力，但有时会生成一些负面的内容，例如：
<ol>
<li>伪造虚假信息</li>
<li>追求不正确的目标</li>
<li>生成错误、误导或带有偏见的表达</li>
</ol>
</li>
<li>出现这种问题的原因通常是在预训练数据中混入了负面内容，但预训练数据太大，清洗是不现实的</li>
<li>因此才出现了对齐微调，对齐微调的目标是 <code>3H</code>（<code>helpfulness / honesty / harmlessness</code>）</li>
<li>对齐微调可能会损伤大模型原有的生成能力，这也被称为 <code>alignment tax</code>（对齐税）</li>
</ol>
</li>
<li><strong>对齐标准</strong>
<ol>
<li><code>Helpfulness</code> 帮助性
<ol>
<li>尽可能简洁高效的帮助人类解决任务或回答问题</li>
<li>当需要更高层次的阐明时，大模型应展现出提出相关的问题来获取额外信息的能力，并且在这个过程中表现出适当的敏感度、洞察力和审慎性</li>
<li>做帮助行为对齐是一件有挑战的事，因为很难精确定义和衡量用户的意图</li>
</ol>
</li>
<li><code>Honesty</code> 诚实性
<ol>
<li>应该给出诚实的回答而不是伪造的信息</li>
<li>为避免产生任何形式的欺诈和虚假陈述，大模型应该适当传达出其输出的不确定性</li>
<li>模型应该了解自身的能力边界</li>
<li>与 <code>Helpfulness</code> 和 <code>Harmlessness</code> 相比，<code>Honesty</code> 更客观，因此对齐需要的人力付出会更少</li>
</ol>
</li>
<li><code>Harmlessness</code> 无害性
<ol>
<li>模型输出不应包含冒犯或歧视</li>
<li>当模型被诱导做出危险行为时，应礼貌的拒绝</li>
<li>但如何定义有害涉及到使用模型的用户、问题类型以及上下文</li>
</ol>
</li>
<li>总结
<ol>
<li>以上三种对齐标准都比较主观，都是基于人类感知定义的，因此直接量化然后去优化是比较难的</li>
<li>一种有效的方法是：<strong>红队对抗</strong>，即让人类对于输入产生违反上述对齐标准的输出，然后让模型将这些作为反面教材去优化</li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="2-收集人类反馈"><a class="markdownIt-Anchor" href="#2-收集人类反馈"></a> 2. 收集人类反馈</h4>
<p>人类反馈在对齐微调大模型的过程中至关重要</p>
<ol>
<li><strong>人类标注员应如何选择</strong>
<ol>
<li>基本要求：
<ol>
<li>学历好：至少本科学历</li>
<li>英文好：英语母语</li>
</ol>
</li>
<li>为了减小研究员和标注员的不匹配，需要研究员和标注者分别标注少量样本，然后选择标注员中和研究员标注相似性高的作为后续标注员</li>
<li>在标注员中选择一个优秀的超级标注员团队，这个团队更高优先级的为大模型标注对齐数据</li>
</ol>
</li>
<li><strong>如何收集人类反馈</strong>
<ol>
<li>基于排序的方法
<ol>
<li>最早的标注方式是：仅选择候选列表中标注员认为最优的选项，且由于每个标注员的偏好不同，这会导致人类的反馈不准确或不完整</li>
<li>基于排序的方法是：系统会自动从候选列表中选择两个选项，标注员选择哪个更好，系统根据标注员的选择对整个候选列表排序，这样可以有效降低不同标注员偏好不同导致的偏差，标注信息更完整</li>
</ol>
</li>
<li>基于问题的方法
<ol>
<li>标注员回答研究员提问的问题，这种类型的标注信息细节丰富，涵盖了对齐标准和其他约束</li>
</ol>
</li>
<li>基于规则的方法
<ol>
<li>通过人为书写的规则自动判断模型输出是否有毒有害</li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="3-rlhf-人类反馈的强化学习"><a class="markdownIt-Anchor" href="#3-rlhf-人类反馈的强化学习"></a> 3. <code>RLHF</code> 人类反馈的强化学习</h4>
<ol>
<li><strong><code>RLHF</code> 系统</strong>
<ol>
<li>包含三个关键组成部分
<ol>
<li>一个用于对齐微调的预训练 <code>LLM</code></li>
<li>一个基于人类反馈训练的奖励模型</li>
<li>一套强化学习算法</li>
</ol>
</li>
<li>预训练模型作为对齐的起点
<ol>
<li><code>InstructGPT 175B</code> 是在预训练的 <code>GPT-3</code> 上对齐的</li>
<li><code>GopherCite 280B</code> 是在 <code>Gopher</code> 上对齐的</li>
</ol>
</li>
<li>奖励模型用于评价人类对模型输出的偏好程度
<ol>
<li>使用人类偏好数据，可以是一个 <code>LM</code> 的微调，也可以是 <code>LM</code> 从头训练</li>
<li>通常比 <code>LLM</code> 参数量少，例如 <code>OpenAI</code> 用 <code>6B GPT-3</code> 作为 <code>Reward Model</code>，<code>DeepMind</code> 用 <code>7B Gopher</code> 作为 <code>Reward Model</code></li>
</ol>
</li>
<li>强化学习算法用奖励模型的信号去微调预训练大模型
<ol>
<li>近端策略优化算法 <code>PPO (Porximal Policy Optimization)</code> 比较常用</li>
</ol>
</li>
</ol>
</li>
<li><strong><code>RLHF</code> 关键步骤</strong><br />
<img src="https://s2.loli.net/2024/09/15/rvDQYzftMBw68l2.png" alt="LLM_survey_13.png" />
<ol>
<li>有监督微调
<ol>
<li>通常以“指令 —— 输出”数据对形式构造，做有监督微调</li>
<li>通常由人类标注员标注得到，需要包含较丰富的多样性</li>
<li>在一些特定场景的 <code>RLHF</code> 中，此步骤可以跳过</li>
</ol>
</li>
<li>训练奖励模型
<ol>
<li>通常由 <code>LM</code> 生成对每个指令生成一系列输出，由人类标注员对输出进行 <strong>偏好排序</strong> 作为训练数据</li>
<li>奖励模型实际是在模仿人类标注员的偏好</li>
<li>通常训练得到的奖励模型更偏向于无害但无帮助的回答，这被称为 <strong>规避问题（evasion problem）</strong></li>
<li>最近有一些工作用 <code>AI Agent</code> 代替标注员对 <code>LM</code> 的输出进行偏好排序（<code>RLAIF</code>）<s>开始套娃</s>，<code>AI Agent</code> 的排序原则是预设的指令对齐原则，这种方式的优势是：
<ol>
<li>可以缓解规避问题，生成无害且有帮助的回答</li>
<li>降低对标注员的依赖，降本增效</li>
</ol>
</li>
</ol>
</li>
<li>强化学习微调
<ol>
<li>用强化学习的方式对第一步微调后的 <code>LM</code> 进行训练，其中强化学习的各个要素分别为：
<ol>
<li>策略（<code>policy</code>）：微调后的 <code>LM</code></li>
<li>动作空间（<code>action space</code>）：<code>LM</code> 的词表</li>
<li>状态（<code>state</code>）：目前生成的 <code>token</code> 序列</li>
<li>奖励（<code>reward</code>）：由第二步训练得到的 <code>RM</code> 提供</li>
<li>为了防止模型退化（逐渐偏离预训练行为），通常在奖励函数中加入一项惩罚项，例如：<code>InstructGPT</code> 通过在奖励函数中加入当前模型输出和微调之前的模型输出之间的 <code>KL</code> 散度，缓解模型的退化问题</li>
<li>通常重复迭代第二步（<code>RM</code> 的训练）和本步（强化学习微调），可以得到较好的模型</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><strong><code>RLHF</code> 实践策略</strong><br />
成功实现 <code>RLHF</code> 是比较困难的，这里提供一些实践上的策略和技巧
<ol>
<li>奖励模型如何有效训练
<ol>
<li>大的奖励模型在评判大模型输出质量方面更优
<ol>
<li>在实践中，奖励模型有小模型（例如：<code>InstructGPT</code> 用 <code>6B GPT</code> 作为奖励模型）和大模型（和对齐模型一样大或者更大的模型作为奖励模型）两条路线，其中大模型路线在评判 <code>LLM</code> 输出质量方面更优</li>
<li>可以用 <code>LLM</code> 预训练过程中的检查点参数初始化 <code>RM</code>，这样可以缓解由于预训练数据不一致导致的对齐策略不匹配问题，<code>LLaMa 2</code> 就是这么做的</li>
<li>大的奖励模型训练容易过拟合，用人类标注的对齐数据的提示词首选响应作为正则化项可以缓解过拟合</li>
</ol>
</li>
<li>训练一个满足所有对齐标准的奖励模型很难，可以用多个对齐模型的组合来实现，每个对齐模型只关注部分对齐标准
<ol>
<li>例如每个奖励模型只关注一项标准，然后用某种策略（例如平均或加权）组合每一种奖励模型的奖励值作为最终奖励</li>
<li>使用这种方法可以手动条件每一项对齐标注的严格程度（通过调节权重）</li>
</ol>
</li>
</ol>
</li>
<li>强化学习过程如何有效训练
<ol>
<li>强化学习通常是不稳定且超参数敏感的，因此需要在强化学习前模型已经得到充分的有监督训练</li>
<li>常用的方法是：
<ol>
<li>收集多样性较为丰富的对齐数据输入，通过采样策略让 <code>LLM</code> 对每个输入推理得到 <code>N</code> 个输出</li>
<li>用奖励模型评判 <code>N</code> 个输出，得到最优的输出</li>
<li>用“输入 —— 最优输出”数据对有监督训练 <code>LLM</code>，知道模型的表现不再提升（收敛）</li>
</ol>
</li>
<li>需要有部分人类标注的对齐数据 <code>benchmark</code> 用来真实地评价模型对齐效果</li>
<li>通常需要奖励模型和强化学习优化过程的多轮迭代</li>
</ol>
</li>
<li>强化学习过程如何高效训练
<ol>
<li>强化学习过程和奖励模型训练多轮迭代会带来巨大的存储和计算开销</li>
<li>可以将奖励模型部署在单独的服务器上，通过 <code>API</code> 调用</li>
<li>对齐模型对于每个指令需要同时输出多组候选输出，用集束搜索算法（<code>beam search</code>）效率更高，且可以提高输出的质量和多样性</li>
</ol>
</li>
</ol>
</li>
<li><strong><code>RLHF</code> 的过程监督</strong>
<ol>
<li><code>RLHF</code> 的监督可以分为两种：
<ol>
<li>对结果监督：监督 <code>LLM</code> 对于输入指令的完整输出</li>
<li>对过程监督：更细粒度的监督 <code>LLM</code> 的输出过程，例如输出的每个句子、每个单词、每个推理步等</li>
</ol>
</li>
<li>过程监督数据集：<code>PRM800K</code>
<ol>
<li><code>PRM800K</code> 是 <code>OpenAI</code> 开源的 <code>RLHF</code> 过程监督数据集，可以用其训练 <code>PRM (Process-supervised Reward Model)</code> 过程监督奖励模型</li>
<li><code>PRM800K</code> 包含：
<ol>
<li><code>12K</code> 个过程标注的数学问题</li>
<li><code>75K</code> 个由 <code>LLM</code> 生成的解法</li>
<li><code>800K</code> 个过程正确性标签，标签分为：
<ol>
<li><code>Positive</code> 正面</li>
<li><code>Negative</code> 负面</li>
<li><code>Neutral</code> 中性</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>过程监督可以和专家迭代强化学习算法（<code>Expert Iteration (EXIT)</code>）结合</li>
</ol>
</li>
</ol>
<h4 id="4-不用-rlhf-的对齐"><a class="markdownIt-Anchor" href="#4-不用-rlhf-的对齐"></a> 4. 不用 <code>RLHF</code> 的对齐</h4>
<ol>
<li><strong><code>RLHF</code> 做对齐微调的痛点</strong>
<ol>
<li>需要训练被对齐模型和奖励模型，同时需要频繁推理参考模型（对齐前的模型，不训练，用于防止对齐过程导致模型退化），存储和计算代价大</li>
<li><code>RLHF</code> 过程中常用的 <code>PPO</code> 算法非常复杂，且对超参数敏感</li>
</ol>
</li>
<li><strong>不用 <code>RLHF</code> 的对齐如何做？</strong>
<ol>
<li>用 <code>SFT</code> 代替 <code>RLHF</code>，即用基于有监督微调代替基于人类反馈的强化学习</li>
<li>这种方法假设 <code>LLM</code> 可以从对齐数据集中学习到对齐行为</li>
<li>这种方法包含两个关键：<strong>构建对齐数据集</strong> 和 <strong>设计微调损失函数</strong></li>
</ol>
</li>
<li>构建对齐数据集<br />
对齐数据集的构建主要包含三种方法：<strong>基于奖励模型的方法</strong>、<strong>基于大模型的生成方法</strong> 和 <strong>基于大模型的互动方法</strong>
<ol>
<li>基于奖励模型的方法
<ol>
<li>从生成模型中采样一批数据</li>
<li>使用奖励模型对其进行评分，筛选出高质量样本（或对样本进行质量分组）</li>
<li>用奖励模型的输出做为监督信息，微调 <code>LLM</code></li>
<li>使用这种方法的算法有：
<ol>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2304.06767"><code>RAFT</code></a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2205.13636"><code>Quark</code></a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.16755"><code>ILF</code></a></li>
</ol>
</li>
<li>一些好用的开源奖励模型：
<ol>
<li><code>OpenAssistant</code> 开源的 <code>DeBERTa</code> 系列奖励模型</li>
<li>复旦大学开源的 <code>Moss-7B</code> 奖励模型</li>
<li>斯坦福大学开源的 <code>Flan-T5-xl</code> 奖励模型</li>
</ol>
</li>
<li>基于奖励模型的方法存在的问题：
<ol>
<li>奖励模型本身的训练需要大量对齐标注数据，这些数据是难以获得且昂贵的</li>
<li>尽管已有的奖励模型可以复用，但它们可以无法准确捕捉到另外一个独立训练的大模型的不对齐行为</li>
</ol>
</li>
</ol>
</li>
<li>基于大模型生成的方法
<ol>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2212.08073"><code>Constitutional AI</code></a> 将人类监督映射为一组原则（自然语言指令的集合），让 <code>LLM</code> 重复的用这组原则批判并修正自己的输出</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.03047"><code>Self-Align</code></a> 是先用 <code>Self-Instruct</code> 方法生成多样性强的指令数据集，然后模型会被提示多个人类编写的原则，这些原则描述了期望的模型规则和行为，以生成符合 <code>3H</code> 标准的数据用于对齐训练</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.04072"><code>FIGA</code></a> 采用正样本（<code>LLM</code> 精炼后的输出）和负样本（原始到低质量输出）对比学习的方法，缓解了 <code>SFT</code> 只能用正样本监督学习的问题，使 <code>LLM</code> 能够深入理解哪些细粒度的修改实际上导致了良好的响应</li>
</ol>
</li>
<li>基于大模型交互的方法
<ol>
<li>传统大模型训练都是孤立的，没有外部反馈信号来改进自己</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.16960"><code>Stable Alignment</code></a> 通过多个 <code>LLM</code> 交互来获得改进的反馈，从而实现自我改进</li>
</ol>
</li>
</ol>
</li>
<li><strong>有监督对齐微调</strong><br />
有监督对齐微调有点类似于指令微调，主要的训练损失函数依然是 <code>Sequence-to-Sequence</code> 的交叉熵损失，但一些研究提出对主要训练目标的改机，并提出了一些辅助损失，可用于挖掘对齐数据集的潜力，提高对齐质量
<ol>
<li>主要训练目标
<ol>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2302.02676"><code>CoT (Chain of Hindsight)</code></a> 对有监督微调数据集中的正负样本分别添加“一个有帮助的回答”和“一个没有帮助的回答”两种指令，且仅对有特殊掩码的响应标记计算损失</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2205.13636"><code>Quark</code></a> 将模型响应数据（对齐监督训练数据）按对齐质量分成不同的分位数，每个监督数据前加入一个特殊的奖励 <code>token</code>，用于表示响应的奖励等级</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.18290"><code>DPO (Direct preference optimization)</code></a> 将大模型本身用于奖励模型，从而不需要显式的奖励模型</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2311.04072"><code>FIGA</code></a> 定义细粒度对比学习损失</li>
</ol>
</li>
<li>辅助训练目标
<ol>
<li>排序损失
<ol>
<li>由于奖励模型可以给每一个响应评分，所以收集同一条指令的多组响应可以排序，可以计算排序辅助损失</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2304.05302"><code>RRHF</code></a> 模型就在 <code>SFT</code> 对齐训练中加入了排序辅助损失</li>
</ol>
</li>
<li>相似性损失
<ol>
<li>模型的响应和人类偏好的相似性可以通过计算潜在空间中的距离来得到</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.10425"><code>SLiC-HF</code></a> 就增加了相似性损失函数来对齐响应和人类偏好</li>
</ol>
</li>
<li>对比学习损失
<ol>
<li>对比学习可以用来提高正确的 “指令 —— 响应” 对的概率，降低错误的 “指令 —— 响应” 对的概率，这样做可以使模型学会指令和响应之间的正确相关性。</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><strong>总结</strong>
<ol>
<li><code>RLHF</code> 是用对齐数据训练一个 <code>RM</code>，然后用 <code>RM</code> 指导模型微调（给模型的响应打分）</li>
<li><code>SFT</code> 是直接用对齐数据微调模型</li>
<li>二者对比来看，<code>RLHF</code> 学习的是响应级监督，而 <code>SFT</code> 学习的是 <code>token</code> 级监督</li>
<li><code>SFT</code> 微调的模型，在遇到对齐微调数据集之外的数据时，更倾向产生幻觉，尤其是在对齐微调数据集是由大模型生成的时候</li>
<li>由于没有奖励模型做标注质量过滤，<code>SFT</code> 对标注质量更敏感</li>
<li><code>RLHF</code> 对缓解有害输出和增强模型能力方面非常有效，在 <code>LLaMa 2</code> 中，<code>RLHF</code> 同时提高了模型的帮助性和无害性得分，并将其归功于 <code>RLHF</code> 实现了一种更优的 “LLM —— 人类” 交互方式</li>
<li><code>RLHF</code> 实际上是通过鼓励 <code>LLM</code> 通过对比自己生成内容的 “好” 和 “不好” 评价，找到一种纠正策略；而不是像 <code>SFT</code> 一样，强制让模型去模仿 “好” 的外部内容（非自我生成）</li>
<li><code>RLHF</code> 可以减轻幻觉行为，这一点在 <code>GPT-4</code> 中被证实</li>
<li>传统强化学习的缺点，<code>RLHF</code> 一样不少，比如样本效率低下和训练稳定性差</li>
<li><code>RLHF</code> 的 <code>LLM</code> 必须先用 <code>SFT</code> 预训练收敛的参数初始化</li>
<li><code>RLHF</code> 需要标注员参与到复杂的迭代过程中，不能像 <code>SFT</code> 一样标注和训练解耦</li>
<li><code>RLHF</code> 的结果对实验过程细节非常敏感，例如：
<ol>
<li>提示词的选择</li>
<li>奖励模型和 <code>PPO</code> 的训练策略</li>
<li>超参数设置</li>
</ol>
</li>
<li><code>SFT</code> 可以提高预训练模型的容量，<code>RLHF</code> 可能会提高 <code>SFT</code> 的模型容量</li>
<li><code>RLHF</code> 过程还比较原始，需要探索和优化的点还有很多</li>
</ol>
</li>
</ol>
<h3 id="53-参数高效的模型适配微调"><a class="markdownIt-Anchor" href="#53-参数高效的模型适配微调"></a> 5.3 参数高效的模型适配微调</h3>
<ol>
<li><strong>参数高效的微调方法</strong><br />
大模型参数量太多，微调全部参数对大多数用户不可实现，因此 <strong>参数高效的微调方法</strong> 主要是通过降低微调过程中可学习的参数量实现参数高效的微调，主要方法有四种，如图：<br />
<img src="https://s2.loli.net/2024/09/26/TpXSCOGfjocHkJR.png" alt="LLM_survey_14.png" />
<ol>
<li><code>Adapter Tuning</code> 适配器微调
<ol>
<li>适配器微调论文出自 <code>2019</code> 年 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1902.00751"><code>Parameter-Efficient Transfer Learning for NLP</code></a>，是 <code>Bert</code> 时代的产物</li>
<li>本质是在 <strong>标准 <code>Transformer</code> 模型预训练结束后</strong>，在每个 <code>Transformer block</code> 中加入两个 <code>Adapter block</code>，其他参数冻结，只微调 <code>Adapter block</code></li>
<li><code>Adapter block</code> 中包含降采样(<code>Down project</code>)算子，因此计算量和参数量都较小</li>
<li><code>Adapter block</code> 在 <code>Transformer block</code> 中的位置以及 <code>Adapter block</code> 长什么样？<br />
<img src="https://s2.loli.net/2024/09/26/qvkPDF8ZfOKpaet.png" alt="LLM_survey_15.png" />
<blockquote>
<p>图中所有的绿色块表示微调过程中可训练的参数</p>
</blockquote>
</li>
</ol>
</li>
<li><code>Prefix Tuning</code> / <code>Prompt Tuning</code> 前缀微调
<ol>
<li>前缀微调的基本假设是：预训练之后的大模型实际上已经完全具备解决任何下游任务的能力，只需要找到合适的提示词（不一定是词表中的词）即可。</li>
<li>开山之作是斯坦福的 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2101.00190"><code>Prefix Tuning</code></a>，详细分析可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/09/26/Prefix-Tuning-Optimizing-Continuous-Prompts-for-Generation/">这篇博客</a></li>
<li>然后是清华大学提出的 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.10385"><code>P-Tuning</code></a>，详细可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/09/29/GPT-Understands-Too/">这篇博客</a></li>
<li>然后是谷歌对 <code>Prefix Tuning</code> 的小修改版本，<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.08691"><code>Prompt Tuning</code></a>，详细分析可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/09/27/The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning/">这篇博客</a></li>
<li>清华大学还对 <code>P-Tuning</code> 进行了升级 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2110.07602"><code>P-Tuning v2</code></a>，详细可参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/10/08/P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks/">这篇博客</a></li>
</ol>
</li>
<li><code>Low-Rank Adaptation (LoRA)</code>
<ul>
<li>具体参考 <a target="_blank" rel="noopener" href="https://zhangzhe.space/2024/10/12/LoRA-Low-Rank-Adaptation-of-Large-Language-Models/">这篇博客</a></li>
</ul>
</li>
</ol>
</li>
</ol>
<h2 id="6-使用"><a class="markdownIt-Anchor" href="#6-使用"></a> 6. 使用</h2>
<h1 id="wip"><a class="markdownIt-Anchor" href="#wip"></a> WIP</h1>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/02/20/%E5%85%B3%E9%94%AE%E8%B7%A8%E8%B6%8A/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/02/20/%E5%85%B3%E9%94%AE%E8%B7%A8%E8%B6%8A/" class="post-title-link" itemprop="url">关键跨越</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-02-20 20:52:50" itemprop="dateCreated datePublished" datetime="2024-02-20T20:52:50+08:00">2024-02-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%A2%86%E5%AF%BC%E5%8A%9B/" itemprop="url" rel="index"><span itemprop="name">领导力</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/02/20/%E5%85%B3%E9%94%AE%E8%B7%A8%E8%B6%8A/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/02/20/%E5%85%B3%E9%94%AE%E8%B7%A8%E8%B6%8A/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="新手管理者的关键跨越"><a class="markdownIt-Anchor" href="#新手管理者的关键跨越"></a> 新手管理者的关键跨越</h1>
<h2 id="1-新手管理者会遇到的-9-个管理难题和需要完成的-3-个关键跨越"><a class="markdownIt-Anchor" href="#1-新手管理者会遇到的-9-个管理难题和需要完成的-3-个关键跨越"></a> 1. 新手管理者会遇到的 9 个管理难题和需要完成的 3 个关键跨越</h2>
<h3 id="11-九个管理难题"><a class="markdownIt-Anchor" href="#11-九个管理难题"></a> 1.1 九个管理难题</h3>
<ol>
<li>从同事变为管理者，接受和适应“管理者”的身份。</li>
<li>空降到团队做管理者，被团队接纳和认可。</li>
<li>给团队成员分配合理的任务，提出合理的要求。</li>
<li>让员工承担更多或更有挑战性的工作，付出额外的努力。</li>
<li>让员工理解和认同管理者的要求，真正承担起责任。</li>
<li>处理团队搞不定的问题和突发状况。</li>
<li>及时掌握团队的任务执行情况，提前干预。</li>
<li>用恰当的方式给予员工反馈。</li>
<li>根据员工的不同情况，因材施教。</li>
</ol>
<h3 id="12-三个关键跨越"><a class="markdownIt-Anchor" href="#12-三个关键跨越"></a> 1.2 三个关键跨越</h3>
<ol>
<li>获得团队的认可和信任，完成“承担管理责任”的跨越。</li>
<li>让团队稳定可靠地交付工作成果，完成“推动执行”的跨越。</li>
<li>帮助团队改进和提升，完成“辅导他人”的跨越。</li>
</ol>
<h2 id="2-新手管理者为何难以完成关键跨越"><a class="markdownIt-Anchor" href="#2-新手管理者为何难以完成关键跨越"></a> 2. 新手管理者为何难以完成关键跨越</h2>
<h3 id="21-新手管理者普遍存在的现象"><a class="markdownIt-Anchor" href="#21-新手管理者普遍存在的现象"></a> 2.1 新手管理者普遍存在的现象</h3>
<ul>
<li>通常当前在任的一线管理者在“承担管理责任”和“推动执行”方面表现良好，但在“辅导他人”方面表现很差，同时这也是相对最不受企业重视的能力。</li>
</ul>
<h3 id="22-管理者难以完成管理跨越的原因"><a class="markdownIt-Anchor" href="#22-管理者难以完成管理跨越的原因"></a> 2.2 管理者难以完成管理跨越的原因</h3>
<ol>
<li>从关注“事”到关注“人”，管理工作需要把工作对象和重心从“事”转移到“人”，这会挑战一部分管理者的工作习惯。</li>
<li>从“短期”到“长期”，管理工作相对需要更长的时间的投入才能看到成效，一部分管理者会等不及。</li>
<li>从“优势”变成“陷阱”，管理者习惯用过去自己习惯和擅长的方式解决问题，也更喜欢做自己擅长的事情。</li>
</ol>
<h3 id="23-新手管理者应该怎么做"><a class="markdownIt-Anchor" href="#23-新手管理者应该怎么做"></a> 2.3 新手管理者应该怎么做</h3>
<ol>
<li>需要做好的心态准备是“空杯心态”。</li>
<li>对“我过去这样成功过”的想法保持警惕。</li>
<li>列出一个反向待办事项清单，训练自己少做和不做过去自己擅长的事。</li>
</ol>
<h2 id="3-成功跨越在行动中改变"><a class="markdownIt-Anchor" href="#3-成功跨越在行动中改变"></a> 3. 成功跨越：在行动中改变</h2>
<h3 id="31-新手管理者在进行管理发展时需要先理解两个问题"><a class="markdownIt-Anchor" href="#31-新手管理者在进行管理发展时需要先理解两个问题"></a> 3.1 新手管理者在进行管理发展时，需要先理解两个问题</h3>
<ol>
<li>某些人可能更具有管理潜力，更适合做管理。具备潜力的人有更高的起点和更好的准备状态，但无论多有管理潜力，都与管理岗位的要求存在差距，而缩小差距的唯一办法就是进行管理实践。</li>
<li>“知行不合一”是常态，管理者能采取有效的管理行动却未必具备相应的素质能力，同样，不具备一定优势的管理者，仍然可以先努力使自己的行为贴近团队管理者应有的表现。</li>
</ol>
<h3 id="32-新手管理者若想获得发展需要采取的发展原则是从自身优势出发先行动起来"><a class="markdownIt-Anchor" href="#32-新手管理者若想获得发展需要采取的发展原则是从自身优势出发先行动起来"></a> 3.2 新手管理者若想获得发展，需要采取的发展原则是从自身优势出发，先行动起来</h3>
<ol>
<li>了解自己的优势，把自己的优势作为一个支撑点和发力点。</li>
<li>行动起来，在行动中学习和发展。</li>
<li>通过管理历练和具体的时间，发展出相应的素质和能力。</li>
</ol>
<h3 id="33-新手管理者可以采用-apple-发展策略"><a class="markdownIt-Anchor" href="#33-新手管理者可以采用-apple-发展策略"></a> 3.3 新手管理者可以采用 APPLE 发展策略</h3>
<p><strong>APPLE 发展策略：</strong></p>
<ol>
<li><code>Awareness</code>: 认知管理者的要求，以及自身优势。</li>
<li><code>Path</code>: 制定一个最小化的发展路线图。从优势出发，给自己建立一个支撑点，并制定一个包括发展目标，具体行动和检验方法的计划。</li>
<li><code>Practice</code>: 付诸行动，通过刻意和反复的练习，跟过去的习惯已建立好的脑区地图抢夺资源，建立起新的通往目的地的路径。</li>
<li><code>Learn</code>: 学习知识，结合实践总结和反思。在实践中先有体验，学习就是带着问题寻找答案的主动过程。</li>
<li><code>Evaluation</code>: 定期评估，学会重新看待“评价”，把评价看做反映某一阶段性状态的中性动作。</li>
</ol>
<h1 id="关键跨越一承担管理责任"><a class="markdownIt-Anchor" href="#关键跨越一承担管理责任"></a> 关键跨越一：承担管理责任</h1>
<h2 id="4-信任的基石承担管理责任"><a class="markdownIt-Anchor" href="#4-信任的基石承担管理责任"></a> 4. 信任的基石：承担管理责任</h2>
<h3 id="41-新手管理者上任后的首要任务是取得团队的认可和信任"><a class="markdownIt-Anchor" href="#41-新手管理者上任后的首要任务是取得团队的认可和信任"></a> 4.1 新手管理者上任后的首要任务是取得团队的认可和信任</h3>
<ol>
<li>必须表现出一个管理者该有的样子，承担起管理的责任。</li>
<li>承担管理责任有三个关键要点：表率垂范、为结果负责和组织意识。</li>
</ol>
<h3 id="42-表率垂范包括以身作则和身先士卒"><a class="markdownIt-Anchor" href="#42-表率垂范包括以身作则和身先士卒"></a> 4.2 表率垂范包括以身作则和身先士卒</h3>
<ol>
<li>以身作则的核心是，要求下属的管理者自己要先做到。</li>
<li>身先士卒主要是，管理者在困难或关键时刻能顶上，冲在最前面。</li>
<li>要做到表率垂范，态度和勇气比能力更重要，是愿不愿的问题，而非能不能到问题。</li>
</ol>
<h3 id="43-为结果负责包括为所做决定负责和为团队的工作结果负责"><a class="markdownIt-Anchor" href="#43-为结果负责包括为所做决定负责和为团队的工作结果负责"></a> 4.3 为结果负责包括为所做决定负责和为团队的工作结果负责</h3>
<ol>
<li>要做到为决定负责，得学会适应两个常态：一是会犯错，二是不能两全其美。</li>
<li>为团队的工作结果负责要区分“好”的和“坏”的结果。取得坏结果时要帮团队“背锅”，取得好结果时则要把舞台和聚光灯留给下属。</li>
</ol>
<h3 id="44-组织意识包括遵守和代表组织的规则以及团队的利益为先"><a class="markdownIt-Anchor" href="#44-组织意识包括遵守和代表组织的规则以及团队的利益为先"></a> 4.4 组织意识包括遵守和代表组织的规则，以及团队的利益为先</h3>
<ol>
<li>在建章立制之前，应先适应和符合现有的规则。</li>
<li>团队利益为先是指你要为团队和公司着想，把个人利益放在团队之后。</li>
</ol>
<h2 id="5-新手管理者容易走进的误区"><a class="markdownIt-Anchor" href="#5-新手管理者容易走进的误区"></a> 5. 新手管理者容易走进的误区</h2>
<h3 id="51-新手管理者在取得下属认可和信任时容易走入的第一类误区"><a class="markdownIt-Anchor" href="#51-新手管理者在取得下属认可和信任时容易走入的第一类误区"></a> 5.1 新手管理者在取得下属认可和信任时，容易走入的第一类误区</h3>
<ol>
<li>过于依赖个人的专业能力，想要靠专业征服团队。这会带来的主要问题是管理者成为团队能力的上限，限制员工的发展。</li>
<li>认为可以完全不靠专业，发挥领导力即可。这会带来的问题是管理浮于表面，无法获得实质性的成效。</li>
</ol>
<h3 id="52-在进入管理岗位后管理者需要在个人能力上实现两个转换"><a class="markdownIt-Anchor" href="#52-在进入管理岗位后管理者需要在个人能力上实现两个转换"></a> 5.2 在进入管理岗位后，管理者需要在个人能力上实现两个转换</h3>
<ol>
<li>从运用自己的专业能力解决具体问题，转换为将专业优势赋能于团队。</li>
<li>从运用自己的个人实力去带领团队，转换为培养和成就团队。</li>
</ol>
<h3 id="53-第二类误区是让下属满意还是让上级满意的问题"><a class="markdownIt-Anchor" href="#53-第二类误区是让下属满意还是让上级满意的问题"></a> 5.3 第二类误区是让下属满意，还是让上级满意的问题</h3>
<ol>
<li>唯下”的管理者通常用两种方式取悦下属：一是让下属尽量少吃苦，二是滥用物质奖励。本质上都只是满足了保障性因素，只能让下属处于“不是不满意，也不是满意”的中性状态。</li>
<li>“唯上”的管理者围绕上级开展工作，不太关心员工的感受。这类管理者的个人发展极为有限，更易受领导更换或组织环境变化影响。</li>
</ol>
<h3 id="54-管理者只需要让客户满意这本质上是对绩效负责"><a class="markdownIt-Anchor" href="#54-管理者只需要让客户满意这本质上是对绩效负责"></a> 5.4 管理者只需要让客户满意，这本质上是对绩效负责</h3>
<ol>
<li>管理者需要为此而帮助下属改进和挑战下属突破。这是管理者与团队建立信任的正确方式。</li>
</ol>
<h3 id="55-第三类误区是关于与下属的距离和关系"><a class="markdownIt-Anchor" href="#55-第三类误区是关于与下属的距离和关系"></a> 5.5 第三类误区是关于与下属的距离和关系</h3>
<p>管理者易走入的两个极端：</p>
<ol>
<li>制造距离感，以树立个人领导权威。</li>
<li>过于注重经营关系，导致为关系所累，或是只运用人际和影响技巧而不交心，变成对下属的操纵控制。</li>
</ol>
<h3 id="56-管理者需要把握不同场合的交往分寸"><a class="markdownIt-Anchor" href="#56-管理者需要把握不同场合的交往分寸"></a> 5.6 管理者需要把握不同场合的交往分寸</h3>
<ul>
<li>管理者需要把握不同场合的交往分寸，做到“工作时严肃立规矩，私下可称兄道弟”。“事务”导向和“人际”导向的管理者所需要的努力不同，前者需要增加交流和互动，后者需要把握好情感投入的度。这样管理者与下属之间才能既有信任，也有温度。</li>
</ul>
<h2 id="6-真诚是最好的套路"><a class="markdownIt-Anchor" href="#6-真诚是最好的套路"></a> 6. 真诚是最好的套路</h2>
<h3 id="61-真诚是赢得信任的终极套路包括真诚坦率和展现真我"><a class="markdownIt-Anchor" href="#61-真诚是赢得信任的终极套路包括真诚坦率和展现真我"></a> 6.1 真诚是赢得信任的终极套路，包括真诚坦率和展现真我</h3>
<h3 id="62-真诚坦率包括两个维度"><a class="markdownIt-Anchor" href="#62-真诚坦率包括两个维度"></a> 6.2 真诚坦率包括两个维度</h3>
<ol>
<li>管理者能分享真实的信息，不隐瞒、不遮掩、不欺骗。</li>
<li>管理者能站在员工的角度理解员工，照顾员工的感受，真正为员工着想。根据这两个维度，管理者与下属相处有四种方式。
<ul>
<li>虚伪应付：不告知员工信息或不讲真话，同时也不在乎员工的感受。这是最不真诚的，管理者展现的是一种高高在上地掌控一切的傲慢。</li>
<li>真情假意：因为担心员工受伤害，而遮遮掩掩，不直接沟通。这样反而会弄巧成拙，员工会感觉到管理者有话不明说，因而会有各种猜测，从而造成很多误会。</li>
<li>直言不讳：有话明说，但不太考虑员工的感受。尽管可能会让员工感觉不舒服，但这种方式比虚伪应付和真情假意更真诚。</li>
<li>真诚坦率：既讲真话、实话，又能照顾到员工的感受。</li>
</ul>
</li>
</ol>
<h3 id="63-做到真诚坦率要注意五点"><a class="markdownIt-Anchor" href="#63-做到真诚坦率要注意五点"></a> 6.3 做到真诚坦率要注意五点</h3>
<ol>
<li>就事论事</li>
<li>讲具体的事</li>
<li>多分析背景信息</li>
<li>不带着情绪</li>
<li>多给建议和指导</li>
</ol>
<h3 id="64-为了满足各种社会期待每个人都会包装自己"><a class="markdownIt-Anchor" href="#64-为了满足各种社会期待每个人都会包装自己"></a> 6.4 为了满足各种社会期待，每个人都会包装自己</h3>
<p>但如果包装后的公众自我与你的内在自我差别很大，就会出现问题。</p>
<ol>
<li>虚张声势很容易会被看出来，让管理者看起来不值得被信赖。</li>
<li>过度假装会让管理者自己很不开心。</li>
</ol>
<h3 id="65-展现真我要做到三点"><a class="markdownIt-Anchor" href="#65-展现真我要做到三点"></a> 6.5 展现真我要做到三点</h3>
<ol>
<li>认识你自己</li>
<li>建立你内心的准则</li>
<li>适当地暴露弱点</li>
</ol>
<h1 id="关键跨越二推动执行"><a class="markdownIt-Anchor" href="#关键跨越二推动执行"></a> 关键跨越二：推动执行</h1>
<h2 id="7-新手管理者的执行力-20"><a class="markdownIt-Anchor" href="#7-新手管理者的执行力-20"></a> 7. 新手管理者的执行力 2.0</h2>
<h3 id="71-新手管理者需要将个人执行力升级为团队执行力"><a class="markdownIt-Anchor" href="#71-新手管理者需要将个人执行力升级为团队执行力"></a> 7.1 新手管理者需要将个人执行力升级为团队执行力</h3>
<ul>
<li>新手管理者需要将个人执行力升级为团队执行力，把最大化团队产出作为自己的工作目标，投入精力完成管理工作。</li>
</ul>
<h3 id="72-新手管理者要充分发挥团队成员的能力"><a class="markdownIt-Anchor" href="#72-新手管理者要充分发挥团队成员的能力"></a> 7.2 新手管理者要充分发挥团队成员的能力</h3>
<ul>
<li>新手管理者要充分发挥团队成员的能力，激发团队成员的工作动力，并提供必要的支持，为团队成员减少工作阻力。</li>
</ul>
<h3 id="73-新手管理者需要警惕常见的六大误区"><a class="markdownIt-Anchor" href="#73-新手管理者需要警惕常见的六大误区"></a> 7.3 新手管理者需要警惕常见的六大误区</h3>
<ul>
<li>新手管理者需要警惕常见的六大误区，规避不适用的思维模式和行为模式，完成管理角色转型。
<ul>
<li>误区一：超人心态</li>
<li>误区二：完美主义</li>
<li>误区三：想当然</li>
<li>误区四：控制狂</li>
<li>误区五：疏离旁观</li>
<li>误区六：安于现状</li>
</ul>
</li>
</ul>
<h2 id="8-做该做的事把猴子还给下属"><a class="markdownIt-Anchor" href="#8-做该做的事把猴子还给下属"></a> 8. 做该做的事，把“猴子”还给下属</h2>
<h3 id="81-管理者要多做自己该做的事少做或不做不该做的事"><a class="markdownIt-Anchor" href="#81-管理者要多做自己该做的事少做或不做不该做的事"></a> 8.1 管理者要多做自己该做的事，少做或不做不该做的事</h3>
<ol>
<li>员工现有能力可以完成的任务，要坚定不移地交给员工去做。</li>
<li>员工“跳一跳”能完成的任务也可以交给员工去做，同时管理者要提供必要的辅导和资源支持。</li>
<li>员工能力差距较大但有意愿去挑战的任务，如果有试错的空间，管理者可以和员工一起做，并承担失败的风险。</li>
</ol>
<h3 id="82-忍住让员工去思考和解决问题避免接过原本属于员工的猴子"><a class="markdownIt-Anchor" href="#82-忍住让员工去思考和解决问题避免接过原本属于员工的猴子"></a> 8.2 忍住，让员工去思考和解决问题，避免接过原本属于员工的“猴子”</h3>
<ol>
<li>不要直接给员工答案。</li>
<li>用提问的方式启发员工，让员工思考下一步如何行动。</li>
<li>让员工为工作任务负起责任来。</li>
</ol>
<h3 id="83-不要做超人放平心态"><a class="markdownIt-Anchor" href="#83-不要做超人放平心态"></a> 8.3 不要做“超人”，放平心态</h3>
<ol>
<li>对团队多一些耐心，不要为了快速达成目标而代替员工完成工作。</li>
<li>通过帮助团队成长获得新的成就感，不要因为无法站在舞台中央的失落感，就选择自己做事，和下属竞争站回舞台中央的机会。</li>
<li>不要因为害怕失败就不敢冒险放手让下属尝试，要给员工犯错空间，并学会把失败当成自己和团队学习的机会。</li>
<li>不需要通过代替员工做事去刻意讨好下属，得有把任务派给员工后被讨厌的勇气。</li>
</ol>
<h2 id="9-要事第一目标取舍的智慧和勇气"><a class="markdownIt-Anchor" href="#9-要事第一目标取舍的智慧和勇气"></a> 9. 要事第一：目标取舍的智慧和勇气</h2>
<h3 id="91-良好的开端是成功的一半在明确目标阶段管理者要做到要事第一"><a class="markdownIt-Anchor" href="#91-良好的开端是成功的一半在明确目标阶段管理者要做到要事第一"></a> 9.1 良好的开端是成功的一半，在明确目标阶段管理者要做到“要事第一”</h3>
<ol>
<li>到重要的20%，重点投入。</li>
<li>跟上级充分沟通，让上级帮助明确不同目标的重要性和优先级排序。</li>
<li>不要追求面面俱到，得学会取舍，避免目标平均主义。</li>
</ol>
<h3 id="92-管理者在完成短期目标的同时需要考虑如何实现年度目标逐步建立长期思维"><a class="markdownIt-Anchor" href="#92-管理者在完成短期目标的同时需要考虑如何实现年度目标逐步建立长期思维"></a> 9.2 管理者在完成短期目标的同时，需要考虑如何实现年度目标，逐步建立长期思维</h3>
<ol>
<li>管理工作本身就是在为长期目标负责。</li>
<li>学会拉长时间维度去评估投入与收益。</li>
<li>根据业务紧迫性和团队成熟度对目标的优先级进行动态调整。</li>
</ol>
<h2 id="10-人事匹配让对的人去做对的事"><a class="markdownIt-Anchor" href="#10-人事匹配让对的人去做对的事"></a> 10. 人事匹配：让对的人去做对的事</h2>
<h3 id="101-根据意愿能力四象限完成人事匹配"><a class="markdownIt-Anchor" href="#101-根据意愿能力四象限完成人事匹配"></a> 10.1 根据意愿能力四象限，完成人事匹配</h3>
<ol>
<li>对于高意愿高能力的明星员工，可以把有难度的重要工作交给他们。</li>
<li>对于低意愿低能力的问题员工，需要进行绩效反馈，明确绩效改进方向。</li>
<li>对于高意愿低能力的“潜力股”员工，应以能胜任的工作任务为主，同时分配一些“跳起来”可以够得着的挑战性任务来提升其能力。</li>
<li>对于低意愿高能力的“精明人”员工，需要适当激发，并保证团队内部任务分配和激励回报的公平性。</li>
</ol>
<h3 id="102-可以通过观察-询问-实战三个环节来判断员工的意愿和能力"><a class="markdownIt-Anchor" href="#102-可以通过观察-询问-实战三个环节来判断员工的意愿和能力"></a> 10.2 可以通过观察、询问、实战三个环节来判断员工的意愿和能力</h3>
<h3 id="103-在进行任务沟通时管理者要做到四点"><a class="markdownIt-Anchor" href="#103-在进行任务沟通时管理者要做到四点"></a> 10.3 在进行任务沟通时，管理者要做到四点</h3>
<ul>
<li>第一，将工作“翻译”成员工更容易听懂的语言，解释清楚“为什么”。</li>
<li>第二，清晰无误地说明任务要求，不遗漏必要信息。</li>
<li>第三，进行双向沟通，获得员工及时反馈。</li>
<li>第四，与员工沟通不同工作的优先级。</li>
</ul>
<h3 id="104-管理者要避免陷入想当然误区"><a class="markdownIt-Anchor" href="#104-管理者要避免陷入想当然误区"></a> 10.4 管理者要避免陷入“想当然”误区</h3>
<ul>
<li>管理者要避免陷入“想当然”误区，主动反思自己是否以己度人，忽略了人与人之间的差异，或低估了任务的难度。</li>
</ul>
<h3 id="105-管理者要避免想当然应该在行动上向员工展现出欢迎提问的姿态也需要在工作中多观察员工的行为了解员工的意愿和能力"><a class="markdownIt-Anchor" href="#105-管理者要避免想当然应该在行动上向员工展现出欢迎提问的姿态也需要在工作中多观察员工的行为了解员工的意愿和能力"></a> 10.5 管理者要避免“想当然”，应该在行动上向员工展现出欢迎提问的姿态，也需要在工作中多观察员工的行为，了解员工的意愿和能力</h3>
<h2 id="11-过程管理把握尺度"><a class="markdownIt-Anchor" href="#11-过程管理把握尺度"></a> 11. 过程管理：把握尺度</h2>
<h3 id="111-根据任务容错率和员工成熟度选择不同的管控方式避免一刀切"><a class="markdownIt-Anchor" href="#111-根据任务容错率和员工成熟度选择不同的管控方式避免一刀切"></a> 11.1 根据任务容错率和员工成熟度选择不同的管控方式，避免一刀切</h3>
<ol>
<li>对于容错率高的任务，如果员工成熟度高，可以让员工放手去做；如果员工成熟度低，则需要加强过程辅导。</li>
<li>对于容错率低的任务，即使员工成熟度高，管理者仍需要管理过程中的关键节点；如果员工成熟度低，这项任务应该由管理者自己负责，带着员工一起完成。</li>
</ol>
<h3 id="112-在过程管理中要避免陷入微观管理变成控制狂也不能放手不管做一个远离团队的甩手掌柜"><a class="markdownIt-Anchor" href="#112-在过程管理中要避免陷入微观管理变成控制狂也不能放手不管做一个远离团队的甩手掌柜"></a> 11.2 在过程管理中要避免陷入微观管理，变成“控制狂”，也不能放手不管，做一个远离团队的“甩手掌柜”</h3>
<h3 id="113-过程管理更有效的方式是设置合理的信息沟通反馈机制"><a class="markdownIt-Anchor" href="#113-过程管理更有效的方式是设置合理的信息沟通反馈机制"></a> 11.3 过程管理更有效的方式是设置合理的信息沟通反馈机制</h3>
<ul>
<li>管理者可以通过以下方式获取需要的信息：
<ul>
<li>定期开例会</li>
<li>建立抄送邮件的规则</li>
<li>工作进度可视化</li>
<li>开展专项会议讨论</li>
<li>加强非正式沟通</li>
</ul>
</li>
</ul>
<h2 id="12-vuca时代需要敏捷执行"><a class="markdownIt-Anchor" href="#12-vuca时代需要敏捷执行"></a> 12. VUCA时代需要敏捷执行</h2>
<h3 id="121-vuca时代需要敏捷执行核心是以终为始抓住关键矛盾"><a class="markdownIt-Anchor" href="#121-vuca时代需要敏捷执行核心是以终为始抓住关键矛盾"></a> 12.1 VUCA时代需要敏捷执行，核心是以终为始，抓住关键矛盾</h3>
<h3 id="122-产出最小化可交付成果尽早获得最终用户的反馈通过多次迭代来更聪明-高效地工作完成比完美更重要"><a class="markdownIt-Anchor" href="#122-产出最小化可交付成果尽早获得最终用户的反馈通过多次迭代来更聪明-高效地工作完成比完美更重要"></a> 12.2 产出最小化可交付成果，尽早获得最终用户的反馈，通过多次迭代来更聪明、高效地工作，完成比完美更重要</h3>
<h3 id="123-制订有弹性的工作计划给自己预留20的时间用于应对临时出现的重要任务或者就用于思考避免被不重要的事情塞满日程表"><a class="markdownIt-Anchor" href="#123-制订有弹性的工作计划给自己预留20的时间用于应对临时出现的重要任务或者就用于思考避免被不重要的事情塞满日程表"></a> 12.3 制订有弹性的工作计划，给自己预留20%的时间用于应对临时出现的重要任务或者就用于思考，避免被不重要的事情塞满日程表</h3>
<h3 id="124-管理者要敢于说不赢回自己的时间"><a class="markdownIt-Anchor" href="#124-管理者要敢于说不赢回自己的时间"></a> 12.4 管理者要敢于说“不”，赢回自己的时间</h3>
<p>具体可以参考以下三个步骤：</p>
<ul>
<li>复述对方的要求</li>
<li>解释拒绝的原因</li>
<li>坦诚说“不”</li>
</ul>
<h2 id="13-复盘让管理实现闭环"><a class="markdownIt-Anchor" href="#13-复盘让管理实现闭环"></a> 13. 复盘让管理实现闭环</h2>
<h3 id="131-复盘让管理形成闭环为管理者提供思考的空间也是团队改进和提升的原点"><a class="markdownIt-Anchor" href="#131-复盘让管理形成闭环为管理者提供思考的空间也是团队改进和提升的原点"></a> 13.1 复盘让管理形成闭环，为管理者提供思考的空间，也是团队改进和提升的原点</h3>
<h3 id="132-成功的复盘要求管理者和团队成员建立信任保持开放-包容的心态并有能力从过往的实践中提炼出规律性的结论指导行动"><a class="markdownIt-Anchor" href="#132-成功的复盘要求管理者和团队成员建立信任保持开放-包容的心态并有能力从过往的实践中提炼出规律性的结论指导行动"></a> 13.2 成功的复盘要求管理者和团队成员建立信任，保持开放、包容的心态，并有能力从过往的实践中提炼出规律性的结论，指导行动</h3>
<h3 id="133-复盘可以作为日常管理的工具要做到及时和精要才能保证良好的复盘效果"><a class="markdownIt-Anchor" href="#133-复盘可以作为日常管理的工具要做到及时和精要才能保证良好的复盘效果"></a> 13.3 复盘可以作为日常管理的工具，要做到及时和精要，才能保证良好的复盘效果</h3>
<h3 id="134-专项复盘可以帮助团队及时总结失败教训沉淀成功经验"><a class="markdownIt-Anchor" href="#134-专项复盘可以帮助团队及时总结失败教训沉淀成功经验"></a> 13.4 专项复盘可以帮助团队及时总结失败教训，沉淀成功经验</h3>
<p>专项复盘分为三步曲：</p>
<ul>
<li>还原事实</li>
<li>分析问题根因</li>
<li>制订行动计划</li>
</ul>
<h1 id="关键跨越三辅导他人"><a class="markdownIt-Anchor" href="#关键跨越三辅导他人"></a> 关键跨越三：辅导他人</h1>
<h2 id="14-辅导他人亟待提升"><a class="markdownIt-Anchor" href="#14-辅导他人亟待提升"></a> 14. 辅导他人，亟待提升</h2>
<h3 id="141-辅导员工的关键四步"><a class="markdownIt-Anchor" href="#141-辅导员工的关键四步"></a> 14.1 .辅导员工的关键四步</h3>
<ul>
<li>投入时间：坚持在辅导上投入时间，切实帮助团队提升。</li>
<li>明确目标：以绩效目标为导向，了解员工现状，和员工就发展目标达成共识。</li>
<li>反馈与指导：在辅导现场，直面挑战，提升员工的积极性，帮助员工解决问题。</li>
<li>跟进与评价：跟进与评价员工的表现，评价他们的行为进展，并通过正确地批评和表扬他们，帮助他们更好地提升。</li>
</ul>
<h3 id="142-新手管理者在辅导上容易陷入的三个误区"><a class="markdownIt-Anchor" href="#142-新手管理者在辅导上容易陷入的三个误区"></a> 14.2 新手管理者在辅导上容易陷入的三个误区</h3>
<ul>
<li>理想化：辅导形式大于内容，不考虑业务需求和员工现状。</li>
<li>以自我为中心：只从自己的想法出发，忽视员工与自己的差异，遇到问题不是从自身寻找原因。</li>
<li>急于求成：对员工的成长没有耐心，辅导员工时容易急躁，急于给员工下定论，难以持续投入。</li>
</ul>
<h2 id="15-辅导的开始如何投入时间"><a class="markdownIt-Anchor" href="#15-辅导的开始如何投入时间"></a> 15. 辅导的开始：如何投入时间</h2>
<p>管理者进行辅导的第一步：切实有效地在辅导上投入时间。管理者要注意：</p>
<h3 id="151-不为自己没有在辅导上投入找借口"><a class="markdownIt-Anchor" href="#151-不为自己没有在辅导上投入找借口"></a> 15.1 不为自己没有在辅导上投入找借口</h3>
<ol>
<li>正视自己没有辅导员工的现状，思考自己要如何改变。</li>
<li>相信自己可以决定自己的时间，并为自己的时间负责。</li>
</ol>
<h3 id="152-找到问题的症结所在避免陷入越努力越忙碌的处境"><a class="markdownIt-Anchor" href="#152-找到问题的症结所在避免陷入越努力越忙碌的处境"></a> 15.2 找到问题的症结所在，避免陷入“越努力，越忙碌”的处境</h3>
<ol>
<li>管理者面对的问题是系统性问题，单一的问题解决思路会起到反效果。</li>
<li>评估自己的行为会对团队产生的影响，通过辅导提升团队能力，从而建立自己在工作中的正向循环。</li>
</ol>
<h3 id="153-坚持在辅导上进行投入"><a class="markdownIt-Anchor" href="#153-坚持在辅导上进行投入"></a> 15.3 坚持在辅导上进行投入</h3>
<ol>
<li>辅导更需要细水长流的投入，考验的是管理者是否能坚持。</li>
<li>管理者需要有意识地培养自己的辅导习惯，可以通过诸如“辅导他人行为清单”的方式提醒自己。</li>
</ol>
<h3 id="154-基于二八原则分配自己的时间"><a class="markdownIt-Anchor" href="#154-基于二八原则分配自己的时间"></a> 15.4 基于二八原则分配自己的时间</h3>
<ol>
<li>管理者辅导员工时需要以团队的产出最大化为目标。</li>
<li>表现优秀的员工更值得，也更需要管理者的辅导。</li>
<li>只关注绩效表现不佳的员工，容易让其他员工感到不公平。</li>
<li>有效分配时间的关键在于准确地对员工进行分类。</li>
<li>管理者在评估员工时，要同时关注当下工作和未来工作的要求。</li>
</ol>
<h2 id="16-明确目标促进绩效达成"><a class="markdownIt-Anchor" href="#16-明确目标促进绩效达成"></a> 16. 明确目标，促进绩效达成</h2>
<p>管理者在和员工制定辅导目标时，需要遵循以下三个原则：</p>
<h3 id="161-促进绩效提升"><a class="markdownIt-Anchor" href="#161-促进绩效提升"></a> 16.1 促进绩效提升</h3>
<ol>
<li>基于对绩效目标的分析，结合员工当下的重点工作，初步找出可能需要提升的地方。</li>
<li>还原工作现场，通过行为观察、他人反馈、情境模拟等多种方式，了解员工实际的工作情况。</li>
<li>深入分析，找到员工表现背后的原因，制定有针对性的辅导方向。</li>
</ol>
<h3 id="162-和员工达成共识"><a class="markdownIt-Anchor" href="#162-和员工达成共识"></a> 16.2 和员工达成共识</h3>
<ol>
<li>在与员工沟通前，管理者和员工都需要做好充分的准备。</li>
<li>鼓励员工发表意见，认真倾听员工的想法，并且即使遇到冲突也就事论事，不强求员工听取自己的意见，也不和员工去争一时的对错。</li>
</ol>
<h3 id="163-辅导目标可评估-可实现"><a class="markdownIt-Anchor" href="#163-辅导目标可评估-可实现"></a> 16.3 辅导目标可评估、可实现</h3>
<ol>
<li>辅导目标要注重可行性，不要好高骛远。</li>
<li>辅导目标中应该包含具体的行为，有助于管理者和员工达成共识。</li>
</ol>
<h2 id="17-信任-激发与赋能"><a class="markdownIt-Anchor" href="#17-信任-激发与赋能"></a> 17. 信任、激发与赋能</h2>
<p>在成功辅导员工的过程中，管理者要做到三件事情：与员工建立相互信任的辅导关系；激发员工不断提升自我的积极性；赋能员工，提升员工解决问题的能力。</p>
<h3 id="171-建立相互信任的辅导关系"><a class="markdownIt-Anchor" href="#171-建立相互信任的辅导关系"></a> 17.1 建立相互信任的辅导关系</h3>
<ol>
<li>管理者要让员工尽快感受到自己的提升，从而让其对辅导抱有信心。</li>
<li>管理者需要避免高高在上，和员工做平等沟通，多倾听员工的想法。</li>
</ol>
<h3 id="172-激发员工的积极性"><a class="markdownIt-Anchor" href="#172-激发员工的积极性"></a> 17.2 激发员工的积极性</h3>
<ol>
<li>面对受挫的员工：管理者需要引导员工从长远和正向的角度看待问题，理解其受挫的感受和心情，并通过工作的调配转移其注意力。</li>
<li>面对积极性不高的员工：让员工更客观地认知自己的水平；为员工树立榜样，展现未来发展愿景；通过竞争持续调动员工的积极性。</li>
<li>面对缺少行动力的员工：发挥目标的管控作用，要求员工必须有行动；让员工为自己负责，管理者避免越俎代庖；必要时，终止辅导关系。</li>
</ol>
<h3 id="173-赋能员工"><a class="markdownIt-Anchor" href="#173-赋能员工"></a> 17.3 赋能员工</h3>
<ol>
<li>理解员工能力提升的三个阶段：知道、理解和应用。员工要逐步形成自己的知识体系，并通过思考和实践，不断地获得反馈和提升。</li>
<li>只让员工去尝试而不给予反馈，或只让员工学习知识而不实践都不是适合员工的辅导方式。</li>
<li>在赋能员工时，管理者要让员工通过历练，感受到挑战和问题所在，并对问题进行分析和思考，进而在实践中做出尝试和探索。在逐步探索中，管理者要鼓励员工形成自己的判断，通过对外输出，将自己的经验转化为能力。</li>
</ol>
<h2 id="18-跟进与评价"><a class="markdownIt-Anchor" href="#18-跟进与评价"></a> 18. 跟进与评价</h2>
<p>员工的能力提升需要经历持续练习和反馈的过程。管理者需要在这个过程中持续跟进员工的行为表现，及时发现并指出员工的问题，帮助他们持续改进。管理者还需要及时看到员工取得的进展，并及时给予鼓励和肯定。</p>
<h3 id="181-把辅导当成项目来管理"><a class="markdownIt-Anchor" href="#181-把辅导当成项目来管理"></a> 18.1 把辅导当成项目来管理</h3>
<p>跟进最难的地方在于坚持，管理者可以按照管理项目的方式，始终聚焦辅导目标，制订跟进计划，明确责任人，使用辅助工具，以帮助自己形成跟进的习惯。</p>
<h3 id="182-对员工的成长有耐心"><a class="markdownIt-Anchor" href="#182-对员工的成长有耐心"></a> 18.2 对员工的成长有耐心</h3>
<p>员工的成长并非一蹴而就，管理者需要给员工时间和试错的空间，并且当员工取得进步时，即使没有达到期待，也要给予正向的鼓励。</p>
<h3 id="183-做出正确的批评和表扬"><a class="markdownIt-Anchor" href="#183-做出正确的批评和表扬"></a> 18.3 做出正确的批评和表扬</h3>
<p>跟进是评价和反馈的基础，要做到正确地批评和表扬，管理者要以事实为依据，以解决问题为导向，并在沟通时保持真诚。</p>
<h1 id="成为管理者"><a class="markdownIt-Anchor" href="#成为管理者"></a> 成为管理者</h1>
<h2 id="19-管理者发展的全景图五个阶段的关键跨越"><a class="markdownIt-Anchor" href="#19-管理者发展的全景图五个阶段的关键跨越"></a> 19. 管理者发展的全景图：五个阶段的关键跨越</h2>
<h3 id="191-一个人的职业发展会历经很多角色了解管理者发展的全景图能帮助你提前做好准备学会换位思考理解上下级的工作挑战和想法"><a class="markdownIt-Anchor" href="#191-一个人的职业发展会历经很多角色了解管理者发展的全景图能帮助你提前做好准备学会换位思考理解上下级的工作挑战和想法"></a> 19.1 一个人的职业发展会历经很多角色，了解管理者发展的全景图，能帮助你提前做好准备，学会换位思考，理解上下级的工作挑战和想法</h3>
<h3 id="192-你会经历的职场角色有五个阶段"><a class="markdownIt-Anchor" href="#192-你会经历的职场角色有五个阶段"></a> 19.2 你会经历的职场角色有五个阶段</h3>
<ol>
<li>管理自我</li>
<li>管理他人</li>
<li>管理管理者</li>
<li>管理职能/事业部</li>
<li>管理企业</li>
</ol>
<h3 id="193-管理自我阶段的关键挑战"><a class="markdownIt-Anchor" href="#193-管理自我阶段的关键挑战"></a> 19.3 管理自我阶段的关键挑战</h3>
<p>管理自我阶段的关键挑战:稳定可靠地交付工作成果、保持并提高专业的水准和效率、与客户和工作伙伴顺畅沟通。<br />
所需完成的关键跨越：</p>
<ol>
<li>高效执行</li>
<li>展现专业素养</li>
<li>有效沟通</li>
</ol>
<h3 id="194-管理他人阶段的关键挑战"><a class="markdownIt-Anchor" href="#194-管理他人阶段的关键挑战"></a> 19.4 管理他人阶段的关键挑战</h3>
<p>管理他人阶段的关键挑战：获得团队的认可和信任、让团队稳定可靠地交付工作成果、帮助团队改进和提升。<br />
所需完成的关键跨越：</p>
<ol>
<li>承担管理责任</li>
<li>推动执行</li>
<li>辅导他人</li>
</ol>
<h3 id="195-管理管理者阶段的关键挑战"><a class="markdownIt-Anchor" href="#195-管理管理者阶段的关键挑战"></a> 19.5 管理管理者阶段的关键挑战</h3>
<p>管理管理者阶段的关键挑战：</p>
<ol>
<li>系统性地解决问题</li>
<li>让一线管理者充分发挥作用</li>
<li>统一目标，平衡资源和利益<br />
所需完成的关键跨越：</li>
<li>系统化思考</li>
<li>授权</li>
<li>协同增效</li>
</ol>
<h3 id="196-管理职能事业部阶段的关键挑战"><a class="markdownIt-Anchor" href="#196-管理职能事业部阶段的关键挑战"></a> 19.6 管理职能/事业部阶段的关键挑战</h3>
<p>应对常态化的模糊和不确定状况、以经营思维管理职能部门或事业部、确保人才梯队支持业务持续发展。所需完成的关键跨越：</p>
<ol>
<li>模糊决策</li>
<li>经营意识</li>
<li>构建人才梯队</li>
</ol>
<h3 id="197-整个职业发展过程中也起着决定性作用的另外几个底层能力"><a class="markdownIt-Anchor" href="#197-整个职业发展过程中也起着决定性作用的另外几个底层能力"></a> 19.7 整个职业发展过程中也起着决定性作用的另外几个底层能力</h3>
<p>还有几个底层能力，在整个职业发展过程中也起着决定性作用。这些能力包括：</p>
<ol>
<li>清晰的自我认知能力</li>
<li>持续学习能力</li>
<li>弹性和韧性</li>
</ol>
<h3 id="198-发展关键跨越上的能力"><a class="markdownIt-Anchor" href="#198-发展关键跨越上的能力"></a> 19.8 发展关键跨越上的能力</h3>
<p>发展关键跨越上的能力需要做到：</p>
<ol>
<li>充分了解这些能力的完整行为链条</li>
<li>保持刻意练习</li>
<li>做好打持久战的准备</li>
</ol>
<h2 id="20-一生的修炼更好的自己"><a class="markdownIt-Anchor" href="#20-一生的修炼更好的自己"></a> 20. 一生的修炼，更好的自己</h2>
<p>如同电影《和平战士》中，心灵导师苏格拉底对主人公丹·米尔曼所说：“没有开始或者终止，只有过程。”人生是一场修炼，修的是心性，炼的是技能，没有终点，出生即开始，永远都在进程中。我们陪伴了很多管理者走过“至暗时刻”，别着急，每个人都会经历，没有谁比谁更高明，只要坚持就会成功。在坚持的路上，除了职场的收获，你还会获得很多可迁移的技能。正如在游泳池中学会了游泳，在大海中也能施展一样。管理者练就的管理技能、打磨的心性，都可以在更多人生的场景找到应用机会。所以可以说，一旦成为管理者，就进入了这场修行的经验加速区：管理技能要求的倾听、沟通、共情，用在处理家庭矛盾、开展子女教育中，也效果明显；管理角色要求的时间管理、任务分配、绩效辅导、培养员工等技能，在自我管理、家庭决策、子女教育中，同样增益匪浅。成为管理者，能加速人生的修炼，乃至成就更好的自己。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2024/01/10/[WIP]Nerf/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/10/%5BWIP%5DNerf/" class="post-title-link" itemprop="url">Nerf</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-01-10 09:10:21" itemprop="dateCreated datePublished" datetime="2024-01-10T09:10:21+08:00">2024-01-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Nerf/" itemprop="url" rel="index"><span itemprop="name">Nerf</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2024/01/10/%5BWIP%5DNerf/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2024/01/10/%5BWIP%5DNerf/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="1-三维重建流程"><a class="markdownIt-Anchor" href="#1-三维重建流程"></a> 1. 三维重建流程</h1>
<h2 id="11-运动恢复结构structure-from-motion-sfm"><a class="markdownIt-Anchor" href="#11-运动恢复结构structure-from-motion-sfm"></a> 1.1 运动恢复结构（Structure from Motion, SfM）</h2>
<ul>
<li>输入：
<ul>
<li>多视角图像</li>
<li>相机内参</li>
</ul>
</li>
<li>输出：
<ul>
<li>稀疏三维点云</li>
<li>相机外参（位姿）</li>
</ul>
</li>
<li>主要过程：
<ul>
<li>特征提取： 从图像中提取出能够用于匹配的特征点，如角点、边缘等。</li>
<li>特征匹配： 在图像序列中匹配相对应的特征点，以建立图像之间的对应关系。</li>
<li>相机定位： 利用特征匹配信息，估计相机在不同图像之间的运动，即相机的位姿。</li>
<li>三维重建： 基于相机的位姿估计和特征点的视差信息，计算出场景中物体的三维坐标。</li>
</ul>
</li>
</ul>
<h2 id="12-多立体视觉multi-view-stereo-mvs"><a class="markdownIt-Anchor" href="#12-多立体视觉multi-view-stereo-mvs"></a> 1.2 多立体视觉（Multi-View Stereo, MVS）</h2>
<ul>
<li>输入：
<ul>
<li>多视角图像</li>
<li>相机内外参</li>
<li>稀疏三维点云</li>
</ul>
</li>
<li>输出：
<ul>
<li>稠密三维点云</li>
</ul>
</li>
<li>主要过程：
<ul>
<li>图像对齐： 通过相机定位和特征匹配，将多个图像对齐，确保它们在同一坐标系下。</li>
<li>深度图生成： 对每个像素估计其在场景中的深度或距离。这可以通过多个视角的图像之间的视差信息来实现，视差越大表示物体离</li>
<li>机越近。</li>
<li>点云重建： 利用深度图，将每个像素映射到三维空间中，形成一个点云表示物体的表面。</li>
</ul>
</li>
</ul>
<h2 id="13-表面重建"><a class="markdownIt-Anchor" href="#13-表面重建"></a> 1.3 表面重建</h2>
<ul>
<li>输入：稠密三维点云</li>
<li>输出：场景/模型的三角网格（三角面片）</li>
<li>主要过程：
<ul>
<li>网格生成： 将点云转换为更为紧凑和结构化的表示，通常是三角网格。</li>
</ul>
</li>
<li>表面模型通常可导入可视化软件，也可进行物理仿真</li>
</ul>
<h2 id="14-纹理重建"><a class="markdownIt-Anchor" href="#14-纹理重建"></a> 1.4 纹理重建</h2>
<ul>
<li>输入：
<ul>
<li>多视角图像</li>
<li>相机内外参</li>
</ul>
</li>
<li>输出：
<ul>
<li>场景/模型的纹理图像</li>
</ul>
</li>
<li>主要过程：
<ul>
<li>纹理映射（Texture Mapping）： 将从图像中捕捉到的纹理信息映射到三维模型的表面上。这可以通过将图像中的颜色信息映射相应的三维模型表面上的顶点或像素来实现。这样，模型就能够呈现出与真实世界相似的外观。</li>
<li>相邻像素插值： 由于模型表面上的顶点或像素数量有限，需要进行插值操作，以在整个表面上创建平滑和连续的纹理。这通常涉及对相邻像素之间的颜色进行插值，以便在纹理映射的过程中产生平滑的过渡效果。</li>
<li>去除失真和伸缩： 在将图像纹理映射到三维模型时，可能会发生一些失真和伸缩。为了保持模型的准确性和真实性，需要进行一些校正步骤，以修复这些失真。</li>
</ul>
</li>
<li>纹理重建后即可可视化</li>
</ul>
<h1 id="2-神经辐射场neural-radiance-fields-nerf"><a class="markdownIt-Anchor" href="#2-神经辐射场neural-radiance-fields-nerf"></a> 2. 神经辐射场（Neural Radiance Fields, NeRF）</h1>
<ul>
<li>将三维重建流程存储在 <strong>三角面片和纹理信息</strong> 的三维信息用神经网络拟合（隐式建模）。</li>
<li>缺点是无法进行物理仿真。</li>
<li>优点：
<ul>
<li>ppl 简单</li>
<li>无空洞</li>
<li>高逼真</li>
</ul>
</li>
</ul>
<h1 id="wip"><a class="markdownIt-Anchor" href="#wip"></a> WIP</h1>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/09/07/A-Keypoint-based-Global-Association-Network-for-Lane-Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/07/A-Keypoint-based-Global-Association-Network-for-Lane-Detection/" class="post-title-link" itemprop="url">A Keypoint-based Global Association Network for Lane Detection</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-09-07 16:20:10" itemprop="dateCreated datePublished" datetime="2023-09-07T16:20:10+08:00">2023-09-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Autopilot/" itemprop="url" rel="index"><span itemprop="name">Autopilot</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/09/07/A-Keypoint-based-Global-Association-Network-for-Lane-Detection/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/09/07/A-Keypoint-based-Global-Association-Network-for-Lane-Detection/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2204.07335.pdf">https://arxiv.org/pdf/2204.07335.pdf</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/Wolfwjs/GANet">https://github.com/Wolfwjs/GANet</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>传统基于关键点检测的车道线检测网络通常需要根据任务的定义设计模型输出头结构，比如 <code>UFLD</code> 算法每条车道线需要占据一个输出 <code>channel</code> 。</li>
<li>本论文提出一种新颖的车道线检测范式，解耦了任务和网络，仅使用固定的输出通道数即可检测任意多条车道线。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<h3 id="总体思路"><a class="markdownIt-Anchor" href="#总体思路"></a> 总体思路</h3>
<p><img src="https://s2.loli.net/2023/09/07/rTU59Ca6tMz24QD.png" alt="ganet2.png" /></p>
<ul>
<li>如何实现只用一个 <code>channel</code> 输出即可检测任意多条车道线？一个可以想到的简单方法是：
<ol>
<li>输出一个 <code>channel = 1</code> 的 <code>heat map</code>，其中每个位置的 <code>heat map value</code> 依旧表示该位置是车道线关键点的概率。</li>
<li>使用阈值过滤得到所有车道线的关键点坐标（每条车道线关键点数量应 &gt;= 2）。</li>
<li>使用聚类的方式将一堆关键点分成若干组，每组关键点表示一条车道线。聚类中的 “距离” 判定逻辑需要根据一些先验知识进行设计（比如：因为车道线在图片中更接近竖直方向，因此水平距离权重小于垂直距离）。</li>
</ol>
</li>
<li>上述操作中的聚类过程包含了很多人为总结的先验知识，非常不 “机器学习”，于是我们可以改进这个过程：
<ol>
<li>输出一个 <code>channel = 1</code> 的 <code>heat map</code> 和一个 <code>channel = 2</code> 的 <code>offset map</code>，其中每个位置的 <code>heat map value</code> 依旧表示该位置是车道线关键点的概率，每个位置的 <code>offset map value</code> 表示 <strong>如果该点是关键点，那么该点相对于本条车道线起始点的偏移（x, y）</strong>，起始点表示一条车道线关键点中最靠近图片下方的点。</li>
<li>使用阈值过滤得到所有关键点，将关键点对应位置的偏移 <code>offset</code> 得到新的点 <code>p'</code>，理论上同一条车道线的每一个关键点偏移后得到的新位置 <code>p'</code> 都一致，都是车道线起始点。</li>
<li>因为神经网络不太能拟合到 <code>loss == 0</code>，因此还需要对所有的 <code>p'</code> 进行聚类，每个类表示一条车道线实例，本质相当于将聚类中的距离判定逻辑吸到神经网络内部。</li>
</ol>
</li>
<li>以上就是本论文提出的 <code>GANet</code> 算法的核心思想：用固定的有限个输出通道去预测任意条车道线。</li>
</ul>
<h3 id="网络结构"><a class="markdownIt-Anchor" href="#网络结构"></a> 网络结构</h3>
<p><img src="https://s2.loli.net/2023/09/07/nfbWKHOtFgjp6oz.png" alt="ganet1.png" /></p>
<h3 id="lfalane-aware-feature-aggregator"><a class="markdownIt-Anchor" href="#lfalane-aware-feature-aggregator"></a> LFA（Lane-aware Feature Aggregator）</h3>
<p><img src="https://s2.loli.net/2023/09/07/nk9NbMJztSWQRrq.png" alt="ganet3.png" /></p>
<h4 id="动机"><a class="markdownIt-Anchor" href="#动机"></a> 动机</h4>
<ul>
<li>传统的2D卷积在固定的网格状区域内采样特征，这不适用于处理车道线的狭长形状。</li>
<li>因此作者使用如下步骤改进各关键点上的局部特征：
<ol>
<li>预测该关键点同一条车道线紧邻的 <code>num_adjacent_keypoints</code> 个点的 <code>offset</code>，进行显式监督。</li>
<li>用预测的 <code>offset</code> 引导可变形卷积改进关键点局部特征。</li>
</ol>
</li>
</ul>
<h4 id="代码实现"><a class="markdownIt-Anchor" href="#代码实现"></a> 代码实现</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.ops <span class="keyword">import</span> deform_conv2d</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LFA</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, num_adjacent_keypoints=<span class="number">5</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LFA, self).__init__()</span><br><span class="line">        self.offset_conv = nn.Conv2d(in_channels, <span class="number">2</span> * num_adjacent_keypoints, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.deform_conv_weight = nn.Parameter(torch.Tensor(out_channels, in_channels, <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">        nn.init.kaiming_uniform_(self.deform_conv_weight, a=math.sqrt(<span class="number">5</span>))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># x: input feature map with shape [batch_size, in_channels, height, width]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 1: Predict the offsets for adjacent keypoints</span></span><br><span class="line">        offsets = self.offset_conv(x)  <span class="comment"># shape: [batch_size, 2 * num_adjacent_keypoints, height, width]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2: Perform deformable convolution to aggregate features</span></span><br><span class="line">        aggregated_features = deform_conv2d(x, offsets, self.deform_conv_weight, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> aggregated_features, offsets  <span class="comment"># Return both aggregated features and offsets</span></span><br><span class="line"><span class="comment"># Initialize LFA module</span></span><br><span class="line">lfa = LFA(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>, num_adjacent_keypoints=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># Dummy input feature map with shape [batch_size, in_channels, height, width]</span></span><br><span class="line">input_feature_map = torch.randn(<span class="number">16</span>, <span class="number">64</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"><span class="comment"># Forward pass</span></span><br><span class="line">aggregated_features, predicted_offsets = lfa(input_feature_map)</span><br><span class="line"><span class="comment"># aggregated_features 是特征输出</span></span><br><span class="line"><span class="comment"># predicted_offsets 是预测的相邻的 num_adjacent_keypoints 个车道线的偏移量，显式监督</span></span><br></pre></td></tr></table></figure>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>提出了一种灵活的车道线检测范式，具有较好的可拓展性，目前在车道线榜单上比较靠前。</li>
<li>另外一个创新点是<code>LFA module</code>，主要是用到了可形变卷积，对于大多数动态性较差的端侧芯片来说，不容易部署。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://real-zhangzhe.github.io/2023/08/16/BEVFormer-Learning-Bird%E2%80%99s-Eye-View-Representation-from-Multi-Camera-Images-via-Spatiotemporal-Transformers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhangzhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhangzhe's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/08/16/BEVFormer-Learning-Bird%E2%80%99s-Eye-View-Representation-from-Multi-Camera-Images-via-Spatiotemporal-Transformers/" class="post-title-link" itemprop="url">BEVFormer: Learning Bird’s-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-08-16 12:02:58" itemprop="dateCreated datePublished" datetime="2023-08-16T12:02:58+08:00">2023-08-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-23 13:32:17" itemprop="dateModified" datetime="2025-10-23T13:32:17+08:00">2025-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BEV/" itemprop="url" rel="index"><span itemprop="name">BEV</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2023/08/16/BEVFormer-Learning-Bird%E2%80%99s-Eye-View-Representation-from-Multi-Camera-Images-via-Spatiotemporal-Transformers/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/08/16/BEVFormer-Learning-Bird%E2%80%99s-Eye-View-Representation-from-Multi-Camera-Images-via-Spatiotemporal-Transformers/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="url"><a class="markdownIt-Anchor" href="#url"></a> URL</h2>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2203.17270.pdf">https://arxiv.org/pdf/2203.17270.pdf</a></li>
<li>chinese paper: <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1dKnD6gUHhBXZ8gT733cIU_A7dHEEzNTP/view?pli=1">https://drive.google.com/file/d/1dKnD6gUHhBXZ8gT733cIU_A7dHEEzNTP/view?pli=1</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/fundamentalvision/BEVFormer">https://github.com/fundamentalvision/BEVFormer</a></li>
</ul>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ul>
<li>传统 <code>BEV</code> 算法中 <code>View Transform</code> 都是通过 <code>LSS</code> 实现 <code>Image View</code> 到 <code>BEV View</code> 的转变，这种视角转换方法依赖于图像视角的深度估计（显式（例如 <code>BEVDepth</code>）或隐式（例如 <code>LSS / BEVDet</code> 等））。</li>
<li>本文提出一种新的通过时空注意力机制实现的 <code>View Transform</code> 方法，在 <code>Neuscenes</code> 数据集上取得了不错的 <code>3D</code> 目标检测成绩（略差于 <code>BEVDet4D</code>）。</li>
</ul>
<h2 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h2>
<p><img src="https://s2.loli.net/2024/10/09/wkgV4SOFjJtncAX.png" alt="bevformer.png" /></p>
<h3 id="整体架构"><a class="markdownIt-Anchor" href="#整体架构"></a> 整体架构</h3>
<h4 id="1-输入"><a class="markdownIt-Anchor" href="#1-输入"></a> 1. 输入</h4>
<ul>
<li>输入包含两部分，分别是：
<ul>
<li>环视图（<code>6</code> 张）</li>
<li><code>BEV Queries</code>（<code>shape = [num_voxel, dim]</code>）</li>
<li><code>History BEV Feature</code>（上一帧的 <code>BEV Feature</code> 输出，<code>shape = [num_voxel, dim]</code>）</li>
</ul>
</li>
</ul>
<h4 id="2-输出"><a class="markdownIt-Anchor" href="#2-输出"></a> 2. 输出</h4>
<ul>
<li>输出为当前帧的 <code>BEV Feature</code>（<code>shape = [num_voxel, dim]</code>），记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">B_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li>暂时不考虑任务头</li>
</ul>
<h4 id="3-网络模块"><a class="markdownIt-Anchor" href="#3-网络模块"></a> 3. 网络模块</h4>
<ol>
<li>图像特征提取
<ul>
<li><code>6</code> 张图片单独做 <code>CNN base</code> 特征提取，输出记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">F_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
<li>时序信息融合：
<ul>
<li>将构造的 <code>BEV Queries</code>（记作 <code>Q</code>），和上一帧的 <code>BEV Feature</code>（记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">B_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>）做 <code>Self-Attention</code></li>
<li>其中 <code>Q</code> 作为 <code>Query</code>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">B_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 作为 <code>Key / value</code>，做 <code>Attention</code> 运算</li>
<li>虽然这里的 <code>Query / Key / Value</code> 并不同源，但依然被称为是 <code>Self-Attention</code> 而不是 <code>Cross-Attention</code>，是因为 <code>Q</code> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">B_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 都属于 <code>BEV</code> 语义</li>
<li>输出记作 <code>Q'</code></li>
</ul>
</li>
<li>空间交叉注意力（<strong>视角转换</strong>）
<ul>
<li>此步骤是本文的重点，<code>BEVFormer</code> 通过这一步将透视图特征转换为俯视图特征</li>
<li>输入为:
<ul>
<li><code>Q'</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">F_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
<li>做 <code>Cross-Attention</code> 运算，其中：
<ul>
<li><code>Q'</code> 作为 <code>Queries</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">F_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 作为 <code>Key / Value</code></li>
</ul>
</li>
<li>用预设的无意义且可学习的 <code>BEV Queries</code> 去查询图片总体特征，得到 <code>BEV Feature</code> 输出，记作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">B_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
<li>任务相关头
<ul>
<li>输入为：<code>BEV Feature</code></li>
<li>输出为：<code>BEV</code> 视角下的检测 / 分割等任务预测结果</li>
<li>模型结构：可以是 <code>CNN base</code> 也可以是 <code>Transformer base</code> 的</li>
</ul>
</li>
</ol>
<ul>
<li>以上提到的所有 <code>Attention</code> 过程都需要额外添加 <code>Position embedding</code></li>
</ul>
<h2 id="thought"><a class="markdownIt-Anchor" href="#thought"></a> Thought</h2>
<ul>
<li>过程并不复杂，只要看过经典的 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2005.12872"><code>DETR</code></a>，都熟悉这种套路：<strong>预设一个无意义的（随机初始化但可学习） <code>pattern</code> 序列作为 <code>Query</code> 去查询 <code>image features</code>，得到有意义的结果（或者说是可监督的结果）</strong></li>
<li>后续的部分工作对其改进是：<strong>将随机初始化预设的 <code>Query</code> 有意义化（例如通过一个轻量化 <code>2D</code> 检测头预检测，得到 <code>proposal</code> 并编码为 <code>Query</code>）</strong></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/8/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/10/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhangzhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">172</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">52</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">106</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhangzhe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js', () => {
    // 初始化 Mermaid 配置
    mermaid.initialize({
      theme    : 'dark',  // 设置主题
      logLevel : 3,  // 设置日志等级
      flowchart: { curve: 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 },
      themeVariables: {
        'fontFamily': 'Microsoft YaHei, Arial, sans-serif',  // 设置中文字体
      }
    });

    // 初始化 Mermaid 图表
    mermaid.init(undefined, document.querySelectorAll('pre.mermaid'));
  }, window.mermaid);
}
</script>


  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'eK3W25jybCO5jVUrYBBpAPqM-gzGzoHsz',
      appKey     : 'F4KVyUj9wHI5c80Bhz7O2uhq',
      placeholder: "说点什么再走吧...",
      avatar     : 'hide',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
